
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The paper presents CudaSIFT-SLAM, a V-SLAM system that robustly maps in real-time and locates camera poses in human colonoscopies, overcoming limitations of ORB-SLAM3 by using SIFT features and brute-force matching, and achieving 88% mapping coverage in the C3VD dataset and a 70% improvement over ORB-SLAM3 in a real colonoscopy.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel RGB-only Simultaneous Localization and Mapping (SLAM) system utilizing a dense 3D Gaussian map representation that dynamically adapts to keyframe pose and depth updates, achieving superior tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth strategy to efficiently cover unknown environments and provide accurate mapping and tracking performance.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method, ETA, that enhances translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM by using a 3-DoF Bundle Adjustment and updating rotation estimation with IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper proposes Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos by combining human-aware metric SLAM and scene-aware SMPL denoising, addressing depth, scale, and dynamic ambiguities and providing a common world frame for consistent reconstructions.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The key contributions of the paper include the creation of a real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, distinct spatial viewpoints, and complementary sensor modalities, which leverages the untapped potential of multi-robot collaborative perception to enhance overall perception despite challenges like sensor noise, occlusions, and sensor failures.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The paper's abstract and introduction discuss the key contributions regarding minimizing human effort in deploying perception-based robotic systems in previously unseen environments. Here are the key contributions in a single sentence under 50 words:The authors explored continual learning and reducing human annotations for efficient perception and mapping in robotics, enabling robots to adapt to new environments while retaining high performance on previous domains using methods such as continual SLAM, label-efficient segmentation, and collaborative mapping.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, achieving high-fidelity reconstruction, drift-corrected tracking, and a high-level understanding of the environment, using 3D Gaussian representations and CLIP features.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry (LIO) framework for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, addressing challenges in point cloud registration due to rapid changes in LiDAR scans and repetitive structural features.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work out of the box in diverse scenarios, consisting of ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to reject featureless points, handle moving objects, and overcome catastrophic failure.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel Lightweight Circular Convolutional Transformer network, CCTNet, that addresses issues of "restricted receptive fields" and "excessive focus on local regions" in range image-based place recognition, achieving superior performance in real-world scenarios with movable objects.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The key contributions of the paper are an optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry data, and a new formulation of the Occupancy-SLAM problem that optimizes robot poses and occupancy values together, allowing for more accurate map estimation.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the abstract and introduction in under 50 words:The paper presents IPC, a consensus-based approach for Pose Graph Optimization, which incrementally builds a maximally consistent set of loop closure measurements, robustly handling outliers and providing online performance, with a focus on scalable and reliable SLAM solutions.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The proposed OverlapMamba method represents input range views as sequences and employs a stochastic reconstruction approach to build shift state space models, outperforming typical LiDAR and multi-view combination methods in time complexity and speed for robust place recognition capabilities and real-time efficiency.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes SceneFactory, a workflow-centric framework that supports various scene modeling applications, including depth estimation, 3D reconstruction, and SLAM, with contributions including a unified framework, depth estimation block, and surface light field representation.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|The paper proposes a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU without GPU support, using a mask prediction mechanism to parallelize deep learning and camera tracking, and a dual-stage optical flow tracking approach to enhance efficiency and robustness.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a system that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, which can run on a portable device like an iPhone 14 Pro.* The system enables interactive and immersive holographic experiences for a wide range of applications, including augmented reality, telepresence, and entertainment.* The paper highlights the limitations of existing methods for real-time 3D reconstruction, which often require highly calibrated scenes, incur steep computation costs, or fail to render dynamic scenes.* The paper proposes three high-fidelity reconstruction tools that can run on a portable device, including monocular depth estimation, LiDAR + TrueDepth fusion, and template modeling.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The key contributions of this paper are: a novel approach called Truncated Depth NeRF (TD-NeRF) that enables training Neural Radiance Fields from unknown camera poses, a novel depth-based ray sampling strategy, a coarse-to-fine training strategy, and a robust inter-frame point constraint that uses Gaussian kernel function to measure distances between inter-frame point clouds, improving the accuracy of pose estimation and the quality of view synthesis.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|The key contributions of the paper include: introducing the first SLAM system that combines sparse visual odometry with 3D Gaussian Splatting, developing a pre-trained Multi-View Stereo depth estimation network, proposing a geometric depth smooth loss, and developing a Sparse-Dense Adjustment Ring to ensure scale consistency.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|The authors propose a novel framework, NeuRSS, for sidescan sonar (SSS) simultaneous localization and mapping (SLAM) that leverages neural rendering to estimate bathymetry and improves positioning accuracy by iteratively refining the bathymetry and pose estimation estimates.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a single sentence summarizing the paper's abstract and introduction under 50 words:NGM-SLAM proposes a novel 3D Gaussian Splatting-based SLAM system that uses neural radiance field submaps for progressive scene representation and integrates strengths of both methods to achieve high-fidelity mapping, accurate loop closure detection, and state-of-the-art performance on large-scale scenes.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) in autonomous robotics, analyzing its applications in perception, localization and navigation, and decision-making modules, and exploring future research directions.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper highlights the importance of place recognition (PR) in achieving real-world autonomy in robotics, reviewing current state-of-the-art advancements and challenges in PR, and showcasing its broad applications in robotics, with a focus on integrating advanced AI technologies and providing a comprehensive review of PR's formulation, key research challenges, and open-source solutions.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|The paper proposes a neural mapping framework that anchors lightweight neural fields to a pose graph, enabling efficient incorporation of large-scale loop closures and scalable mapping, outperforming existing state-of-the-art approaches in terms of quality and runtime.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a versatile hybrid visual SLAM system that combines deep feature extraction and deep matching methods to improve tracking robustness and adaptability in challenging environments, outperforming state-of-the-art algorithms.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents X-SLAM, a real-time and differentiable dense SLAM system that employs the complex-step finite difference method to calculate numerical derivatives, enabling task-oriented optimization and higher-order differentiation for improved accuracy and faster convergence in camera relocalization and active robotic scanning tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM is a robust visual SLAM system that handles unknown moving objects in dynamic environments using panoptic segmentation, achieving high accuracy and robustness, outperforming state-of-the-art methods in several scenarios, including real-world robotics experiments.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:Key contributions:* Modeling the exchange of information between different mobile terminals (MTs), enabling cooperative localization and data fusion of map features (virtual anchors) across different MTs.* Integrating inertial measurement units (IMUs) as additional sensors for each MT, unlocking additional information for orientation and state transition estimation, and enabling the handling of complex trajectories.* Analyzing the impact of VA data fusion and cooperative measurements in multipath-based simultaneous localization and mapping (MP-SLAM) for multiple-input multiple-output (MIMO) and single-input multiple-output (SIMO) systems using numerical simulation.* Developing a Bayesian particle-based sum-product algorithm for cooperative MP-SLAM that enables data fusion over different observations of map features (VAs) by different MTs.Note that the paper introduces a novel approach to cooperative MP-SLAM that combines data fusion and VA detection using a Bayesian particle-based algorithm, and presents simulations demonstrating the effectiveness of this approach in various scenarios.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system using Gaussian splatting, featuring a compact Gaussian representation and on-the-fly Gaussian optimization, achieving comparable reconstruction quality at twice the speed and half the memory cost of state-of-the-art NeRF-based SLAM methods.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
