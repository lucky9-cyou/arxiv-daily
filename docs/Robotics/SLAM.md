
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Manhattan Gaussian SLAM (MG-SLAM), a novel RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness in Gaussian SLAM, achieving state-of-the-art performance with improved tracking and mapping capabilities.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel approach to detect and classify ten different reflector landmarks with varying radii using in-air 3D sonar. The approach uses a convolutional neural network (CNN) to predict the orientation angle of the detected landmarks. The network is trained on cochleograms, which represent echoes received by the sensor in a time-frequency domain. The paper's main contributions are:* A CNN-based approach for detecting and classifying reflector landmarks with varying radii using in-air 3D sonar.* A novel representation of echoes using cochleograms, which enables the network to learn features from the time-frequency domain.* Experimental results showing promising performance, with a classification accuracy of 97.3% and a prediction error of less than 10 degrees for the orientation angle.The paper's introduction highlights the challenges of traditional sensing modalities in harsh environmental conditions and the potential of in-air sonar as a resilient alternative. It also discusses the importance of semantic understanding of the environment for autonomous mobile systems, such as Simultaneous Localization and Mapping (SLAM) and autonomous navigation.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a single sentence summarizing the key contributions of the paper: The paper proposes a batch simultaneous localization and mapping (SLAM) approach for joint calibration of multiple asynchronous microphone arrays and sound source localization, achieving higher accuracy and faster convergence in calibration.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|The paper introduces a cutting-edge 3DGS-based SLAM system that overcomes the limitations of traditional methods by leveraging the Fusion Bridge module, which seamlessly integrates tracking-centered ORB Visual Odometry with online 3DGS, and achieves state-of-the-art rendering quality and localization accuracy.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a real-time V-SLAM system that overcomes tracking losses in human colonoscopies by using SIFT features and brute-force matching, achieving 100% precision and 53% mapping coverage in real colonoscopy sequences.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Splat-SLAM, a first-of-its-kind RGB-only SLAM system that implements globally optimized tracking and dynamic map deformation using 3D Gaussians, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive performance in unfamiliar environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a novel method for enhancing translation accuracy during the initialization stage of Stereo Visual-Inertial Slam (VI-SLAM) systems.* The method uses a 3-DoF Bundle Adjustment (BA) to refine the translation estimate, while keeping the rotation estimate fixed, unlike ORB-SLAM3's 6-DoF BA.* The method also updates the rotation estimate by considering IMU measurements and gyroscope bias, unlike ORB-SLAM3's rotation estimate, which is directly obtained from stereo visual odometry.* The paper demonstrates the effectiveness of the proposed method through extensive evaluations on the public EuRoC dataset, achieving improved accuracy compared to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs 3D human and camera motion in a consistent global coordinate system from monocular videos, leveraging human-aware SLAM to estimate metric-scale camera poses and scene point clouds, and then using scene-aware SMPL denoiser to enhance world-frame HMR.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper presents a pioneering real-world multi-robot collaborative perception dataset featuring distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities, allowing researchers to study multi-modal collaborative perception using real-world data.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The author's research investigates minimizing human effort in deploying perception-based robotic systems to new environments by leveraging continual learning and reducing human annotations, focusing on label-efficient panoptic segmentation and efficient robot learning for various tasks, such as SLAM, depth estimation, and collaborative mapping.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves high-fidelity reconstruction, drift-corrected tracking, and a high-level understanding of the environment without requiring depth sensors or RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, which extracts normal vectors from LiDAR scans and utilizes them for enhanced point cloud registration, addressing challenges in confined indoor settings.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes novel approaches to overcome the limitations of deep learning-based perception technologies and SLAM methods, including ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to achieve a robust long-term robotic mapping system.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve high-fidelity scene representation, accurate tracking, and efficient rendering with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summarized key contribution in a single sentence under 50 words:The paper proposes a Lightweight Circular Convolutional Transformer network (CCTNet) that addresses issues of "restricted receptive fields" and "excessive focus on local regions" in current range image-based networks, achieving superior performance in place recognition tasks especially in scenarios with movable objects.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The key contributions of the paper are: proposing an optimization-based SLAM approach that simultaneously optimizes the robot trajectory and occupancy map using 2D laser scans and odometry, and developing a variation of Gauss-Newton method to solve the formulated problem.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the abstract and introduction in a single sentence under 50 words:The paper presents IPC, a consensus-based method for Pose Graph Optimization that incrementally builds a maximally consistent set of loop closure measurements, capable of handling large numbers of outliers while providing online performances, and evaluates its performance on standard benchmarks.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes OverlapMamba, a novel place recognition method that uses raw range views as input and a stochastic reconstruction approach to build shift state space models, achieving robust loop closure detection and global localization with real-time efficiency and outperforming typical LiDAR and multi-view combination methods.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is the key contribution of the paper's abstract and introduction summarized in a single sentence under 50 words:The paper presents SceneFactory, a workflow-centric framework for incremental scene modeling that supports various applications, including multi-view depth estimation, LiDAR completion, and RGB-D/RGB-L/Mono reconstruction, with a focus on independent modular design and high flexibility.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|The paper proposes a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU without GPU support by incorporating a mask prediction mechanism and a dual-stage optical flow tracking approach, thereby enhancing efficiency and robustness while maintaining high localization accuracy in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel application for creating real-time holographic overlays using LiDAR augmented 3D reconstruction, enabling interactive and immersive holographic experiences on portable devices like the iPhone 14 Pro, and proposes three high-fidelity reconstruction tools that can run on such devices.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, featuring a truncated depth-based ray sampling strategy, coarse-to-fine training, and a robust inter-frame point constraint for accurate pose estimation and depth geometry.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MGS-SLAM, a novel monocular Gaussian Splatting-based SLAM system that integrates sparse visual odometry with 3D Gaussian Splatting to reconstruct a dense map from RGB images, addressing limitations of existing methods and achieving state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeuRSS, a scalable framework for sidescan sonar (SSS) simultaneous localization and mapping (SLAM) that uses neural rendering to estimate bathymetry, alleviating the elevation degeneracy issue and improving positioning and bathymetric mapping accuracy.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NGM-SLAM, a novel dense SLAM system that combines neural radiance field submaps with 3D Gaussian Splatting to achieve high-fidelity mapping, progressive scene expression, and accurate hole filling for monocular, stereo, and RGB-D inputs.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) for enhancing autonomous robots' perception, localization, and decision-making capabilities, benchmarking existing methods, and exploring future research avenues, including integrating NeRF with advanced techniques like 3D Gaussian splatting and large language models.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper aims to bridge the gap in place recognition (PR) technology for real-world robotic systems, highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and providing a comprehensive review of current state-of-the-art advancements and remaining challenges.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a neural mapping framework that combines sparse visual SLAM with neural fields, allowing for large-scale map deformations while limiting necessary reintegration, and demonstrates its scalability and quality by successful building-scale mapping with multiple loop closures.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|The paper introduces a versatile hybrid visual SLAM system, dubbed SL-SLAM, that combines deep feature extraction and deep matching methods to improve adaptability in challenging environments, achieving superior performance over traditional approaches in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
