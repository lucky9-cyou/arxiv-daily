
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, the first V-SLAM system able to process complete human colonoscopies in real-time, by using SIFT features and brute-force matching, achieving better mapping coverage and longer sub-maps compared to ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose the first RGB-only SLAM system with a dense 3D Gaussian map representation, leveraging global tracking and online deformations, and achieve superior tracking, mapping, and rendering accuracy with smaller map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to efficiently represent and track complex scenes.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A new method for enhancing translation accuracy during the initialization stage of Visual-Inertial SLAM (VI-SLAM) systems, which is based on a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) conducted independently, while keeping the rotation estimate fixed.* A method that updates the rotation estimate by considering IMU measurements and gyroscope bias, unlike previous methods that derive the rotation directly from stereo visual odometry.* A method that achieves performance comparable to Stereo-NEC while maintaining a runtime similar to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos in a common global coordinate system, leveraging human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents the first real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration with heterogeneous sensor modalities, spatial viewpoints, and coverage ranges, and provides annotations for pose estimation and high-level perception tasks.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:Contributions:1. The author presents a framework for minimizing human effort in deploying robotic systems to previously unseen environments, focusing on leveraging continual learning and reducing human annotations for efficient learning.2. The research explores the use of visual foundation models for extremely label-efficient training in panoptic segmentation.3. Continual Learning for Robotics is proposed, allowing an autonomous agent to adapt to unseen domains while retaining high performance on previous domains.4. Label-Efficient Panoptic Segmentation is developed, enabling training of segmentation networks with almost zero labels.5. LiDAR-Based Mapping is introduced, fusing complementary information from cameras and LiDAR sensors and proposing automatic target-less camera-LiDAR calibration.6. Collaborative Robot Mapping is explored, enabling multi-agent collaboration for efficient robot learning.Overall, the research aims to develop more efficient and adaptable robotic systems that can learn from limited data and adapt to new environments with minimal human intervention.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system that uses 3D Gaussian representation and a CLIP feature-based loop closure module to achieve drift-corrected tracking, high-fidelity reconstruction, and high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper's key contributions are: proposing a normal vector-based tightly-coupled LIO framework, NV-LIO, for robust SLAM in indoor environments with multiple floors, and developing novel methods for addressing degeneracy situations and preventing wrong correspondences in loop closure.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to address challenges in modeling, data points, and dynamic real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity mapping and tracking with reduced memory usage and state-of-the-art performance on RGB-D datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a lightweight circular convolutional Transformer network, CCTNet, which enhances place recognition by capturing structural information in point clouds and facilitating cross-dimensional interaction, achieving superior performance in various datasets, including the KITTI and Ford Campus datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a novel optimization-based SLAM approach that simultaneously optimizes the robot trajectory and occupancy map using 2D laser scans and odometry, offering improved accuracy and uncertainty estimation compared to existing methods, particularly when a relatively accurate initial guess is provided.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|The paper presents IPC (Incremental Probabilistic Consensus), a method that approximates the solution to the combinatorial problem of finding the maximally consistent set of loop closure measurements in an incremental fashion, allowing for robust handling of large numbers of outliers while providing online performance.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes OverlapMamba, a novel deep learning-based LiDAR-based place recognition method that represents input range views as sequences, employing a stochastic reconstruction approach to build shift state space models and achieve robust place recognition with real-time efficiency.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present SceneFactory, a workflow-centric framework that supports various incremental scene modeling applications, and contribute four key components: a unified depth estimation block, dual-purpose multi-resolution neural points, and improved point rasterization, which together demonstrate high flexibility and quality competitiveness with state-of-the-art approaches.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU without GPU support by incorporating a mask prediction mechanism and a dual-stage optical flow tracking approach, enhancing efficiency and robustness in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel application that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, introducing three high-fidelity reconstruction tools that can run on portable devices like the iPhone 14 Pro, enabling interactive and immersive holographic experiences.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and NeRF radiance fields using depth priors, introducing three key advancements: truncated depth-based ray sampling, coarse-to-fine training, and inter-frame point constraints for enhanced pose estimation accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|The key contributions of the paper are: introducing the first SLAM system combining sparse visual odometry with 3D Gaussian Splatting, developing a pre-trained MVS depth estimation network, proposing a depth smooth loss, and introducing a Sparse-Dense Adjustment Ring (SDAR) to ensure scale consistency.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose a novel framework, NeuRSS, that combines sidescan sonar (SSS) SLAM and neural rendering to estimate bathymetry and improve autonomous underwater vehicle (AUV) positioning, addressing elevation degeneracy and providing a scalable and efficient solution for large-scale surveys.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NGM-SLAM, a progressive dense Gaussian splatting SLAM system that utilizes neural radiance field submaps for scene expression and loop closure detection, achieving high-quality scene reconstruction, accuracy, and real-time performance in large-scale scenes.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) in autonomous robotics, exploring its applications in perception, localization, navigation, and decision-making, as well as benchmarking its performance and discussing future avenues for integration with advanced technologies.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper presents a comprehensive review of place recognition (PR) techniques, highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and provides a roadmap for future advancements while introducing an open-source PR package and benchmark for the robotics community.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a neural mapping framework that anchors lightweight neural fields to a sparse pose graph, enabling large-scale scene representation with efficient loop closure handling, scalable mapping, and outperforming state-of-the-art approaches on large scenes.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a versatile hybrid SLAM system that combines deep feature extraction and matching methods, achieving improved adaptability and performance in challenging environments and outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents X-SLAM, a real-time differentiable SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, enabling end-to-end optimization and efficient calculation of higher-order derivatives for improved accuracy and convergence.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM presents a robust open-source visual SLAM system that utilizes panoptic segmentation to filter dynamic objects, achieving average accuracy four times higher than PVO and two times higher than DynaSLAM, and tested on real-world datasets and quadruped robot scenarios.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The paper proposes a Bayesian particle-based sum-product algorithm (SPA) for cooperative multipath-based simultaneous localization and mapping (MP-SLAM) in wireless networks. The key contributions are:1. Modeling the exchange of information between different mobile terminals (MTs) to enable cooperative localization and data fusion of virtual anchors (VAs) over different MTs.2. Fully integrating an inertial measurement unit (IMU) as an additional sensor for each MT to unlock additional information for orientation and state transition estimation.3. Analyzing the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulations.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|The paper presents Real-time Gaussian SLAM (RTG-SLAM), a system that achieves real-time 3D reconstruction of large-scale environments using Gaussian splatting, featuring a compact Gaussian representation and a highly efficient on-the-fly Gaussian optimization scheme, which outperforms state-of-the-art NeRF-based SLAM methods in terms of speed, memory cost, and realism of novel view synthesis.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
