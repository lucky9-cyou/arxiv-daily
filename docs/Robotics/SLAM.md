
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3, achieving real-time mapping and localization in human colonoscopies.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel RGB-only SLAM system that combines frame-to-frame tracking with 3D Gaussian map representation, enabling online map deformations and accurate surface reconstruction, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve efficient and real-time mapping and tracking in unfamiliar environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a method to enhance translation accuracy during initialization in Stereo Visual-Inertial SLAM, which uses a 3-DoF Bundle Adjustment and updates the rotation estimate by considering IMU measurements and gyroscope bias, improving performance in challenging scenarios.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces SynCHMR, a synergy between visual SLAM and human mesh reconstruction, achieving consistent reconstructions of camera trajectories, human meshes, and dense scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents a novel, comprehensive, and real-world multi-robot collaborative perception dataset, leveraging the untapped potential of air-ground robot collaboration, featuring distinct spatial viewpoints, sensor modalities, and coverage ranges to advance research in this underexplored area.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The research focuses on minimizing human effort in deploying perception-based robotic systems to previously unseen environments through continual learning and label-efficient learning, exploring methods for efficient robot learning, and leveraging vision foundation models for extremely label-efficient training.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, achieving drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, using 3D Gaussian representation and CLIP features for loop closure detection.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The key contributions of the paper are the development of NV-LIO, a normal vector-based LIO framework for SLAM in indoor environments, which utilizes normal vectors from LiDAR scans to enhance point cloud registration and robustly handles loop closures in multifloor buildings.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising fast ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to enable reliable and accurate mapping in diverse scenarios.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach called MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS to achieve high-fidelity tracking, mapping, and rendering with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a lightweight circular convolutional Transformer network (CCTNet) that improves LiDAR-based place recognition by capturing structural information and enabling cross-dimensional interaction, achieving superior performance on various datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed optimization-based SLAM approach simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry, representing a novelty in joint optimization of map and pose estimation, achieving improved accuracy and uncertainty estimation.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes IPC, a consensus-based method for incremental probabilistic consensus, which approximates the maximally consistent set of loop closure measurements in online fashion, demonstrating robustness and scalability in handling large numbers of outliers while providing online performances.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes OverlapMamba, a novel deep learning-based LiDAR-based Place Recognition (LPR) approach that represents input range views as sequences, using a stochastic reconstruction approach to build shift state space models, achieving robust and real-time place recognition capabilities.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a single sentence summarizing the key contributions from the abstract and introduction:The authors propose SceneFactory, a workflow-centric framework that supports a wide range of scene modeling applications, including mono-SLAM, multi-view depth estimation, 3D reconstruction, and SLAM, with modular components, including a dense depth estimation block and multi-resolution neural points representation for Surface Light Fields and Point Rasterization.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NGD-SLAM, a real-time visual SLAM system for dynamic environments that achieves tracking frame rate of 56 fps on a single CPU without GPU support, using a novel mask prediction mechanism and dual-stage optical flow tracking to enhance efficiency and robustness.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes an application that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, capable of running on a portable device like an iPhone 14 Pro. The paper presents three high-fidelity reconstruction tools that can achieve metric accurate facial reconstructions.The paper highlights the limitations of existing methods, such as SLAM and NeRFs, which require highly calibrated scenes, incur steep computation costs, or fail to render dynamic scenes. The proposed approach aims to overcome these limitations by leveraging the complementary strengths of geometric and photometric information from LiDAR and computer vision techniques.The paper presents three attempts to achieve real-time 3D facial reconstructions: monocular depth estimation, LiDAR + TrueDepth, and template modeling. The first attempt uses Intel MiDaS as the core backbone of the depth estimation pipeline, while the second attempt uses the iPhone 14 Pro's LiDAR and TrueDepth sensors and a custom-trained SRCNN model to upscale the LiDAR depth frame. The third attempt uses a deep-learning approach to render a facial reconstruction and apply texture + mesh transformations directly through an end-to-end approach.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF) to jointly optimize camera poses and radiance fields from unknown camera poses, leveraging monocular depth priors through three key advancements: truncated depth-based ray sampling, coarse-to-fine training, and robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|The paper introduces a novel framework for dense Visual Simultaneous Localization and Mapping (VSLAM) using Gaussian Splatting, which integrates advanced sparse visual odometry with dense Gaussian Splatting scene representation for the first time, eliminating the need for depth maps and enhancing tracking robustness.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel framework, NeuRSS, which combines neural rendering for bathymetry estimation with loop closures and dead reckoning for underwater SLAM, addressing the elevation degeneracy issue and improving both localization and bathymetric mapping.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce NGM-SLAM, a 3D Gaussian Splatting SLAM system that leverages neural radiance field submaps for progressive scene expression, effective loop closure detection, and real-time scene reconstruction, achieving state-of-the-art performance on multiple datasets.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:This comprehensive survey investigates the state-of-the-art techniques for leveraging Neural Radiance Fields (NeRF) to enhance the capabilities of autonomous robots, particularly in perception, localization, and navigation modules, and explores future research avenues.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper reviews the state-of-the-art place recognition (PR) methods and their applications in robotics, highlighting the importance of PR in Simultaneous Localization and Mapping (SLAM) 2.0 and its need for scalable, adaptable, and efficient solutions.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|The paper proposes a neural mapping framework that anchors multiple neural fields to a pose graph, allowing for efficient incorporation of loop closure constraints and scalable mapping, outperforming existing state-of-the-art approaches on large scenes.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a deep learning-based SLAM system, called SL-SLAM, which combines end-to-end and hybrid approaches to improve visual SLAM performance in challenging environments, outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose X-SLAM, a real-time, differentiable SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, enabling task-aware optimization and achieving better accuracy and faster convergence in camera relocalization and active robotic scanning tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Panoptic-SLAM, a novel visual SLAM system that uses panoptic segmentation to filter dynamic objects, including unknown and unlabeled moving objects, achieving robust localization and mapping in dynamic environments while outperforming state-of-the-art methods.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:1. A Bayesian particle-based sum-product algorithm (SPA) for cooperative MP-SLAM that enables data fusion over different observations of map features (VAs) by different MTs and cooperative MT-to-MT measurements using RF signals.2. A novel approach to integrate an inertial measurement unit (IMU) as an additional sensor for each MT, allowing for the unlocking of additional information for orientation and state transition estimation.3. The authors analyze the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulations, and present the impact of using an IMU for the mentioned cases.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Real-time Gaussian SLAM (RTG-SLAM), a system that achieves real-time 3D reconstruction at scale using Gaussian splatting, featuring a compact Gaussian representation and efficient online optimization, outperforming state-of-the-art NeRF-based SLAM methods in speed, memory, and realism.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
