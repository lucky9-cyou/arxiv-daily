
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a scalable and real-time neural RGB-D SLAM system for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to efficiently cover the entire scene while maintaining high mapping and tracking performance.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A method to enhance the translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems, by using a 3-DoF Bundle Adjustment (BA) to refine the translation estimate independently, while keeping the rotation estimate fixed.* Updating the rotation estimate by considering IMU measurements and gyroscope bias, unlike ORB-SLAM3 which directly obtains rotation from stereo visual odometry and may perform poorly in challenging scenarios.* The proposed method achieves comparable performance to Stereo-NEC while maintaining a runtime similar to that of ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities by integrating human-aware metric SLAM and scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper presents a pioneering, comprehensive, and real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, distinct spatial viewpoints, and sensor modalities, which serves as a foundation for researching high-level scene understanding through multimodal collaborative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The research aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments. The key contributions are:1. Continual learning for robotics, which equips an autonomous agent with the capability to adapt to unseen domains while retaining high performance on previous domains.2. Label-Efficient Panoptic Segmentation, which enables training panoptic segmentation networks with almost zero labels using vision foundation models.3. Robot mapping, including automated camera-LiDAR calibration and fusion of camera and LiDAR data.4. Collaborative robot mapping and efficient robot learning via multi-agent collaboration, which enables sharing online detections and updating maps in real-time.Overall, the research focuses on reducing human annotations and enabling robots to learn from their environment without extensive training data.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without requiring RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NV-LIO, a normal vector-based LIO framework for indoor SLAM in multifloor environments, which enhances point cloud registration performance by using normal vectors for correspondence search and addresses degeneracy situations and potential mismatches in the alignment process.|[2405.12563v1](http://arxiv.org/abs/2405.12563v1)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes four key contributions to achieve a robust long-term robotic mapping system: fast and robust ground segmentation, outlier-robust registration using graduated non-convexity, hierarchical multi-session SLAM, and instance-aware static map building to handle changing environments and moving objects.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving state-of-the-art performance in tracking, mapping, and rendering with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The paper proposes a lightweight circular convolutional Transformer network (CCTNet) for place recognition in LiDAR-based SLAM, addressing issues of "restricted receptive fields" and "excessive focus on local regions" in existing methods by introducing Circular Convolution Module and Range Transformer Module.|[2405.10793v1](http://arxiv.org/abs/2405.10793v1)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes an optimization-based SLAM approach that jointly optimizes robot trajectory and occupancy map using 2D laser scans and odometry, outperforming existing methods by leveraging all available information and providing more accurate results with uncertainty estimates.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes IPC, a robust and online Pose Graph Optimization method that approximates the maximally consistent set of loop closure measurements in an incremental fashion, capable of handling large numbers of outliers while providing online performance.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction: The authors propose OverlapMamba, a novel deep learning-based LiDAR-based place recognition (LPR) method that utilizes raw range views (RVs) as input and outperforms traditional methods in time complexity and speed, achieving state-of-the-art performance on loop closure detection and place recognition tasks.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summarized key contribution from the paper's abstract and introduction in a single sentence under 50 words:The SceneFactory framework, a workflow-centric and unified platform, supports a wide range of applications, such as multi-view depth estimation, LiDAR completion, and RGB-D reconstruction, with four building blocks for independent expansion and competitive quality.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words: The authors propose NGD-SLAM, a real-time visual SLAM system for dynamic environments that operates on a CPU without GPU support, achieving high localization accuracy and a tracking frame rate of 56 fps using a novel mask prediction mechanism and dual-stage optical flow tracking approach.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three approaches for real-time 3D facial reconstructions using LiDAR and TrueDepth sensors on portable devices like the iPhone 14 Pro, overcoming limitations of previous methods relying on SLAM, NeRFs, and stereo vision with monocular depth estimation, LiDAR, and template modeling approaches.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using monocular depth priors, with three key advancements: depth-based ray sampling, coarse-to-fine training, and a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MGS-SLAM, a novel monocular Gaussian Splatting-based SLAM system that integrates sparse visual odometry with dense Gaussian Splatting, eliminating depth map dependencies, enhancing tracking robustness, and achieving state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a scalable framework, NeuRSS, for sidescan sonar (SSS) simultaneous localization and mapping (SLAM) using dead reckoning (DR) and loop closures (LCs) over large timescales, which improves localization and bathymetric mapping by addressing elevation degeneracy with an elevation prior from neural rendering.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces NGM-SLAM, a progressive dense Gaussian splatting SLAM system that leverages neural submaps for high-fidelity mapping, loop closure detection, and real-time correction, achieving state-of-the-art tracking and mapping performance on large-scale scenes with monocular, stereo, and RGB-D inputs.|[2405.05702v4](http://arxiv.org/abs/2405.05702v4)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This survey reviews and analyzes the application of Neural Radiance Fields (NeRF) in enhancing autonomous robots' perception, localization, navigation, and decision-making capabilities, benchmarking existing methods and exploring future avenues for integration with advanced techniques.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper aims to bridge the gap in place recognition (PR) by highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and providing a comprehensive review of current advancements and challenges in PR, alongside its broad applications in robotics.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel neural mapping framework that anchors lightweight neural fields to a pose graph of a sparse visual SLAM system, enabling efficient integration of large-scale loop closures and limiting necessary reintegration, while achieving scalability and outperforming existing methods on large scenes.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a hybrid visual SLAM system that integrates deep feature extraction and matching methods to enhance adaptability in challenging environments, achieving superior localization accuracy and tracking robustness compared to traditional approaches.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|The key contributions of the paper are the development of X-SLAM, a real-time dense differentiable SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, and the implementation of end-to-end optimization frameworks for camera relocalization and active robotic scanning, achieving better accuracy and faster convergence.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM, an open-source visual SLAM system, uses panoptic segmentation to filter dynamic objects from the scene, achieving robust localization in dynamic environments with unknown and unlabeled moving objects, outperforming state-of-the-art methods in various benchmarks.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:1. Modeling the exchange of information between different mobile terminals (MTs), enabling cooperative localization and data fusion of virtual anchors (VAs) over different MTs.2. Integrating an inertial measurement unit (IMU) as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation.3. Analyzing the impact of VA data fusion and cooperative measurements in multipath-based simultaneous localization and mapping (MP-SLAM) for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulation.The paper proposes a Bayesian particle-based sum-product algorithm (SPA) for cooperative MP-SLAM, which enables data fusion over different observations of map features (VAs) by different MTs and cooperative MT-to-MT measurements using radio signals.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper introduces Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system that uses Gaussian splatting for large-scale environments, featuring a compact Gaussian representation and a highly efficient online Gaussian optimization scheme.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
|**2024-04-29**|**Non-convex Pose Graph Optimization in SLAM via Proximal Linearized Riemannian ADMM**|Xin Chen et.al.|Here are the key contributions summarized from the paper's abstract and introduction:**Contributions:**1. **Propose a new pose graph optimization model** based on the von Mises-Fisher distribution, representing rotations by a unit quaternion and translations by a 3D vector.2. **Propose a proximal linearized Riemannian alternating direction method of multipliers (PieADMM)**, which has closed-form solutions, parallelizable sub-problems, and low memory requirements.3. **Establish the iteration complexity** of O(1/ε²) for PieADMM to find an ϵ-stationary solution of the proposed model.The contributions are built upon:1. Quaternion representations for rotation and translations2. Von Mises-Fisher distribution for rotational noise modeling3. Augmented unit quaternions (AU) for combining quaternion and 3D vector representations4. ADMM framework for solving the pose graph optimization problem.The contributions are validated through numerical experiments on two synthetic and four 3D SLAM benchmark datasets, demonstrating the efficiency of the proposed method.|[2404.18560v1](http://arxiv.org/abs/2404.18560v1)|null|
|**2024-04-29**|**Mesh-based Photorealistic and Real-time 3D Mapping for Robust Visual Perception of Autonomous Underwater Vehicle**|Jungwoo Lee et.al.|Here is the summary:The paper proposes a photorealistic real-time dense 3D mapping system for underwater environments, utilizing a learning-based image enhancement method and mesh-based map representation. The system aims to improve localization accuracy and generate photorealistic maps.|[2404.18395v1](http://arxiv.org/abs/2404.18395v1)|null|
