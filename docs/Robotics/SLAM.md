
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome tracking losses and scene deformation in endoscopy, achieving real-time processing and significantly longer sub-maps compared to ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel 3D Gaussian Splatting-based RGB-only SLAM system that combines frame-to-frame tracking with global consistency, online map deformations, and proxy depth estimation for improved reconstruction quality and rendering, achieving state-of-the-art tracking accuracy and fidelity.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time and predictive mapping and tracking in unfamiliar environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:1. A novel method to enhance the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems, which improves translation accuracy during initialization.2. A 3-DoF Bundle Adjustment (BA) approach to refine the translation estimate independently while keeping the rotation estimate fixed, unlike traditional 6-DoF BA methods.3. The use of IMU measurements and gyroscope bias to update the rotation estimate, unlike ORB-SLAM3's direct use of stereo visual odometry.4. The method's ability to achieve performance comparable to Stereo-NEC while maintaining a runtime similar to ORB-SLAM3.5. Extensive evaluations on the EuRoC dataset demonstrating the method's accuracy and robustness in various challenging scenarios.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), which merges the best of both worlds by jointly reconstructing camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents the first comprehensive, real-world multi-robot collaborative perception dataset, featuring heterogeneous sensors, robots, and modalities, to facilitate research in this underexplored area, which has the potential to unlock high-level scene understanding through multi-modal collaborative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:1. Investigating how to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning.2. Exploring the application of vision foundation models for extremely label-efficient training.3. Developing label-efficient panoptic segmentation methods that can be adapted to new domains without requiring extensive human annotation.4. Investigating the transfer of insights gained from vision-based label-efficient panoptic segmentation to 3D point clouds and sensor cost optimization in mapping approaches.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|The paper presents MG-SLAM, a monocular Gaussian SLAM system that leverages a 3D Gaussian representation to perform drift-corrected tracking, high-fidelity reconstruction, and achieve a high-level understanding of the environment through a language-extended loop closure module based on CLIP features.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper proposes NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments with multifloor structures, addressing challenges in point cloud registration and degeneracy detection.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes four contributions to develop a robust long-term robotic mapping system: fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building, to overcome the limitations of deep learning-based methods and enable robots to operate effectively in diverse and changing real-world scenarios.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:A novel 3DGS-based SLAM approach, MotionGS, is proposed, integrating deep feature extraction, dual keyframe selection, and 3DGS, achieving accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption with state-of-the-art performance on various datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a lightweight circular convolutional Transformer network (CCTNet) that addresses limitations of range image-based networks, enhancing performance by capturing structural information and facilitating cross-dimensional interaction for place recognition with movable objects.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes a novel optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry information, outperforming existing methods by estimating more accurate maps and robot trajectories.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Incremental Probabilistic Consensus (IPC), a simple and easy-to-implement method that approximates the maximally consistent set of measurements in an incremental fashion, outperforming state-of-the-art methods in handling outliers and providing online performances.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes OverlapMamba, a novel deep learning-based LiDAR-based Place Recognition (LPR) approach that represents input range views as sequences, employing a stochastic reconstruction approach to build shift state space models, and demonstrates strong place recognition capabilities and real-time efficiency.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes SceneFactory, a workflow-centric framework that supports various incremental scene modeling applications, including SLAM, depth estimation, and 3D reconstruction, and contributes novel techniques such as the U2-MVD model, ScaleCov, and DM-NPs for high-quality scene modeling.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NGD-SLAM, a real-time visual SLAM system for dynamic environments that runs entirely on CPU, achieving 56 fps, by introducing a mask prediction mechanism and a dual-stage optical flow tracking approach, enhancing efficiency and robustness without GPU support.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction, attempting to overcome limitations of previous methods such as limited environments, high computation costs, and low portability.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, introducing a novel depth-based ray sampling strategy, coarse-to-fine training, and robust inter-frame point constraint for enhanced pose estimation accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel framework for dense Visual Simultaneous Localization and Mapping (VSLAM) that integrates advanced sparse visual odometry with 3D Gaussian Splatting, eliminating depth map dependency and enhancing tracking robustness, and achieves state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a modern and scalable framework, NeuRSS, for sidescan sonar (SSS) Simultaneous Localization and Mapping (SLAM) based on dead reckoning and loop closures, incorporating elevation prior using neural rendering for bathymetry estimation.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|The paper introduces NGM-SLAM, a 3DGS-based SLAM system that uses neural radiance fields for progressive scene expression and loop closure detection, achieving high-quality scene representation, accurate hole filling, and real-time loop adjustments.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive survey of Neural Radiance Fields (NeRF) in enhancing the capabilities of autonomous robots, focusing on perception, localization, navigation, and decision-making, and exploring potential integration with advanced techniques for enhanced reconstruction efficiency and scene understanding.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper bridging the gap between place recognition (PR) and real-world robotic systems by highlighting the crucial role of PR in Simultaneous Localization and Mapping (SLAM) 2.0, and providing a comprehensive review of current advancements and remaining challenges in PR.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|The paper proposes a neural mapping framework that uses a set of lightweight neural fields anchored to a pose graph, enabling efficient incorporation of loop closure constraints and scalability, which outperforms existing state-of-the-art approaches on large scenes in terms of quality and runtime.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a deep learning-based hybrid SLAM system that combines deep feature extraction and matching methods to enhance adaptability in challenging environments, outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper presents X-SLAM, a real-time differentiable dense SLAM system that employs the complex-step finite difference method to calculate numerical derivatives, enabling task-aware optimization and higher-order differentiation, and achieving improved accuracy and efficiency in camera relocalization and robotic scanning.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present Panoptic-SLAM, an open-source visual SLAM system that uses panoptic segmentation to filter dynamic objects and is robust in dynamic environments, outperforming several state-of-the-art systems.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions from the paper's abstract and introduction are:1. The introduction of a Bayesian particle-based Sum-Product Algorithm (SPA) for cooperative Multipath-Based Simultaneous Localization and Mapping (MP-SLAM) that enables data fusion over different observations of map features by different mobile terminals (MTs) and cooperative MT-to-MT measurements using Radio Frequency (RF) signals.2. The consideration of multiple mobile terminals (MTs) and base stations (BSs) with unknown positions and orientations, enabling more robust mapping and higher localization accuracy.3. The integration of an inertial measurement unit (IMU) as an additional sensor for each MT, allowing for orientation and state transition estimation, which helps to cope with complex trajectories.The paper proposes a novel method for cooperative MP-SLAM that takes into account the exchange of information between different MTs, enabling data fusion and cooperative localization. The algorithm is based on a Bayesian particle-based SPA that considers the uncertainty of the measurements and the presence of multiple MTs and BSs.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:RTG-SLAM, a real-time 3D reconstruction system, uses Gaussian splatting to reconstruct large-scale environments with compact Gaussian representation and efficient on-the-fly optimization, achieving high-quality reconstructions at twice the speed and half the memory cost of state-of-the-art NeRF-based SLAM methods.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
