
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|The paper proposes Manhattan Gaussian SLAM (MG-SLAM), a RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness, addressing the issue of incomplete reconstructions in complex indoor environments.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|The paper proposes a novel approach to detect and classify landmarks using in-air 3D sonar, which is a resilient sensing modality in challenging environments. The key contributions are:* A convolutional neural network (CNN) that detects and classifies 10 different reflector landmarks with varying radii using cochleograms, which are time-frequency representations of echoes.* The CNN achieves a high classification accuracy of 97.3% and predicts landmark orientation angles with a root mean squared error (RMSE) lower than 10 degrees, enhancing the utility in Simultaneous Localization and Mapping (SLAM) and autonomous navigation applications.* The approach uses a bio-inspired representation of the reflected echoes, modeled after the inner ear of an echolocating bat, which allows for robust and accurate classification in noisy and distorted environments.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a joint calibration method for multiple asynchronous microphone arrays and sound source localization using batch SLAM, ensuring accurate initialization of unknown parameters, and outperforming existing methods in precision and convergence rate through extensive numerical simulations and real experiments.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces a novel 3D Gaussian Splatting (3DGS)-based SLAM system that addresses limitations of 3DGS, including motion blur and camera noise, by incorporating a Fusion Bridge module that integrates tracking-centered ORB Visual Odometry with online 3DGS for robust and real-time performance.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes CudaSIFT-SLAM, a novel monocular visual simultaneous localization and mapping system that overcomes challenges in human colonoscopy by using SIFT features and brute-force matching, achieving real-time performance and improving mapping accuracy and coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes the first RGB-only SLAM system with a dense 3D Gaussian map representation that utilizes globally optimized tracking and dynamically adapts to keyframe pose and depth updates, leading to superior or on-par performance with existing RGB-only SLAM methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which divides the scene into sub-maps using adaptive map growth and neural blocks, allowing for efficient representation and coverage of large, unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions discussed in the abstract and introduction are: the proposal of a new method for enhancing translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM, which uses a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) to refine the translation estimate independently while keeping the rotation estimate fixed, and takes into account IMU measurements and gyroscope bias. The method aims to achieve performance comparable to Stereo-NEC while maintaining a runtime similar to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper presents SynCHMR, a synergistic approach that combines camera-frame human mesh recovery with human-aware metric SLAM to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a comprehensive real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, diverse sensor modalities, and realistic sensing characteristics, allowing researchers to study and develop multi-modal collaborative perception algorithms.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The paper investigates how to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations.* The research focuses on using vision foundation models for extremely label-efficient training, enabling robots to adapt to new environments without sacrificing performance on previous domains.* The paper presents three main research directions: Continual Learning for Robotics, Label-Efficient Panoptic Segmentation, and Collaborative Robot Mapping.* The paper's contributions include a novel concept of continual SLAM, a dual-network architecture for online continual learning, and a method for automatic target-less camera-LiDAR calibration.* The paper also presents ongoing and future directions, including transferring insights from vision-based label-efficient panoptic segmentation to 3D point clouds and investigating the impact of foundation models on unsupervised domain adaptation.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, allowing for drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, without requiring RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|This paper proposes NV-LIO, a normal vector-based LiDAR-inertial odometry framework that enhances point cloud registration performance in indoor environments with multifloor structures, particularly addressing challenges such as point cloud degeneracy and double-side issue.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work out of the box, addressing challenges such as catastrophic failure in untrained scenes, dynamic environments, and moving objects, through novel methods for ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep visual feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve real-time tracking, accurate mapping, and high-fidelity scene representation, outperforming existing methods with lower memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The key contributions from the paper's abstract and introduction are: a novel lightweight circular convolutional Transformer network (CCTNet) that improves range image-based place recognition by capturing structural information in point clouds and facilitating cross-dimensional interaction, and a Range Transformer Module (RTM) that enhances accuracy in scenarios with movable objects.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry, formulating the problem as a continuous occupancy map where each point has an evidence value, and solving it using a variation of Gauss-Newton method.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents IPC, a consensus-based approach that incrementally builds a good approximation of the maximally consistent set of loop closure measurements, allowing for online performance and robust handling of large numbers of outliers, and outperforms state-of-the-art methods in standard benchmarking datasets.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|The novel OverlapMamba deep learning model, combined with state space models, for place recognition represents input range views as sequences, exhibiting robustness in detecting loop closures and outperforming typical LiDAR-based methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:SceneFactory, a workflow-centric and unified framework, supports a wide range of incremental scene modeling applications, including SLAM, multi-view depth estimation, LiDAR completion, and 3D reconstruction, with contributions including a modular design, a robust depth estimation block, and a dual-purpose multi-resolution neural points representation.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes NGD-SLAM, a real-time SLAM system for dynamic environments that operates on a single CPU without GPU support, featuring a novel mask prediction mechanism, dual-stage optical flow tracking, and hybrid usage of optical flow and ORB features for high accuracy and efficiency.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions in the paper's abstract and introduction:The paper proposes three high-fidelity reconstruction tools that can run on a portable device, such as an iPhone 14 Pro, to enable interactive and immersive holographic experiences. The tools are designed to overcome the limitations of previous methods that rely on SLAM, NeRFs, or traditional depth estimation techniques. The paper aims to achieve high-quality facial reconstructions in real-time, with the goal of creating a novel holographic overlay application.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:TD-NeRF proposes a novel approach that jointly optimizes camera poses and Neural Radiance Fields using monocular depth priors, improving pose estimation accuracy, and featuring a truncated depth-based ray sampling strategy, coarse-to-fine training, and robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel dense VSLAM framework that integrates sparse visual odometry with 3D Gaussian Splatting, utilizing a pre-trained MVS depth estimation network, depth smooth loss, and Sparse-Dense Adjustment Ring to achieve state-of-the-art performance and robustness.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes NeuRSS, a scalable and modern framework for sidescan sonar SLAM that utilizes dead reckoning and loop closures to estimate the relative pose and bathymetric map, achieving improved accuracy and robustness in seafloor reconstruction.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors present the NGM-SLAM system, which combines neural radiance fields with 3D Gaussian Splatting to achieve high-quality scene expression, large-scale scene representation, and accurate hole filling, with real-time loop closure detection and correction.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) in autonomous robots, highlighting its applications in perception, localization, and navigation, and exploring its integration with cutting-edge technologies for enhancing robot capabilities and scene understanding.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper aims to bridge the gap in real-world place recognition (PR) technology for robotic systems by highlighting the crucial role of PR within Simultaneous Localization and Mapping (SLAM) 2.0 and providing a comprehensive review of current state-of-the-art advancements, challenges, and applications.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction: The proposed neural mapping framework combines the strengths of sparse visual SLAM and neural scene representations, enabling efficient integration of large-scale loop closures while limiting necessary reintegration and achieving scalability and quality performance.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the paper's key contributions in one sentence under 50 words:This paper proposes a hybrid visual SLAM system combining deep feature extraction and matching methods, which significantly improves adaptability in challenging environments and outperforms traditional state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
