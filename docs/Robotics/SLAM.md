
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a real-time V-SLAM system that utilizes SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3 in human colonoscopy, achieving significantly longer sub-maps and higher mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes an RGB-only SLAM system with a novel 3D Gaussian map representation that leverages global map and pose optimization, adaptively deforms the map to keyframe pose and depth updates, and refines depth updates with a monocular depth estimator, achieving superior or on-par performance with existing RGB-only SLAM methods.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based RGB-D SLAM system for unknown scenes, which integrates a divide-and-conquer mapping strategy and an adaptive map growth strategy for efficient representation and tracking of large-scale unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed method, ETA, enhances translation accuracy in stereo visual-inertial SLAM initialization by using a 3-DoF bundle adjustment independently while updating rotation estimation with IMU measurements and gyroscope bias, outperforming existing methods in accuracy and run-time speed.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces SynCHMR, a synergistic camera and human reconstruction method that jointly estimates camera poses, scene point clouds, and human meshes in a common global coordinate system, addressing ambiguities in depth, scale, and dynamic scenarios.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring distinct spatial viewpoints, complementary robot mobilities, and sensor modalities, to facilitate the study of multi-modal collaborative perception using real-world data.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions in the abstract and introduction:The abstract highlights the research's focus on minimizing human effort in deploying perception-based robotic systems to previously unseen environments. The research explores ways to leverage continual learning and reduce human annotations for efficient learning.The introduction emphasizes the importance of holistic scene understanding in autonomous robotics, which requires a well-defined representation of the surroundings to capture spatial structure and assigning semantic meaning to individual objects. The research aims to address this challenge by investigating how to minimize human effort in deploying perception-based robotic systems to previously unseen environments, specifically focusing on leveraging continual learning and reducing human annotations for efficient learning.Overall, the abstract and introduction highlight the research's goal of developing more efficient and adaptable robotics systems that can learn and adapt to new environments with minimal human intervention.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking and high-fidelity reconstruction without depth sensors, using 3D Gaussian representation and CLIP feature-based loop closure.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework designed for indoor SLAM in multifloor environments, which extracts normal vectors from LiDAR scans and uses them for correspondence search to enhance point cloud registration performance, addressing challenges in indoor environments such as rapid changes in scans and repetitive structural features.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that addresses catastrophic failures in deep learning-based approaches, incorporating ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to work effectively in diverse real-world scenarios.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summarized key contribution in a single sentence under 50 words:The paper proposes MotionGS, a novel dense visual SLAM method using 3D Gaussian splatting, which combines deep feature extraction, dual keyframe selection, and optimization to achieve high-fidelity tracking, mapping, and rendering with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The authors propose a lightweight circular convolutional Transformer network (CCTNet) that captures structural information in point clouds, improves place recognition accuracy, and surpasses comparable methods in extensive experiments on various datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes a novel optimization-based SLAM approach that simultaneously estimates the robot trajectory and occupancy map using 2D laser scans and odometry information, where the robot poses and occupancy map are optimized together, unlike existing approaches.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|The paper presents IPC, a robust online method for Pose Graph Optimization (PGO) that approximates the solution to the combinatorial problem of finding the maximally consistent set of measurements in an incremental fashion, and outperforms state-of-the-art methods in handling outliers while providing online performances.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes OverlapMamba, a novel place recognition method that utilizes raw range views (RVs) as input sequences, outperforming typical LiDAR and multi-view combination methods in time complexity and speed, and achieving state-of-the-art performance on loop closure detection and place recognition tasks.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:SceneFactory, a workflow-centric framework, supports a wide range of incremental scene modeling applications with different input combinations, and contributes a robust depth estimation block, dual-purpose multi-resolution neural points representation, and high-quality scene reconstruction methods.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NGD-SLAM, a novel real-time visual SLAM system that achieves high localization accuracy in dynamic environments without GPU support, using a mask prediction mechanism and dual-stage optical flow tracking approach for efficient and robust camera tracking.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|The paper proposes three approaches to generate real-time 3D facial reconstructions: (1) monocular depth estimation, (2) LiDAR + TrueDepth, and (3) template modeling. The key contributions are:* Developing a hybrid approach that combines depth estimation, LiDAR, and TrueDepth sensors to achieve high-fidelity facial reconstructions in real-time.* Proposing a novel pipeline that utilizes Intel MiDaS, Marigold, and SRCNN models for monocular depth estimation, LiDAR depth upsampling, and TrueDepth-based facial reconstruction.* Leveraging the iPhone 14 Pro's LiDAR and TrueDepth sensors for real-time reconstruction, and using Metal shaders for rendering the reconstructed voxel map.* Adapting a template modeling approach using MICA to render a facial reconstruction and apply texture + mesh transformations directly through an end-to-end approach.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses, leveraging monocular depth priors through three key advancements: a novel depth-based ray sampling strategy, a coarse-to-fine training strategy, and a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel framework that integrates sparse visual odometry with 3D Gaussian Splatting for dense visual simultaneous localization and mapping, eliminating the need for depth maps and enhancing tracking robustness, achieving state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeuRSS, a scalable framework for simultaneous localization and mapping (SLAM) using sidescan sonar (SSS) data, addressing the challenge of rough positioning accuracy by incorporating an elevation prior from neural rendering-based bathymetry estimation.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NGM-SLAM, a progressive dense Gaussian splatting SLAM system that utilizes neural radiance field submaps for scene expression and loop closure detection, achieving high-quality scene reconstruction, accuracy, and real-time performance in large-scale scenes.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the state-of-the-art techniques for utilizing Neural Radiance Fields (NeRF) in autonomous robotics, focusing on perception, localization, and decision-making, and explores its potential integration with advanced techniques to enhance robotic capabilities and pave the way for innovative solutions.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper bridges the gap in place recognition (PR) technology for real-world robotics by highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and provides a comprehensive review of state-of-the-art advancements and challenges in PR.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a neural mapping framework that anchors lightweight neural fields to a pose graph, enabling efficient integration of loop closures and scalability, outperforming existing state-of-the-art approaches.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a hybrid visual SLAM system that combines deep feature extraction and matching methods, enhancing adaptability in challenging environments, and outperforms state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present X-SLAM, a real-time and differentiable dense SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, enabling task-aware optimization and achieving better accuracy and faster convergence in camera relocalization and active robotic scanning tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper presents Panoptic-SLAM, an open-source visual SLAM system that uses panoptic segmentation to filter dynamic objects from the scene, achieving robust localization in dynamic environments with unknown and unlabeled moving objects.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:* Modeling the exchange of information between different mobile terminals (MTs), enabling cooperative localization and data fusion of virtual anchors (VAs) over different MTs.* Fully integrating an inertial measurement unit (IMU) as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation, allowing for more robust mapping and higher localization accuracy.* Analyzing the impact of VA data fusion and cooperative measurements in multipath-based simultaneous localization and mapping (MP-SLAM) for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulations.The paper presents a Bayesian particle-based sum-product algorithm (SPA) for cooperative MP-SLAM, which enables data fusion over different observations of map features (VAs) by different MTs, as well as cooperative MT-to-MT measurements using radio signals. The algorithm jointly performs probabilistic data association (PDA) and sequential estimation of the states of the MTs and potential VAs.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors present Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system using Gaussian splatting with a compact Gaussian representation and on-the-fly Gaussian optimization, achieving comparable high-quality reconstruction with faster speed and lower memory cost compared to state-of-the-art NeRF-based SLAM methods.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
