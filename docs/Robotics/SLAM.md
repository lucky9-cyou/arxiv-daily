
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a monocular V-SLAM system that processes human colonoscopies in real-time, overcoming limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving 100% precision and 53% mapping coverage in real colonoscopy sequences.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel RGB-only SLAM system that combines frame-to-frame tracking with 3D Gaussian map representation, enabling online map deformations, proxy depth estimation, and improved accuracy and efficiency in dense SLAM tasks.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM method for handling unknown scenes, which employs a divide-and-conquer mapping strategy and an adaptive map growth strategy to achieve full coverage of the unknown environment during tracking, and demonstrates competitive performance in mapping and tracking on various datasets.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a new initialization method for stereo visual-inertial SLAM systems, aiming to enhance translation accuracy during the initialization stage.* The proposed method uses a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) to refine the translation estimate, independently of the rotation estimate.* Unlike ORB-SLAM3, which uses a 6-DoF BA, the proposed method takes into account IMU measurements and gyroscope bias to update the rotation estimate.* The paper claims that the proposed method outperforms Stereo-NEC and other state-of-the-art methods in terms of accuracy while maintaining a comparable runtime speed.* The method is evaluated on the public benchmark, the EuRoC dataset, and the results show that the proposed method excels in accuracy.* The paper aims to address the limitations of previous methods, which are vulnerable to challenges such as fast motion, poor lighting, and textureless environments.* The method has the potential to be used in real-world visual-inertial state estimation tasks.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the contributions from the paper's abstract and introduction in one sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR) that jointly reconstructs camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities by integrating human-aware metric SLAM with scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents the first comprehensive real-world multi-robot collaborative perception dataset, featuring heterogeneous robots, distinct spatial viewpoints, and various sensor modalities, to facilitate research in this area and unlock benefits such as enhanced perception, accuracy, and redundancy.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The paper aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations.* The paper proposes a novel concept of continual SLAM that combines lifelong SLAM and domain adaptation, allowing an autonomous vehicle to adapt to new environments without losing performance in previous environments.* The paper also proposes a label-efficient learning approach for panoptic segmentation using foundation models, which requires only a few annotated images and can yield results competitive with fully supervised learning methods.* The paper discusses the importance of fusing camera and LiDAR data for accurate mapping and proposes a novel method for automatic target-less camera-LiDAR calibration.* The paper mentions the ongoing and future directions, including transferring the insights gained from vision-based label-efficient panoptic segmentation to 3D point clouds, and exploring the impact of foundation models on unsupervised domain adaptation.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present MG-SLAM, a monocular Gaussian SLAM system with a CLIP feature-based loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM in multifloor environments, addressing challenges of point cloud registration in confined spaces with rapid changes and repetitive structural features.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes four contributions to achieve a robust long-term robotic mapping system: ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building to handle changing environments and moving objects.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity mapping and tracking with reduced memory usage and state-of-the-art performance on RGB-D datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The paper proposes a lightweight circular convolutional Transformer network, CCTNet, which addresses the issues of "restricted receptive fields" and "excessive focus on local regions" in range image-based networks by capturing structural information in point clouds and facilitating cross-dimensional interaction of spatial and channel information.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a single sentence summarizing the paper's abstract and introduction, under 50 words: The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot poses and occupancy maps using laser scans and odometry information, outperforming existing state-of-the-art methods when a relatively accurate initial guess is provided.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents IPC, a consensus-based method that incrementally approximates the maximally consistent set of loop closure measurements, and shows that it competes with or outperforms state-of-the-art methods in handling outliers while achieving online performances in SLAM problems.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes OverlapMamba, a novel network for place recognition using raw range views (RVs) as input sequences, which outperforms typical LiDAR and multi-view combination methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents SceneFactory, a workflow-centric framework for incremental scene modeling that supports a wide range of applications, including mono-SLAM, 3D reconstruction, LiDAR completion, and SLAM, and provides a modular and expandable design for ease of upgrading and modification.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NGD-SLAM, a real-time visual SLAM system for dynamic environments that operates entirely on CPU without GPU support, achieving high localization accuracy and a tracking frame rate of 56 fps.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three high-fidelity reconstruction tools for real-time holographic overlays using LiDAR augmented 3D reconstruction, aiming to enable interactive and immersive holographic experiences on portable devices like the iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses, utilizing monocular depth priors through three key advancements: depth-based ray sampling, coarse-to-fine training, and inter-frame point constraints.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel framework for dense Visual Simultaneous Localization and Mapping (VSLAM) using Gaussian Splatting and sparse visual odometry, which eliminates the dependency on depth maps and enhances tracking robustness, achieving state-of-the-art performance in pose estimation and novel view synthesis fidelity.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a framework, NeuRSS, for sidescan sonar (SSS) Simultaneous Localization and Mapping (SLAM) that combines neural rendering with loop closures to estimate bathymetry and improve autonomous underwater vehicle positioning and mapping.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words: The authors introduce NGM-SLAM, a 3D Gaussian Splatting SLAM system that leverages neural radiance field submaps for progressive scene representation and integrates strengths of neural fields and 3D Gaussian Splatting for accurate hole filling and high-quality scene expression.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the state-of-the-art techniques for utilizing Neural Radiance Fields (NeRF) to enhance the capabilities of autonomous robots, focusing on perception, localization, and navigation, and exploring potential future research directions.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper aims to address the challenges in place recognition (PR) for real-world robotics by highlighting its importance in Simultaneous Localization and Mapping (SLAM) 2.0 and providing a comprehensive review of current advancements and remaining challenges in PR for scalable, adaptable, and efficient robotic navigation.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel SLAM framework that combines sparse visual SLAM and neural scene representations, introducing a multi-field scene representation that allows for large-scale map deformations and efficient loop closure handling while maintaining accuracy.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce a hybrid visual SLAM system that combines deep feature extraction and deep matching methods to enhance adaptability in challenging environments, outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in one sentence under 50 words:X-SLAM, a real-time differentiable SLAM system, leverages the complex-step finite difference method to calculate numerical derivatives, bypassing the need for a large-scale computational graph, and enables task-aware optimization of SLAM parameters with high-order differentiation.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|The paper presents Panoptic-SLAM, an open-source visual SLAM system that can robustly localize and map unknown dynamic environments, using panoptic segmentation to filter dynamic objects, and achieves higher accuracy compared to state-of-the-art methods.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions from the paper's abstract and introduction are:1. **Cooperative MP-SLAM**: The authors propose a Bayesian particle-based sum-product algorithm for cooperative MP-SLAM, which enables data fusion over different observations of map features (virtual anchors) by different mobile terminals (MTs).2. **Inertial Measurement Unit (IMU) integration**: The algorithm integrates additional IMU sensor data from each MT to unlock more information for orientation and state transition estimation, allowing for more robust mapping and localization in complex trajectories.3. **Numerical simulation analysis**: The authors analyze the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple-input multiple-output (MIMO) and single-input multiple-output (SIMO) systems using numerical simulations.4. **Scalability and efficiency**: The proposed algorithm is designed to be scalable for large numbers of PVAs and measurements, achieving efficient estimation of the MT and PVA states.5. **Message passing framework**: The authors use a message passing framework to model the communication between MTs and the exchange of information about VAs.These contributions aim to improve the accuracy and robustness of MP-SLAM in wireless networks by exploiting cooperative information and integrating additional sensor data.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:RTG-SLAM, a real-time 3D reconstruction system, proposes a compact Gaussian representation and efficient on-the-fly optimization scheme, achieving high-quality reconstructions in large-scale environments with comparable speed and memory efficiency to state-of-the-art NeRF-based SLAM methods.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
