
### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Manhattan Gaussian SLAM (MG-SLAM) system leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness in indoor scenes, integrating fused line segments for robust tracking and scene completion, and achieves state-of-the-art performance in both synthetic and real-world datasets.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper presents a novel approach to detect and classify ten different reflector landmarks using in-air 3D sonar, with a focus on improving the robustness and accuracy of autonomous systems in challenging environments.* The authors use a convolutional neural network (CNN) to predict the orientation angle of detected landmarks, achieving a classification accuracy of 97.3% on the test dataset and predicting landmark orientation with an Root Mean Squared Error (RMSE) lower than 10 degrees.* The introduction highlights the challenges faced by light-based sensing modalities in harsh environmental conditions, emphasizing the need for alternative sensing modalities like in-air sonar.* The authors discuss the benefits of using shapes that can vary in size, such as dish-shaped leaves, for landmark detection and classification.* The paper focuses on detecting and classifying bio-inspired artificial landmarks using in-air 3D sonar, with the goal of enhancing the utility of autonomous systems in challenging environments.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose a batch SLAM approach for the joint calibration of multiple asynchronous microphone arrays and sound source localization, addressing the challenges of simultaneous calibration and parameter identifiability.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce a 3DGS-based SLAM system that leverages the Fusion Bridge module to integrate tracking-centered ORB Visual Odometry with online 3DGS, achieving state-of-the-art rendering quality, localization accuracy, and real-time performance over 5 FPS in long-session robotic tasks.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving the first real-time V-SLAM processing of human colonoscopies, with significant improvements in map size and coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Splat-SLAM, an RGB-only SLAM system that combines frame-to-frame tracking with a dense 3D Gaussian map, which adaptively deforms online for loop closure and global bundle adjustment, achieving superior or on-par performance in tracking and mapping while reducing map size and runtime.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words: The authors propose NeB-SLAM, a neural block-based RGB-D SLAM system for unknown scenes, which combines a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a method called ETA that enhances translation accuracy during the initialization stage in Stereo Visual-Inertial SLAM (VI-SLAM) systems, which accurately determine the 6-DOF (degrees of freedom) state.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a novel method that jointly reconstructs 3D humans and camera motion from monocular videos, leveraging human-aware metric SLAM and scene-aware SMPL denoising to achieve consistent and coherent reconstructions.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The key contributions of this paper are: (1) presenting a pioneering real-world multi-robot collaborative perception dataset, which features distinct spatial viewpoints, complementary robot mobilities, and diverse modalities from ground and aerial robots; (2) providing raw sensor data, pose estimation, and optional high-level perception annotation to accommodate diverse research interests; and (3) qualitatively demonstrating the value of this dataset through multiple collaborative perception tasks.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions of the paper are:* Continual learning for robotics: The paper presents approaches to enable robotic systems to adapt to new environments and retain performance on previous domains.* Label-efficient panoptic segmentation: The authors propose methods for training panoptic segmentation networks with almost zero labels.* LiDAR-based mapping: The paper introduces a novel method for automatic target-less camera-LiDAR calibration, which can be used in robotic applications.* Collaborative robot learning: The authors explore the idea of multi-agent collaboration for efficient robot learning and adaptation.Note that the summary is under 50 words.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present MG-SLAM, a monocular Gaussian SLAM system that uses a language-extended loop closure module to correct drift errors, achieve high-fidelity reconstruction, and gain a high-level understanding of the environment, leveraging 3D Gaussian representation and CLIP features.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping (SLAM) in indoor environments, particularly in multifloor buildings, which improves point cloud registration performance by using normal vectors and addresses degeneracy issues and loop closure problems.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes four contributions to achieve a robust long-term robotic mapping system, including fast ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to tackle challenges such as untrained scenes, changing environments, and moving objects.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summarized sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting for accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a lightweight Circular Convolutional Transformer Network (CCTNet) for LiDAR-based place recognition, addressing issues of restricted receptive fields and local focus through circular convolution and transformer modules, achieving superior performance in place recognition tasks.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes an optimization-based SLAM approach that simultaneously optimizes the robot's trajectory and occupancy map using 2D laser scans and odometry information, with key contributions including formulating the problem as an optimization problem, proposing a Gauss-Newton method solution, and demonstrating improved accuracy and uncertainty estimation compared to state-of-the-art techniques.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes Incremental Probabilistic Consensus (IPC), a novel online method that incrementally builds a maximally consistent set of loop closure measurements, outperforming state-of-the-art methods in handling outliers and providing online performances, while being simple and easy to implement.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes OverlapMamba, a novel network for place recognition that utilizes raw range view inputs, employing a stochastic reconstruction approach to build shift state space models and compressing visual representation, achieving robust place recognition capabilities and real-time efficiency.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose SceneFactory, a workflow-centric framework that supports various scene modeling applications, including multi-view depth estimation, LiDAR completion, and SLAM, with four building blocks: Mono-SLAM, depth estimation, fusion, and scene reconstruction, and contribute novel models for depth estimation, surface light fields, and point rasterization.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The authors propose a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU without GPU support, utilizing a mask prediction mechanism and a dual-stage optical flow tracking approach to enhance efficiency and robustness in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|The paper's abstract and introduction summarize the key contributions as follows: The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction, LiDAR+TrueDepth sensor data, and template modeling. The approaches are designed to run on a portable device, such as an iPhone 14 Pro, and do not require highly calibrated scenes, technical expertise, or expensive equipment. The paper introduces engineering constraints to ensure that the solutions are novel and challenging to implement.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and NeRF using depth priors, introducing a truncated depth-based ray sampling strategy, coarse-to-fine training, and a robust inter-frame point constraint to improve pose estimation accuracy and robustness.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a single sentence summary of the paper's abstract and introduction under 50 words:The paper proposes a novel monocular Gaussian Splatting-based Simultaneous Localization and Mapping (SLAM) system, integrating sparse visual odometry and Gaussian Splatting, and achieving state-of-the-art performance in pose estimation and novel view synthesis.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeuRSS, a novel framework for sidescan sonar (SSS) Simultaneous Localization and Mapping (SLAM) that leverages neural rendering to estimate bathymetry and improve positioning accuracy over large timescales, addressing the limitations of traditional SSS SLAM methods.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NGM-SLAM, a progressive dense SLAM system that combines neural radiance fields and 3D Gaussian Splatting to achieve high-fidelity mapping, online loop closure detection, and real-time rendering, supporting monocular, stereo, and RGB-D inputs, and achieving state-of-the-art performance.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) for enhancing autonomous robots' capabilities, focusing on perception, localization, navigation, and decision-making, and exploring future research avenues, including integration with advanced techniques like 3D Gaussian splatting and large language models.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper proposes a comprehensive review of place recognition (PR) methods and their application in robotics, highlighting the need for scalable, adaptable, and efficient PR solutions to support real-world robotic systems.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a neural mapping framework that combines sparse visual SLAM with neural scene representations, allowing for efficient loop closure handling and large-scale map deformations while showcasing improved quality and runtime.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in under 50 words:The paper proposes a hybrid visual SLAM system that combines deep feature extraction and matching methods, enhancing adaptability in challenging environments, and outperforms state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
