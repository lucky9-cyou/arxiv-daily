
### Gaussian Splatting
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings, leveraging neural parametric head models for increased expression control and dynamic expressivity.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The proposed method, DGD, learns a unified 3D representation for dynamic scenes, representing appearance, semantics, and geometry, and enables high-quality novel view synthesis and dense semantic 3D object tracking using a simple and intuitive interface.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel clustered differential privacy federated learning (DPFL) algorithm that effectively identifies clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees, effectively mitigating disparate impact and achieving results competitive with state-of-the-art DPFL.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|The key contributions from the paper's abstract and introduction are:The authors introduce a framework that employs a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples from a transformation map derived from the stationary Fokker-Planck equation.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors develop a descriptive model of Ion Temperature Gradient (ITG) modes, retaining wave-particle and magnetic drift resonant effects, and capturing field-line dependence of the electrostatic potential, which they resolve using a polynomial-gaussian expansion in the field-following coordinate. This model captures long-wavelength Landau damping, ion-scale Larmor radius stabilization, and magnetic-drift resonant stabilization, yielding spectra with multiple maxima, and provides a clear qualitative framework for interpreting ITG mode spectra with realistic geometries.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes $E^3$Gen, a novel avatar generation method that uses a structured 2D UV space representation to efficiently generate expressive and editable digital avatars with real-time rendering capabilities.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a single-sentence summary of the key contributions from the abstract and introduction: The authors implement Gaussian process regression to reconstruct the expansion history of the universe, using various SN-Ia compilations and BAO measurements, and find hints towards a quintessence-like dark energy scenario, while also studying the evolution of the total equation of state and constraints on the ratio H0r_d.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a single sentence summarizing the key contributions of the paper:The DeepOKAN model, a neural operator utilizing Kolmogorov-Arnold networks and Gaussian radial basis functions, outperforms traditional deep neural networks in solving mechanics problems with complex geometries and requires fewer learnable parameters while achieving comparable accuracy.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a Prior-guided Bayesian Optimization (P-BO) algorithm that integrates a surrogate model as a function prior into Bayesian optimization to improve query efficiency and attack success rate in black-box adversarial attacks, outperforming state-of-the-art methods.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The paper presents a method for implementing high-order multi-mode non-Gaussian gates using fixed non-Gaussian ancillary states and adaptive linear optics. The key contributions are:1. A general methodology for implementing general, multi-mode, and higher-order non-Gaussian gates using a fixation of non-Gaussian ancillary states and adaptive linear optics, which allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates.2. A measurement-based method to directly implement general, multi-mode, and higher-order non-Gaussian gates using fixed non-Gaussian ancillary states and adaptive linear optics.3. A reduction in the number of ancillary modes required for implementing the gates, using heuristic approaches based on Chow decomposition of polynomials.4. Applications of the method to several important examples, including the cubic quantum non-demolition gate and the CV Toffoli gate, and their higher-order extensions.These contributions have the potential to expedite the progress toward fault-tolerant universal quantum computing and efficient quantum simulation.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors develop a novel framework to evaluate the effectiveness of stochastic continuous gravitational-wave (CW) follow-ups, achieving a ten-fold reduction in computing cost and simplifying multi-stage follow-up schemes, with applications to all-sky searches in the LIGO-Virgo-KAGRA collaboration.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes the Multi-scale Deep Feature Statistics (MDFS) model for opinion-unaware blind image quality assessment, integrating deep features from pre-trained visual models with a statistical analysis model to achieve superior consistency with human visual perception and improved generalizability.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|The key contributions from the paper's abstract and introduction are:* Proposing a learning-to-prune 3D Gaussian Splatting (3DGS) method (LP-3DGS), which automatically learns the optimal pruning ratio for each scene, eliminating the need for manual tuning.* The proposed LP-3DGS uses a trainable mask applied to the importance score, which is compatible with different types of importance scores defined in prior works, to find the optimal balance between pruning ratio and rendering quality.* The trainable mask is redesigned to leverage the Gumbel-Sigmoid activation function, making the masking function differentiable and integrating with the existing training process of 3DGS, unlike prior works that used a fixed threshold or straight-through estimator.* Experimental results demonstrate that LP-3DGS outperforms traditional pruning methods and can adapt to different scenes with minimal additional training.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a new Markov chain Monte Carlo algorithm, Plug-and-Play Diffusion Model (PnP-DM), that rigorously integrates measurements with expressive image priors from diffusion models (DMs) without approximations, achieving more accurate reconstructions and posterior estimation in various inverse problems.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|The paper's key contributions are summarized as:1. Language Model-based Optimal Differential Privacy (LMO-DP) mechanism, the first non-Gaussian DP mechanism for privately fine-tuning large language models with strong DP guarantees.2. Offline optimal noise search method to efficiently derive a sub-optimal DP, which significantly reduces noise magnitude.3. Empirically demonstrating the effectiveness of LMO-DP, achieving superior convergence rates in a diverse range of language model tasks, and accuracy boosting from 50% to 90% in some cases.These contributions are the result of innovations in differential privacy, primarily through the application of R2DP [14], which is a universal and automated approach to optimizing the randomization mechanisms of differential privacy.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The Deep Bayesian Filtering (DBF) method proposed in the paper provides a novel solution for state estimation in nonlinear state space models (SSMs) by constraining the state transition on a new "fancy" space to be linear and Gaussian, and learning a Gaussian inverse observation operator (IOO) using neural networks. This approach allows for the recursive computation of posteriors without accumulating Monte-Carlo sampling errors over time steps. DBF is shown to outperform existing methods in various tasks and conditions.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words: The paper explores the application of boson sampling and Gaussian boson sampling to biclustering, a machine learning problem, and proposes heuristics for finding clusters in datasets, showing promising results through simulations, but with limitations and areas for future research.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Conformal Confidence Regions (CCR), a novel approach that combines conformal prediction intervals for model outputs to establish confidence regions for model parameters, providing finite-sample guarantees under minimal assumptions on data distribution.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper investigates the transition from quantum to classical mechanics using a one-dimensional free particle model, demonstrating a novel approach to recover classical probability density from quantum probability density by truncating Fourier components, and illustrating the connection between quantum interference and decoherence.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|Here are the key contributions from the paper's abstract and introduction:**Abstract:** The paper proposes a sparse covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components. The theory and numerical simulations demonstrate the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings.**Introduction:** The paper investigates sparse covariance operator estimation in an infinite-dimensional function space setting. It contributes to the largely unexplored subject of sparse covariance operator estimation in infinite dimension, by adapting thresholding the sample covariance and exploiting structural assumptions in the design and analysis of estimators. The paper focuses on a novel class of covariance operators that satisfy a weighted L^q-sparsity condition and establish a bound on the operator norm error of the adaptive threshold estimator in terms of two dimension-free quantities: the sparsity level and the expected supremum of the normalized field.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|The key contributions from the paper's abstract and introduction are:* A proof of almost sure invertibility of unsymmetric random Kansa collocation matrices for the Poisson equation with Dirichlet boundary conditions by a class of analytic RBFs that vanishing at infinity, including popular Positive Definite instances such as Gaussians, Generalized Inverse MultiQuadrics, and Matern RBFs.These results provide sufficient conditions for the unisolvence of unsymmetric Kansa collocation by random RBFs, filling a substantial gap in the literature on the topic.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The study presents a novel method to constrain the nature of galactic dark matter using the velocity distributions of stars in thin stellar streams, which are perturbed by dark matter subhalos, providing a measurement of the subhalo mass function and cosmological model.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a general theoretical description of spin self-diffusion under nonlinear gradient fields, extending the effective phase diffusion method for linear gradient fields.* The paper reveals three types of phase evolutions: phase diffusion, float phase evolution, and shift based on the starting position.* The authors show that the proposed method can handle random-order nonlinear gradient fields and provides a general theoretical framework for spin diffusion under nonlinear gradients.* The paper presents the phase variance and corresponding NMR signal attenuation for spins starting diffusion from the origin or non-origin positions.* The authors demonstrate that the signal attenuation obeys Gaussian attenuation for a short time, then changes to Lorentzian or Mittag-Leffler function attenuations when time increases.* The paper discusses the limitations of existing theories and highlights the importance of developing new theoretical treatments to understand nonlinear gradient fields better.* The authors provide examples of simulations and theoretical calculations to verify the proposed method and show its versatility in describing spin diffusion under various nonlinear gradient fields.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|The key contributions of this paper can be summarized in one sentence under 50 words as follows: This paper derives closed-form expressions for optimal decision boundaries in high-dimensional Gaussian mixture model (GMM) classification and empirically demonstrates that deep neural networks trained on GMMs and real-world data learn predictors approximating the derived optimal classifiers.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|Here are the key contributions from the abstract and introduction:* The paper proposes a new approach to reconstructing 4D scenes from a single, uncalibrated video input, without relying on camera Pose estimation or prior knowledge of scene structure.* The approach, called GFlow, uses an explicit representation based on 3D Gaussian Splatting to reconstruct the dynamic scene and camera movement.* GFlow clusters the scene into still and moving parts and uses sequential optimization to jointly optimize camera poses and 3D Gaussian points based on 2D priors and scene clustering.* The framework enables tracking of any points across frames without prior training and segments moving objects from the scene in an unsupervised way.* The camera Poses of each frame can be derived from GFlow, allowing for rendering of novel views of the video scene.* Various experiments are conducted to evaluate the video reconstruction quality, camera pose accuracy, and object segmentation results of GFlow, which demonstrate its effectiveness and versatility.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose 3DitScene, a unified scene editing framework that leverages language-guided disentangled Gaussian Splatting to enable precise control over scene composition and individual objects, allowing for seamless editing from 2D to 3D and manipulation at both global and individual levels.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors introduce StreetUnveiler, a 3D reconstruction method for unveiling an empty street scene from in-car camera video, which addresses the challenging task of removing temporary static objects. The method proposes a 3D representation based on hard-label semantic 2D Gaussian Splatting, a time-reversal inpainting framework, and a decomposition of the scene into observed, partial-observed, and unobserved regions to minimize inpainted regions.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a perturbation approach to calculate the short-time propagator of the one-dimensional Fokker-Planck equation, preserving probability exactly and allowing for arbitrary accurate evaluation of expectation values.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Abstract:*** The paper discusses iterative methods for scalable Gaussian process (GP) optimization.* The authors propose three improvements to accelerate the iteration process: a pathwise gradient estimator, warm starting, and early stopping.* These techniques are applied to different linear system solvers (conjugate gradients, alternating projections, and stochastic gradient descent) and shown to provide speed-ups of up to 72x when solving to tolerance and decrease the average residual norm by up to 7x when stopping early.**Introduction:*** GPs are a popular probabilistic machine learning model, but their effectiveness depends on good estimates of hyperparameters.* The authors focus on iterative methods for GP optimization, which use linear system solvers to construct an estimate of the marginal likelihood gradient.* The paper proposes three key improvements to accelerate the iteration process: a pathwise gradient estimator, warm starting, and early stopping.* These techniques are designed to reduce the required number of solver iterations and accelerate the convergence of the linear system solver.Let me know if you have any further questions or if you'd like me to summarize any of the experimental results or methodology used in the paper.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction are:* The authors consider iterative methods for Gaussian process regression, which allow for a trade-off between compute time and accuracy of a solution.* They introduce a three-level hierarchy of marginal likelihood optimisation for iterative Gaussian processes, which identifies that the computational costs are dominated by solving sequential batches of large positive-definite systems of linear equations.* They propose a "warm start" method, which reuses solutions of linear system solvers as initialisations in the next step, providing a speed-up of up to 16 times compared to the conventional procedure.* The authors demonstrate the effectiveness of the warm start method on regression tasks, achieving the same results as the conventional procedure while providing significant speed-ups.Overall, the paper presents a novel approach to marginal likelihood optimisation for iterative Gaussian processes, which can be used to improve the scalability and efficiency of Gaussian process regression.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
