
### Gaussian Splatting
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Sparse Expansion and Neuronal Disentanglement**|Shashata Sawmya et.al.|The main contributions of this paper are:1. **Sparse Expansion**: A one-shot pruning technique that expands a language model into a mixture of sparse experts, each of which is a copy of the original weights, pruned for a specific cluster of input values.2. **Disentangling neurons**: The paper shows that the mixture of sparse experts is effective in disentangling the output distributions of individual neurons across clusters of input values, which improves the performance of the model.3. **Wasserstein distance**: The paper uses the Wasserstein distance between a neuron's output distribution and a Gaussian distribution as a metric to quantify the degree of entanglement of a neuron, and shows that highly entangled neurons are more difficult to sparsify.4. **Improved performance**: The paper demonstrates that Sparse Expansion outperforms other one-shot pruning techniques in terms of parameters activated per token, across LLMs from the Llama and Pythia families, with minimal loss in accuracy.5. **Inference speedup**: The paper shows that Sparse Expansion can achieve non-trivial speedups for generative inference, with a variant of the approach providing speedups of 3x and 4.8x for the largest linear layers in Llama 2 7B and 70B, respectively.|[2405.15756v1](http://arxiv.org/abs/2405.15756v1)|null|
|**2024-05-24**|**Interaction in the dark sector: a phenomenological approach**|Z. C. Santana et.al.|The abstract and introduction suggest that the paper investigates the possibility of non-gravitational interactions affecting the evolution of dark matter density, proposing alternative scenarios to the standard law, and through Bayesian analysis using various datasets, finds that the simplest model remains within 2σ confidence level and that evidence is inconclusive or weak in favor of alternative models.|[2405.15726v1](http://arxiv.org/abs/2405.15726v1)|null|
|**2024-05-24**|**Fast adiabatic preparation of multi-squeezed states by jumping along the path**|Chuan Chen et.al.|Here are the key contributions from the paper's abstract and introduction:* Introduction of a novel shortcuts to adiabaticity (STA) method for fast preparation of multi-squeezed states, which simplifies the process and accelerates state preparation compared to previous STA methods.* The STA method is based on the theory of necessary and sufficient conditions of quantum adiabatic evolution and eliminates non-adiabatic errors.* The method is applied to prepare multi-squeezed states, which exhibit non-classical properties such as large phase-space Wigner negativities.* The STA method is also extended to prepare hybrid entangled states between a bosonic mode and a qubit.|[2405.15595v1](http://arxiv.org/abs/2405.15595v1)|null|
|**2024-05-24**|**A graph-space optimal transport FWI approach based on κ-generalized Gaussian distribution**|Sérgio Luiz E. F. da Silva et.al.|The key contributions from the paper's abstract and introduction are:* Propose a new objective function for full-waveform inversion (FWI) based on the graph-space optimal transport framework and the κ-generalized Gaussian statistics.* Demonstrate the robustness of the proposed approach in mitigating the impacts of cycle-skipping problems and non-Gaussian errors.* Show that the assumption of errors following a κ-Gaussian distribution with κ = 0.6 can reduce the computational execution time of the transport plan.|[2405.15536v1](http://arxiv.org/abs/2405.15536v1)|null|
|**2024-05-24**|**A Preference-oriented Diversity Model Based on Mutual-information in Re-ranking for E-commerce Search**|Huimu Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a Preference-oriented Diversity Model Based on Mutual-information (PODM-MI) for re-ranking in e-commerce search, which balances accuracy and diversity by maximizing the mutual information between user diversity preferences and candidate items, achieving significant improvements over state-of-the-art models.|[2405.15521v1](http://arxiv.org/abs/2405.15521v1)|null|
|**2024-05-24**|**Feature Splatting for Better Novel View Synthesis with Low Overlap**|T. Berriel Martins et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Feature Splatting (FeatSplat), a novel approach that replaces spherical harmonics with feature vectors to encode color information in 3D Gaussian Splatting, achieving significant improvement in novel view synthesis, especially for low-overlap views.|[2405.15518v1](http://arxiv.org/abs/2405.15518v1)|null|
|**2024-05-24**|**Learning to Discretize Denoising Diffusion ODEs**|Vinh Tong et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LD3, a lightweight framework that learns time discretization while sampling from diffusion models, improving sampling efficiency and preserving generation quality, and achieves competitive results on various datasets and conditions without retraining neural networks.|[2405.15506v1](http://arxiv.org/abs/2405.15506v1)|null|
|**2024-05-24**|**GSDeformer: Direct Cage-based Deformation for 3D Gaussian Splatting**|Jiajun Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GSDeformer, a method for free-form deformation on 3D Gaussian Splatting without modifying its underlying architecture, accompanied by an automatic cage construction algorithm and extensive experiments demonstrating ease of use and comparable quality compared to existing methods.|[2405.15491v1](http://arxiv.org/abs/2405.15491v1)|null|
|**2024-05-24**|**Out of Many, One: Designing and Scaffolding Proteins at the Scale of the Structural Universe with Genie 2**|Yeqing Lin et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Genie 2, an improved protein design model that extends the original Genie model to capture a larger and more diverse protein structure space.* The ability of Genie 2 to perform multi-motif scaffolding, which allows it to design proteins with multiple independent motifs, a feature not previously possible with other protein design models.* The use of a novel multi-motif framework that designs co-occurring motifs with unspecified inter-motif positions and orientations.* The ability of Genie 2 to set a new standard for structure-based protein design, achieving state-of-the-art results in designability, diversity, and novelty on both unconditional and conditional generation tasks.* The inclusion of a benchmark set of multi-motif scaffolding problems, which provides a comprehensive evaluation of the model's performance.The paper also provides additional results on unconditional protein generation, single-motif scaffolding, and multi-motif scaffolding, including performance comparisons with other protein design models and visualizations of the model's output.|[2405.15489v1](http://arxiv.org/abs/2405.15489v1)|null|
|**2024-05-24**|**Volumetric Primitives for Modeling and Rendering Scattering and Emissive Media**|Jorge Condor et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel volumetric representation based on kernel-based primitives for modeling and rendering scattering and emissive media, introducing closed-form solutions for transmittance and emission, and a ray-tracing-based implementation for efficient rendering.|[2405.15425v1](http://arxiv.org/abs/2405.15425v1)|null|
|**2024-05-24**|**Stochastic SR for Gaussian microtextures**|Emile Pierret et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces an efficient and provably exact sampler for stochastic Super-Resolution of Gaussian microtextures, outperforming state-of-the-art deep learning methods, while also discussing limitations of reconstruction metrics for evaluating SR routines.|[2405.15399v1](http://arxiv.org/abs/2405.15399v1)|null|
|**2024-05-24**|**Adaptive Finite Element Method for a Nonlinear Helmholtz Equation with High Wave Number**|Run Jiang et.al.|The key contributions of the paper are:* Developing a nonlinear Helmholtz equation with high frequencies and corner singularities,* Deriving stability estimates and a posteriori error estimates for the equation,* Establishing a priori stability and error estimates for the finite element method on shape regular meshes, including the case of locally refined meshes,* Proving the convergence and quasi-optimality of the adaptive finite element algorithm using a new residual-type error estimator,* Validating the theoretical findings with numerical examples that demonstrate the ability of the adaptive algorithm to reduce pollution errors.|[2405.15344v1](http://arxiv.org/abs/2405.15344v1)|null|
|**2024-05-24**|**Discriminative Estimation of Total Variation Distance: A Fidelity Auditor for Generative Data**|Lan Tao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose a discriminative approach to estimate the total variation distance between two distributions as a measure of generative data fidelity, and establish theoretical results for its convergence rate, demonstrating faster convergence compared to existing methods.|[2405.15337v1](http://arxiv.org/abs/2405.15337v1)|null|
|**2024-05-24**|**Minimizing UCB: a Better Local Search Strategy in Local Bayesian Optimization**|Zheyi Fan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Abstract:**1. The paper proposes a new local Bayesian optimization algorithm, MinUCB, which replaces the gradient descent step with minimizing the Upper Confidence Bound (UCB) in the GIBO algorithm.2. The paper shows that MinUCB can achieve a better local exploitation strategy than direct gradient descent, and maintains a similar convergence rate with GIBO.3. The paper further improves the acquisition function of MinUCB through a look-ahead strategy, leading to a more efficient algorithm called LA-MinUCB.**Introduction:**1. Bayesian optimization is a popular method for solving high-dimensional black-box function optimization problems.2. Local Bayesian optimization methods focus on finding a local optimum instead of the global optimum, which can be more practical for high-dimensional problems.3. The paper introduces the approximated gradient class of methods, including GIBO and MPD, which are based on minimizing the posterior variance of the gradient at a given location.4. The paper motivates the development of a new local Bayesian optimization algorithm by pointing out that GIBO and MPD may not fully utilize the information provided by the Gaussian process surrogate.The key contributions of the paper are the development of the MinUCB algorithm, which is a new local Bayesian optimization algorithm that replaces the gradient descent step with minimizing the UCB, and the improvement of the acquisition function of MinUCB through a look-ahead strategy, leading to the LA-MinUCB algorithm.|[2405.15285v1](http://arxiv.org/abs/2405.15285v1)|null|
|**2024-05-24**|**DisC-GS: Discontinuity-aware Gaussian Splatting**|Haoxuan Qu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes DisContinuity-aware Gaussian Splatting (DisC-GS), a novel framework that enables Gaussian Splatting to accurately render discontinuities and boundaries in images, addressing a key limitation of Gaussian Splatting, and introduces a Bézier-boundary gradient approximation strategy to maintain differentiability.|[2405.15196v1](http://arxiv.org/abs/2405.15196v1)|null|
|**2024-05-24**|**Addressing Duplicated Data in Point Process Models**|Lingling Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a Modified Minimum Contrast (MMC) method to accommodate duplicated points in spatial point process models, which is demonstrated to outperform existing methods in simulation studies and applied to real-world conflict data from Afghanistan.|[2405.15192v1](http://arxiv.org/abs/2405.15192v1)|null|
|**2024-05-24**|**Diffusion Actor-Critic with Entropy Regulator**|Yinuo Wang et.al.|Here is a single sentence summary of the key contributions from the paper's abstract and introduction:The authors propose a novel online reinforcement learning algorithm, DACER, that leverages the representational capacity of diffusion models to model multimodal distributions, achieving state-of-the-art performance on MuJoCo benchmarks while enhancing policy exploratory capabilities.|[2405.15177v1](http://arxiv.org/abs/2405.15177v1)|null|
|**2024-05-24**|**Optimal Reference Nodes Deployment for Positioning Seafloor Anchor Nodes**|Wei Huang et.al.|The key contributions of the paper can be summarized as follows:* The paper proposes an optimal reference node deployment strategy for time-of-arrival (TOA) localization in three-dimensional (3D) underwater space, considering the non-uniform distribution of underwater sound speed.* The authors adopt the criterion of minimizing the trace of the inverse Fisher information matrix (FIM) to determine the optimal reference node deployment.* A new semi-closed form solution is found to determine the optimal geometries, which is more general and applicable to the 3D underwater space.* The authors demonstrate the effectiveness of the proposed method through both simulations and sea trials on underwater anchor node positioning.|[2405.15153v1](http://arxiv.org/abs/2405.15153v1)|null|
|**2024-05-24**|**Fluctuations around the mean-field limit for attractive Riesz potentials in the moderate regime**|Li Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors establish a central limit theorem for moderately interacting particles with attractive sub-Coulomb potentials, allowing for Gaussian fluctuations around the mean-field limit, and providing a new quantitative convergence result for smoothed empirical measures.|[2405.15128v1](http://arxiv.org/abs/2405.15128v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The key contributions of the paper are: proposing a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR imaging that can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, and presenting a Dual Dynamic Range Gaussian point cloud model with two Parallel Differentiable Rasterization processes.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose GS-Hider, a novel steganography framework for 3D Gaussian Splatting (3DGS), which embeds 3D scenes and images into original 3DGS point cloud files in an invisible manner, ensuring exceptional security, robustness, capacity, and flexibility for copyright protection and secret communication.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**Efficient Certificates of Anti-Concentration Beyond Gaussians**|Ainesh Bakshi et.al.|The paper presents a set of contributions, including developing a natural formulation for certifying anti-concentration for a broad class of distributions, exhibiting quasi-polynomial time certificates of anti-concentration using sum-of-squares relaxations, unifying previous applications of anti-concentration, and improving results for list-decodable linear regression and clustering mixtures of reasonably anti-concentrated distributions.|[2405.15084v1](http://arxiv.org/abs/2405.15084v1)|null|
|**2024-05-23**|**Scale-dependent chirality as a smoking gun for Abelian gauge fields during inflation**|Ogan Özsoy et.al.|The paper numerically studies particle production and its impact on scalar and tensor spectra in axion-inflation models with an Abelian gauge sector, finding significant deviations from previous approximate analytic templates and exploring the implications for gravitational wave detection.|[2405.14963v1](http://arxiv.org/abs/2405.14963v1)|null|
|**2024-05-23**|**EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting**|Jiaxu Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose EvGGS, a collaborative learning framework for event-based generalizable 3D Gaussian Splatting, which can reconstruct 3D scenes from raw event streams and generalize to unseen scenarios without retraining.|[2405.14959v1](http://arxiv.org/abs/2405.14959v1)|[link](https://github.com/mercerai/evggs)|
|**2024-05-23**|**The NANOGrav 15 yr Data Set: Chromatic Gaussian Process Noise Models for Six Pulsars**|Bjorn Larsen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper assesses the impact of different chromatic noise models on the achromatic noise properties of six pulsars, finding that the choice of model significantly affects noise properties, particularly for PSR J1713+0747, with potential implications for improving pulsar timing array sensitivity to gravitational waves.|[2405.14941v1](http://arxiv.org/abs/2405.14941v1)|null|
|**2024-05-23**|**Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution**|Zakariya Chaouai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper explores robust super-resolution (RSR) methods, introducing median randomized smoothing (MRS) as a universal approach to improve the robustness of deep learning SR models, achieving state-of-the-art results and outperforming adversarial learning techniques in real-world SR applications.|[2405.14934v1](http://arxiv.org/abs/2405.14934v1)|null|
|**2024-05-23**|**Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras**|Hanzhang Tu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper presents Tele-Aloha, a low-budget and high-authenticity bidirectional telepresence system that achieves high-resolution (2048x2048), real-time (30 fps), and low-latency (less than 150 ms) communication using only four sparse RGB cameras and one consumer-grade GPU.* The system focuses on upper-body communication and is designed to work with only four cameras, which increases the difficulty of novel view synthesis.* The paper introduces a novel view synthesis algorithm that includes a cascaded disparity estimator for obtaining a robust geometry cue, a neural rasterizer for projecting latent features onto target views, and a refiner module for refining the decoded image.* The system also uses a weighted blending mechanism to refine the decoded image and take advantage of the high-resolution RGB input.* The system has an affordable price tag of around $15,000, making it a consumer-grade product that can be mass-produced.|[2405.14866v1](http://arxiv.org/abs/2405.14866v1)|null|
|**2024-05-23**|**Analysis of Atom-level pretraining with QM data for Graph Neural Networks Molecular property models**|Jose Arjona-Medina et.al.|The contributions of the paper can be summarized as follows:1. The authors show that atom-level pretraining with quantum mechanics (QM) data improves performance and generalization on downstream tasks, including property modeling.2. They demonstrate that atom-level pretraining produces a more normal distribution of features compared to scratch and molecular-level pretraining.3. The authors show that atom-level pretraining produces a more robust molecular representation against distribution shift from train to eval and train to test datasets.In summary, the paper explores the effect of atom-level pretraining with QM data on molecular representations and their impact on property modeling. The results suggest that such pretraining can lead to better generalization and robustness to distribution shifts.|[2405.14837v1](http://arxiv.org/abs/2405.14837v1)|null|
|**2024-05-23**|**A central limit theorem for coefficients of L-functions in short intervals**|Sun-Kai Leung et.al.|The paper's abstract and introduction provide an overview of the main contributions, which are:1. A central limit theorem for the sum of coefficients of a general L-function in short intervals of appropriate length, assuming the generalized Lindelöf hypothesis (GLH), a weak generalized Ramanujan conjecture, and a Rankin-Selberg type partial sum estimate.2. The result generalizes Hughes-Rudnick's result on lattice point counts in thin annuli to a broader class of L-functions.3. The proof relies on the dual sum, which is the Voronoï summation formula without twists.The main theorem, Theorem 3.1, states that under the assumed conditions, the sum of coefficients of an L-function in short intervals has a Gaussian limiting distribution. The proof involves bounding the variance of the sum using the method of moments and tracking the dependencies on the parameters.The references provided at the end of the paper include various works on number theory, including the Lindelöf hypothesis, the Ramanujan conjecture, and the distribution of prime numbers.|[2405.14834v1](http://arxiv.org/abs/2405.14834v1)|null|
|**2024-05-23**|**A Quantum Speed-Up for Approximating the Top Eigenvectors of a Matrix**|Yanlin Chen et.al.|The paper presents two quantum algorithms for approximating the top eigenvector of a Hermitian matrix, with complexities of O(d^1.75) and O(d^1.5+o(1)), respectively, and proves a lower bound of O(d^1.5) on the quantum query complexity of approximating the top eigenvector.|[2405.14765v1](http://arxiv.org/abs/2405.14765v1)|null|
