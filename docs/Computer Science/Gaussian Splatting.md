
### Gaussian Splatting
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Sparse Expansion and Neuronal Disentanglement**|Shashata Sawmya et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a new approach called Sparse Expansion, which expands a pre-trained language model into a mixture of sparse experts, each of which is a copy of the original weights, one-shot pruned for a specific cluster of input values.* Sparse Expansion outperforms all other one-shot sparsification approaches for the same inference FLOP budget per token, and this gap grows as sparsity increases, leading to inference speedups.* The authors provide strong evidence that the mixture of sparse experts effectively disentangles the input-output relationship of every individual neuron across clusters of inputs, which improves model performance.* They also show that the Wasserstein distance between a neuron's output distribution and a Gaussian distribution is an indicator of its entanglement level and contribution to the accuracy of the model.* The authors demonstrate the effectiveness of Sparse Expansion across different model sizes, sparsity levels, and compression schemes, and achieve state-of-the-art performance for post-training one-shot sparsification.|[2405.15756v1](http://arxiv.org/abs/2405.15756v1)|null|
|**2024-05-24**|**Interaction in the dark sector: a phenomenological approach**|Z. C. Santana et.al.|The paper investigates the non-gravitational interaction between dark matter and dark energy, proposing three parameterizations for the dark matter energy density evolution law, and uses galaxy cluster gas mass fraction measurements, SNe Ia observations, Cosmic Chronometers, and BAO data to test these models, finding that the standard evolution law is within 2σ c.l.|[2405.15726v1](http://arxiv.org/abs/2405.15726v1)|null|
|**2024-05-24**|**Fast adiabatic preparation of multi-squeezed states by jumping along the path**|Chuan Chen et.al.|The key contributions from the paper's abstract and introduction are:* The authors introduce a novel shortcuts to adiabaticity (STA) method, called STAM, for fast and robust preparation of multi-squeezed states, which exhibit non-classical properties such as large phase-space Wigner negativities.* The STAM method is a new approach to construct parameterized Hamiltonians for adiabatic control, which eliminates the need for auxiliary driving and simplifies the process.* The authors demonstrate the high-fidelity and fast preparation of multi-squeezed states and hybrid entangled states between a bosonic mode and a qubit using the STAM method.* The method is based on the necessary and sufficient condition of quantum adiabatic evolution, which allows for the elimination of non-adiabatic errors.* The authors also discuss the importance of non-Gaussian resources, such as multi-squeezed states, for quantum information technology and their applications.Note that these contributions are summarized in a single sentence under 50 words.|[2405.15595v1](http://arxiv.org/abs/2405.15595v1)|null|
|**2024-05-24**|**A graph-space optimal transport FWI approach based on κ-generalized Gaussian distribution**|Sérgio Luiz E. F. da Silva et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The presentation proposes a new full-waveform inversion (FWI) approach based on graph-space optimal transport and κ-generalized Gaussian distribution, which is shown to be robust in mitigating cycle-skipping issues and non-Gaussian errors in seismic data inversion.|[2405.15536v1](http://arxiv.org/abs/2405.15536v1)|null|
|**2024-05-24**|**A Preference-oriented Diversity Model Based on Mutual-information in Re-ranking for E-commerce Search**|Huimu Wang et.al.|Here is a summary of the key contributions in one sentence under 50 words:This paper proposes a Preference-oriented Diversity Model Based on Mutual-information (PODM-MI) that balances accuracy and diversity in re-ranking for e-commerce search, demonstrating significant improvements in online experiments and being successfully deployed on an e-commerce search platform.|[2405.15521v1](http://arxiv.org/abs/2405.15521v1)|null|
|**2024-05-24**|**Feature Splatting for Better Novel View Synthesis with Low Overlap**|T. Berriel Martins et.al.|Here is a summarized version of the contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes Feature Splatting (FeatSplat), a novel approach that replaces spherical harmonics with learned feature vectors in 3D Gaussian Splatting, enabling the representation to generalize better to novel views with low overlap and distant views, improving novel view synthesis and semantic segmentation.|[2405.15518v1](http://arxiv.org/abs/2405.15518v1)|null|
|**2024-05-24**|**Learning to Discretize Denoising Diffusion ODEs**|Vinh Tong et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LD3, a lightweight framework that learns time discretization while sampling from diffusion ODEs encapsulated by DPMs, improving sampling efficiency and reducing computational costs without retraining neural networks.|[2405.15506v1](http://arxiv.org/abs/2405.15506v1)|null|
|**2024-05-24**|**GSDeformer: Direct Cage-based Deformation for 3D Gaussian Splatting**|Jiajun Huang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce GSDeformer, a method for free-form deformation on 3D Gaussian Splatting without modifying its architecture, achieved by converting 3DGS into a proxy point cloud representation, and propose an automatic cage construction algorithm for minimization of manual work.|[2405.15491v1](http://arxiv.org/abs/2405.15491v1)|null|
|**2024-05-24**|**Out of Many, One: Designing and Scaffolding Proteins at the Scale of the Structural Universe with Genie 2**|Yeqing Lin et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces Genie 2, an improved protein design model that can capture a larger and more diverse protein structure space through architectural innovations and massive data augmentation.* Genie 2 is capable of multi-motif scaffolding, which is a challenging problem that previous models have not been able to solve.* The model is evaluated on both unconditional and conditional protein generation, showing state-of-the-art performance in designability, diversity, and novelty.* Genie 2 is compared to other state-of-the-art models, including RFDiffusion and FrameFlow, and outperforms them in multi-motif scaffolding tasks.|[2405.15489v1](http://arxiv.org/abs/2405.15489v1)|null|
|**2024-05-24**|**Volumetric Primitives for Modeling and Rendering Scattering and Emissive Media**|Jorge Condor et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel volumetric representation based on kernel-based primitives for modeling and rendering scattering and emissive media, providing closed-form solutions for transmittance and emission, and efficient ray-tracing-based implementation for both forward and inverse rendering.|[2405.15425v1](http://arxiv.org/abs/2405.15425v1)|null|
|**2024-05-24**|**Stochastic SR for Gaussian microtextures**|Emile Pierret et.al.|The paper presents a novel, efficient, and provably exact sampler for stochastic Super-Resolution (SR) of Gaussian microtextures, which competes with deep learning state-of-the-art methods in terms of perceptual metric and execution time, and provides a framework for rigorously discussing the limitations of various reconstruction metrics.|[2405.15399v1](http://arxiv.org/abs/2405.15399v1)|null|
|**2024-05-24**|**Adaptive Finite Element Method for a Nonlinear Helmholtz Equation with High Wave Number**|Run Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Key contributions:**1. The paper presents a nonlinear Helmholtz (NLH) equation with high frequencies and corner singularities, and develops a linear finite element method (FEM) to discretize it.2. The authors derive wave-number-explicit stability estimates and singularity decomposition for the NLH problem, and establish a priori stability and error estimates for the FEM on shape-regular meshes, including locally refined meshes.3. A new residual-type error estimator is derived, which is equivalent to the standard one, but with a significant result: it seriously underestimates the error of the FE solution in the preasymptotic regime.4. Based on the new error estimator, the authors prove the convergence and quasi-optimality of the resulting adaptive finite element algorithm (AFEM) for the NLH problem, when the initial mesh size lies in the preasymptotic regime.5. Numerical examples validate the theoretical findings and demonstrate the efficiency of the AFEM in simulating nonlinear optical phenomena, such as optical bistability with Gaussian incident waves.|[2405.15344v1](http://arxiv.org/abs/2405.15344v1)|null|
|**2024-05-24**|**Discriminative Estimation of Total Variation Distance: A Fidelity Auditor for Generative Data**|Lan Tao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a discriminative approach to estimate the total variation (TV) distance between two distributions as an effective measure of generative data fidelity, establishing theoretical results on convergence rate and empirical validation through simulations and applications to synthetic image data.|[2405.15337v1](http://arxiv.org/abs/2405.15337v1)|null|
|**2024-05-24**|**Minimizing UCB: a Better Local Search Strategy in Local Bayesian Optimization**|Zheyi Fan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Key Contributions:**1. The paper develops a relationship between the steps of the gradient descent method and minimizing the Upper Confidence Bound (UCB).2. The paper proposes a new local Bayesian optimization algorithm, MinUCB, which replaces the gradient descent step with minimizing UCB in GIBO.3. The paper improves the local exploration acquisition function of MinUCB and obtains a more efficient algorithm, LA-MinUCB.4. The paper provides theoretical guarantees for the convergence rate of MinUCB and LA-MinUCB, showing that they maintain a similar convergence rate as GIBO.5. The paper demonstrates the effectiveness of the proposed algorithms through extensive experiments on synthetic and real-world functions.The paper's main contributions can be summarized as follows:* Developing a new local Bayesian optimization algorithm, MinUCB, which outperforms existing methods in some cases.* Improving the local exploration acquisition function of MinUCB, leading to a more efficient algorithm, LA-MinUCB.* Providing theoretical guarantees for the convergence rate of MinUCB and LA-MinUCB, showing that they are Bayesian optimal in some cases.* Demonstrating the effectiveness of the proposed algorithms through extensive experiments on synthetic and real-world functions.|[2405.15285v1](http://arxiv.org/abs/2405.15285v1)|null|
|**2024-05-24**|**DisC-GS: Discontinuity-aware Gaussian Splatting**|Haoxuan Qu et.al.|The key contributions from the paper's abstract and introduction are the proposal of a novel framework, DisContinuity-aware Gaussian Splatting (DisC-GS), which enables Gaussian Splatting to accurately render discontinuities and boundaries in images by introducing a "pre-scissoring" step using cubic Bézier curves and a Bézier-boundary gradient approximation strategy, thereby overcoming the fundamental limitation of Gaussian Splatting.|[2405.15196v1](http://arxiv.org/abs/2405.15196v1)|null|
|**2024-05-24**|**Addressing Duplicated Data in Point Process Models**|Lingling Chen et.al.|Key contributions from the paper's abstract and introduction:1. The paper discusses the issue of duplicated points in spatial point process models, which can occur due to geo-coding decisions or lack of exact location information.2. The authors propose the Modified Minimum Contrast (MMC) method to account for duplicated points without altering the data, and demonstrate its advantages over existing approaches.3. The paper also highlights the effect of geo-coding decisions on parameter estimation and provides insights into the implementation of the MMC method.4. The authors subsequently investigate the performance of the proposed method through simulation experiments and apply it to a real-world conflict data from Afghanistan.Note: The reply is limited to 50 words as requested.|[2405.15192v1](http://arxiv.org/abs/2405.15192v1)|null|
|**2024-05-24**|**Diffusion Actor-Critic with Entropy Regulator**|Yinuo Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose an online reinforcement learning algorithm, DACER, that combines diffusion models with actor-critic methods to enhance the representational capacity of the policy, achieving state-of-the-art performance in various control tasks.|[2405.15177v1](http://arxiv.org/abs/2405.15177v1)|null|
|**2024-05-24**|**Optimal Reference Nodes Deployment for Positioning Seafloor Anchor Nodes**|Wei Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an optimal reference node deployment strategy for time-of-arrival (TOA) localization in 3D underwater space, considering the non-uniform distribution of underwater sound speed, and derives a semi-closed form solution to minimize the trace of the inverse Fisher information matrix.|[2405.15153v1](http://arxiv.org/abs/2405.15153v1)|null|
|**2024-05-24**|**Fluctuations around the mean-field limit for attractive Riesz potentials in the moderate regime**|Li Chen et.al.|The key contributions of the paper can be summarized in one sentence:The authors establish a central limit theorem for moderately interacting particles with attractive or repulsive sub-Coulomb potentials, demonstrating that the fluctuations around the mean-field limit become asymptotically Gaussian in the large population limit, with a novel proof that allows for attractive potentials and uses a mean-square convergence in expectation with algebraic rate.|[2405.15128v1](http://arxiv.org/abs/2405.15128v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods by 3.84 and 1.91 dB with 1000x faster inference speed and 6.3% training time.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction:The paper proposes a steganography framework for 3D Gaussian Splatting (3DGS) called GS-Hider, which can embed 3D scenes and images into original GS point clouds in an invisible manner and accurately extract the hidden messages, ensuring security, fidelity, and high capacity.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**Efficient Certificates of Anti-Concentration Beyond Gaussians**|Ainesh Bakshi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper presents a new formulation for anti-concentration, which is a property of high-dimensional random variables.* The authors show that anti-concentration can be certified for a wide class of non-Gaussian distributions, including bounded product distributions and uniform distributions over Lp balls.* The paper provides quasi-polynomial time verifiable sum-of-squares certificates of anti-concentration for these distributions.* The authors also unify several prior applications of anti-concentration and resolve other open problems raised in prior works.Note that the summary is limited to a single sentence under 50 words and focuses on the main contributions of the paper.|[2405.15084v1](http://arxiv.org/abs/2405.15084v1)|null|
|**2024-05-23**|**Scale-dependent chirality as a smoking gun for Abelian gauge fields during inflation**|Ogan Özsoy et.al.|The paper presents a numerical study of particle production and its impact on cosmological perturbations in axion-inflation models with an Abelian gauge sector, finding significant deviations from previous approximate analytic results and predicting a scale-dependent chirality in the gravitational wave background.|[2405.14963v1](http://arxiv.org/abs/2405.14963v1)|null|
|**2024-05-23**|**EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting**|Jiaxu Wang et.al.|Here is a summary of the key contributions from the abstract and introduction:* The authors propose a novel event-based 3D reconstruction framework, called EvGGS, which reconstructs scenes as 3D Gaussians from raw event input in a feedforward manner and can generalize to unseen cases without retraining.* EvGGS includes a depth estimation module, an intensity reconstruction module, and a Gaussian regression module, which are trained collaboratively using a joint loss function.* The authors also introduce a novel event-based 3D dataset, Ev3DS, with varying material objects and well-calibrated labels of grayscale images, depth maps, camera poses, and silhouettes.* The contributions can be summarized as follows:	1. Proposing the first event-based, generalizable 3D Gaussian framework (EvGGS) that reconstructs scenes from raw event streams.	2. Introducing an end-to-end collaborative learning framework to jointly train event-based monocular depth estimation, intensity recovery, and 3D Gaussian reconstruction.	3. Establishing a novel event-based 3D dataset (Ev3DS) to facilitate related studies.Note that the contributions are focused on the development of an event-based 3D reconstruction framework and the presentation of a novel dataset, rather than reviewing existing related work.|[2405.14959v1](http://arxiv.org/abs/2405.14959v1)|[link](https://github.com/mercerai/evggs)|
|**2024-05-23**|**The NANOGrav 15 yr Data Set: Chromatic Gaussian Process Noise Models for Six Pulsars**|Bjorn Larsen et.al.|The paper assesses the impact of different chromatic noise models on the achromatic noise properties of pulsars, comparing existing models used by NANOGrav and EPTA DR2, and finds that the choice of model noticeably affects the achromatic noise properties of several pulsars, with potential implications for PTA sensitivity to gravitational waves.|[2405.14941v1](http://arxiv.org/abs/2405.14941v1)|null|
|**2024-05-23**|**Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution**|Zakariya Chaouai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper explores the universality of robustness methods for deep learning-based image Super-Resolution (SR) models, discovering that Median Randomized Smoothing (MRS) is more general and effective than other methods in handling a wide range of adversarial attacks and real-world corruptions.|[2405.14934v1](http://arxiv.org/abs/2405.14934v1)|null|
|**2024-05-23**|**Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras**|Hanzhang Tu et.al.|The key contributions from the paper's abstract and introduction are:1. The development of a low-budget and high-authenticity bidirectional telepresence system, Tele-Aloha, which uses only four sparse RGB cameras, one consumer-grade GPU, and one autostereoscopic screen to achieve high-resolution (2048x2048), real-time (30 fps), low-latency (less than 150ms) and robust distant communication.2. The design of a novel view synthesis algorithm that uses a cascaded disparity estimator to obtain robust geometry cues, a neural rasterizer, and a decoder network to generalize to any unseen person and achieve high-fidelity rendering.3. The implementation of an efficient refinement module that upsamples the novel view rendering to the final output resolution.4. The use of weighted blending to refine the decoded image and provide strong cues to the refinement module.5. The development of a system that is affordable and can be mass-produced, with a total cost of around $15,000.|[2405.14866v1](http://arxiv.org/abs/2405.14866v1)|null|
|**2024-05-23**|**Analysis of Atom-level pretraining with QM data for Graph Neural Networks Molecular property models**|Jose Arjona-Medina et.al.|Key Contributions:* Atom-level pretraining with quantum mechanics data improves performance in downstream molecular property modeling tasks.* Atom-level pretraining creates a more normal distribution of features, making the learned molecular representations more robust against distribution shifts.* Molecule-level pretraining yields worse performance than atom-level pretraining and scratch results in some datasets.* The study shows that pretrained models can learn more valuable molecular representations, which explains the performance gain in most datasets.|[2405.14837v1](http://arxiv.org/abs/2405.14837v1)|null|
|**2024-05-23**|**A central limit theorem for coefficients of L-functions in short intervals**|Sun-Kai Leung et.al.|The paper's abstract and introduction summarize the main contributions of the paper, which are:* A central limit theorem for the coefficients of a general L-function in short intervals of appropriate length, assuming the generalized Lindelöf hypothesis, a weak generalized Ramanujan conjecture, and a Rankin-Selberg type partial sum estimate.* The theorem generalizes the results of Hughes-Rudnick and Harper on lattice point counts in thin annuli and short character sums, respectively.* The authors use the method of moments and the Voronoi summation formula to prove the theorem.The main result, Theorem 3.1, states that if the conditions of the theorem are satisfied, then the sum of the coefficients of the L-function in a short interval of length δ is asymptotically normally distributed with mean 0 and variance σf (δ)2.|[2405.14834v1](http://arxiv.org/abs/2405.14834v1)|null|
|**2024-05-23**|**A Quantum Speed-Up for Approximating the Top Eigenvectors of a Matrix**|Yanlin Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents two quantum algorithms with complexities of O(d^1.75) and O(d^1.5+o(1)) to approximate the top eigenvector of a Hermitian matrix, outperforming classical algorithms, and a nearly-optimal lower bound on the quantum query complexity of approximating the top eigenvector.|[2405.14765v1](http://arxiv.org/abs/2405.14765v1)|null|
