
### Gaussian Splatting
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings, using 3D Gaussian Splatting and neural parametric head models, outperforming the state-of-the-art by 2.6 PSNR on the self-reenactment task.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose DGD, a unified 3D representation that learns dynamic radiance fields with joint optimization of appearance and semantic attributes, enabling dense semantic 3D object tracking and rendering in real-time for a diverse set of scenes.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel clustered differentially private federated learning algorithm that clusters clients based on both model updates and training loss values, addressing performance disparities and maintaining high accuracy with differential privacy guarantees.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper proposes a novel sampling method, named Weak Generative Sampler (WGS), to estimate the invariant distribution of an Ito diffusion process and generate independent and identically distributed (iid) samples from it. The WGS method employs a weak generative model based on the weak form of the Fokker-Planck equation and normalizing flows to characterize the invariant distribution and facilitate sample generation from the base distribution.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors develop a polynomial-gaussian expansion in the field-following coordinate to describe ion temperature gradient (ITG) driven localized modes, capturing wave-particle and magnetic drift effects, and provide a semi-analytical formula for the mode spectrum, which exhibits multiple maxima observed in gyrokinetic simulations.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method, $E^3$Gen, for efficient, expressive, and editable digital avatar generation using a 3D Gaussian representation, a generative UV features plane, and a part-aware deformation module, achieving superior performance and versatility in avatar generation and editing.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper implements Gaussian process regression to reconstruct the universe's expansion history using various SN-Ia and BAO datasets, providing evidence for a quintessence-like dark energy scenario, constraining $H_0 r_d$, and highlighting discrepancies between different datasets.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of a new neural operator called DeepOKAN, which uses Kolmogorov-Arnold networks (KANs) rather than conventional neural network architectures.* The use of Gaussian radial basis functions (RBFs) instead of B-splines, resulting in a significant computational speedup.* The demonstration of the effectiveness of DeepOKAN in solving mechanics problems, including 2D orthotropic elasticity.* The observation that DeepOKAN outperforms the traditional DeepONet with the same number of learnable parameters, and that training DeepOKAN for more epochs yields a computational boost.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Prior-guided Bayesian Optimization (P-BO), an efficient black-box adversarial attack method that leverages a surrogate model as a function prior to improve query efficiency and attack success rates, outperforming state-of-the-art methods on various benchmarks.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a measurement-based method to implement general, multi-mode, and higher-order non-Gaussian gates using fixed non-Gaussian ancillary states and adaptive linear optics.* The method allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates that are important for various applications in optical quantum technology.* The authors show that their method can be used to implement the cubic quantum non-demolition gate and the CV Toffoli gate, which are important for fault-tolerant universal quantum computing and efficient quantum simulation.The paper's introduction highlights the importance of non-Gaussian operations in optical quantum information processing, and how they are crucial for many practical tasks such as fault-tolerant universal quantum computing and quantum simulation. The authors also discuss the challenges of implementing non-Gaussian gates, and how their measurement-based method addresses these challenges.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|The paper presents a novel framework to evaluate the effectiveness of stochastic continuous gravitational-wave (CW) follow-ups, allowing for a ten-fold reduction in computing cost using pyfstat, a well-established follow-up method.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose the Multi-scale Deep Feature Statistics (MDFS) model for opinion-unaware blind image quality assessment, integrating deep features from pre-trained visual models with statistical analysis to eliminate the reliance on human rating data and achieve superior performance.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a learning-to-prune (LP-3DGS) method that automatically determines the optimal pruning ratio for 3D Gaussian Splatting (3DGS) by leveraging a trainable mask and Gumbel-Sigmoid activation function, enabling efficient and high-quality novel view synthesis.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a Markov chain Monte Carlo (MCMC) algorithm, Plug-and-Play Diffusion Models (PnP-DM), that rigorously solves Bayesian image denoising problems using a range of state-of-the-art diffusion models (DMs) as image priors. This method circumvents approximations in the generative process, providing more accurate sample distributions that deviate from the target posterior. The paper's key contributions include: (1) a new MCMC algorithm that samples the posterior distribution using a unified interface for DMs, (2) a connection between Bayesian denoising and unconditional image generation under a general DM formulation, and (3) strong empirical performance on three linear and three nonlinear noisy inverse problems, including a black hole imaging problem.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|The key contributions from the paper's abstract and introduction are:1. The proposal of a novel Language Model-based Optimal Differential Privacy (LMO-DP) mechanism for fine-tuning large-scale pre-trained language models.2. The development of a two-fold mixture distribution-derived noise generation method to ensure a tight composition of accuracy and privacy, even in strong privacy regimes (e.g., ε < 3).3. The introduction of a novel offline optimal noise search method to efficiently derive the sub-optimal DP mechanism without sacrificing accuracy.4. Experimental results showing the effectiveness of LMO-DP in fine-tuning RoBERTa-large and Llama-2 with strong DP guarantees, achieving higher accuracy than existing methods.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Deep Bayesian Filtering (DBF), a novel methodology for data assimilation that constructs new latent variables on a "fancy space" and learns a Gaussian inverse observation operator using neural networks, allowing for analytical computation of posteriors and outperforming existing methods.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper explores the application of quantum computing models, boson sampling and Gaussian boson sampling, to the unsupervised learning problem of biclustering, proposing heuristics and simulating the results for detecting clusters in a dataset.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces CCR, a novel approach that employs conformal prediction intervals for model outputs to construct confidence regions for model parameters with finite-sample validity under minimal assumptions on data distribution, and demonstrates its applicability to various methodologies.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper investigates the transition from quantum to classical mechanics using a one-dimensional free particle model, demonstrating that quantum probability density can be equivalent to classical distributions, and proposing a novel method to recover classical behavior using Fourier analysis.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|The key contributions from the paper's abstract and introduction are:1. The paper introduces a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components.2. The paper derives an operator norm bound on the estimation error in terms of the sparsity level of the covariance and the expected supremum of the normalized process.3. The paper demonstrates the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings.4. The paper contributes to the emerging literature on operator estimation and learning, emphasizing the importance of exploiting structural assumptions in the design and analysis of estimators.5. The paper focuses on the infinite-dimensional setting, where it reveals key dimension-free quantities that control the estimation error and explains how the correlation lengthscale and the marginal variance function affect the estimation problem.In summary, the paper presents a novel covariance operator estimator that adapts to the nonstationary nature of the data and provides a theoretical justification for its performance, with the aim of improving estimation accuracy in high-dimensional settings.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proves that a class of analytic radial basis functions (RBFs) that vanish at infinity, including Gaussians, Generalized Inverse MultiQuadrics, and Matern RBFs, ensure the almost sure invertibility of unsymmetric Kansa collocation matrices for the Poisson equation with Dirichlet boundary conditions.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|The paper discusses how the dark matter subhalos perturb the orbits of stars in stellar streams, leading to non-Gaussian velocity distributions with Gaussian cores and exponential wings, which can be used to constrain the nature of dark matter.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The key contributions from the paper's abstract and introduction can be summarized as follows:* The paper proposes a general theoretical description of spin self-diffusion under nonlinear gradient fields, which extends the effective phase diffusion method for linear gradient fields.* The proposed method reveals the general features of phase evolutions in nonlinear gradient fields, including three types of phase evolutions: phase diffusion, float phase evolution, and shift based on the starting position.* The method shows that the diffusing and float phase evolutions come from the first and second derivatives of the gradient field, respectively.* The paper provides a general expression for the phase variance and corresponding NMR signal attenuation, which is demonstrated using calculations under parabolic and cubic fields.* The results indicate that signal attenuation obeys Gaussian attenuation for a short time, but changes to Lorentzian or Mittag-Leffler function attenuations when time increases.* The paper also discusses the limitations of existing theories, including the need for new theoretical treatments to understand the nonlinear gradient field better.* The method is shown to be versatile and can be applied to calculate signal attenuation for various situations, including higher-order gradient fields and fractional diffusion.The paper's abstract and introduction highlight the importance of developing new theoretical treatments to understand the nonlinear gradient field better, and the proposed method is shown to be a powerful tool for describing spin self-diffusion under nonlinear gradient fields.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|The paper derives closed-form expressions for optimal decision boundaries in binary classification of high-dimensional overlapping Gaussian mixture model (GMM) data, showing how they depend on the eigenstructure of class covariances, and empirically demonstrates that deep neural networks trained for classification approximate these optimal classifiers.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces GFlow, a novel framework that uses 2D priors (depth and optical flow) to reconstruct a 4D world from a single monocular video input without camera parameters, and simultaneously tracks points across frames and segments moving objects in an unsupervised manner.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|The authors propose 3DitScene, a novel framework for scene image editing, which enables seamless 2D-to-3D editing with precise control over scene composition and individual objects, by leveraging language-guided disentangled Gaussian Splatting and disentangling objects accurately, addressing the limitations of existing methods.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce StreetUnveiler, a method that uses hard-label semantic 2D Gaussian Splatting (2DGS) and a time-reversal inpainting framework to reconstruct an empty street from in-car camera videos, overcoming obstacles like limited object observation and temporal inconsistency.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present a perturbation approach to calculate the short-time propagator of the one-dimensional Fokker-Planck equation to arbitrary order, preserving probability and enabling accurate evaluation of expectation values, and validate the results with a numerical example showing improvements over the Gaussian approximation.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|Here are the key contributions from the paper's abstract and introduction:**Abstract:**1. The paper presents three key improvements to accelerate iterative Gaussian process (GP) methods: a pathwise gradient estimator, warm starting linear system solvers, and early stopping.2. These techniques provide speed-ups of up to 72× when solving to tolerance and decrease the average residual norm by up to 7× when stopping early.**Introduction:**1. Iterative GP methods are essential for large-scale GP problems, but their scalability is limited by the computational cost of solving linear systems.2. The paper focuses on iterative methods, which use linear system solvers to construct an estimate of the marginal likelihood gradient.3. The authors identify three key improvements: (i) a pathwise gradient estimator, (ii) warm starting linear system solvers, and (iii) early stopping linear system solvers.4. These techniques are applied to different linear system solvers, including conjugate gradients, alternating projections, and stochastic gradient descent.5. The paper aims to accelerate marginal likelihood optimisation for iterative GPs, enabling the use of larger datasets and more complex models.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a three-level hierarchy of marginal likelihood optimisation for iterative Gaussian processes, which involves iterative optimisation, gradient estimation, and linear system solving.* The authors identify that the computational costs are dominated by solving sequential batches of large positive-definite systems of linear equations.* The authors propose to amortise computations by reusing solutions of linear system solvers as initialisations in the next step, providing a "warm start" approach.* The authors demonstrate the effectiveness of the warm start approach, achieving the same results as the conventional procedure while providing up to a 16× average speed-up among datasets.The paper's abstract and introduction provide an overview of the problem of marginal likelihood optimisation for iterative Gaussian processes, and the proposed solution involves using iterative optimisation, gradient estimation, and linear system solving. The authors identify the computational bottleneck as solving sequential batches of large positive-definite systems of linear equations, and propose to amortise computations by reusing solutions of linear system solvers as initialisations in the next step. The authors demonstrate the effectiveness of the warm start approach through experimental results.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
