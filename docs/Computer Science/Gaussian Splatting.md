
### Gaussian Splatting
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach that creates high-fidelity, controllable avatars from multi-view video recordings, leveraging neural parametric head models and 3D Gaussian Splatting for efficient rendering and photo-realistic reconstructions.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Dynamic Gamma Distribution (DGD), a unified 3D representation that captures appearance, geometry, and semantics of dynamic 3D scenes, allowing for efficient semantic understanding and manipulation of dynamic scenes, and enabling dense semantic 3D object tracking.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|The paper proposes a novel clustered DPFL algorithm that identifies clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees, addressing performance disparities and disparate impact in DPFL through a hybrid clustering approach combining model updates and loss values.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a weak generative sampler framework to directly generate independent and identically distributed samples from the invariant distribution of a stochastic differential equation, utilizing a transformation map derived from the stationary Fokker-Planck equation and a novel loss function.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors develop a simple semi-analytical model that captures the key features of Ion Temperature Gradient (ITG) driven localized modes, including wave-particle and magnetic drift resonant effects, Landau damping, and ion-scale Larmor radius stabilization, while resolving the problem using a polynomial-gaussian expansion in the field-following coordinate.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|The paper proposes a novel avatar generation method, $E^3$Gen, which combines 3D Gaussian representation with diffusion models to generate efficient, expressive, and editable digital avatars, addressing the challenges of unstructured 3D Gaussian and expressive animation in a generative setting.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper implements Gaussian process regression to reconstruct the universe's expansion history using various SN-Ia compilations and BAO measurements, providing evidence for a quintessence-like dark energy scenario and constraining $H_0 r_d$ without assuming pre-recombination physics.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper introduces a new neural operator called DeepOKAN, which uses Kolmogorov-Arnold networks (KANs) instead of conventional neural network architectures and Gaussian radial basis functions (RBFs) instead of B-splines. The DeepOKAN is used to develop surrogates for different mechanics problems, and it requires a smaller number of learnable parameters than current MLP-based DeepONets to achieve comparable accuracy.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The proposed Prior-guided Bayesian Optimization (P-BO) algorithm incorporates a surrogate model as a function prior to improve the query efficiency of black-box adversarial attacks, achieving higher attack success rates and requiring fewer queries compared to state-of-the-art methods.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a measurement-based method to implement general, multi-mode, and higher-order non-Gaussian gates using fixed non-Gaussian ancillary states and adaptive linear optics.* The method allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates, including the two-mode cubic quantum non-demolition gate and the three-mode continuous-variable Toffoli gate, and their higher-order extensions.* The authors show that their method can reduce the number of ancillary modes required for implementing higher-order gates compared to conventional schemes.The key contributions from the paper's sections are:* Section II introduces the definitions and notations used throughout the paper.* Section III discusses the gate decomposition into quadrature gates, showing that any multi-mode unitary operation can be decomposed into linear operations and Hamiltonians of the form xmk.* Section IV presents the measurement-based implementation of quadrature gates, showing that the measurement of non-Gaussian operators can be performed using multi-mode non-Gaussian ancillary states and linear optics.* Section V proposes implementations of multi-mode 3rd-order gates, introducing the concept of generalized linear coupling.* Section VI describes some examples of 3rd-order gates and their implementations.* Section VII presents the general methodology of how to implement higher-order gates.* Section VIII proposes some heuristic approaches to reduce the number of ancillary modes using mathematical tools such as Chow decomposition.* Section IX presents some examples of higher-order gates and demonstrates the resource-efficiency of the proposed method.Overall, the paper presents a new method for implementing higher-order non-Gaussian gates in continuous-variable quantum systems, which has the potential to improve the efficiency and feasibility of quantum information processing applications.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors develop a novel framework to evaluate the effectiveness of stochastic continuous gravitational-wave follow-ups, achieving a ten-fold reduction in computing cost and simplifying multi-stage follow-up schemes, with implications for increasing the sensitivity of all-sky searches in future LIGO-Virgo-KAGRA observing runs.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the abstract and introduction in a single sentence under 50 words:The authors propose a multi-scale deep feature statistics (MDFS) model for opinion-unaware blind image quality assessment, combining pre-trained deep features with statistical analysis to achieve cost-effective and human-consistent image quality evaluation, outperforming state-of-the-art methods in terms of both efficiency and performance.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a learning-to-prune 3D Gaussian Splatting (LP-3DGS) method that automatically determines the optimal pruning ratio for each scene, without requiring manual tuning, by designing a trainable mask using the Gumbel-Sigmoid activation function to minimize the model size while maintaining rendering quality.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is the summary of the key contributions in one sentence under 50 words:The proposed Markov chain Monte Carlo algorithm, Plug-and-Play Diffusion Models (PnP-DM), integrates diffusion models (DMs) in a principled way, circumventing approximations and enables rigorous posterior sampling for general inverse problems using state-of-the-art DMs as image priors.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|Here is a summary of the paper's key contributions:* The paper proposes a novel Language Model-based Optimal Differential Privacy (LMO-DP) mechanism that provides a tight composition of private training performance and strong privacy guarantees.* LMO-DP is a non-Gaussian mechanism that generates sub-optimal noise to ensure strong differential privacy, and is the first mechanism to support large language models (LLMs).* The paper shows that LMO-DP can significantly boost the performance of DP-SGD and other variants with high noise reduction, particularly in strong privacy regimes (e.g., epsilon < 3).* LMO-DP is also the first solution to accurately fine-tune LLMs with strong differential privacy guarantees, such as epsilon = 0.3 and delta = 10^-10.The paper introduces several key concepts and techniques, including:* R2DP: a universal and automated approach to optimizing randomization mechanisms for differential privacy.* Rényi Accountant: a method for accounting the privacy expenditure of differential privacy mechanisms.* LMO noise: a novel noise mechanism generated using a two-fold mixture distribution derived from the R2DP framework.* Off-line optimal noise search method: a technique for efficiently deriving the sub-optimal DP noise that minimizes the privacy expenditure.Overall, the paper's contributions and techniques aim to provide a rigorous and practical solution for ensuring differential privacy in the training of large language models.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel data assimilation methodology, Deep Bayesian Filtering (DBF), which constructs a new latent space and approximates the inverse observation operator using neural networks, allowing for Gaussian posteriors and recursive computation of the estimate without accumulating Monte-Carlo sampling errors.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|The authors propose using quantum computing models like boson and Gaussian boson sampling to identify biclusters in a dataset, and develop a heuristic to find clusters by converting the dataset into a bipartite graph and then applying Gaussian boson sampling.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a novel approach, Conformal Confidence Regions (CCR), which employs conformal prediction intervals to construct confidence regions for model parameters, providing finite-sample validity under minimal assumptions, and applicable to various methodologies, including black-box models.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper investigates the transition from quantum to classical mechanics using a one-dimensional free particle model, demonstrating that the quantum probability density can be equivalent to the classical distribution, and proposing a novel method to recover classical behavior using truncated Fourier analysis.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components.* The estimator is shown to have a smaller estimation error than the universal threshold and sample covariance estimators in nonstationary settings.* The paper studies sparse covariance operator estimation in an infinite-dimensional function space setting, focusing on the case where the marginal variance varies widely in the domain and the correlation lengthscale is small.* The authors introduce a new class of covariance operators that satisfy a weighted Lq-sparsity condition, and establish a bound on the operator norm error of the adaptive threshold estimator in terms of two dimension-free quantities: the sparsity level and the expected supremum of the normalized field.* The paper provides a detailed comparison with the existing infinite-dimensional covariance estimation literature and highlights the importance of exploiting structural assumptions in the design and analysis of estimators.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proves that a class of analytic RBFs, including popular Positive Definite instances such as Gaussians, Generalized Inverse MultiQuadrics, and Matern RBFs, lead to almost sure invertibility of unsymmetric random Kansa collocation matrices for the Poisson equation with Dirichlet boundary conditions.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|The authors investigate how dark matter subhalos perturb stellar streams in galactic halos, finding that the resulting velocity distributions can constrain WDM cosmology models, with the measurement prospects discussed.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The key contributions of the paper can be summarized as follows:1. The authors propose a general theoretical description of spin self-diffusion under nonlinear gradient fields, extending the effective phase diffusion method for linear gradient fields.2. They show that the phase evolutions in nonlinear gradient fields can be divided into three types: phase diffusion, float phase evolution, and shift based on the starting position.3. The authors derive expressions for the phase variance and corresponding NMR signal attenuation under parabolic and cubic fields, demonstrating that signal attenuation obeys Gaussian, Lorentzian, or Mittag-Leffler function attenuations.4. They also discuss the effects of nonlinear gradient fields on diffusion-based imaging and the importance of accurate theoretical expressions for understanding and interpreting experimental results.5. The authors provide numerical simulations to verify their theoretical results and demonstrate the applicability of their method to various situations, including fractional diffusion.Overall, the paper presents a comprehensive study of spin self-diffusion under nonlinear gradient fields, providing a new perspective on the phase evolution of spin coherence and its impact on NMR signal attenuation.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper derives closed-form expressions for Bayes optimal decision boundaries in binary classification of high-dimensional overlapping Gaussian mixture model data, and empirically demonstrates that neural networks trained for classification learn predictors that approximate these optimal classifiers in both simulated and real-world data.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|The key contributions from the paper's abstract and introduction are:* The problem of reconstructing 4D scenes from a single, uncalibrated monocular video input is formulated as "Any Video-to-4D" or "AnyV4D", which is a highly challenging task.* A new framework called GFlow is introduced, which utilizes 2D priors (depth and optical flow) to lift a video to a 4D explicit representation, enabling reconstruction of dynamic 3D scenes and camera motion from a single video input without any camera parameters.* GFlow is able to reconstruct dynamic scenes in high quality, track any points across frames in 3D world coordinates without prior training, and segment moving objects from the scene in an unsupervised way.* The framework achieves state-of-the-art results in video reconstruction quality and camera pose accuracy on benchmark datasets.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose 3DitScene, a novel scene editing framework that leverages language-guided disentangled Gaussian Splatting to enable unified 3D editing of scene composition and individual objects, allowing for precise control over scene editing at both global and individual levels.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The StreetUnveiler method reconstructs an empty 3D street scene from crowded in-car camera video observations by introducing a novel 3D representation using hard-label semantic 2D Gaussian Splatting, temporal decomposition, and a time-reversal inpainting framework to maintain temporal consistency and achieve scalable representation.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|The key contributions from the paper's abstract and introduction are:* The development of a perturbation approach to calculate the short-time propagator (transition density) of the one-dimensional Fokker-Planck equation to arbitrary order in the time increment.* The preservation of probability exactly and the ability to evaluate expectation values of analytical observables to arbitrary accuracy.* The derivation of perturbation expansions for the moments of the spatial increment, finite-time Kramers-Moyal coefficients, and mean medium entropy production rate.* The validation of the perturbative results for an explicit multiplicative-noise system with an available analytical solution.* The comparison of the perturbative results with those obtained from the Gaussian approximation of the short-time propagator, which is shown to lead to errors that can be many orders of magnitude larger than those resulting from the perturbation approach.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|Here are the key contributions from the paper's abstract and introduction:* The paper focuses on iterative methods for scaling hyperparameter optimization to very large datasets in Gaussian process (GP) regression.* The authors identify three key improvements to accelerate iterative GPs:	1. A pathwise gradient estimator that reduces the required number of solver iterations and amortises the computational cost of making predictions.	2. Warm starting linear system solvers with the solution from the previous step, which leads to faster solver convergence at the cost of negligible bias.	3. Early stopping linear system solvers after a limited computational budget, which synergises with warm starting and allows solver progress to accumulate over multiple marginal likelihood steps.* These techniques provide speed-ups of up to 72× when solving to tolerance and decrease the average residual norm by up to 7× when stopping early.* The authors also demonstrate empirical results on several large datasets, showing the effectiveness of their methods in reducing computation time and improving predictive performance.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions of the paper can be summarized as follows:1. The authors propose a three-level hierarchy for marginal likelihood optimisation for iterative Gaussian processes, which allows for a trade-off between computation time and accuracy of the solution.2. They identify that the computational costs are dominated by solving sequential batches of large positive-definite systems of linear equations.3. They propose a warm start method, which reuses the solution of the previous step as an initialisation for the next step, providing a significant speed-up without degrading performance.4. They demonstrate the effectiveness of the warm start method on regression tasks, achieving the same results as the conventional procedure while providing up to a 16x average speed-up among datasets.5. They provide an empirical evaluation of the proposed method on various datasets using different linear system solvers, including conjugate gradients, alternating projections, and stochastic gradient descent.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
