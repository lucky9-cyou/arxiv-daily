
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Self-Supervised Street Gaussian (S3Gaussian), a method that decomposes dynamic and static 3D Gaussians in street scenes without manual annotations, enabling efficient 3D scene reconstruction and novel view synthesis tasks with state-of-the-art rendering quality.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:TetSphere splatting is an explicit, Lagrangian geometry representation that directly yields high-quality meshes without neural networks or post-processing, offering faster optimization, enhanced mesh quality, and reliable preservation of thin structures.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here is a summarized version of the key contributions and main points from the paper's abstract and introduction:**Key Contributions:**1. Creation of a new set of FF synthetic and real visual scenes with respective camera poses, usable for assessing NVS methods.2. Subjective evaluation of NVS methods using a well-known and reliable subjective assessment methodology, considering different scene classes and recently proposed NVS methods.3. Evaluation of the performance of state-of-the-art IQA and VQA metrics in the context of NVS, using different scene classes.**Main Points:**1. NVS is a technology that enables high-quality, immersive visual content from multiple viewpoints, with applications in virtual/augmented reality, 3D modeling, and film entertainment.2. NVS methods have structural limitations that may lead to artifacts in the final visual result, negatively impacting perceived quality.3. Existing 2D image and video quality assessment metrics are not sufficient for evaluating NVS quality, and new metrics specifically designed for NVS are needed.4. The paper presents a comprehensive evaluation of NVS quality assessment, including subjective and objective assessments, and identifies the strengths and weaknesses of different NVS solutions for different scene classes.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MG-SLAM, an RGB-D Gaussian SLAM system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness, using line features for robust tracking and surface completion to overcome limitations in indoor environments.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:IReNe, a novel approach, addresses the limitations of existing NeRF color editing techniques by introducing a trainable segmentation module, automated neuron classification, and selective fine-tuning of the last network layer, enabling swift and consistent color editing in NeRF models.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|The key contributions from the paper's abstract and introduction are:* Using in-air 3D sonar to detect and classify ten different reflector landmarks with varying radii, enhancing the robustness and accuracy of autonomous systems in challenging environments.* Developing a convolutional neural network (CNN) that uses a bio-inspired representation of the reflected echoes in the form of a cochleogram to classify and predict the orientation of the detected landmarks.* Achieving a 97.3% classification accuracy on the test dataset and accurately detecting both the presence and absence of landmarks, as well as predicting landmark orientation angles with an RMSE lower than 10 degrees.* Building on previous research, this paper expands on the work by Simon et al. and uses a CNN with supervised learning to classify and detect reflector landmarks with unique radii values.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a single sentence summarizing the paper's abstract and introduction:This paper proposes a novel batch simultaneous localization and mapping (SLAM) approach for joint calibration of multiple asynchronous microphone arrays and sound source localization, addressing the challenging problem of parameter identification and calibration in microphone array-based robotic auditory systems.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles using symmetry prior, regularization constraints, and large human datasets, achieving improved performance by over 15% PSNR compared to state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a novel approach to lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation.* The method learns a novel feature field within a Neural Radiance Field (NeRF) representing a 3D scene, whose segmentation structure can be revealed at different scales by simply using different thresholds on feature distance.* The authors use ultrametric distances, which are ideally suited for hierarchical clustering, to group pixels in the feature space and create a hierarchical structure.* The method can produce view-consistent hierarchical segmentations at arbitrary levels of granularity, which is not possible with existing methods.Note that these are the main contributions mentioned in the abstract and introduction, and the paper provides more details and results in the subsequent sections.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|The paper introduces a 3DGS-based SLAM system that leverages the efficiency and flexibility of 3DGS to achieve real-time performance while remaining robust against sensor noise, motion blur, and long-session SLAM challenges, via a Fusion Bridge module that integrates tracking-centered ORB Visual Odometry with online 3DGS.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that applies neural radiance fields (NeRF) to monocular gastroscopic data for synthesizing high-quality images from novel viewpoints, which addresses the limitations of traditional 3D reconstruction methods and outperforms existing NeRF methods in terms of image quality.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeRF On-the-go, a simple yet effective method, enables robust novel view synthesis in complex, real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving a faster convergence speed, and significantly outperforming state-of-the-art techniques in various scenes.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the abstract and introduction:The authors propose a self-supervised pre-training framework, called NS-MAE, for multi-modal perception models in autonomous driving, which is transferable to both multi-modal and single-modal perception models. The NS-MAE framework learns transferable multi-modal representations by masking and reconstructing multi-modal input data, such as images and LiDAR point clouds, using neural radiance fields (NeRF). The framework is designed to be scalable, adaptable, and unified, making it suitable for diverse input modalities and architectures.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Based on the abstract and introduction, the key contributions of this paper are:* The authors propose a refined representation of 3D Gaussians for high-quality dynamic scene reconstruction, which outperforms existing methods in terms of rendering quality, speed, and memory usage.* The authors employ a hybrid representation that combines deformation fields, hash encoding, and 3D Gaussians to reduce storage consumption and improve rendering accuracy.* The authors introduce a learnable denoising mask to filter out noise points from the scene, which enhances rendering quality and reduces memory usage.* The authors utilize static constraints and motion consistency constraints to mitigate motion artifacts in the points, ensuring accuracy and efficiency in rendering.In summary, the contributions of this paper are threefold: a hybrid representation, a learnable denoising mask, and constraints for mitigating motion artifacts.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of the paper are:* A method that enables 3DGS manipulation, allowing for direct transfer of mesh manipulation to 3DGS with 3DGS self-adaptation, which maintains high-quality rendering.* The introduction of a triangle shape-aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations.Note: The above summary is under 50 words.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) while maintaining high-quality image rendering. F-3DGS employs factorization techniques to represent dense clusters of Gaussians with significantly fewer Gaussians, reducing storage overhead and enabling real-time rendering. The method achieves a storage reduction of over 90% compared to 3DGS, while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome limitations of ORB-SLAM3 in processing colonoscopy videos, achieving real-time performance and significantly improving mapping coverage and relocalization accuracy.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Pyramidal 3D Gaussian Splatting (PyGS) with NeRF initialization, which enables efficient rendering of large-scale scenes with high-fidelity details and accelerates rendering performance by over 400 times compared to state-of-the-art methods.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes the first RGB-only SLAM system with a dense 3D Gaussian map representation that utilizes global map and pose optimization, dynamically adapting to keyframe pose and depth updates, and refining depth updates with a monocular depth estimator for improved accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view 360° scene reconstruction by filling in missing details and cleaning novel views through a cascade of in-painting and artifact removal models.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:The authors introduce Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model. NEMos can be generated from imagery, providing a lightweight representation of terrain through an implicit continuous and differentiable height field. The authors propose a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression. They also introduce a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.The authors aim to address the limitations of expensive 3D sensors by leveraging inexpensive cameras to reconstruct 3D environments and provide a more robust and versatile navigation solution. The proposed method can generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods. The authors also discuss future directions, including incorporating features and semantics into the height field to create a generalized terrain model.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeB-SLAM, a neural block-based scalable RGB-D SLAM method, proposes a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive mapping in unknown environments, outperforming existing methods in both mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel 3D imaging method that efficiently renders HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while achieving significant speedup.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original GS point clouds in an invisible manner, ensuring security, fidelity, capacity, and flexibility, with applications in copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:1. A new initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) that improves translation accuracy during the initialization stage by using a 3-DoF Bundle Adjustment (BA) approach, independently varying the translation estimate while keeping the rotation estimate fixed.2. The method updates the rotation estimate based on IMU measurements and gyroscope bias, unlike ORB-SLAM3, which directly obtains the rotation from stereo visual odometry, potentially leading to inferior results in challenging scenarios.3. The method shows comparable performance to Stereo-NEC, which is a state-of-the-art method, but with a significantly reduced runtime, making it more practical for real-world applications.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel approach to Neural Radiance Fields (NeRF) that employs ray tracing to render detailed, consistent reflections of nearby and distant scene content, while reducing the computational cost and improving rendering speed, outperforming prior methods in view synthesis.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a unified approach to reconstructing camera trajectories, human meshes, and scene point clouds in a common world frame, leveraging camera-frame HMR as a strong prior for SLAM and incorporating spatio-temporal coherency and dynamic scene constraints.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding method for rendering specular objects, which encodes directional information into feature grids and cone-traces spatial features to accurately model high-frequency angular signals and interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, using a hash-encoded NeRF for fast training and robust camera pose refinement, and introduce a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to address noisy image gradient computing issues.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
