
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose NS-MAE, a self-supervised pre-training framework that leverages masked multi-modal reconstruction in neural radiance fields to learn transferable representations for multi-modal perception models, achieving promising results on various 3D perception tasks with diverse input modalities.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper's abstract and introduction are:* A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian Splatting to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask and noise loss to effectively identify and remove noise points in 3D Gaussian Splatting, enhancing rendering quality.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.* Experiments on three datasets (NeRF-DS, HyperNeRF, and NeRF-DS) demonstrating the effectiveness of the proposed method in terms of rendering quality, speed, and memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses challenges in spatial and temporal frequency perspectives, achieving superior rendering quality and overcoming limitations of previous methods.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh as a proxy, allowing for large deformations, local manipulations, and soft body simulations while maintaining high-quality rendering and tolerating inaccurate meshes.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while preserving image quality by factorizing dense clusters of Gaussians using efficient factorization techniques, resulting in a compact and fast rendering framework for 3D scenes.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome limitations of ORB-SLAM3, achieving real-time processing of human colonoscopies with increased map size and coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS) with NeRF initialization, which addresses challenges in scaling 3D Gaussian Splatting to large-scale scenes by introducing a hierarchical assembly of pyramidal Gaussians and a compact weighting network for dynamic contribution evaluation.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the paper's abstract and introduction in under 50 words:The paper proposes a novel RGB-only SLAM system that uses 3D Gaussian Splatting, a dense and efficient map representation, and a dynamically deformable map to achieve globally optimized tracking, while refining depth updates with a monocular depth estimator for improved reconstruction accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes SparseSplat360, a novel method that uses a 2D diffusion model, in-painting, and artifact removal to improve the reconstruction of 360° scenes from sparse-view images, achieving state-of-the-art results on the challenging Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), a novel approach for representing terrain as a continuous and differentiable height field, which can be learned from aerial imagery.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression to learn the height information from images.* A path planning algorithm that leverages the differentiability of the height field to optimize a continuous cost function for path planning, minimizing distance, slope changes, and control effort.In summary, NEMos integrate the strengths of NeRFs in capturing complex terrain details and the suitability of DEMs for path planning, enabling robust and versatile navigation solutions.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The key contributions from this paper are the proposal of NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, leveraging a divide-and-conquer mapping strategy and an adaptive map growth strategy to construct a high-quality 3D scene representation while demonstrating competitive mapping and tracking accuracy on various datasets.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR imaging, which achieves better performance on HDR novel view synthesis while enjoying 1000x faster inference speed and only requiring 6.3% of the training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, to embed 3D scenes and images into original GS point clouds, ensure security, fidelity, and flexibility, and demonstrate its effectiveness in hiding multiple 3D scenes and a single image in a single 3D scene.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A novel method for enhancing translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems.* The method uses a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) to refine the translation estimate independently, while keeping the rotation estimate fixed.* The rotation estimate is updated by considering IMU measurements and gyroscope bias, unlike ORB-SLAM3's rotation which is directly obtained from stereo visual odometry.* The method is evaluated on the EuRoC dataset and outperforms existing methods in terms of accuracy.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel approach that improves Neural Radiance Fields (NeRFs) by introducing ray tracing, casting reflection rays to synthesize consistent reflections of nearby and distant content, and decoding feature vectors into color using a small MLP, enabling more efficient rendering of view-dependent appearance.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a method that reconstructs 3D humans and cameras from monocular videos in a common global coordinate system, addressing depth, scale, and dynamic ambiguities to achieve consistent reconstructions.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding of neural radiance fields (NeRF) that efficiently models high-frequency angular signals and addresses challenging interreflection effects, achieving state-of-the-art results on view synthesis of specular objects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting conditions to improve camera relocalization using neural radiance fields (NeRFs). It implements a hash-encoded NeRF representation and introduces a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to optimize pose refinement.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summarized single sentence under 50 words:The authors present a pioneering real-world dataset for multi-robot collaborative perception, featuring air-ground robot collaboration, diverse sensor modalities, and high-level perception annotation, to facilitate research in this underexplored area and unlock potential research in scene understanding.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The research aims to minimize human effort in deploying perception-based robotic systems to unseen environments by leveraging continual learning and reducing annotations for efficient learning, with key contributions including label-efficient panoptic segmentation and automatic targetless camera-LiDAR calibration.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured mesh from a single image or text prompts, leveraging a multi-view diffusion model, transformer-based SDF field prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:JointRF proposes a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving significantly improved quality and compression efficiency by employing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, achieving a 6+ times speedup in training time and state-of-the-art rendering quality on large-scale scenes while maintaining the global 3D Gaussian model.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment using 3D Gaussian representation and CLIP features.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) is a real-time rendering method that models time-dependent Gaussian primitives to reconstruct 3D scenes with vastly varying appearances, achieving state-of-the-art rendering fidelity and speed, while disentangling appearance changes and interpolating smoothly.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Motion-Based 3D Clothed Humans Synthesis (MOSS), a framework that utilizes kinematic information to achieve motion-aware Gaussian split and surface deformation detection, achieving state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The key contributions from the paper's abstract and introduction are:The paper presents a novel method that allows an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target, by leveraging Neural Radiance Fields (NeRFs) to extend the scope of existing pose estimation methods to unknown targets. The method uses an in-the-wild NeRF to generate a large dataset that captures the diversity of both the pose distribution and illumination conditions encountered in orbit, and then trains an off-the-shelf Spacecraft Pose Estimation (SPE) network on this dataset.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summarized key contribution from the paper's abstract and introduction in a single sentence under 50 words: The paper presents NV-LIO, a normal vector-based LIO framework designed for indoor SLAM in multifloor environments, which utilizes normal vectors for robust point cloud registration, degeneracy detection, and loop closure, demonstrated through public datasets and own dataset validation.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The key contributions of the paper include a generalizable 3D Gaussian representation approach called MVSGaussian, which efficiently reconstructs unseen scenes through a hybrid Gaussian rendering method and a multi-view geometric consistent aggregation strategy for fast per-scene optimization, achieving real-time rendering and better synthesis quality than existing methods.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper focuses on the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G wireless networks for immersive communications, which require efficient representation, transmission, and reconstruction of 3D contents.Key contributions:1. Overview of radiance field rendering techniques, NeRF, and 3D-GS, highlighting their applications, implementation challenges, and limitations.2. Discussion of the need for integrated radiance field rendering in 6G wireless networks, considering the challenges of distributed training and inference, processing, and storage resources.3. Proposal of a new semantic communication-enabled 3D content transmission design, exploiting radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.4. Emphasis on the importance of joint computation and communication designs to minimize end-to-end latency while preserving quality of experience (QoE) requirements.5. Identification of key technical challenges, such as large-scale 3D scene modeling, storage, and transmission, and seeking novel distributed training and inference methods for radiance fields.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
