
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a self-supervised pre-training framework for multi-modal perception, called NS-MAE, which leverages masked multi-modal reconstruction in neural radiance fields to learn transferable representations.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines the advantages of NeRF and 3D-GS, introducing a dynamic scene rendering framework based on a hybrid representation of explicit and implicit features.* The contributions include:	+ A hybrid representation that significantly reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.	+ A learnable denoising mask that effectively identifies and removes noise points from the scene, enhancing rendering quality.	+ Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, addressing under-reconstruction issues from spatial and temporal frequency perspectives, and achieves superior rendering quality in extensive experiments.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling large deformation, local manipulation, and soft body simulation while maintaining high-quality rendering and having a high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining image quality by factorizing coordinates and attributes of 3D Gaussians, allowing for efficient representation of dense scenes with a relatively small number of elements.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that overcomes tracking losses and deformation challenges in human colonoscopies by using SIFT features instead of ORB and brute-force matching, achieving real-time performance and improved mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that addresses the challenges of modeling large-scale scenes by using a hierarchical assembly of Gaussians and dynamic weighting, achieving significant performance leaps and rendering speedup compared to state-of-the-art approaches.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a RGB-only SLAM system using 3D Gaussian Splatting, which combines frame-to-frame tracking with global consistency, online map deformations, and proxy depth estimation to achieve superior or comparable performance to existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve the reconstruction of 360 3D scenes from sparse views, achieving multi-view consistency and coherent details through an iterative update strategy and explicit scene representation.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for simultaneous estimation of depth and color from a 2D image.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression to extract height information from images.* A path planning algorithm that leverages the continuous and differentiable nature of the height field to perform gradient-based optimization of a cost function for minimizing distance, slope changes, and control effort.Please note that the paper's abstract is around 150 words and the introduction is around 300 words, so there are many more details and key contributions mentioned in the rest of the paper.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes NeB-SLAM, an end-to-end neural block-based scalable RGB-D SLAM approach for unknown scenes, which divides the scene into sub-maps (neural blocks) and adaptively grows them during camera tracking to achieve real-time and scalable mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a new framework for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, achieving better performance with faster training and inference speeds compared to state-of-the-art NeRF-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files, maintaining high security, fidelity, and capacity, while enabling efficient extraction and rendering of hidden messages.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of this paper are:*Proposing a method to improve translation accuracy during the initial stage of Stereo Visual Inertial SLAM; the method uses a separate 3-DoF Bundle Adjustment to refine translational estimates while keeping roational estimates fixed, enabling more accurate initialization. In contrast to existing methods (ORB-SLAM2 and Stereo-NEC), this approach does so without requiring feature matching of keypoint tracking to recover gyroscope bias. An evaluation on the EuRoC dataset demonstrates the feasibility and effectiveness of this scheme.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper's key contributions are a new approach to Neural Radiance Fields (NeRF) that uses ray tracing to render highly specular objects by casting reflection rays from a camera ray, synthesizing consistent reflections, and encoding features into reflected color, outperforming prior methods in view synthesis of scenes with shiny objects.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that combines human-aware metric SLAM and scene-aware SMPL denoising to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame from monocular videos.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is the summary:The paper presents Neural Directional Encoding (NDE), a novel approach to view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, improving the ability to model high-frequency angular signals and addressing interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizes a hash-encoded NeRF for fast training and robust pose refinement, and introduces a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration with distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here are the key contributions from the paper's abstract and introduction:The research aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments, focusing on:* Continual Learning (CL) for unsupervised adaptation of robotic vision systems* Label-Efficient Learning, which reduces the need for human annotationsThe research explores the use of CL and label-efficient learning for tasks such as:* Simultaneous Localization and Mapping (SLAM) and panoptic segmentation* Unsupervised depth estimation and panoptic segmentation* Automatic target-less camera-LiDAR calibration* Collaborative robot mappingBy leveraging vision foundation models and transfer learning, the research aims to reduce the need for human annotations and enable label-efficient learning for robotic tasks.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework generating high-fidelity, illumination-decoupled textured meshes from single images or text prompts, featuring a tensorial SDF representation, adaptive Œ≤ adjusting schedule, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is the summary in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving superior quality and compression efficiency by employing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality, overcoming the challenges of high memory usage and long training time for large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module that uses 3D Gaussian representation to guide scene geometry estimation and achieve real-time tracking, high-fidelity reconstruction, and a high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a real-time rendering method for reconstructing 3D scenes with vastly varying appearances, using a lightweight neural network to model time-dependent Gaussian primitives and decompose color, achieving state-of-the-art rendering quality and efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework that employs kinematic information to achieve motion-aware Gaussian split on the human surface, improving the realism of reconstructed surfaces and achieving state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, using a Neural Radiance Field (NeRF) to represent the target and generate a large training set from sparse spaceborne images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework for indoor SLAM in multifloor environments, which extracts normal vectors from LiDAR scans to enhance point cloud registration performance and addresses degeneracy situations and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo to efficiently reconstruct unseen scenes with real-time rendering and better synthesis quality, outperforming previous generalizable NeRF-based methods.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Key contributions from the paper's abstract and introduction are:1. The emergence of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) as two promising 3D representation techniques for 6G networks, enabling photorealistic rendering of complex scenes.2. The importance of efficiently representing, transmitting, and reconstructing 3D contents over wireless networks for immersive communications.3. The need for new interdisciplinary design approaches to tackle the challenges of integrating NeRF and 3D-GS in 6G networks, including joint computation and communication designs, model compression, and rendering acceleration.4. The potential applications of radiance field rendering in various areas, such as wireless sensing, communication, mobile edge computation, and artificial intelligence.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
