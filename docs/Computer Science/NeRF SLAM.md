
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Self-Supervised Street Gaussians (S3Gaussian), a method for decomposing dynamic and static elements in 3D street scenes without requiring 3D annotations, using a spatial-temporal field network and 3D Gaussians to model the scene and achieve state-of-the-art results in novel view synthesis and scene reconstruction tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|The authors introduce TetSphere splatting, an explicit, Lagrangian representation that reconstructs 3D shapes with high-quality geometry by directly deforming tetrahedral spheres, achieving superior mesh quality, faster optimization speed, and reliable preservation of thin structures, without relying on neural networks or post-processing.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|The key contributions of the paper are:1. Creation of a new set of synthetic and real visual scenes with respective camera poses, which can be used to assess NeRF methods.2. Subjective evaluation of the impact of NeRF view synthesis (NVS) on perceived quality, considering several scene classes and recently proposed NVS methods.3. Evaluation of the performance of state-of-the-art conventional and learning-based full-reference 2D image and video quality assessment metrics in the context of NVS.The rest of the paper further details the related work, fundamentals of NeRF view synthesis, selected NVS methods, and characterization of artifacts generated by the synthesis process.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes Manhattan Gaussian SLAM (MG-SLAM), a novel RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness in complex indoor environments, achieving state-of-the-art performance and efficient scene completion.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:IReNe presents a novel approach for instant recoloring of Neural Radiance Fields (NeRF), efficiently addressing limitations of current methods by selectively fine-tuning the last network layer, leveraging a trainable segmentation module, and automating neuron classification to accelerate training and ensure consistent color edits.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:A convolutional neural network (CNN) is proposed to detect and classify ten different reflector landmarks with varying radii using in-air 3D sonar, achieving 97.3% classification accuracy and accurately predicting landmark orientation angles with RMSE < 10 degrees.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a batch SLAM approach for joint calibration of multiple asynchronous microphone arrays and sound source localization, addressing the challenges of parameter identifiability and providing a efficient framework for initialization and optimization, demonstrated through simulations and real experiments.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles by introducing symmetry priors, regularization constraints, and training cues from large human datasets, achieving a 15% PSNR improvement over previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation using a NeRF-based approach with an ultrametric feature field, and demonstrates improved accuracy and viewpoint-consistency on synthetic and real-world datasets.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents an improved 3D Gaussian Splatting-based SLAM system, leveraging a Fusion Bridge module to integrate tracking-centered ORB Visual Odometry with online 3DGS, achieving state-of-the-art rendering quality, localization accuracy, and real-time performance in long-session robotic tasks.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|The key contributions are:* A novel geometry-based loss is proposed for neural radiance fields (NeRF) to address the performance degradation due to view sparsity in monocular gastroscopy data, which is defined as the difference between the rendered depth and reference depth values obtained from the reconstructed 3D point cloud, along with a depth smoothness loss.* The geometry-based loss is applied to both observed and unobserved views to effectively constrain the learned geometry of NeRF.* The method is evaluated on two monocular gastroscopic videos and achieves high-fidelity image renderings from novel viewpoints, outperforming existing NeRF methods.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple yet effective approach for synthesizing photorealistic views in complex, in-the-wild scenes from casual image sequences, efficiently eliminating distractors and achieving fast convergence speed, outperforming state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training framework for multi-modal representation learning in autonomous driving, aiming to learn transferable representations across diverse input modalities, architectures, and downstream tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian Splatting (3D-GS) to achieve efficient and realistic rendering of dynamic scenes while reducing memory usage.* A learnable denoising mask that can effectively identify and remove noise points, enhancing rendering quality.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.These contributions aim to address the limitations of existing methods, such as neural networks and explicit grid representations, and provide a more efficient and accurate approach for rendering dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses spatial and temporal frequency challenges, including under-reconstruction, by incorporating deformation fields and frequency emphasis reconstruction to achieve superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling direct transfer of mesh manipulation to 3DGS with high-quality rendering, tolerance for mesh accuracy, and various 3DGS manipulations, including large deformation, local manipulation, and soft body simulation.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) by representing dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, while preserving image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors present CudaSIFT-SLAM, a real-time monocular visual simultaneous localization and mapping system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving improved sub-map merging and relocation in challenging colonoscopy scenarios.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The key contributions are the introduction of Pyramidal 3D Gaussian Splatting (PyGS), which presents a hierarchical assembly of Gaussians in a pyramidal fashion, initialized with rapidly trained grid-based NeRF, and dynamic weighting of each level's contribution through a compact gating network, achieving a significant performance leap and rendering time over 400 times faster than current state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik SandstrÃ¶m et.al.|The paper proposes a novel RGB-only SLAM system that uses 3D Gaussian Splatting as a dense map representation, which enables efficient and high-quality map rendering while adapting dynamically to keyframe pose and depth updates.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The authors propose a novel method, SparseSplat360, which leverages pretrained 2D diffusion models and a cascade of in-painting and artifact removal models to reconstruct 360-degree scenes from sparse views, achieving multi-view consistency and high-quality details with as few as 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* Introducing Neural Elevation Models (NEMos) that adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* Developing a novel method for joint training of a height field and radiance field within a NeRF framework, leveraging quantile regression.* Proposing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* Validating the proposed approach through experiments on simulated and real-world terrain imagery, demonstrating the ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown environments, which uses a divide-and-conquer mapping strategy and adaptive map growth to represent the scene as a set of neural blocks, enabling efficient memory usage and hole-filling.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a new framework for 3D HDR imaging, which efficiently renders novel HDR views, reconstructs LDR images with controllable exposure time, and outperforms state-of-the-art methods in terms of image quality and speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, large capacity, and versatility, with applications in copyright protection, encrypted communication, and 3D compression.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The paper proposes a method called ETA, which aims to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems. The key contributions are: (1) Independently refining the translation estimate using a 3-DoF Bundle Adjustment (BA) while keeping the rotation estimate fixed, and (2) updating the rotation estimate by considering IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present a ray tracing-based approach to enhance Neural Radiance Fields (NeRF) for rendering high-frequency, view-dependent appearances in 3D scenes, particularly for shiny objects with accurate reflections of nearby and distant content.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper introduces SynCHMR, a method that combines human-aware metric SLAM and scene-aware SMPL denoising to reconstruct consistent camera trajectories, human meshes, and scene point clouds from monocular videos in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The paper presents Neural Directional Encoding (NDE), a feature-grid-like encoding method that models the appearance of shiny objects by encoding view-dependent effects into feature grids with spatially varying directional encoding, which achieves both high-quality modeling of view-dependent effects and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizing a hash-encoded NeRF with a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique for robust pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
