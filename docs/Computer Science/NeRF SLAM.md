
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|The paper proposes a self-supervised street Gaussian method, S3Gaussian, to decompose dynamic and static elements from 4D consistency for 3D scene reconstruction, achieving state-of-the-art rendering quality without requiring tracked 3D bounding boxes or costly annotations.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|The paper proposes TetSphere splatting, an explicit, Lagrangian representation for reconstructing 3D shapes with high-quality geometry, using underused tetrahedral meshes that directly yield superior mesh quality without relying on neural networks or post-processing.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here are the key contributions from the paper's abstract and introduction:1. Creation of a new set of front-facing (FF) synthetic and real visual scenes with corresponding camera poses, which can be used to assess NeRF methods.2. Evaluation of the impact of NeRF view synthesis (NVS) on perceived quality using a well-known and reliable subjective assessment methodology, considering several scene classes and recently proposed NVS methods.3. Evaluation of objective quality assessment metrics developed for 2D images and video, using several scene classes (namely real and synthetic 360° and FF scenes).Note: The abstract does not mention the goal of creating a dataset for the evaluation of NeRF methods, but this is mentioned in the introduction.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes MG-SLAM, an RGB-D Gaussian SLAM system that leverages the Manhattan World hypothesis to improve geometric accuracy and completeness by integrating line segments, ensuring robust tracking in textureless areas and efficient scene completion.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces IReNe, a novel approach that enables near real-time color editing in Neural Radiance Fields (NeRFs) by leveraging a pre-trained NeRF model, a trainable segmentation module, and automated classification of neuron types, achieving swift and accurate editing while retaining photorealism.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|The key contributions of the paper are:* A novel approach to detect and classify ten different reflector landmarks with varying radii using in-air 3D sonar, achieving a classification accuracy of 97.3% and predicting landmark orientation angles with an RMSE lower than 10 degrees.* The use of a convolutional neural network with supervised learning on a large dataset to detect and classify reflector landmarks, using a bio-inspired representation of the reflected echoes in the form of a cochleogram.* The implementation of a fully embedded real-time 3D imaging sonar sensor (eRTIS) with a 32-element microphone array and a single transducer for broadband signal emission, capable of scanning the frontal hemisphere of the sensor.* The ability to overcome optical interference and environmental challenges, providing a more resilient and accurate approach to autonomous navigation and SLAM.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed HINT algorithm uses symmetry priors, regularization constraints, and large human datasets to learn a detailed and complete human model from limited viewing angles, achieving a 15% PSNR improvement over previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|Here is a rewritten version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a novel method for lifting zero-shot image segmentations from the Segment Anything Model to a hierarchical and 3D-consistent representation, using ultrametric features within a Neural Radiance Field, and achieve view-consistent hierarchical segmentation outperforming existing open-vocabulary 3D segmentation methods.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel 3DGS-based SLAM system that leverages the efficiency and flexibility of 3DGS to achieve real-time performance while remaining robust against sensor noise, motion blur, and long-session SLAM challenges, through a Fusion Bridge module integrating tracking-centered ORB Visual Odometry with online 3DGS.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method that applies neural radiance fields (NeRF) to monocular gastroscopic images to enable the synthesis of high-quality images for novel viewpoints within the stomach, addressing view sparsity and low-texture regions using a novel geometry-based loss.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions in a single sentence under 50 words:NeRF On-the-go, a novel approach, enables robust novel view synthesis in complex, real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving faster convergence speed and improved render quality compared to existing state-of-the-art methods.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summarized version of the key contributions in under 50 words:The paper proposes NS-MAE, a self-supervised pre-training method for multi-modal representation learning in autonomous driving, which enables transferable representation learning and unifies optimization of multi-modal representations using neural radiance fields.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here are the key contributions from the paper's abstract and introduction:**Abstract:*** The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines deformation fields, hash encoding, and 3D Gaussian splatting to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* The learnable denoising mask and static constraints are introduced to eliminate noise points and mitigate motion artifacts.**Introduction:*** The paper aims to address the challenges of rendering dynamic scenes with 3D Gaussian splatting (3D-GS), which has led to a significant increase in memory usage.* Existing approaches, such as Deformable-GS and 4D-GS, have not resolved the problem of memory consumption and rendering quality.* The paper proposes a hybrid representation that combines deformation fields, hash encoding, and 3D-GS to reduce memory usage and achieve efficient rendering of dynamic scenes.Let me know if you'd like me to elaborate on any of these points!|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes a novel approach, HFGS, for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction, which achieve superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of this paper are:* A method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, allowing for large deformation, local manipulation, and soft body simulation while maintaining high-quality rendering.* A triangle shape-aware Gaussian binding strategy with self-adaptation that can handle inaccurate meshes and supports various 3DGS manipulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) for rapid rendering speed while preserving image quality. Inspired by classical matrix and tensor factorization techniques, F-3DGS aims to efficiently represent dense 3D Gaussians by approximating them with a limited amount of information for each axis and their combinations, allowing for significant reduction in storage costs while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a real-time V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling successful merging of sub-maps and relocation in human colonoscopies, and achieving 70% improvement in mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that scales 3D Gaussian Splatting to large-scale scenes by using a hierarchical pyramidal structure and dynamic weighting, achieving a significant performance leap and rendering time that is over 400 times faster than state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel RGB-only SLAM system that leverages 3D Gaussian Splatting, frame-to-frame tracking, and online map deformations, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models with fine-tuning to reconstruct 360-degree scenes from sparse views, achieving high-quality results with coherent details and multi-view consistency.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* Experiments on simulated and real-world terrain imagery, demonstrating NEMos' ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM system for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to cover the entire unknown environment while maintaining real-time performance and efficient memory usage.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods by 3.84 and 1.91 dB on LDR and HDR novel view synthesis tasks, respectively, while enjoying 1000x inference speed and only requiring 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, that embeds 3D scenes and images into 3D Gaussian Splatting point cloud files in an invisible manner, while ensuring high security, fidelity, large capacity, and versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper can be summarized in one sentence:The authors propose a method, ETA, which enhances translation accuracy during the initialization stage of stereo visual-inertial SLAM by using a 3-DoF bundle adjustment to refine the translation estimate independently, while keeping the rotation estimate fixed, and updating the rotation estimate based on IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents an approach that combines ray tracing with Neural Radiance Fields (NeRF) to render highly specular objects with consistent reflections of both nearby and distant content, outperforming prior methods in efficiency and visual quality.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a novel approach that combines camera-frame Human Mesh Recovery (HMR) with Human-aware Metric SLAM to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the introduction of Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, and a feature-grid-like approach to efficiently model high-frequency angular signals and global illumination effects, such as reflections and interreflections, for novel-view synthesis.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a two-stage pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, using a hash-encoded NeRF and two novel techniques: a truncated dynamic low-pass filter and numerical gradient averaging, to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
