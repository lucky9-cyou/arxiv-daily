
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a self-supervised 3D Gaussian Splatting method, S3Gaussian, to decompose static and dynamic elements in street scenes without costly annotations, achieving state-of-the-art rendering quality in scene reconstruction and novel view synthesis tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:TetSphere splatting is a novel, Lagrangian geometry representation that reconstructs 3D shapes with high-quality geometry using deformed tetrahedral spheres, achieving faster optimization speed, enhanced mesh quality, and reliable preservation of thin structures without relying on neural networks or post-processing.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Key contributions from the paper's abstract and introduction:* Creation of a new dataset for evaluating the quality of Neural Radiance Fields (NeRF) methods, including real and synthetic scenes, with front-facing and 360-degree camera trajectories.* Conducting a rigorous subjective quality assessment test to evaluate the perceived quality of different NeRF methods and objective quality metrics.* Evaluating the performance of various state-of-the-art conventional and learning-based full-reference 2D image and video quality assessment metrics in the context of NeRF view synthesis.* Characterizing the artifacts generated by NeRF methods, including floaters, flawed geometry, and flickering object edges.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a single sentence summarizing the key contributions:The paper introduces Manhattan Gaussian SLAM (MG-SLAM), an RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy, completeness, and efficiency by utilizing line features for robust tracking, surface segmentation for scene completion, and Poisson reconstruction for high-quality mesh extraction.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:IReNe introduces a novel approach for instant recoloring of Neural Radiance Fields (NeRF) by leveraging a pre-trained NeRF model, a single training image with user-applied color edits, and a trainable segmentation module to achieve swift, near real-time color editing while retaining photorealism and multi-view consistency.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a convolutional neural network (CNN) that detects and classifies ten different reflector landmarks with varying radii using in-air 3D sonar, achieving a 97.3% classification accuracy and accurately predicting the orientation angle, enhancing the robustness and accuracy of autonomous systems in challenging environments.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|This paper proposes a batch simultaneous localization and mapping (SLAM) method for joint calibration of multiple asynchronous microphone arrays and sound source localization, addressing the challenges of complex parameter identifiability and initialization.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the paper's key contributions:The paper proposes HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, addressing the challenge of generating human replicas from real-world monocular hand-held or robotic sensor setups. Key contributions include introducing symmetry prior, regularization constraints, and training cues from large human datasets, enabling the reconstruction of complete humans even from a few viewing angles, with a 15% PSNR improvement over previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation.* The method learns a novel feature field within a Neural Radiance Field (NeRF) representing a 3D scene, whose segmentation structure can be revealed at different scales by simply using different thresholds on feature distance.* The method uses ultrametric distances, which are ideally suited for hierarchical clustering because distance-based groupings are transitive, allowing for the automatic creation of a hierarchy.* The method is evaluated on synthetic datasets with multi-view images and multi-granular segmentation, showcasing improved accuracy and viewpoint-consistency compared to baselines.Note that the abstract and introduction provide an overview of the paper's main contributions, but do not provide a detailed description of the method or results.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces a 3DGS-based SLAM system that achieves real-time performance, robustness against sensor noise and motion blur, and state-of-the-art rendering quality and localization accuracy through precise pose initialization and strategic viewpoint selection.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel view synthesis method for monocular gastroscopic images using neural radiance fields (NeRF), incorporating geometry priors from a pre-reconstructed point cloud to improve image rendering quality and address view sparsity.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a sentence summarizing the key contributions from the paper's abstract and introduction:The researchers introduce NeRF On-the-go, a simple method that efficiently eliminates distractors and achieves faster convergence and improved render quality in challenging, real-world scenes for novel view synthesis, filling a gap in existing NRS techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:Contribution: The authors propose a self-supervised pre-training framework for multi-modal representation learning for autonomous driving, called NS-MAE, which is transferable to both multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines deformation fields, hash encoding, and 3D-GS to significantly reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* The learnable denoising mask and static constraints and motion consistency constraints are introduced to eliminate noise points, reduce storage consumption, and ensure the accuracy and efficiency of the rendering framework.The paper aims to address the challenges of 3D-GS, including high memory usage and difficulties in rendering dynamic scenes. The proposed method is expected to provide a more effective and efficient solution for dynamic scene reconstruction.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes, incorporating deformation fields and introducing Spatial High-Frequency Emphasis Reconstruction and Temporal High-Frequency Emphasis Reconstruction to improve rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a method to manipulate 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling controllable and high-quality manipulation for various 3DGS applications, including large deformations, local manipulations, and soft body simulations, while maintaining rendering quality and tolerating mesh inaccuracies.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel method that reduces the storage requirements of 3D Gaussian Splatting (3DGS) by using factorization techniques to represent and approximate dense clusters of Gaussians with significantly fewer Gaussians, achieving a substantial reduction in storage costs while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The researchers present CudaSIFT-SLAM, a novel V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling the system to process complete human colonoscopies in real-time and merge sub-maps, achieving a 70% improvement in mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS), a method that represents large-scale scenes with hierarchical Gaussians and NeRF initialization, achieving a 400x rendering speedup and high-fidelity visual results while addressing the challenges of long rendering durations and lost fine details.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes the first RGB-only SLAM system that utilizes a dense 3D Gaussian map representation, enabling online map deformations and accurate surface reconstruction through proxy depth estimation, outperforming existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a method, SparseSplat360, that uses latent diffusion models to improve the reconstruction of 360 3D scenes from sparse views, achieving multi-view consistency and coherent details through a cascade of in-painting and artifact removal models.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* NEMos can be generated from imagery and provide a lightweight representation of terrain as an implicit continuous and differentiable height field.* The paper proposes a novel method for jointly training a height field and radiance field within a NeRF framework using quantile regression.* The paper also introduces a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, capable of efficiently reconstructing 3D scenes while maintaining real-time performance, scalable storage, and competitive mapping and tracking capabilities.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds in an invisible manner, ensuring security, fidelity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* A novel initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) that enhances translation accuracy using a 3-Degree-of-Freedom (DoF) Bundle Adjustment (BA) method.* The proposed method independently refines the translation estimate while keeping the rotation estimate fixed, unlike traditional methods that use a 6-DoF BA method.* The rotation estimate is updated by considering IMU measurements and gyroscope bias, which is more accurate than directly deriving it from stereo visual odometry.* The proposed method is evaluated on the public EuRoC dataset, demonstrating improved accuracy and performance compared to existing methods.Note that the main idea is to improve the translation accuracy during the initialization stage of Stereo VI-SLAM, which is critical for the overall system performance.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose an approach that integrates ray tracing into Neural Radiance Fields (NeRFs) to improve view synthesis of shiny objects with high-frequency view-dependent appearance, achieving consistent reflections of nearby content and reducing the computational cost of representing view-dependent functions.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities by leveraging human-aware metric SLAM and scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the introduction of Neural Directional Encoding (NDE), a feature-grid-like neural representation that accurately models the appearance of shiny objects by encoding view-dependent effects, and the design of a novel spatio-spatial parameterization that captures near-field interreflection effects, achieving high-quality modeling of view-dependent effects and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizes a hash-encoded NeRF for fast and robust camera pose refinement, and introduces a novel dataset with varying lighting conditions, achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
