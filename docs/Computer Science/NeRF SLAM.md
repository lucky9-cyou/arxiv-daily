
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining high-quality rendering by factoring out redundant information in 3D Gaussian representations, improving rendering speed and efficiency.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The paper presents CudaSIFT-SLAM, a V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling real-time processing of human colonoscopies and achieving longer sub-maps and higher mapping coverage, with a 70% improvement over ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The key contributions of the paper are the introduction of Pyramidal 3D Gaussian Splatting (PyGS), which achieves high-fidelity visual results and accelerated rendering performance on large-scale scenes, through a hierarchical assembly of Gaussians and dynamic weighting of each level's contribution.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes an RGB-only SLAM system that combines a frame-to-frame tracker with global consistency and a dense deformable 3D Gaussian map, achieving high-quality reconstruction and rendering while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a novel method, SparseSplat360, that uses pretrained 2D diffusion models to improve sparse-view 360° scene reconstruction, filling in missing details and cleaning novel views through a cascade of in-painting and artifact removal models.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model that can be generated from imagery.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework using quantile regression.* Developing a path planning algorithm that leverages the continuous and differentiable nature of the height field to optimize for distance, slope changes, and control effort.* Demonstrate the effectiveness of NEMos on simulated and real-world terrain imagery, showing high-quality reconstructions and smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in one sentence under 50 words:The authors propose NeB-SLAM, a neural block-based RGB-D SLAM system that adapts to unknown scenes using a divide-and-conquer mapping strategy and adaptive map growth, enabling real-time, scalable, and predictive mapping and tracking performance.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that renders HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The contributions of the paper can be summarized as: proposing the first 3DGS steganography framework (GS-Hider) for embedding and extracting 3D scenes and images, ensuring security, fidelity, and versatility, and experimenting on the 3DGS dataset to demonstrate robustness and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* Proposing a new method called ETA that enhances translation accuracy during the initialization stage in stereo Visual-Inertial SLAM (VI-SLAM) systems, independently estimating translation using 3-DoF bundle adjustment while keeping rotation estimate fixed.* Improving upon existing methods, including ORB-SLAM3 and Stereo-NEC, by providing comparable performance with reduced runtime and enhanced accuracy in challenging scenarios.* Focusing on the disjoint method for initialization, which typically yields more accurate results than the joint method, and building on Stereo-NEC by separately estimating rotation using IMU integration and leveraging precise rotation estimates to enhance translation estimation.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper addresses the limitations of Neural Radiance Fields (NeRFs) in rendering high-frequency view-dependent appearance of shiny objects, specifically by introducing ray tracing to synthesize consistent reflections of nearby and distant content using a small and inexpensive network.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), which combines best practices from visual SLAM and Human Mesh Recovery (HMR) to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame from monocular videos, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a view-dependent appearance encoding of Neural Radiance Fields (NeRF) for rendering specular objects, which captures both geometry and view-dependent appearance, and outperforms state-of-the-art methods while achieving fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizing a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, heterogeneous sensor modalities, and diverse spatial viewpoints, to facilitate research in multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The development of techniques for efficient and label-efficient deployment of perception-based robotic systems in previously unseen environments.* The application of continual learning and domain adaptation concepts to improve the performance of robotic systems in adapting to new domains.* The use of vision foundation models to leverage semantically rich image representations for training downstream tasks with minimal human annotations.* The proposal of novel methods for camera-LiDAR calibration, panoptic segmentation, and mapping in robotics.(Note: The abstract and introduction provide a brief overview of the paper's contributions, but do not exhaustively summarize all the research results.)|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes LDM, a novel feed-forward framework that generates high-quality mesh assets with illumination-decoupled textures from single images or text prompts, enabling fast and efficient 3D content creation.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end learning scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior rate-distortion performance and efficient representation of dynamic and long-sequence radiance fields.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality by decomposing scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the paper's key contributions:This paper presents MG-SLAM, a monocular Gaussian SLAM system that utilizes a language-extended loop closure module based on CLIP features to correct drift errors, achieve high-fidelity reconstruction, and perform real-time mapping with depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent Gaussian primitives and decomposes rendering color to achieve accurate reconstruction of dynamic scenes with vastly varying appearances, outperforming state-of-the-art methods in terms of both quality and efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework for single-view clothed human reconstruction that incorporates kinematic information to achieve motion-aware Gaussian split on the human surface, enabling realistic clothing deformation and improving visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions in the abstract and introduction:The authors propose a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, which is essential for autonomous rendezvous and proximity operations in Active Debris Removal missions. The method leverages a Neural Radiance Field (NeRF) to generate a large dataset of diverse images from a small set of images taken by the spacecraft, allowing an off-the-shelf pose estimation network to be trained on the target spacecraft without knowing its CAD model.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose NV-LIO, a normal vector-based LiDAR-inertial odometry framework designed for simultaneous localization and mapping in indoor environments with multifloor structures, addressing challenges in point cloud registration and loop closure, and achieving robust registration and mapping capabilities.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a novel generalizable Gaussian Splatting method derived from Multi-View Stereo, which efficiently reconstructs unseen scenes with real-time rendering, better synthesis quality, and fast per-scene optimization, achieving state-of-the-art performance on multiple datasets.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the abstract and introduction:The key contributions of the paper can be summarized as follows:* The paper provides an overview of the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for immersive communication applications.* The paper highlights the importance of representing 3D contents in a efficient manner for transmitting and reconstructing them over wireless networks.* It discusses the pros and cons of NeRF and 3D-GS as 3D representation approaches, including their computational resources, storage requirements, and rendering efficiency.* It proposes a new semantic communication enabled 3D content transmission design, which uses radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* It also proposes a new joint computation and communication design for distributed radiance field rendering.* The paper reviews the relevant literature on NeRF and 3D-GS, including their applications and implementation challenges over wireless networks.* It discusses the importance of embracing NeRF and 3D-GS in 6G networks for immersive communication applications, including telepresence and immersive gaming.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions of the paper can be summarized in one sentence:The authors propose a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly models point light attenuation and raytraces cast shadows, and optimizes a fully neural material renderer to estimate 3D shape and texture from photometric stereo images.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems, which can evade detection and pose a realistic threat to the system's robustness.* The method introduces a novel entity called the 'Judge' that assesses the realism of adversarial objects and integrates this evaluation into the loss function to encourage the neural object renderer to produce realistic and adversarial textures.* The Judge is designed to evaluate objects based on three criteria: color similarity, law of traffic, and real-life appearance, with each criterion having a different weight.* The paper explores various strategies for optimizing the Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced vision-language models, pretraining neurosymbolic systems, and utilizing traditional image processing techniques.* The authors highlight the limitations of using adversarial objects with minor textural adjustments, such as stickers or color changes, and propose a new approach to generating more sophisticated and realistic adversarial objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions from the paper's abstract and introduction can be summarized as:* A novel Neural Radiance Fields (NeRF) based ray tracing method for modeling electromagnetic signals in Reconfigurable Intelligent Surface (RIS) enabled wireless environments.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that combines fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to overcome the limitations of conventional SLAM approaches in diverse scenarios.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
