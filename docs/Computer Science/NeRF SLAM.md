
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in under 50 words:The authors propose S3Gaussian, a self-supervised method for decomposing dynamic and static 3D Gaussians in street scenes without annotations, using a spatial-temporal field network to compactly model 4D dynamics, achieving state-of-the-art performance on novel view synthesis and scene reconstruction tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces TetSphere splatting, an explicit, Lagrangian 3D geometry representation that reconstructs high-quality meshes efficiently by deforming tetrahedral spheres, outperforming existing methods like NeRF, NeuS, and DMTet in terms of mesh quality, optimization speed, and computational efficiency.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive study on the quality assessment of Neural Radiance Fields (NeRF) methods, evaluating several recently proposed methods, including instant-NGP, Mip-NeRF 360, and NeRF++, on real and synthetic scenes, with front-face and 360-degree camera trajectories.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Manhattan Gaussian SLAM (MG-SLAM), which leverages the Manhattan World hypothesis to improve geometric accuracy and completeness in indoor scene reconstruction, allowing for seamless tracking and map refinement.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a single sentence summary of the paper's abstract and introduction:IReNe, a novel approach, enables swift and near real-time color editing in Neural Radiance Fields (NeRF) by leveraging a pre-trained NeRF model, a single training image with user-applied color edits, and a trainable segmentation module to achieve accurate object boundary control and multi-view consistency, outperforming existing methods with speeds of 5x to 500x.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|The key contributions of the paper can be summarized as:The development of a deep neural network that detects and classifies in-air sonar landmarks with varying radii, and predicts their orientation angles, achieving a high accuracy of 97.3% in classification and a low prediction error of <10 degrees in orientation estimation.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a batch SLAM approach for joint calibration of multiple asynchronous microphone arrays and sound source localization, which involves observability analysis, parameter initialization, and optimization for accurate and efficient calibration.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, using symmetry prior, regularization constraints, and large human datasets, achieving improved results by 15% PSNR and 34% LPIPS compared to previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation.* The method learns an ultrametric feature field within a Neural Radiance Field (NeRF) representing a 3D scene, allowing for hierarchical segmentation at different scales by simply specifying a threshold on feature distance.* The paper addresses the challenging task of creating a view-consistent hierarchy of segmentations from 2D image segmentations.* The method is evaluated on synthetic datasets with multi-view images and multi-granular segmentation, showcasing improved accuracy and viewpoint-consistency compared to baseline methods.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a cutting-edge 3DGS-based SLAM system that leverages a Fusion Bridge module to integrate tracking-centered ORB Visual Odometry with online 3DGS, achieving real-time performance, robustness against sensor noise and motion blur, and state-of-the-art rendering quality and localization accuracy.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method for synthesizing high-quality novel viewpoint images within a patient's stomach from monocular gastroscopic images using neural radiance fields (NeRF), incorporating a geometry-based loss to address view sparsity and improve rendering quality.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple approach that enables robust novel view synthesis in complex, dynamic scenes from casually captured images, eliminating distractors and achieving faster convergence speed and better render quality than state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|The paper proposes a self-supervised pre-training method called NS-MAE (NeRF-Supervised Masked Auto Encoder) for multi-modal representation learning in autonomous driving. The contributions can be summarized as: • A unified self-supervised pre-training framework for multi-modal perception models, which learns transferable representations across various input modalities, architectures, and downstream tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* A refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* A hybrid representation combining deformation fields, hash encoding, and 3D-GS, which significantly reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask in conjunction with noise loss, which effectively identifies and removes noise points, enhancing the purity and quality of scene rendering.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring that deformation fields accurately learn the dynamic offset of points.Note that the above summary is under 50 words.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes a novel approach, HFGS, for deformable endoscopic reconstruction that addresses under-reconstruction from spatial and temporal frequency perspectives, achieving superior rendering quality in experiments on two benchmark datasets.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, allowing for direct transfer of mesh manipulation to 3DGS with 3DGS self-adaptation.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements while preserving image quality by approximating dense clusters of 3D Gaussians with significantly fewer Gaussians through efficient factorization, achieving a significant reduction in storage costs with comparable quality in rendered images.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose CudaSIFT-SLAM, a monocular V-SLAM system that utilizes SIFT features and brute-force matching to overcome limitations of ORB-SLAM3 and successfully process human colonoscopies in real-time.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS), which improves 3D scene representation by hierarchically arranging Gaussians in a pyramid structure, initialized with NeRF and dynamically weighted for viewpoint consideration, achieving faster rendering and better detail capture.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel RGB-only SLAM system that uses a dense 3D Gaussian map representation, dynamically adapting to keyframe pose and depth updates, and refines depth estimates using monocular depth estimation, achieving superior or comparable performance to existing methods in tracking, mapping, and rendering accuracy while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pretrained 2D diffusion models to improve sparse-view reconstruction of 360-degree scenes by filling in missing details and cleaning novel views, outperforming existing methods on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, enabling path planning with a continuous cost function and outperforming discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which addresses the limitation of neural implicit methods in requiring known scene sizes.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which achieves better results than state-of-the-art methods in terms of PSNR, SSIM, and LPIPS while enjoying 1000x inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that effectively conceals multimodal messages, achieving exceptional security, robustness, capacity, and flexibility while protecting the copyright and privacy of 3D scenes.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* A new method, ETA, for enhancing translation accuracy during initialization in stereo Visual-Inertial SLAM (VI-SLAM) systems, which improves upon previous methods.* The method uses a 3-DoF Bundle Adjustment (BA) to refine the translation estimate independently while keeping the rotation estimate fixed, unlike previous methods that use a 6-DoF BA.* The method updates the rotation estimate by taking into account IMU measurements and gyroscope bias, unlike previous methods that directly obtain the rotation estimate from stereo visual odometry.* The method aims to achieve performance comparable to Stereo-NEC while maintaining a runtime similar to that of ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors present a novel ray tracing-based approach to improve Neural Radiance Fields (NeRFs) for rendering view-dependent appearance, particularly for scenes with shiny objects, by efficiently casting reflection rays and decoding features into reflected color, achieving better quality and speed.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in under 50 words:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a novel approach that jointly reconstructs 3D human meshes and camera trajectories from monocular videos, using human-aware metric SLAM and a scene-aware SMPL denoiser to achieve consistent and physically plausible results.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction, under 50 words:The authors present Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for rendering specular objects, which transfers feature-grid-based spatial encoding to the angular domain, allowing for better modeling of high-frequency angular signals and addressing challenging interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting and shadow conditions, utilizing a hash-encoded NeRF and a re-devised filter for smooth gradient computation, achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
