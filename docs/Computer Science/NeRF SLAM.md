
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:This work proposes NS-MAE, a self-supervised pre-training framework for multi-modal perception models, which learns transferable representations by leveraging masked multi-modal reconstruction in neural radiance fields and demonstrates enhanced robustness and performance in various 3D perception tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Main Contributions:**1. A hybrid representation that combines deformation fields, hash encoding, and 3D Gaussian Splatting, which significantly reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.2. A learnable denoising mask that effectively identifies and removes noise points, enhancing rendering quality.3. Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate deformation field learning.**Summary:**The paper presents a novel framework for dynamic scene rendering using 3D Gaussian Splatting, which combines the strengths of implicit and explicit representations. The framework includes deformation fields, hash encoding, and a learnable denoising mask to achieve efficient and realistic rendering of dynamic scenes. The results demonstrate that the proposed method outperforms existing approaches in terms of rendering quality, speed, and memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, addressing under-reconstruction challenges from spatial and temporal frequency perspectives, by introducing SHF and THF modules, and achieving superior rendering quality in extensive experiments.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh as a proxy, allowing for direct transfer of mesh manipulation to 3DGS with self-adaptation, and achieves high-quality rendering and editing results with large deformations, local manipulations, and soft body simulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions of the paper are:* Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements while maintaining image quality by approximating dense clusters of Gaussians with fewer Gaussians through efficient factorization.* Integration of factorization techniques, inspired by classical matrix and tensor factorization, to represent and approximate dense 3D Gaussians with significantly fewer Gaussians.* Binary mask for removing non-essential Gaussians to accelerate both training and rendering speed, which marginally improves representation quality and significantly increases rendering speed nearly doubling frames per second (FPS).|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The paper presents CudaSIFT-SLAM, a V-SLAM system that successfully maps a human colonoscopy in real-time, overcoming the limitations of previous top-performing multiple-map V-SLAM systems like ORB-SLAM3. By using SIFT features and brute-force matching instead of ORB features and DBoW2 bag-of-words, CudaSIFT-SLAM achieves higher accuracy and recall for place recognition, resulting in longer sub-maps and improved mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Pyramidal 3D Gaussian Splatting (PyGS) that uses a hierarchical assembly of Gaussians arranged in a pyramidal fashion, initialized via rapidly trained grid-based NeRF, to achieve a significant performance leap and rendering time reduction over 400 times faster than current state-of-the-art approaches.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose the first RGB-only SLAM system with a dense 3D Gaussian map representation that utilizes global optimized tracking and dynamically adapts to keyframe pose and depth updates, achieving superior or on-par performance in tracking, mapping, and rendering accuracy with fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|This paper presents a novel method, SparseSplat360, that uses pre-trained 2D diffusion models to improve sparse-view 360-degree scene reconstruction, outperforming existing methods and generating detailed scenes from as few as 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos), a novel framework that combines Neural Radiance Fields with a height field to represent terrain, enabling efficient and accurate path planning in challenging environments with no explicit depth data.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose NeB-SLAM, a scalable and real-time neural RGB-D SLAM system that can handle unknown scenes, utilizing a divide-and-conquer mapping strategy and adaptive map growth strategy to cover the entire scene with fixed-size neural blocks.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art methods in terms of PSNR, SSIM, and LPIPS while achieving faster inference speed and shorter training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summarized key contribution sentence under 50 words:The paper proposes a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original GS point clouds, ensuring security, fidelity, capacity, and flexibility, and effectively conceals multimodal messages without compromising rendering quality.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* Proposing a new method to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems, which independently refines the translation estimate using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) while keeping the rotation estimate fixed.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel approach to improve Neural Radiance Fields (NeRF) for rendering high-frequency view-dependent appearance, particularly specular reflections, by incorporating ray tracing to reduce the need for large neural networks and increase rendering efficiency and quality.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces SynCHMR, a novel approach that fuses static scene reconstruction and human body reconstruction from monocular videos by leveraging camera-frame human motion estimation as a prior to improve scale and depth accuracy, ultimately achieving consistent reconstructions of camera trajectories, human meshes, and scene point clouds in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for neural radiance fields (NeRF) that models high-frequency angular signals and spatially varying directional effects for faithful novel-view synthesis of specular objects, achieving state-of-the-art results.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summarized sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a pioneering and comprehensive real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, distinct spatial viewpoints, complementary robot mobilities, and sensor modalities, to facilitate research in this area.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the key contributions in the paper's abstract and introduction:* The paper explores the idea of minimizing human effort in deploying perception-based robotic systems to unseen environments, focusing on leveraging continual learning and reducing human annotations for efficient learning.* The research aims to contribute to the fundamental area of holistic scene understanding, particularly in the areas of simultaneous localization and mapping (SLAM), panoptic segmentation, and label-efficient learning.* The main contributions of the research include:	+ Continual learning for robotics, which enables autonomous agents to adapt to unseen domains while retaining performance on previous domains.	+ Label-efficient panoptic segmentation, which requires as few as ten annotated images.	+ Online continual learning for joint depth estimation and panoptic segmentation.	+ Automatic target-less camera-LiDAR calibration from motion and deep point correspondences.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts, achieving high-quality 3D mesh assets with corresponding decomposed RGB textures within seconds.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by leveraging residual feature grids and sequential feature compression, outperforming state-of-the-art methods in rate-distortion performance.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors propose DoGaussian, a distributed training method for large-scale 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times while maintaining high-fidelity rendering quality through a recursive block-splitting approach and Alternating Direction Method of Multipliers (ADMM) consensus.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents MG-SLAM, a monocular Gaussian SLAM system that integrates a language-extended loop closure module to achieve drift-corrected tracking and high-fidelity reconstruction, leveraging 3D Gaussian representation and CLIP features for loop detection and text-to-trajectory querying.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Gaussian Time Machine (GTM) is a real-time rendering method that models long-term variations in 3D scenes with discontinuous appearance changes, achieving state-of-the-art rendering fidelity and speeds (100 times faster than NeRF-based counterparts) while maintaining geometry consistency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework that employs kinematic information to achieve motion-aware Gaussian split on the human surface, improving 3D clothed human synthesis with realistic joint details, fine clothing folds, and efficient training and rendering.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, leveraging Neural Radiance Fields to generate a large training set from a sparse collection of images and train an off-the-shelf pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry (LIO) framework for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, which extracts normal vectors from LiDAR scans for enhanced point cloud registration and robust loop closure detection.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose MVSGaussian, a generalizable Gaussian Splatting method derived from Multi-View Stereo that achieves real-time rendering with better synthesis quality, while reducing training computational cost and outperforming previous methods in novel view synthesis.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction can be summarized as:The paper discusses the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks to support immersive communications, which aim to create highly engaging and interactive environments for communication users. The authors highlight the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks, and discuss the challenges involved. They propose a comprehensive overview of the integration of NeRF and 3D-GS in 6G, including the basics of radiance field rendering techniques, over-the-air training of NeRF and 3D-GS models, and rendering architectures at wireless network edges.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
