
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions of the paper:The paper proposes NeRF-Supervised Masked Auto Encoder (NS-MAE), a self-supervised pre-training paradigm for transferable multi-modal representation learning, which learns to reconstruct missing or corrupted input data across multiple modalities and achieves robustness in degraded environments and demonstrated improved transferability across various 3D perception tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is the summary of the key contributions from the paper's abstract and introduction:* The authors propose a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, addressing the representation of dynamic scenes, incorporating deformation fields, hash encoding, and denoising masks.* The framework combines the advantages of NeRF and 3D Gaussian Splatting, introducing a novel view synthesis method tailored for dynamic mapping.Note that the reply is limited to 50 words, so some details may have been omitted.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields and introducing Spatial High-Frequency Emphasis Reconstruction (SHF) and Temporal High-Frequency Emphasis Reconstruction (THF) to enhance rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a method that enables 3D Gaussian Splatting (3DGS) manipulation using a triangular mesh as a proxy, allowing for direct transfer of mesh manipulation to 3DGS with self-adaptation and achieving high-quality rendering while tolerating mesh accuracy errors.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a method that reduces storage requirements and maintains image quality by representing dense 3D Gaussians with significantly fewer Gaussians through efficient factorization, achieving a substantial reduction in storage costs.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome tracking losses in human colonoscopies, achieving real-time performance and significantly longer sub-maps compared to ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical scene representation that achieves high-fidelity visual results and accelerated rendering performance, leveraging a grid-based NeRF for initialization and clustering pyramidal Gaussians to balance detail levels.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose the first RGB-only SLAM system using 3D Gaussian Splatting, which combines frame-to-frame tracking with global optimization, deformable maps, and proxy depth estimation, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents a novel method, SparseSplat360, that employs pre-trained 2D diffusion models with fine-tuning to reconstruct a 360-degree scene from sparse views, using an explicit scene representation in the form of 3D Gaussians, achieving superior results on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos) that adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, which can be generated from imagery and provides a lightweight representation of terrain.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeB-SLAM is a neural block-based RGB-D SLAM system for unknown scenes, proposing a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve scalable, real-time, and predictive mapping and tracking in unexplored environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The key contributions of the paper are: proposing a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR imaging that can efficiently render novel HDR views and reconstruct LDR images with a user-input exposure time, and demonstrating that HDR-GS outperforms state-of-the-art NeRF-based methods by 3.84 dB on LDR NVS and 1.91 dB on HDR NVS while enjoying 1000x inference speed and only requiring 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a novel steganography framework, GS-Hider, for 3D Gaussian Splatting, allowing the embedding of 3D scenes and images into original point clouds in an invisible manner, while ensuring security, fidelity, capacity, and flexibility, addressing the challenges of copyright protection and secret communication in 3D scene reconstruction and novel view synthesis.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A new initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) that enhances translation accuracy during the initialization stage.* The method uses a 3-DoF Bundle Adjustment (BA) to refine the translation estimate independently, while keeping the rotation estimate fixed.* The rotation estimate is updated by considering IMU measurements and gyroscope bias, unlike ORB-SLAM3's rotation which is directly obtained from stereo visual odometry.* The method achieves improved performance in terms of accuracy while maintaining a comparable run-time speed to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce a ray tracing-based approach to improve Neural Radiance Fields' ability to render highly specular objects, reducing the reliance on large neural networks and enabling the synthesis of consistent reflections of both distant and nearby scene content.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a system that jointly reconstructs 3D human bodies, camera trajectories, and dense scene point clouds from monocular videos, addressing long-standing challenges in human motion reconstruction and monocular SLAM.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper's abstract and introduction are:A novel neural directional encoding (NDE) framework for rendering specular objects with high-quality view-dependent appearance and fast inference, leveraging feature-grid-like encoding and cone-tracing spatial features to model both far-field reflections and near-field interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a comprehensive real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, diverse spatial viewpoints, and complementary sensor modalities, to boost research in this area and facilitate the study of high-level scene understanding through multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper explores the challenge of deploying perception-based robotic systems to previously unseen environments with minimal human effort by leveraging continual learning and reducing human annotations for efficient learning.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel feed-forward framework, LDM, that generates high-fidelity, illumination-decoupled textured mesh from single images or text prompts using a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, achieving improved quality and compression efficiency through a compact residual feature grid and sequential compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a single sentence summary of the key contributions from the paper's abstract and introduction:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality while concurrently promoting scene decomposition and consensus between shared 3D Gaussians.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without relying on depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a single sentence summarizing the paper's key contributions in under 50 words:Gaussian Time Machine (GTM) is proposed, leveraging a lightweight MLP and decomposed color model to accurately reconstruct 3D scenes with vastly varying appearances at real-time rendering speed, achieving state-of-the-art quality and performance in various datasets.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a framework that leverages kinematic information to achieve motion-aware Gaussian split, enabling realistic clothing deformation and joint details in 3D reconstructed humans, outperforming previous methods in visual quality and efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method to estimate the 6D pose of an unknown target spacecraft using a monocular camera, leveraging Neural Radiance Fields to generate a diverse training set from a sparse set of images, enabling the use of off-the-shelf pose estimation networks.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework that enhances point cloud registration accuracy in indoor environments with multifloor structures by utilizing normal vectors and adjusting matching uncertainty to handle degeneracy situations and incorrect correspondences.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MVSGaussian, a generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes by leveraging Multi-View Stereo, incorporating hybrid Gaussian rendering, and introducing a consistent aggregation strategy for fast optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a comprehensive overview of the integration of NeRF and 3D-GS in 6G networks for immersive communications, discussing the representation, transmission, and reconstruction of 3D contents, as well as distributed training and inference methods over wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
