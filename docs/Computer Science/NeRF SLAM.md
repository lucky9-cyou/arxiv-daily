
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while preserving image quality. The key contributions are: 1) factorized coordinates and features using classical matrix and tensor factorization techniques, and 2) a binary mask for removing unnecessary Gaussians to accelerate training and rendering speed. The method achieves a significant reduction in storage costs by downsizing 3DGS over 90%, while maintaining comparable image quality.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a real-time V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving 88% mapping coverage in the C3VD dataset and 53% in a real colonoscopy, a 70% improvement over ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Pyramidal 3D Gaussian Splatting (PyGS), which enhances 3D Gaussian Splatting to model large-scale scenes with high-fidelity results and accelerated rendering performance, addressing challenges such as heterogenous object scales and sparse point cloud generation.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a novel RGB-only SLAM system using 3D Gaussian Splatting that combines frame-to-frame tracking with global map and pose optimization, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses 2D diffusion models and a cascaded approach to fill in missing details and clean novel views in sparse-view reconstruction of 360-degree scenes.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper's abstract and introduction can be summarized as follows:* The authors introduce Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model, allowing for the representation of terrain elevation from 2D camera images.* NEMos jointly train a height field and radiance field within a NeRF framework, leveraging quantile regression to learn the height information from images alongside the NeRF density distribution.* The authors propose a novel method for path planning that leverages the continuous and differentiable nature of the height field to achieve smoother paths than those obtained via discrete planning over equivalent digital elevation models (DEMs).* The paper evaluates the quality of the NEMo training and analyzes the path planning results for the KT-22 and Red Rocks scenes, demonstrating the effectiveness of the proposed approach.Note that this summary is focused on the key contributions mentioned in the abstract and introduction, and does not include all the details provided in the paper.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive dense SLAM in unfamiliar settings.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which outperforms state-of-the-art NeRF-based methods by 1.91 dB on HDR novel view synthesis while enjoying 1000x inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel steganography framework, dubbed GS-Hider, which enables the invisible embedding and extraction of 3D scenes and images into 3D Gaussian Splatting (3DGS) point cloud files, addressing the unique challenges of 3DGS's explicit 3D representation and real-time rendering speeds.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method, ETA, that enhances translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM systems by using a 3 Degree-of-Freedom Bundle Adjustment to refine translation estimates independently of rotation, while also considering IMU measurements and gyroscope bias to improve rotation estimation.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a ray tracing approach for Neural Radiance Fields (NeRFs) that tackles the limitations of previous methods by rendering consistent reflections of nearby and distant scene content using a small MLP and ray tracing, achieving improved efficiency and photorealistic specular appearance.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper introduces SynCHMR, a pipeline that combines Human-aware Metric SLAM with Scene-aware SMPL Denoising to reconstruct metric-scale camera poses, scene point clouds, and human meshes from monocular videos, enabling consistent and synergistic recovery of camera and human movements in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the introduction of Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) that improves the modeling of high-frequency angular signals and specifically addresses the challenging interreflection effects in rendering specular objects. NDE uses a novel spatio-spatial parameterization by cone-tracing a spatial feature grid to encode near-field reflections and achieves both high-quality modeling of view-dependent effects and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization under varying lighting conditions, utilizing a hash-encoded neural radiance field (NeRF) and a shadow removal module, and contributes a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve the pose optimization process.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring raw sensor inputs, pose estimation, and optional high-level perception annotation, to facilitate research in this understudied area and unlock the potential of multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The contributions from the paper's abstract and introduction can be summarized in a single sentence under 50 words:The research focuses on developing label-efficient and continual learning approaches for robotic systems, enabling robots to adapt to new environments and tasks with minimal human supervision, utilizing concepts from vision foundation models and graph-based optimization.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel feed-forward framework called LDM that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts, introducing a tensorial SDF representation to improve convergence speed and enhancing geometry and texture quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel approach that jointly optimizes dynamic NeRF representation and compression, achieving superior quality and compression efficiency by leveraging a compact residual feature grid and sequential feature compression, and outperforms state-of-the-art methods in rate-distortion performance.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining high-fidelity rendering quality, addressing the limitations of previous 3DGS methods on memory and training time.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's abstract and introduction in under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module that performs drift-corrected tracking, high-fidelity reconstruction, and achieves a high-level understanding of the environment without requiring depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The Gaussian Time Machine (GTM) method is proposed to reconstruct 3D scenes with discontinuous appearance variations, achieving state-of-the-art rendering fidelity and real-time rendering capabilities while disentangling appearance changes from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, an innovative framework for single-view clothed human reconstruction, which employs kinematic information to achieve motion-aware Gaussian split on the human surface, resulting in state-of-the-art visual quality and improved detail and realism.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) to generate a large dataset from a sparse set of images, demonstrating its feasibility on realistic images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework that enhances point cloud registration performance in indoor environments with multifloor structures by extracting normal vectors and analyzing their distribution to address degeneracy and uncertainty.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:MVSGaussian proposes a generalizable 3D Gaussian representation approach derived from Multi-View Stereo, incorporating efficient rendering and geometric consistent aggregation, achieving real-time rendering with better novel view synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:1. The authors highlight the importance of efficient representation, transmission, and reconstruction of 3D contents for immersive communication, a key challenge in 6G networks.2. They discuss the pros and cons of two promising 3D representation techniques, Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS), and their potential applications in 6G networks.3. The integration of NeRF and 3D-GS in 6G networks is envisioned to support emerging 3D applications with enhanced quality of experience, particularly in immersive communication scenarios.4. The authors propose new approaches to address the technical challenges of integrating radiance field models into 6G networks, including joint computation and communication designs, and federated learning for distributed training and inference.5. The paper highlights the need for a unified design of the sensing-communication-computation pipeline over 6G wireless networks to minimize end-to-end latency while preserving quality of experience requirements.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and raytraces cast shadows to estimate 3D shape, achieving competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a Judge mechanism that evaluates the realism of generated objects, aiming to create a balance between adversarial effectiveness and visual realism.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method for modeling dynamic electromagnetic fields in RIS-enabled environments, accurately capturing complex propagation dynamics and enabling efficient RIS deployment for improved communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work out-of-the-box by addressing issues of catastrophic failure, ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
