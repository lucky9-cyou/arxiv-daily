
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning, which leverages masked multi-modal reconstruction in neural radiance fields to learn robust and generalizable representations for autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, which addresses the issues of memory usage and rendering quality in 3D Gaussian Splatting (3D-GS) by incorporating deformation fields, hash encoding, and denoising masks.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction challenges by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction, achieving superior rendering quality.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh as a proxy, enabling direct transfer of mesh manipulation to 3DGS while maintaining high-quality rendering, and demonstrating its effectiveness through various experimentation results.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Factorized 3D Gaussian Splatting (F-3DGS) is proposed to reduce storage costs and improve rendering speed while maintaining high-quality image representation by factorizing and compressing overlapping Gaussian representations in 3D scenes.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a novel V-SLAM system that uses SIFT features and brute-force matching to overcome limitations of ORB-SLAM3, achieving real-time processing and significantly improved tracking and mapping performance in challenging colonoscopy scenarios.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization, which efficiently represents large-scale scenes with hierarchical Gaussians, achieves high-quality rendering, and accelerates rendering time by over 400 times compared to state-of-the-art NeRF-based methods.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an RGB-only SLAM system that combines 3D Gaussian Splatting with global map and pose optimization, dynamically deforming the map to improve reconstruction quality, and leveraging monocular depth estimation to enhance rendering and accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that leverages pre-trained 2D diffusion models to reconstruct 360-degree scenes from sparse views by filling in missing details and cleaning novel views through a cascade of in-painting and artifact removal models.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to capture continuous and differentiable terrain elevation from camera images, enabling smooth path planning and navigation in challenging terrain environments.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed NeB-SLAM method addresses scalability limitations in neural implicit representations for unknown scenes, introducing a divide-and-conquer mapping strategy and adaptive map growth to achieve efficient and real-time performance in dense 3D SLAM for unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for rendering photorealistic images from novel viewpoints with high dynamic range, achieving state-of-the-art results with significantly faster inference speed and training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed GS-Hider steganography framework embeds 3D scenes and images into original 3DGS point cloud files, concealing messages and allowing accurate extraction, with features including robust security, high fidelity, large capacity, and versatility, making it suitable for copyright protection and encrypted communication.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method, called ETA, that enhances translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems, which improves accuracy and robustness while maintaining a comparable runtime speed to existing methods.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes an approach that addresses the limitations of Neural Radiance Fields (NeRFs) in reconstructing and rendering high-frequency view-dependent appearance, particularly in scenes with shiny objects, by incorporating ray tracing to synthesize consistent reflections of nearby and distant content using a small neural network.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that combines visual SLAM and human mesh reconstruction to jointly reconstruct camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Neural Directional Encoding (NDE), a feature-grid-like neural representation that efficiently models high-frequency view-dependent appearance and interreflection effects for rendering specular objects, outperforming state-of-the-art methods in novel-view synthesis and achieving fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents the first real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration with heterogeneous sensor modalities, spatial viewpoints, and coverage ranges, and provides annotations for pose estimation and high-level perception, enabling research in this unexplored area.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper contributes to the development of efficient robot learning for perception and mapping by addressing the challenges of deploying robotic systems in previously unseen environments. The key ideas are:1. Continual Learning for Robotics: The paper proposes a novel approach to enabling an autonomous agent to adapt to unseen domains while retaining high performance on previous domains, thereby reducing human effort in deploying perception-based robotic systems.2. Label-Efficient Panoptic Segmentation: The paper introduces a method for extremely label-efficient training of panoptic segmentation networks using task-agnostic pretraining and semantic feature transfer from a frozen DINOv2 backbone.3. Autonomous Target-less Camera-LiDAR Calibration: The paper presents a novel method for automatic target-less camera-LiDAR calibration using a graph optimization problem constrained by sensor motion and point correspondences.4. Multi-Agent Collaboration: The paper proposes an approach to efficient robot learning via multi-agent collaboration, where ego agents share online detections to enable inter-agent sharing of information.The paper's ongoing research focuses on transferring the insights gained from vision-based label-efficient panoptic segmentation to 3D point clouds, exploring the use of foundation models for processing LiDAR data, and investigating the impact of foundation models on unsupervised domain adaptation.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes a novel feed-forward framework, called LDM, that generates high-quality triangular meshes with illumination-decoupled RGB textures from text or a single image input, leveraging multi-view diffusion, transformer-based models, and gradient-based mesh optimization layers.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The authors propose JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Field representation and compression, which improves quality and compression efficiency against previous methods, achieving better rate-distortion performance with reduced redundancy and enhanced details.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The key contributions of the paper are: introducing DoGaussian, a distributed method for training 3D Gaussian Splatting (3DGS) on large-scale scenes, which reduces training time by 6+ times while achieving state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the abstract and introduction in a single sentence under 50 words:The paper proposes MG-SLAM, a monocular SLAM system using 3D Gaussian Splatting and a language-extended loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, without requiring depth sensors.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that efficiently models time-dependent attributes of Gaussian primitives, achieving state-of-the-art rendering fidelity on 3 datasets and 100 times faster rendering than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MOSS, a novel framework that achieves motion-aware 3D clothed human synthesis by incorporating kinematic information to guide Gaussian splatting and detecting local occlusions to compensate for deformations, resulting in improved visual quality and realism.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a novel method that enables the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images of an unknown target spacecraft, using an implicit representation of the target through a learned Neural Radiance Field, to extend the scope of existing pose estimation methods to unknown targets.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|This paper proposes a novel LiDAR-inertial odometry (LIO) framework, NV-LIO, designed for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures. The method extracts normal vectors from LiDAR scans to enhance point cloud registration performance and addresses degeneracy and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach that leverages MVS, hybrid Gaussian rendering, and a consistent aggregation strategy to achieve real-time rendering with better synthesis quality, outperforming existing methods with faster training and inference speeds.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions of the paper's abstract and introduction are:* An overview of the integration of Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks to support immersive communications.* Discussion of the challenges and opportunities of integrating NeRF and 3D-GS in 6G networks, including efficient representation, transmission, and reconstruction of 3D contents.* Emphasizing the importance of distributed training and inference methods for NeRF and 3D-GS models over wireless networks.* Highlighting the need for efficient rendering architectures, model compression, and joint computation and communication designs to support immersive communications over 6G networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
