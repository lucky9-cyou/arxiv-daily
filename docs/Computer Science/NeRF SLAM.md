
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning, which leverages masked multi-modal reconstruction in neural radiance fields to learn robust and generalizable representations for autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, combining deformation fields, hash encoding, and a denoising mask to reduce memory usage and enhance rendering speed and quality.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes HFGS, a novel approach that addresses under-reconstruction issues in deformable endoscopic tissues reconstruction by incorporating spatial and temporal high-frequency emphasis reconstruction modules, achieving superior rendering quality in experiments over multiple benchmarks.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a method to manipulate 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling large deformation, local manipulation, and soft body simulation while maintaining high-quality rendering, with a key insight being the use of a triangle shape-aware Gaussian binding strategy with self-adaptation.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by 90% while maintaining image quality, by factorizing coordinates and attributes of Gaussians, enabling efficient rendering and compact storage.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3 and successfully process human colonoscopies in real-time, achieving 88% mapping coverage in the C3VD dataset and 53% in a real screening colonoscopy.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), which addresses challenges in scaling 3D Gaussian Splatting to large-scale scenes by incorporating a hierarchical pyramidal structure and NeRF initialization, achieving a significant performance leap with a rendering time 400 times faster.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a first-ever RGB-only SLAM system with a dense 3D Gaussian map representation, leveraging global optimization and adaptive deformation for improved reconstruction, rendering, and tracking accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a novel method that uses pretrained 2D diffusion models for sparse-view reconstruction of 360 3D scenes, leveraging a cascade of in-painting and artifact removal models to generate detailed and coherent scenes from few input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* NEMos leverage quantile regression to learn the height information from images alongside the NeRF density distribution.* The proposed method allows for joint training of the NeRF and height field, enabling efficient generation of terrain models from imagery.* The approach enables path planning on the NEMo height field, which produces smoother and more efficient paths compared to traditional discrete path planning methods.Note that the provided text is a summary and not the original abstract or introduction.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown scenarios, featuring a divide-and-conquer mapping strategy and adaptive map growth strategy, achieving real-time, scalable, and predictive performance in mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes a new framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR imaging, which achieves better performance and faster training/inference speeds compared to existing methods, including NeRF-based methods and 3D Gaussian Splatting (3DGS).|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files, ensuring security, fidelity, and versatility, and can hide multiple messages, including 3D scenes and images, without compromising rendering quality.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper's abstract and introduction are:* A new initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) systems, called ETA, which improves translation accuracy without increasing runtime.* The ETA method uses a 3-DoF Bundle Adjustment (BA) to refine translation estimates independently, while keeping rotation estimates fixed.* The method also updates rotation estimates using IMU measurements and gyroscope bias, unlike previous methods which may suffer from inferior results in challenging scenarios.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces an approach that combines Neural Radiance Fields (NeRF) with ray tracing to improve the rendering of highly specular objects, synthesizing consistent reflections of nearby and distant content while reducing computational complexity and optimizing rendering speed.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR) to jointly reconstruct metric-scale camera poses, scene point clouds, and human meshes from monocular videos, leveraging human-aware metric SLAM and scene-aware SMPL denoiser to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-based spatial encoding method that efficiently models high-frequency angular signals and addresses interreflection effects, achieving state-of-the-art results in view synthesis of specular objects with fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizing a hash-encoded NeRF representation and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper presents a pioneering, real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, diverse sensor modalities, and high-level perception annotation, aiming to boost research in this area by providing a comprehensive and challenging dataset.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The author's research aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning, and key contributions include approaches to continual unsupervised adaptation of robotic vision systems, label-efficient panoptic segmentation, and collaborative robot mapping.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-quality textured meshes from single images or text prompts in seconds, leveraging multi-view diffusion, transformer-based models, and gradient-based mesh optimization to produce accurate and decoupled SDF fields and textures.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end Joint Optimization scheme for dynamic Neural Radiance Field representation and compression, achieving improved quality and compression efficiency by utilizing a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes DoGaussian, a novel method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, reducing training time by 6+ times while achieving state-of-the-art rendering quality, and overcoming the limitations of previous distributed training approaches for 3DGS.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces MG-SLAM, a monocular Gaussian SLAM system that achieves high-fidelity reconstruction and drift-corrected tracking using a CLIP feature-based loop closure module, and performs well on multiple challenging datasets in tracking and mapping.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent Gaussian primitives with discrete time embedding, achieving state-of-the-art rendering fidelity, 100x faster rendering, and accurate disentanglement of appearance changes.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce an innovative framework, MOSS, that incorporates kinematic information to achieve motion-aware Gaussian splatting for 3D clothed human synthesis, overcoming limitations by addressing global motion constraints, occlusions, and joint details, achieving state-of-the-art visual quality.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target spacecraft by leveraging an in-the-wild Neural Radiance Field (NeRF) model. The method involves training a NeRF model using a sparse collection of images depicting the target spacecraft and generating a large dataset that captures the diversity of both pose distribution and illumination conditions encountered in orbit. The trained NeRF model is then used to generate a training set for an off-the-shelf Spacecraft Pose Estimation (SPE) network, which is demonstrated to successfully estimate the relative pose of an unknown target spacecraft with a monocular camera.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper proposes NV-LIO, a normal vector-based LiDAR-inertial odometry framework that utilizes normal vectors from LiDAR scans to achieve robust registration in indoor environments with multifloor structures.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo, pixel-aligned Gaussian representations, and a consistent aggregation strategy to achieve real-time rendering with better synthesis quality and fast fine-tuning.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a comprehensive overview of integrating Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for immersive communications. The authors highlight the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks, which requires new interdisciplinary design approaches. They review the basics of radiance field rendering techniques, applications, and implementation challenges over wireless networks. The paper also presents various learning techniques, including federated learning, for over-the-air training of NeRF and 3D-GS models and discusses practical rendering architectures, model compression, and joint computation and communication designs.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
