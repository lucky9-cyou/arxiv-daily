
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Neural Elevation Models (NEMos) introduce a novel representation for terrain mapping that combines Neural Radiance Fields with a continuous and differentiable height field, enabling efficient path planning and robust navigation in complex environments.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to achieve real-time scalable and predictive performance in unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HDR-GS, a novel framework for 3D HDR imaging that uses a Dual Dynamic Range Gaussian point cloud model to render HDR images and LDR views with controllable exposure time, outperforming state-of-the-art methods in terms of PSNR, SSIM, and LPIPS while enjoying faster training and inference speed.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original point cloud files in an invisible manner, ensuring security, fidelity, capacity, and flexibility, with robustness and versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A method to improve translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM systems, by using a 3-Degree-of-Freedom (DoF) Bundle Adjustment (BA) separately from rotation estimation.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The key contributions of the paper are an approach that uses ray tracing to render high-quality specular reflections of nearby and distant content in scenes with shiny objects, improving upon existing NeRF methods that struggle with consistent reflections and rely on large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a novel approach that jointly reconstructs 3D human models, camera trajectories, and dense scene point clouds from monocular videos, addressing depth, scale, and dynamic ambiguities to produce consistent and coherent results.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction within a single sentence under 50 words:Neural Directional Encoding (NDE) is introduced, a view-dependent appearance encoding for neural radiance fields (NeRF) that captures glossy and specular effects, including multi-bounce reflections, and achieves high-quality rendering with fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions, and a hash-encoded NeRF, to improve camera relocalization, introducing a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions in one sentence under 50 words:This paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, heterogeneous sensors, and diverse spatial viewpoints, to facilitate research in multi-modal collaborative perception and unlock its potential for high-level scene understanding.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas VÃ¶disch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper explores how to minimize human effort in deploying perception-based robotic systems to previously unseen environments, focusing on leveraging continual learning and reducing human annotations for efficient learning.* The paper introduces two concepts: Continual Learning for Robotics (CLR) and Label-Efficient Panoptic Segmentation (LEPS).* CLR aims to equip an autonomous agent with the capability to automatically adapt to unseen domains while retaining high performance on all previous domains.* LEPS renders a highly impactful paradigm shift for deploying panoptic segmentation in the wild, as it requires as few as ten annotated images and produces competitive results with fully supervised learning methods.Let me know if you'd like me to add or clarify anything!|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from text or images, using a multi-view diffusion model, a transformer-based SDF prediction model, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by employing a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS), addresses the memory and training time issues of 3DGS on large-scale scenes by decomposing the scene into blocks, applying Alternating Direction Method of Multipliers (ADMM), and guaranteeing training convergence and stability.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module that enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, without requiring RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives to reconstruct 3D scenes with vastly varying appearances, achieving state-of-the-art rendering fidelity and 100 times faster rendering speed than NeRF-based methods.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose a motion-aware framework, MOSS, which uses kinematic information to guide Gaussian distributions and overcome limitations in single-view clothed human reconstruction, achieving state-of-the-art visual quality and realistic joint details and clothing folds.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces a novel method that enables the estimation of the 6D pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF) to generate a diverse and large training set from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM, addressing challenges in point cloud registration and degeneracy detection, and demonstrating effectiveness through validation on public and private datasets.|[2405.12563v1](http://arxiv.org/abs/2405.12563v1)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:MVSGaussian presents a new generalizable 3D Gaussian representation approach that integrates Multi-View Stereo encoding, pixel-aligned Gaussian parameters, and a hybrid Gaussian rendering method, achieving fast and high-quality novel view synthesis with reduced training cost.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The paper explores the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G wireless networks for efficient representation, transmission, and reconstruction of 3D contents.* NeRF and 3D-GS are two promising 3D representation techniques based on radiance field rendering, which provide photorealistic rendering results for complex scenes.* The paper discusses the challenges of integrating NeRF and 3D-GS in 6G wireless networks, including the need for distributed training and inference methods, joint computation and communication designs, and minimization of end-to-end latency while preserving quality of experience (QoE) requirements.* The paper also highlights the importance of embracing NeRF and 3D-GS in 6G wireless networks to support emerging 3D applications with enhanced quality of experience.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly modeling point light attenuation and raytracing cast shadows, and uses a fully neural material renderer. The key contributions are:* A neural multi-view photometric stereo approach that fully leverages pixel intensity information for estimating 3D shape from photometric stereo images.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:This paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a "Judge" mechanism that assesses the realism of objects and refines their textures to blend in with real-world environments.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Developing a novel two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, accurately characterizing signal dynamics.* Proposing a NeRF-based ray tracing method to model dynamic electromagnetic fields, enabling the prediction of signal fields at any specified RIS placement and receiver location.* Experimental validations through simulated and measured data demonstrate the effectiveness of the proposed method.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising fast ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building, to address the challenges of catastrophic failure in learning-based methods and dynamic real-world environments with moving objects.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep visual feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve high-fidelity scene representation with reduced memory usage and improved tracking performance.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The paper proposes a lightweight circular convolutional Transformer network, CCTNet, to address the issues of "restricted receptive fields" and "excessive focus on local regions" in current range image-based networks, achieving superior performance in place recognition tasks.|[2405.10793v1](http://arxiv.org/abs/2405.10793v1)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry, differing from existing approaches that require pre-estimated accurate robot poses to estimate the map.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a comprehensive survey of methodologies enabling Large Language Models (LLMs) to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction in embodied AI systems, and outlining challenges and future research directions.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here are the key contributions from the paper's abstract and introduction:The paper presents a method to convert between parametric (NeRF) and non-parametric (Gaussian Splatting, GS) representations of 3D scenes, achieving the best of both worlds in terms of PSNR, SSIM, and LPIPS. The conversion process is fast and minor compared to training the models from scratch.The key contributions are:1. A procedure to convert NeRFs to GS, allowing for fast rendering and easy modification of the representation.2. A procedure to convert GS back to NeRFs, enabling the update of the map and distilled features.3. The approach achieves state-of-the-art results in terms of PSNR, SSIM, and LPIPS, especially for views that are dissimilar to the training views.The paper is significant in the field of robotics, as it allows for the use of parametric representations for scene modeling and understanding, while still providing fast rendering and ease of modification, which are essential for real-time robotics applications.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
