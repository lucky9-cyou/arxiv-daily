
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method for synthesizing photo-realistic images of the stomach from monocular gastroscopic data using neural radiance fields (NeRF), incorporating geometry-based loss to address view sparsity and improve rendering quality.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple yet effective approach that enables robust novel view synthesis in complex, dynamic real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving faster convergence and improved render quality compared to state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes NeRF-Supervised Masked Auto Encoder (NS-MAE), a self-supervised pre-training paradigm for transferable multi-modal representation learning, which enables efficient fine-tuning of models for both multi-modal and single-modal perception tasks in autonomous driving scenarios.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here are the key contributions summarized in a single sentence under 50 words:The authors propose a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, combining deformation fields, hash encoding, and learnable denoising masks, and introducing static and motion consistency constraints to achieve more efficient rendering and reduced memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in static and dynamic scenes by incorporating deformation fields and frequency regularization modules for improved spatial and temporal detail rendering.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a method that enables 3D Gaussian Splatting (3DGS) manipulation using a triangular mesh, achieving high-quality and photo-realistic rendering while maintaining rendering quality and having a high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements while maintaining image quality in 3D Gaussian Splatting (3DGS). F-3DGS uses factorization techniques to approximate dense clusters of Gaussians with significantly fewer Gaussians, achieving a substantial reduction in storage costs. By exploiting structural patterns and redundancies, the approach achieves a reduction in storage costs by down-sizing 3DGS over 90% while maintaining comparable image quality. The method allows for efficient representation of 3D scenes by approximating dense clusters of Gaussians with a limited amount of information for each axis and their combinations, enabling fast rendering speed and compact storage.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce CudaSIFT-SLAM, a novel V-SLAM system that uses SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3, achieving real-time processing and successfully mapping complex colonoscopy sequences with high coverage and precision.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS) with NeRF initialization, which enhances 3D Gaussian Splatting to model large-scale scenes, achieving high-fidelity visual results and accelerated rendering performance, with a significant performance leap and rendering time improvement over state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a single sentence summary of the paper's abstract and introduction under 50 words:The proposed RGB-only SLAM system uses 3D Gaussian Splatting with dynamic map deformation and proxy depth estimation to achieve accurate reconstruction, rendering, and tracking, outperforming existing methods while maintaining fast runtimes and small map sizes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses fine-tuned 2D diffusion models to reconstruct 360-degree scenes from sparse views, achieving multi-view consistency and detail coherence with superior performance and rendering speeds.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|According to the abstract and introduction, the key contributions of this work are:* Adapting Neural Radiance Fields (NeRF) to a 2.5D continuous and differentiable terrain model, named Neural Elevation Models (NEMos), which allows for generating high-quality terrain reconstructions from low-cost imagery.* A novel method for jointly training the NeRF and a height field within a NeRF framework, leveraging quantile regression.* A continuous path planning algorithm that can optimize for distance, slope changes, and control effort, enabled by the differentiability of the height field.These contributions provide a new approach to modeling complex terrain and enable robust path planning for autonomous vehicles navigating challenging environments.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive tracking and mapping in unfamiliar environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods in terms of quality and speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework called GS-Hider that embeds 3D scenes and images into original 3D Gaussian Splatting point cloud files, ensuring copyright protection, encrypted communication, and compression, with robust security, high fidelity, large capacity, and versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* A method to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM systems, which is called ETA.* The method uses a 3-DoF Bundle Adjustment, independently, while keeping the rotation estimate fixed, unlike ORB-SLAM3's 6-DoF BA.* The method updates the rotation estimate by taking into account IMU measurements and gyroscope bias, unlike ORB-SLAM3, which may yield inferior results in challenging scenarios.* Extensive evaluations on the EuRoC dataset demonstrate that the method excels in accuracy.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents a novel approach to Neural Radiance Fields (NeRFs) that addresses the challenges of rendering highly specular objects with accurate reflections, using ray tracing to synthesize feature vectors and decode them into color, achieving more efficient and higher-quality results than prior methods.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that combines human-aware metric SLAM and scene-aware SMPL denoising to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame from monocular videos.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the introduction of Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, and its ability to efficiently model high-frequency angular signals, far-field reflections, and near-field interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting conditions and shadows to improve camera relocalization, utilizing a hash-encoded NeRF representation and a revamped truncated dynamic low-pass filter and numerical gradient averaging technique to optimize camera poses.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper introduces a pioneering real-world dataset for multi-robot collaborative perception, featuring compressed, intermittent, limited, heterogeneous, and asynchronous environmental information from multiple robots, to enhance overall perception despite sensing challenges.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction, in a single sentence under 50 words:The research explores efficient robot learning for perception and mapping by leveraging continual learning and reducing human annotations, aiming to deploy robots in previously unseen environments with minimal human effort.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The proposed LDM framework generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts by utilizing a multi-view diffusion model, a transformer-based SDF predictor, and a gradient-based mesh optimization layer, outperforming existing methods in speed and quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by leveraging a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, accelerating training time by 6+ times for large-scale scenes while maintaining state-of-the-art rendering quality, and introducing a recursive approach to split scenes into balanced-sized blocks.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, that achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, leveraging 3D Gaussian representation and CLIP features for loop detection and global optimization.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a novel method that uses a lightweight neural network to model the time-dependent attributes of Gaussian primitives, allowing for efficient reconstruction of 3D scenes with vastly varying appearances and achieving state-of-the-art rendering fidelity and speed.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here are the key contributions from the paper's abstract and introduction:The authors introduce a novel framework, Motion-Based 3D Clothed Humans Synthesis (MOSS), which employs kinematic information to achieve motion-aware Gaussian split for realistic clothing deformation and joint detail reconstruction, improving human body reconstruction by 33.94% and Gaussian Splatting by 16.75%.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summarized version of the paper's abstract and introduction in a single sentence under 50 words:This paper presents a novel method for estimating the 6D pose of an unknown spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF) to generate a training set from a sparse collection of images, enabling the use of an off-the-shelf pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper proposes NV-LIO, a normal vector-based LIO framework for indoor SLAM in multifloor environments, addressing challenges such as rapid changes in LiDAR scans, repetitive structural features, and degeneracy issues, and achieves robust registration and localization results in indoor settings.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
