
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a concise summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper proposes a self-supervised 3D Gaussian Splatting method, S3Gaussian, that decomposes dynamic and static elements in street scenes without requiring 3D annotations, enabling efficient 4D scene reconstruction and novel view synthesis for autonomous driving scenarios.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:TetSphere splatting, an explicit, Lagrangian geometry representation, directly reconstructs 3D shapes with high-quality geometry using tetrahedral meshes, offering superior mesh quality, faster optimization speed, and reliable preservation of thin structures, which outperforms existing representations.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|The key contributions of the paper are:* Creation of a new set of FF synthetic and real visual scenes with respective camera poses, which can be used to evaluate NVS methods.* Evaluation of the impact of NVS on perceived quality using a well-known and reliable subjective assessment methodology, considering several scene classes and recently proposed NVS methods.* Evaluation of objective quality assessment metrics developed for 2D images and video, using several scene classes (namely real and synthetic 360º and FF scenes).|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Manhattan Gaussian SLAM (MG-SLAM), an RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness, enabling robust tracking and efficient scene completion in textureless indoor areas.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:IReNe, a novel approach for instant recoloring of neural radiance fields, efficiently edits 3D scene representations while retaining photorealism, addressing limitations such as slow processing, inaccurate object boundary control, and inconsistent view-specific effects, offering real-time color editing capabilities.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel approach for detecting and classifying semantic landmarks using in-air 3D sonar and a convolutional neural network, achieving a 97.3% classification accuracy and predicting landmark orientation angles with an RMSE of less than 10 degrees.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a batch simultaneous localization and mapping (SLAM) approach for joint calibration of multiple asynchronous microphone arrays and sound source localization, addressing challenges in parameter identifiability and optimization initialization.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes HINT, a NeRF-based algorithm that learns detailed and complete human models from limited viewing angles, using symmetry, regularization constraints, and training cues from large human datasets, achieving a 15% PSNR improvement over previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation.* The method learns a feature field within a Neural Radiance Field (NeRF) representing a 3D scene, whose segmentation structure can be revealed at different scales by simply using different thresholds on feature distance.* The method is evaluated on synthetic datasets with multi-view images and multi-granular segmentation, showcasing improved accuracy and viewpoint-consistency.* The paper introduces a new synthetic dataset, and proposes new evaluation metrics, to quantify the progress and facilitate future work.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|The paper introduces a cutting-edge 3D Gaussian Splatting (3DGS)-based SLAM system that leverages efficiency and flexibility to achieve real-time performance while remaining robust against sensor noise, motion blur, and long-session SLAM challenges, through the Fusion Bridge module that integrates tracking-centered ORB Visual Odometry with mapping-centered online 3DGS.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a novel approach to synthesize arbitrary viewpoint images within a patient's stomach from pre-captured monocular gastroscopic images using neural radiance fields (NeRF).* The method leverages the advantages of NeRF, enabling photo-realistic image rendering from novel viewpoints, and addresses the performance degradation caused by view sparsity in local regions of monocular gastroscopy.* The paper introduces a novel geometry-based loss that incorporates geometry priors from a pre-reconstructed point cloud into the training of NeRF, which improves the quality of rendered images and reconstructed geometry.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|The paper introduces NeRF On-the-go, a novel approach that enables robust and efficient synthesis of novel views in complex, in-the-wild scenes from casually captured image sequences, demonstrating a significant improvement over state-of-the-art techniques while effectively eliminating distractors even when predominant in captures.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions of the paper:The paper proposes a self-supervised pre-training framework, NS-MAE, which leverages masked multi-modal reconstruction in neural radiance fields to learn transferable multi-modal representations for autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper are:1. A hybrid representation that combines deformation fields, hash encoding, and 3D-GS to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.2. A learnable denoising mask that effectively identifies and removes noise points from the scene, enhancing rendering quality.3. Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.These contributions aim to address the challenges of memory consumption and rendering issues in 3D-GS, while providing a refined representation for high-quality dynamic scene reconstruction.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction by incorporating deformation fields and frequency regularization, achieving superior rendering quality and dynamic awareness in neural rendering.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of the paper are:The proposed method enables 3D Gaussian Splatting (3DGS) manipulation, achieving high-quality and photo-realistic rendering while maintaining flexibility.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions from the paper's abstract and introduction are:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach to reduce the storage overhead of 3D Gaussian Splatting (3DGS) while maintaining excellent image quality. F-3DGS represents dense 3D Gaussians by approximating them with a limited amount of information for each axis and their combinations, allowing for a significant reduction in storage costs.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a Visual Simultaneous Localization and Mapping system that uses SIFT features and brute-force matching to overcome tracking losses in human colonoscopies, achieving real-time performance and significantly longer sub-maps than ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS), a method that addresses the challenges of large-scale scene modeling by using a hierarchical assembly of Gaussians with dynamic weighting and NeRF initialization, achieving a significant performance leap and rendering speedup over state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in one sentence under 50 words:This paper proposes an RGB-only dense SLAM system that combines frame-to-frame tracking with a deformable 3D Gaussian map, utilizing proxy depth and online map deformations at loop closure and global BA for high-quality reconstruction and rendering.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models with fine-tuning to reconstruct 360-degree scenes from sparse views, achieving high-quality results with details coherent with the observed inputs.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* Experimental results demonstrating the ability of NEMos to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.Note that the paper focuses on the development of NEMos and their application to terrain mapping and path planning, and does not provide a comprehensive review of the existing literature on these topics.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which addresses the limitations of existing methods by introducing a divide-and-conquer mapping strategy and an adaptive map growth strategy to achieve efficient and real-time SLAM in unseen environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods in terms of PSNR, SSIM, and LPIPS performance.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original point clouds, ensuring security, fidelity, and flexibility, without compromising rendering quality, and demonstrates its effectiveness through extensive experiments.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A new initialization method for stereo Visual-Inertial SLAM (VI-SLAM) that enhances translation accuracy and robustness.* The proposed method focuses on refining the translation estimate using a 3-DoF Bundle Adjustment, conducted independently, while keeping the rotation estimate fixed.* Unlike previous methods, this approach updates the rotation estimate by taking into account IMU measurements and gyroscope bias.* The method is evaluated on the public EuRoC dataset, demonstrating improved accuracy compared to existing methods.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces a novel approach to Neural Radiance Fields (NeRFs) that addresses the limitations of rendering highly specular objects by incorporating ray tracing, allowing for more efficient and accurate rendering of view-dependent appearance and reflections.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a novel approach combining metric-scale camera poses and scene point clouds with human meshes from monocular videos, addressing depth, scale, and dynamic ambiguities to produce consistent reconstructions in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for rendering specular objects, which transfers feature-grid-based spatial encoding to the angular domain, improving the ability to model high-frequency angular signals and capturing complex reflections and interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-stage camera relocalization pipeline that normalizes images with varying lighting conditions using a hash-encoded NeRF, along with a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique, achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
