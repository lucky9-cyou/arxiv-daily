
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a unified self-supervised pre-training framework for multi-modal representation learning, called NS-MAE, which is designed to provide pre-trained model initializations for efficient and high-performance fine-tuning. The framework combines the strengths of Masked Auto-Encoder (MAE) and Neural Radiance Fields (NeRF) to learn transferable multi-modal representations.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:**Key Contributions:**1. A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian Splatting (3D-GS) to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.2. A learnable denoising mask to effectively identify and remove noise points in 3D-GS, enhancing rendering quality.3. Introducing static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, addressing under-reconstruction issues by incorporating deformation fields and introducing Spatial and Temporal High-Frequency Emphasis Reconstruction modules for superior rendering quality.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The paper proposes a method called Mani-GS, which enables 3D Gaussian Splatting (3DGS) manipulation using a triangular mesh while maintaining high-quality rendering. The key contributions are:* A triangle shape-aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations.* The ability to achieve large deformation, local manipulation, and soft body simulation with high-quality results.* State-of-the-art results on the NeRF synthetic dataset, outperforming previous methods in terms of PSNR, SSIM, and LPIPS metrics.* The ability to achieve high-fidelity manipulation even when the mesh is of low quality, such as the Marching Cube mesh.* Ablation studies that verify the effectiveness of the triangle shape-aware Gaussian binding and adapting method, as well as the importance of a high-quality mesh.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while preserving image quality by factorizing dense clusters of Gaussians using efficient decomposition techniques.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a novel V-SLAM system that overcomes the limitations of ORB-SLAM3 in human colonoscopy by using SIFT features and brute-force matching, achieving real-time performance and significant improvements in map size and coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Pyramidal 3D Gaussian Splatting (PyGS) which addresses the challenges of large-scale scene modeling by using a hierarchical assembly of Gaussians, initialized with a grid-based NeRF, to achieve high-fidelity visual results and accelerated rendering performance.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes the first RGB-only SLAM system with a dense 3D Gaussian map representation that adapts dynamically to keyframe pose and depth updates, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper introduces SparseSplat360, a method that uses pre-trained 2D diffusion models fine-tuned for sparse-view reconstruction of a 360 3D scene, resulting in a multi-view consistent scene representation with coherent details.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), a novel approach that adapts Neural Radiance Fields to 2.5D continuous and differentiable terrain models, allowing for efficient generation and manipulation of terrain maps.* The ability to generate high-quality reconstructions of terrain from images, and to produce smoother paths for navigation compared to traditional discrete path planning methods.* The proposal of a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression to learn the height information from images.* The development of a path planning algorithm that leverages the continuous and differentiable nature of the height field to achieve smoother paths and reduced slope changes.These contributions aim to provide a more efficient and effective way to model and navigate complex terrain environments, leveraging the strengths of NeRFs in capturing rich visual detail and the benefits of a continuous and differentiable height field for path planning and robotics applications.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to achieve real-time, scalable, and predictive localization and mapping in unfamiliar environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while achieving 1000x faster inference speed and 6.3% shorter training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The contributions of the paper are:* Proposing a novel steganography framework called GS-Hider for embedding 3D scenes and images into original 3D Gaussian Splatting (3DGS) point cloud files in an invisible manner, and extracting the hidden messages accurately.* Designing a coupled secured feature attribute to replace the original 3DGS's spherical harmonics coefficients, and using parallel scene and message decoders to disentangle the original RGB scene and hidden message.* Demonstrating the effectiveness of GS-Hider in concealing multiple modal messages without compromising rendering quality, with exceptional security, robustness, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The paper's abstract and introduction highlight the limitations of existing Stereo Visual-Inertial SLAM (VI-SLAM) frameworks, particularly ORB-SLAM3, which rely on visual odometry to estimate camera trajectories and inertial parameters. The authors propose a new method, ETA, that enhances translation accuracy during initialization by using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) and updating the rotation estimate using IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a ray-tracing-based approach to Neural Radiance Fields (NeRFs) that enables rendering of highly specular objects with consistent reflections of nearby and distant content, outperforming prior methods while requiring comparable optimization time and using a small, inexpensive network.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces SynCHMR, a system that synergistically reconstructs camera trajectories, human meshes, and dense scene point clouds from monocular videos, addressing the limitations of existing methods in estimating 3D human motion and camera motion independently.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like neural radiance field (NeRF) that efficiently encodes view-dependent appearance and interreflection effects for rendering specular objects, achieving state-of-the-art results and fast inference speed.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions and implement a hash-encoded NeRF for camera relocalization, addressing limitations of previous methods and achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, heterogeneous sensor modalities, and diverse spatial viewpoints, to facilitate research in multi-modal collaborative perception and push the frontier of high-level scene understanding.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper investigates the minimization of human effort in deploying perception-based robotic systems to previously unseen environments, focusing on continual learning and reducing human annotations, with contributions including novel concepts in SLAM, panoptic segmentation, and automatic calibration.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality triangular meshes with illumination-decoupled RGB textures from a single image or text prompt, leveraging a tensorial SDF representation and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, achieving improved quality and compression efficiency by utilizing a compact residual feature grid and a coefficient feature grid.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS), which splits scenes into blocks, applies Alternating Direction Method of Multipliers (ADMM) for consistency, and reduces training time by 6+ times while maintaining high-fidelity rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment using 3D Gaussian and CLIP features.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that disentangles appearance changes from geometry, achieving state-of-the-art reconstruction quality and rendering speed, and successfully handling scenes with vastly varying appearances.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a motion-based framework for synthesizing 3D clothed humans from monocular videos, which incorporates kinematic information to achieve motion-aware Gaussian split and surface deformation, improving visual quality by 33.94% and 16.75% respectively.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The key contributions of the paper are:* Developing a novel method that enables an "off-the-shelf" spacecraft pose estimator, which is supposed to know the target CAD model, to be applied on an unknown target.* Using an in-the-wild Neural Radiance Field (NeRF) model that employs learnable appearance embeddings to represent varying illumination conditions found in natural scenes.* Presenting a three-steps approach for spacecraft pose estimation: image acquisition, on-ground processing, and autonomous pose estimation on board the spacecraft.* Validating the method on Hardware-In-the-Loop images of SPEED+ that emulate lighting conditions close to those encountered on orbit, demonstrating successful pose estimation of an unknown target spacecraft.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework designed for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, addressing challenges such as point cloud registration difficulties, degeneracy, and incorrect correspondences.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach derived from Multi-View Stereo, which efficiently reconstructs unseen scenes, and achieves real-time rendering with better synthesis quality, while requiring less training computational cost compared to previous methods.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions in the paper's abstract and introduction:* The paper introduces the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for the efficient representation, transmission, and reconstruction of 3D contents.* The paper highlights the importance of embracing NeRF and 3D-GS in 6G networks to support emerging 3D applications with enhanced quality of experience.* The authors provide a comprehensive overview of the integration of NeRF and 3D-GS in 6G, including the basics of radiance field rendering techniques, over-the-air learning techniques, and practical rendering architectures.* The paper emphasizes the challenge of efficiently transmitting and reconstructing NeRF and 3D-GS models over wireless networks, due to the large amount of data and computational resources required.* The authors propose a new semantic communication enabled 3D content transmission design, exploiting NeRF models as semantic knowledge bases to reduce communication overhead.(Note: The summary is under 50 words.)|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
