
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summarized key contribution in a single sentence under 50 words:The paper proposes S3Gaussian, a self-supervised method that decomposes dynamic and static 3D Gaussians in street scenes without manual annotations, using a spatial-temporal field for scene decomposition and achieving state-of-the-art rendering quality on novel view synthesis and scene reconstruction tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:TetSphere splatting is an explicit, Lagrangian geometry representation that efficiently reconstructs high-quality meshes for 3D shapes, outperforming existing methods in terms of optimization speed, mesh quality, and thin structure preservation, and offering a versatile approach for various applications.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here is a summarized version of the key contributions and main points from the introduction and abstract:Key Contributions:* Creation of a new set of synthetic and real visual scenes with corresponding camera poses for assessing NeRF view synthesis methods.* Subjective evaluation of the impact of NeRF view synthesis methods on perceived quality using a well-known and reliable subjective assessment methodology.* Evaluation of objective quality assessment metrics developed for 2D images and video, using several scene classes, including real and synthetic 360° and front-facing scenes.Main Points:* NeRF view synthesis methods have emerged as a promising solution for representing and rendering 3D scenes, but their quality assessment is a newly explored topic.* The quality of NeRF view synthesis is often assessed using 2D image and video quality assessment metrics, but there is a lack of comprehensive datasets, reliable assessment methodologies, and objective quality metrics.* The paper focuses on evaluating the quality of NeRF view synthesis methods using a subjective quality assessment study and objective quality assessment metrics.* The study includes a range of NeRF view synthesis methods, scene classes, and camera poses to assess their impact on perceived quality and the effectiveness of objective quality assessment metrics.* The evaluation includes a set of real and synthetic visual scenes, including 360° and front-facing scenes, to assess the methods' ability to handle different scene characteristics.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Manhattan Gaussian SLAM (MG-SLAM), an RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness, and achieves state-of-the-art performance by seamlessly integrating line segments and planar surface assumptions for robust tracking and efficient scene completion.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:IReNe is a novel approach that enables instant, near real-time color editing in Neural Radiance Fields (NeRF) by selectively fine-tuning the last layer of the network, leveraging a trainable segmentation module and automated neuron classification, and achieving efficient and consistent results.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a novel approach to detect and classify ten different reflector landmarks with varying radii using in-air 3D sonar, achieving 97.3% classification accuracy and predicting landmark orientation angles with an RMSE lower than 10 degrees, improving the robustness and accuracy of autonomous systems in challenging environments.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes a batch SLAM framework for joint calibration of multiple asynchronous microphone arrays and sound source localization, achieving higher accuracy and fast convergence through observability analysis and effective initialization of unknown parameters.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper proposes HINT, a NeRF-based algorithm that generates detailed and complete human models from limited-view images, using symmetry prior, regularization constraints, and large human datasets, achieving 15% PSNR improvement over previous state-of-the-art methods.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The paper presents a novel method that lifts multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation. The key contributions of the paper include:* Learning a novel feature field within a Neural Radiance Field (NeRF) representing a 3D scene, whose segmentation structure can be revealed at different scales by simply using different thresholds on feature distance.* Developing an ultrametric feature space, which is better suited for hierarchical clustering than a Euclidean space.* Proposing a new method for distilling view-inconsistent 2D masks into a 3D representation that is both view-consistent and hierarchical.The paper also provides additional implementation details, including the hierarchical sampling algorithm, the normalized covering score, the segmentation injectivity score, and the view consistency score. Additionally, the paper compares its method to several baseline methods, including DFF, LeRF, and SAM-3D.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a cutting-edge 3DGS-based SLAM system that achieves real-time performance and robustness against sensor noise and motion blur by leveraging the Fusion Bridge module, which integrates tracking-centered ORB Visual Odometry with mapping-centered online 3DGS.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method that applies neural radiance fields (NeRF) to monocular gastroscopic data, incorporating geometry priors from a pre-reconstructed point cloud to address view sparsity and noise in low-texture regions, achieving high-fidelity image renderings from novel viewpoints.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce NeRF On-the-go, a simple yet effective approach that enables robust novel view synthesis in complex, in-the-wild scenes from casually captured image sequences, surpassing state-of-the-art techniques with improved distractor removal and faster convergence speed.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This work proposes a self-supervised pre-training framework, NS-MAE, that learns transferable multi-modal representations for autonomous driving by leveraging multi-modal data and neural rendering techniques, facilitating the efficient fine-tuning of single-modal and multi-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper can be summarized as follows:* A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian Splatting to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask in conjunction with noise loss to effectively identify and remove noise points in 3D Gaussian Splatting, enhancing rendering quality.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, addressing challenging issues like under-reconstruction through Spatial High-Frequency Emphasis Reconstruction and Temporal High-Frequency Emphasis Reconstruction, and achieves superior rendering quality in extensive experiments.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling large deformations, local manipulations, and soft body simulations while maintaining high-quality rendering, and outperforms existing methods in terms of PSNR, SSIM, and LPIPS.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper introduces Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining image quality by factorizing dense clusters of Gaussians using efficient decomposition techniques, resulting in a substantial reduction of storage costs and improved rendering speed.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The authors propose CudaSIFT-SLAM, a V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving real-time performance and successfully merging sub-maps and relocating in them.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that uses a hierarchical assembly of Gaussians and NeRF initialization to achieve high-fidelity visual results and accelerated rendering performance, outperforming state-of-the-art approaches by over 400 times.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a groundbreaking RGB-only Simultaneous Localization and Mapping (SLAM) system that leverages dynamically deformed 3D Gaussian maps, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models with fine-tuning to reconstruct 360-degree scenes from sparse views, achieving state-of-the-art results on the Mip-NeRF360 dataset with multi-view consistency and coherent details.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.In summary, the paper presents a new approach for representing and navigating complex terrain using Neural Elevation Models, which combine the advantages of Neural Radiance Fields and Digital Elevation Models.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM system for unknown scenes, which combines a divide-and-conquer mapping strategy and adaptive map growth to efficiently cover and reconstruct the scene.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, achieving better results than state-of-the-art NeRF-based methods with 1000x faster inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and flexibility while hiding multiple messages and maintaining real-time rendering speeds.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The paper proposes a method to enhance the translation accuracy during the initialization stage in Stereo Visual-Inertial SLAM (VI-SLAM) systems. The method improves the translation estimate using a 3-DoF bundle adjustment, independently of the rotation estimate, and updates the rotation estimate considering IMU measurements and gyroscope bias. The key contributions include: (1) enhancing translation accuracy during initialization, (2) using a separate 3-DoF bundle adjustment for translation, and (3) updating rotation estimate considering IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a ray tracing approach to improve Neural Radiance Fields' (NeRF) ability to render detailed specular appearance, rendering consistent reflections of nearby and distant content, while reducing computational complexity and optimization time.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Synergistic Camera and Human Reconstruction (SynCHMR), which marries SLAM and Human Motion Reconstruction by leveraging camera-frame HMR as a prior to reconstruct metric-scale camera poses, scene point clouds, and human meshes in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors introduce Neural Directional Encoding (NDE), a novel view-dependent appearance encoding method for rendering specular objects, which uses a feature-grid-like encoding to model high-frequency angular signals and spatially varying directional encoding to address interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter to optimize pose refinement.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
