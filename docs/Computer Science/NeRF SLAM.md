
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"Contributions: Neural Elevation Models (NEMos) adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, enabling efficient and high-quality terrain reconstruction and path planning from aerial imagery, without relying on expensive sensors."|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a concise sentence summarizing the paper's key contributions and main ideas:"Contributions: NeB-SLAM, a neural block-based scalable RGB-D SLAM, proposes a divide-and-conquer mapping strategy and adaptive map growth strategy to efficiently cover unknown scenes, enabling real-time and predictive mapping and tracking."|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a concise summary of the paper's abstract and introduction in a single sentence of less than 50 words, starting with 'Contributions:'Contributions: The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, achieving better performance, shorter training time, and faster inference speed than state-of-the-art NeRF-based methods, and enables controllable exposure time for LDR views.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a concise summary of the paper's abstract and introduction in a single sentence, starting with "Contributions:":Contributions: This paper proposes GS-Hider, a steganography framework that embeds 3D scenes and images into original 3D Gaussian Splatting (3DGS) point cloud files, allowing for secure and invisible message transmission with high fidelity, robust security, large capacity, and versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a concise summary of the abstract and introduction in a single sentence:The paper proposes a new method called ETA that improves translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) by refining the translation estimate using a 3-DoF Bundle Adjustment (BA) independently of the rotation estimate, and updating the rotation estimate using IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"Contributions: This paper introduces a ray tracing-based approach to Neural Radiance Fields that overcomes limitations in rendering highly specular objects by synthesizing consistent reflections of nearby and distant content, while reducing computational expense and optimizing speed."|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a concise sentence summarizing the key contributions and main ideas:"Contributions: This work presents Synergistic Camera and Human Reconstruction (SynCHMR) that jointly reconstructs metric-scale camera poses, human meshes, and dense scene point clouds in a common world frame from monocular videos, leveraging human-aware metric SLAM and scene-aware SMPL denoising."|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a concise summary of the key contributions and main ideas from the paper's abstract and introduction in a single sentence:"Contributions: This paper presents Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, that achieves high-quality modeling of view-dependent effects and fast evaluation."|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a concise sentence summarizing the key contributions and main ideas of the paper:"Contributions: This paper proposes a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizing a hash-encoded NeRF with a revised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results."|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"Contributions: This paper presents the first real-world multi-robot collaborative perception dataset, featuring heterogeneous air-ground robot collaboration, multiple sensor modalities, and diverse spatial viewpoints, accompanied by raw sensor inputs, pose estimation, and optional high-level perception annotation, to facilitate research in this unexplored area."|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas VÃ¶disch et.al.|Here is a concise summary of the paper's abstract and introduction in a single sentence:Contributions: Research on minimizing human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning.Note: The sentence starts with "Contributions: " as per your request, and focuses on the most important elements from the abstract and introduction, presenting them clearly and objectively without extraneous information.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"Contributions: We propose LDM, a novel feed-forward framework generating high-fidelity, illumination-decoupled textured meshes from single images or text prompts, utilizing a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization."|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"JointRF proposes a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving significantly improved quality and compression efficiency by representing the radiance field with a compact residual feature grid and utilizing sequential feature compression to reduce spatial-temporal redundancy."|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a concise summary of the key contributions and main ideas in a single sentence:"Contributions: We propose DoGaussian, a distributed training method for 3D Gaussian Splatting that splits large-scale scenes into blocks, accelerates training by 6+ times, and achieves state-of-the-art rendering quality while maintaining rendering performance during inference."|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:Contributions: MG-SLAM, a monocular Gaussian SLAM system, presents a language-extended loop closure module based on CLIP features, enabling drift-corrected tracking, high-fidelity reconstruction, and high-level understanding of the environment without relying on RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a concise sentence summarizing the key contributions and main ideas:Contributions: Gaussian Time Machine (GTM) proposes a lightweight neural network for real-time rendering of 3D scenes with vastly varying appearances, outperforming state-of-the-art methods in both quality and speed, with a 100-fold speedup over NeRF-based methods.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a concise sentence summarizing the key contributions and main ideas:"Contributions: MOSS introduces a novel framework for single-view clothed human reconstruction, leveraging kinematic information to guide Gaussians and detect local occlusions, achieving state-of-the-art visual quality and improving upon existing methods by 33.94% and 16.75% in LPIPS and Gaussian Splatting respectively."|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"we present a novel method leveraging Neural Radiance Fields (NeRF) to train an off-the-shelf spacecraft pose estimation network using a sparse set of image samples, enabling autonomous recovery of the relative pose between a chaser spacecraft and an unknown target spacecraft"|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a concise summary of the paper's main ideas and contributions in a single sentence:"Contribution: NV-LIO, a normal vector-based LIO framework, is presented for simultaneous localization and mapping in indoor environments with multifloor structures, addressing challenges in point cloud registration due to rapid changes, repetitive structural features, and degeneracy issues."|[2405.12563v1](http://arxiv.org/abs/2405.12563v1)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a concise summary of the key contributions and main ideas in a single sentence:"Contributions: MVSGaussian presents a generalizable Gaussian Splatting method derived from Multi-View Stereo, achieves real-time rendering with better synthesis quality, and introduces a consistent aggregation strategy for fast per-scene optimization, demonstrating state-of-the-art performance with convincing generalizability, real-time rendering speed, and fast optimization."|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:Contributions: The paper integrates neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks, proposing comprehensive approaches for representation, transmission, and reconstruction of 3D contents, addressing technical challenges and exploring joint computation and communication designs, and highlighting the importance of efficient representation, transmission, and reconstruction for immersive communications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a concise summary of the paper's abstract and introduction in a single sentence:Contributions: The paper presents a novel multi-view photometric stereo method that leverages neural shape representations and learnt renderers, explicitly modeling point light attenuation and casting shadows to approximate each point's incoming radiance, and jointly optimizes the surface with a fully neural material renderer.Note that this summary focuses only on the most important elements and does not include unnecessary information.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a rewritten version of the key contributions and main ideas in a concise sentence:"Contributions: A modified gradient-based texture optimization method for discovering realistic-looking adversarial objects is introduced, incorporating an evaluative mechanism, the 'Judge', to assess and enhance the realism of generated objects, with four strategies proposed for developing a reliable Judge."|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a concise sentence that summarizes the key contributions and main ideas in the paper:"We propose a novel NeRF-based ray tracing method to accurately model the dynamics of electromagnetic fields in reconfigurable intelligent surface (RIS)-enabled wireless environments, allowing for precise characterization of signal propagation and enabling efficient RIS deployment."|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|Here is a concise summary of the paper's abstract and introduction in a single sentence of less than 50 words, starting with "Contributions:":Contributions: This paper proposes a robust long-term robotic mapping system that works out of the box in diverse scenarios, featuring a new approach to ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to handle changing environments and moving objects.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a concise sentence summarizing the key contributions and main ideas of the paper:"Contributions: A novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, integrates deep feature extraction, dual keyframe selection, and 3DGS to achieve high-fidelity scene representation, accurate real-time tracking, and reduced memory usage."|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"Contributions: CCTNet, a lightweight circular convolutional Transformer network, is proposed to address issues of 'restricted receptive fields' and 'excessive focus on local regions' in range image-based place recognition, achieving superior performance and generalization in various datasets."|[2405.10793v1](http://arxiv.org/abs/2405.10793v1)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a concise summary of the paper's abstract and introduction in a single sentence:"Contributions: The paper proposes an optimization-based SLAM approach that simultaneously optimizes the robot trajectory and occupancy map using 2D laser scans and odometry, achieving more accurate results than existing methods by optimizing robot poses and occupancy maps together."|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a concise sentence summarizing the key contributions and main ideas from the paper's abstract and introduction:"Contributions: This survey paper provides an exhaustive overview of methodologies and applications integrating Large Language Models with 3D data, highlighting their potential to advance spatial comprehension and interaction within embodied AI systems, while examining challenges and opportunities for harnessing their full potential."|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a concise summary of the key contributions and main ideas in a single sentence:The paper presents a procedure to convert between implicit scene representations like NeRFs and explicit ones like Gaussian Splatting, achieving the best of both worlds in terms of generalization capability and rendering speed for robotics applications.Note: I focused on the main ideas and contributions mentioned in the abstract and introduction, excluding specific details and technical jargon.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
