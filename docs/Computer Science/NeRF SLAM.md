
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|The paper proposes a self-supervised method, S3Gaussian, for 3D reconstruction of street scenes without requiring 3D annotations, leveraging 3D Gaussian Splatting and a spatial-temporal field network to compactly model the 4D dynamics of dynamic scenes.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a single sentence summarizing the key contributions:The paper presents TetSphere splatting, a novel Lagrangian geometry representation that efficiently reconstructs high-quality 3D shapes with tetrahedral meshes, outperforming existing Eulerian and Lagrangian representations in terms of computational efficiency, mesh quality, and thin structure preservation.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|According to the abstract and introduction, the contributions of this paper are:* Creation of a new set of 360Â° and front-facing synthetic and real visual scenes with camera poses, which can be used to assess Neural Radiance Fields (NeRF) methods.* Conducting a subjective assessment study to evaluate the impact of NeRF view synthesis methods on perceived quality, considering various scene classes and recently proposed NeRF methods.* Evaluating the performance of state-of-the-art conventional and learning-based full-reference 2D image and video quality assessment metrics in the context of NeRF view synthesis.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**Structure Gaussian SLAM with Manhattan World Hypothesis**|Shuhong Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Manhattan Gaussian SLAM (MG-SLAM), a RGB-D system that leverages the Manhattan World hypothesis to enhance geometric accuracy and completeness, enabling robust tracking and scene completion in textureless indoor environments.|[2405.20031v1](http://arxiv.org/abs/2405.20031v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce IReNe, a novel approach that enables swift, near real-time color editing in neural radiance fields (NeRFs) by leveraging a pre-trained model, user-applied color edits, and a trainable segmentation module, achieving significant improvements in efficiency, accuracy, and view-consistency.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**Semantic Landmark Detection & Classification Using Neural Networks For 3D In-Air Sonar**|Wouter Jansen et.al.|The paper's abstract and introduction highlight the key contributions as follows:* Experimental results show promising performance of a convolutional neural network (CNN) in detecting and classifying ten different reflector landmarks using in-air 3D sonar.* The CNN achieves a 97.3% classification accuracy on the test dataset and predicts landmark orientation angles with a root mean square error (RMSE) lower than 10 degrees.* The approach uses a cochleogram, a time-frequency representation of the reflected echoes, as input to the neural network, which is modeled after the inner ear of biological species such as echolocating bats.* The reflectors are based on dish-shaped leaves of the Cuban liana Marcgravia evenia and have varying radii.Overall, the paper presents a novel approach to using in-air 3D sonar for detecting and classifying reflector landmarks, which can enhance the robustness and accuracy of autonomous systems in challenging environments.|[2405.19869v1](http://arxiv.org/abs/2405.19869v1)|null|
|**2024-05-30**|**SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays and Sound Source Localization**|Jiang Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a batch simultaneous localization and mapping framework with the Fisher information matrix approach to jointly calibrate multiple asynchronous microphone arrays and localize sound sources, leveraging observability analysis and parameter identifiability conditions.|[2405.19813v1](http://arxiv.org/abs/2405.19813v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, using symmetry prior, regularization constraints, and large human datasets, achieving improved performance by 15% PSNR and 34% LPIPS compared to previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a novel method for 3D scene segmentation that learns an ultrametric feature field within a Neural Radiance Field (NeRF) representation. The method can distill view-inconsistent 2D masks into a 3D representation that is both view-consistent and hierarchical. This allows for hierarchical segmentation of scenes at multiple levels of granularity. The method outperforms existing open-vocabulary 3D segmentation methods in terms of IoU accuracy and 3D consistency.The key contributions of the paper are:* A novel formulation for 3D scene segmentation using ultrametric feature fields* A method that can distill view-inconsistent 2D masks into a 3D representation that is view-consistent and hierarchical* Improved hierarchical segmentation of scenes at multiple levels of granularity* Outperformance of existing open-vocabulary 3D segmentation methods in terms of IoU accuracy and 3D consistency|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-30**|**TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM**|Peifeng Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed approach introduces a 3DGS-based SLAM system that leverages the efficiency and flexibility of 3DGS to achieve real-time performance while remaining robust against sensor noise and motion blur, through the Fusion Bridge module that integrates tracking-centered ORB Visual Odometry with online 3DGS.|[2405.19614v1](http://arxiv.org/abs/2405.19614v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel approach to address view sparsity in monocular gastroscopy images by integrating geometry-based loss with neural radiance fields (NeRF), achieving high-fidelity image renderings from novel viewpoints with improved rendering quality and recovered geometry.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeRF On-the-go introduces a novel approach for robustly synthesizing novel views in complex, dynamic, real-world scenes from casually captured image sequences, addressing distractors like moving objects, shadows, and lighting changes, and achieving faster convergence speed and improved render quality.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions mentioned in the abstract and introduction:* The paper proposes a self-supervised pre-training framework, NS-MAE, for multi-modal representation learning in autonomous driving, which can be applied to both multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines the advantages of Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS), introducing a hybrid representation of explicit and implicit features.* The framework aims to mitigate the storage consumption associated with 3D-GS and introduces a novel view synthesis method tailored for dynamic mapping.In summary, the paper's main contributions are:|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses challenges by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction, achieving superior rendering quality in extensive experiments.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The proposed method, Mani-GS, enables manipulation of 3D Gaussian Splatting (3DGS) using a triangular mesh as a proxy, allowing for large deformation, local manipulation, and soft body simulation with high-quality rendering while maintaining rendering quality and having a high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements while maintaining image quality for 3D Gaussian Splatting (3DGS). F-3DGS efficiently represents dense clusters of Gaussians with significantly fewer Gaussians through factorization, inspired by classical matrix and tensor factorization techniques. The proposed method allows for substantial reduction in storage costs, achieving high rendering speed and quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The paper presents CudaSIFT-SLAM, a monocular visual simultaneous localization and mapping (V-SLAM) system that can process complete human colonoscopies in real-time, overcoming limitations of previous systems like ORB-SLAM3 by using SIFT features and brute-force matching instead, resulting in significantly improved map merging and relocation capabilities.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that combines Gaussian splatting with NeRF initialization to efficiently handle large-scale scenes, achieving a significant performance leap and rendering time speedup over state-of-the-art methods.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik SandstrÃ¶m et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Splat-SLAM, an RGB-only SLAM system that combines frame-to-frame tracking with a dense deformable 3D Gaussian map, enabling online map deformations and accurate surface reconstruction while maintaining fast runtimes and small map sizes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The key contributions of the paper are the development of a sparse-view reconstruction method, SparseSplat360, that uses pre-trained 2D diffusion models to fine-tune scene reconstruction and improve performance on 360-degree scenes with low-cost processing.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* Introducing a novel method for joint training of a height field and radiance field within a NeRF framework, leveraging quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* Demonstrating NEMo's ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.Note: The abstract and introduction primarily focus on introducing the concept of Neural Elevation Models and its potential applications, rather than presenting a comprehensive summary of the paper's contents.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown environments, which employs a divide-and-conquer mapping strategy and adaptive map growth to achieve scalable and real-time dense mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summarized sentence:The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR novel view synthesis, which achieves better performance, faster training, and inference speed compared to existing NeRF-based methods, and establishes a data foundation for 3DGS-based methods in HDR imaging.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors present GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds messages into original 3D point cloud files, ensuring security, fidelity, capacity, and versatility, while overcoming the challenges of 3DGS's explicit representation and real-time rendering speeds.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper can be summarized as follows: The proposed method enhances translation accuracy during the initialization stage in Stereo Visual-Inertial SLAM systems by using a 3-degree-of-freedom Bundle Adjustment (BA) to refine the translation estimate independently while keeping the rotation estimate fixed. This approach also incorporates IMU measurements and gyroscope bias to update the rotation estimate. The method is comparable to Stereo-NEC in performance but has a faster runtime.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper addresses the limitations of Neural Radiance Fields in rendering highly specular objects by introducing ray tracing, enabling the synthesis of consistent reflections of nearby and distant content while reducing computational cost and improving rendering quality.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper introduces SynCHMR, a method that synergistically reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos by combining and refining human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summarized key contribution in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, which effectively models high-frequency angular signals, far-field reflections, and near-field interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-stage pipeline for camera relocalization under varying lighting conditions, utilizing a hash-encoded NeRF with a normalized image and re-devised low-pass filter, and achieves state-of-the-art results on various datasets.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
