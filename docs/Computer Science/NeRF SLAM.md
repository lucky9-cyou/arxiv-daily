
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel method that reduces storage requirements by up to 90% while maintaining image quality by factorizing dense 3D Gaussians using efficient structured coordinates and decomposed representations.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The key contributions of the paper are the development of CudaSIFT-SLAM, a real-time V-SLAM system capable of processing complete human colonoscopies, and the use of SIFT features and brute-force matching to improve place recognition and overcome tracking losses due to clutter and deformation in endoscopy scenes.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS) with NeRF initialization, a method that scales 3D Gaussian Splatting to large-scale scenes by hierarchical Gaussian representations and dynamic weighting, achieving a significant performance leap and over 400x faster rendering time.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The authors propose the Splat-SLAM system, an RGB-only dense SLAM method that employs a dynamic 3D Gaussian map representation, refined by adaptively deforming the map to keyframe pose and depth updates, and exploiting monocular depth estimation in inaccurate areas for improved 3D reconstruction.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|This paper proposes SparseSplat360, a method that utilizes pretrained 2D diffusion models with fine-tuning to reconstruct 360-degree scenes from sparse views, improving performance and generating detailed scenes from as few as 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Key contributions from the paper's abstract and introduction:* The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for efficient terrain representation and navigation.* NEMos jointly train a height field and radiance field within a NeRF framework, leveraging quantile regression, and enable continuous and differentiable terrain representation.* The paper presents a novel approach for path planning using the continuous and differentiable height field representation, allowing for smoother and more efficient paths.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM system for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth strategy to efficiently represent and reconstruct 3D scenes with unknown sizes.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summarized sentence under 50 words:The paper proposes HDR-GS, a 3D Gaussian Splatting-based method for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and flexibility, with applications in copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a new initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) that enhances translation accuracy during the initialization stage.* The method uses a 3-DoF Bundle Adjustment to refine the translation estimate while keeping the rotation estimate fixed, and updates the rotation estimate using IMU measurements and gyroscope bias.* The authors compare their method with existing methods, including ORB-SLAM3 and Stereo-NEC, and demonstrate its superiority in terms of accuracy and runtime.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces a novel approach to Neural Radiance Fields (NeRFs) that addresses the issue of reconstructing highly specular objects by leveraging ray tracing, allowing for consistent rendering of reflections and reducing the reliance on large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces SynCHMR, a synergistic approach that combines human-aware metric SLAM and scene-aware SMPL denoising to reconstruct metric-scale camera poses, human meshes, and dense scene point clouds from monocular videos, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents Neural Directional Encoding (NDE) for rendering specular objects, achieving high-quality modeling of view-dependent appearance and fast evaluation, by transferring feature-grid-based spatial encoding to the angular domain and incorporating spatially varying directional encoding.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter to improve pose optimization and achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a comprehensive real-world dataset for multi-robot collaborative perception, addressing the lack of real-world datasets and facilitating research in this area.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The research aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations.* The author proposes novel approaches for efficient robot learning, including continual SLAM, label-efficient panoptic segmentation, and collaborative robot mapping.* The author's research contributes to the field of robotic vision by addressing the challenges of adapting to new environments, reducing the need for human annotations, and enabling efficient learning.* The author's methods are demonstrated to be competitive with fully supervised learning methods and have the potential to be applied to various real-world robotic applications.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, utilizing a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for representing and compressing dynamic Neural Radiance Fields, achieving improved quality and compression efficiency by exploiting temporal redundancy and using a compact residual feature grid.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:DoGaussian proposes a distributed training method for 3D Gaussian Splatting, decomposing scenes into blocks, applying ADMM for 3D Gaussian consensus, and reducing training time by 6+ times while achieving state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, achieving drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, with contributions including a novel loop closure module and a real-time mapping approach.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) proposes a real-time rendering method for scenes with varying appearances, using lightweight neural networks to model time-dependent attributes and decompose rendering color, achieving state-of-the-art reconstruction quality and rendering speed.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|The paper introduces an innovative framework, Motion-Based 3D Clothed Humans Synthesis (MOSS), which employs kinematic information to achieve motion-aware Gaussian split on the human surface, enhancing realism and accuracy in reconstructing 3D clothed humans from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The authors propose a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, a crucial step for autonomous rendezvous and proximity operations in Active Debris Removal missions. The method leverages Neural Radiance Fields (NeRFs) to generate a large dataset of diverse images from a sparse set of in-the-wild images, allowing the training of an "off-the-shelf" spacecraft pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper presents NV-LIO, a novel normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor multifloor environments, addressing degeneracy and double-side issues through normal vector registration and viewpoint-based loop closure.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:MVSGaussian, a novel generalizable 3D Gaussian representation approach, efficiently reconstructs unseen scenes using Multi-View Stereo (MVS), includes a hybrid Gaussian rendering approach, and aggregates point clouds for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper discusses the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks for immersive communications. The authors highlight the importance of efficient 3D representation, transmission, and reconstruction for 6G applications like XR, telepresence, and metaverse. They review the basics of NeRF and 3D-GS, and focus on the over-the-air training of NeRF and 3D-GS models over wireless networks, proposing federated learning designs and model compression approaches to reduce communication overhead.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the paper's abstract and introduction are:* A novel multi-view photometric stereo (PS) method that leverages per-pixel intensity renderings rather than relying mainly on estimated normals.* The method explicitly models point light attenuation, raytraces cast shadows, and optimizes a fully neural material renderer to estimate 3D shape from Photometric Stereo images.* The approach outperforms classical methods like DiLiGenT-MV and achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a single sentence summarizing the key contributions of the paper and its introduction:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a novel "Judge" mechanism to evaluate object realism and ensuring that generated objects are both adversarial and realistic in appearance.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a NeRF-based ray tracing method to model dynamic electromagnetic fields in RIS-enabled environments, which accurately captures complex propagation dynamics and enables effective RIS deployment for improving communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a robust long-term robotic mapping system that includes fast ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to overcome challenges in untrained scenes and dynamic environments.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
