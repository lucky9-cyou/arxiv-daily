
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel approach to enable arbitrary viewpoint image synthesis within a patient's stomach from pre-captured monocular gastroscopic images using neural radiance fields (NeRF) and incorporates geometry priors from a pre-reconstructed point cloud to improve rendering quality.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NeRF On-the-go, a simple and effective approach for synthesizing novel views in complex, in-the-wild scenes from casually captured image sequences, while efficiently eliminating distractors and achieving faster convergence speed compared to state-of-the-art methods.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning in autonomous driving, which leverages masked multi-modal reconstruction in neural radiance fields to learn robust and generalizable embeddings.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The main contributions of the paper are:* A hybrid representation that combines deformation fields, hash encoding, and 3D-GS to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask that can effectively identify and remove noise points in 3D-GS, enhancing rendering quality.* Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose a novel approach, HFGS, for deformable endoscopic tissue reconstruction, which addresses the limitations of existing methods by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction to improve rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, while maintaining high-quality rendering. The key contributions are:* Proposing a triangle shape-aware Gaussian binding strategy with self-adaptation, which enables manipulation of 3DGS while maintaining high-fidelity rendering.* Introducing a local triangle space for each triangle, allowing for Gaussian attributes to be optimized in this space, ensuring high-quality rendering even when the mesh is inaccurate.* Evaluating the proposed method on the NeRF synthetic dataset and demonstrating state-of-the-art results, including large deformations, local manipulations, and soft body simulations.Note that the reply is under 50 words.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that factorizes 3D Gaussian Splatting coordinates and features to significantly reduce storage requirements while preserving high-quality image rendering.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a monocular V-SLAM system that successfully processes complete human colonoscopies in real-time by using SIFT features, brute-force matching, and GPU acceleration, overcoming tracking losses and merging sub-maps, and achieving significantly longer sub-maps and higher coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that scales 3D Gaussian Splatting to large-scale scenes by using a hierarchical pyramidal structure and dynamic weighting, achieving a significant performance leap and rendering time over 400 times faster than state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Splat-SLAM, a RGB-only SLAM system that combines 3D Gaussian Splatting with globally optimized tracking, dynamic map deformation, and proxy depth estimation, achieving superior or on-par performance with state-of-the-art methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses fine-tuned 2D diffusion models to reconstruct 360-degree scenes from sparse views, achieving multi-view consistency and detail coherence with superior performance and rendering speeds.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), a novel framework that adapts Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model, which can be generated from imagery and provides a lightweight representation of terrain.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression, which eliminates spurious density above the surface and provides a clean representation of the terrain.* A path planning algorithm that leverages the continuous and differentiable nature of the height field to optimize a cost function for minimizing distance, slope changes, and control effort, enabling smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, utilizing a divide-and-conquer mapping strategy and adaptive map growth strategy to efficiently cover the entire scene.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for HDR novel view synthesis, achieving state-of-the-art results on HDR and LDR novel view synthesis tasks with 1000x faster inference speed and only 6.3% training time required.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes the GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, high fidelity, large capacity, and versatility without compromising rendering quality.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a method to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems, which is a critical step in ensuring accurate and robust localization.* The method uses a 3-DoF Bundle Adjustment (BA) independently to refine the translation estimate while keeping the rotation estimate fixed, unlike existing methods that use 6-DoF BA.* The authors also update the rotation estimate by considering IMU measurements and gyroscope bias, unlike existing methods that directly obtain the rotation from stereo visual odometry.* The method is evaluated on the EuRoC dataset and outperforms existing methods in terms of accuracy while maintaining a comparable run-time speed.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce a ray tracing-based approach that outperforms previous Neural Radiance Field (NeRF) methods in rendering view-dependent appearance, particularly of nearby content, with high-fidelity specular reflections, while reducing training and rendering speed.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a framework that jointly reconstructs 3D human bodies, camera trajectories, and dense scene point clouds from monocular videos, addressing scale, depth, and dynamic ambiguities, and provides a synergy between visual SLAM and human mesh reconstruction.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like encoding that accurately models the appearance of shiny objects by transferring the concept of spatial encoding to the angular domain, significantly improving the ability to model high-frequency angular signals.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline for camera relocalization, normalizing images with varying lighting conditions, and implementing a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique for robust pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The key contributions of the paper can be summarized as: a pioneering and comprehensive real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities, which accommodates diverse research interests and facilitates the study of multi-robot collaborative perception algorithms.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The research aims to minimize human effort in deploying robotic systems in previously unseen environments by leveraging continual learning and reducing human annotations, focusing on advancements in simultaneous localization and mapping (SLAM), panoptic segmentation, and efficient robot learning.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The authors propose LDM, a novel feed-forward framework for generating high-fidelity, illumination-decoupled textured meshes from single images or text prompts, enabling production-ready 3D assets within seconds.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end optimization scheme that jointly represents and compresses dynamic Neural Radiance Fields, achieving superior rate-distortion performance, efficient representation, and elimination of multi-stage training complexity.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining high-fidelity rendering quality and state-of-the-art performance, achieved by redistributing scene decomposition and ADMM consensus.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment, leveraging 3D Gaussian representations and CLIP features.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, achieving state-of-the-art rendering fidelity and speed, and disentangles appearance changes from geometry, enabling smooth appearance interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework for single-view clothed human reconstruction, which employs kinematic information to achieve motion-aware deformation, and achieves state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The paper introduces a novel method that enables the use of "off-the-shelf" spacecraft pose estimation networks on unknown targets, leveraging Neural Radiance Fields (NeRF) models to extend the scope of existing pose estimation methods. The method trains a NeRF model using a small number of images depicting the target, and then generates a large dataset of images that capture the diversity of pose and illumination conditions encountered in orbit. An off-the-shelf pose estimation network is then trained on this dataset, allowing for autonomous estimation of the relative pose of the target spacecraft.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NV-LIO, a normal vector-based LIO framework for indoor SLAM in multifloor environments, which enhances point cloud registration performance by analyzing normal vector directions and addressing degeneracy situations, and is validated through public datasets and their own collected data.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
