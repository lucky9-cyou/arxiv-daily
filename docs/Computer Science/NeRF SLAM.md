
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a new neural radiance field (NeRF) method that enables the synthesis of high-quality, photo-realistic images for novel viewpoints within the stomach from pre-captured monocular gastroscopic images, by incorporating a novel geometry-based loss that incorporates point clouds pre-reconstructed by structure-from-motion (SfM) to address view sparsity and noise in local regions.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|The paper's key contributions are a new approach, NeRF On-the-go, which efficiently eliminates distractors in casually captured image sequences, achieves faster convergence speed, and improves render quality, particularly in high occlusion scenarios, thereby enabling robust synthesis of novel views in complex real-world scenes.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes NS-MAE, a self-supervised pre-training paradigm that learns transferable multi-modal representations for autonomous driving using masked multi-modal reconstruction in neural radiance fields.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions are:* A hybrid representation combining deformation fields, hash encoding, and 3D-GS, which reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask that can effectively identify and remove noise points, enhancing rendering quality.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate deformation field learning and dynamic point representation.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction issues by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction for superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling large deformation, local manipulation, and soft body simulation while maintaining high-quality rendering, and achieves state-of-the-art results on the NeRF synthetic dataset.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by up to 90% while maintaining image quality, by factorizing coordinates and attributes of Gaussian primitives, enabling fast rendering and efficient storage.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a novel V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving real-time processing of human colonoscopies and significantly improving map size and coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS) that addresses the challenges of scaling 3D Gaussian Splatting to large-scale scenes by introducing a hierarchical Gaussian structure and dynamic weighting, achieving a significant performance leap with accelerated rendering.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose the first RGB-only SLAM system using 3D Gaussian Splatting, which adapts dynamically to keyframe pose and depth updates, refining depth updates with a monocular depth estimator, and achieves superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper introduces SparseSplat360, a method that utilizes 2D latent diffusion models to improve reconstruction of 360 3D scenes from sparse views, employing a cascade of in-painting and artifact removal models, iterative updates, and explicit scene representation.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.Note that the abstract and introduction provide an overview of the paper's main contributions, but do not provide a detailed summary of the paper's contents.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth to efficiently cover and reconstruct large-scale scenes.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR novel view synthesis, outperforming state-of-the-art NeRF-based methods by 3.84 and 1.91 dB on LDR and HDR tasks respectively, while achieving 1000x faster inference speed and requiring only 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a novel steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original GS point cloud files in an invisible manner, ensuring robust security, high fidelity, large capacity, and strong versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A novel method for enhancing translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems, which is achieved by using a 3-DoF Bundle Adjustment (BA) to refine the translation estimate independently while keeping the rotation estimate fixed.* The method updates the rotation estimate by considering IMU measurements and gyroscope bias, unlike ORB-SLAM3's rotation estimate which is directly obtained from stereo visual odometry and may yield inferior results in challenging scenarios.* The proposed method demonstrates improved performance in terms of accuracy while maintaining a comparable run-time speed to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents an approach that improves Neural Radiance Fields (NeRF) by introducing ray tracing to render view-dependent appearance, particularly for highly specular objects, and achieves photorealistic reflections of both nearby and distant content while requiring comparable optimization time to current state-of-the-art models.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces SynCHMR, a synergy between visual SLAM and human mesh recovery, achieving consistent reconstructions of camera trajectories, human meshes, and dense scene point clouds in a common world frame, addressing ambiguities in depth, scale, and dynamic scenes.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, achieving high-quality modeling of view-dependent effects and fast evaluation through efficient encoding of directional information.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline for normalizing images with varying lighting conditions, implementing a hash-encoded NeRF for fast training and camera pose refinement, and introducing a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, diverse spatial viewpoints, and heterogeneous sensor modalities, which enables the study of collaborative perception algorithms and facilitates the development of high-level scene understanding capabilities.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper contributes to the field of autonomous robotics by proposing methods for efficient robot learning, including continual learning, label-efficient panoptic segmentation, and collaborative robot mapping, which aim to reduce human effort and enable deployment in previously unseen environments.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words: The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, utilizing tensorial SDF representation and decoupled color fields, and achieves high-quality results in just a few seconds.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The paper proposes a novel end-to-end joint optimization scheme called JointRF, which jointly optimizes dynamic NeRF representation and compression, achieving significantly improved quality and compression efficiency compared to previous methods.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, reducing training time by 6+ times and achieving state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors present MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking and high-fidelity reconstruction, leveraging 3D Gaussian representation and a CLIP feature-based loop closure module for global optimization and loop detection.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent Gaussian primitives with lightweight MLPs, achieving state-of-the-art rendering fidelity, 100x faster rendering, and disentangling appearance changes from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, an innovative framework that leverages kinematic information to achieve motion-aware 3D clothed human synthesis, improving visual quality by 33.94% and 16.75% in LPIPS and Gaussian Splatting, respectively, while addressing limitations in current methodologies.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel method that enables the estimation of the 6D pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF) model, allowing the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper proposes NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments with multifloor structures. The contributions include extracting normal vectors from LiDAR scans for correspondence search, analyzing normal vector directions to detect degeneracy, and implementing a viewpoint-based loop closure module to ensure robust registration and accurate mapping.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
