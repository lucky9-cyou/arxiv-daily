
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel approach to enable high-fidelity novel view synthesis within the stomach using monocular gastroscopic images by incorporating geometry priors from a pre-reconstructed point cloud into neural radiance fields (NeRF) training, leading to improved rendering quality and recovered geometry compared to existing methods.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeRF On-the-go introduces a simple yet effective approach to robustly synthesize novel views in complex, real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving a faster convergence speed compared to state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NS-MAE, a self-supervised pre-training framework for multi-modal representation learning that leverages masked multi-modal reconstruction in neural radiance fields (NeRF) to enable transferable representation learning across diverse multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper can be summarized in one sentence as follows:The paper proposes a refined 3D Gaussian representation for dynamic scene reconstruction, which combines deformation fields, hash encoding, and a learnable denoising mask to reduce memory usage and enhance rendering quality, while also introducing static constraints and motion consistency constraints to minimize noise points and artifacts.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes a novel approach, HFGS, for deformable endoscopic reconstruction that addresses under-reconstruction in both spatial and temporal frequency perspectives, achieving superior rendering quality and dynamic awareness through its Frequency Regularization Module and Temporal High-Frequency Emphasis Reconstruction.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Mani-GS, a method for Gaussian Splatting manipulation with triangular mesh, which enables controllable 3DGS manipulation, high-quality rendering, and a high tolerance for mesh accuracy, outperforming existing methods in various scenarios.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions of the paper's abstract and introduction are as follows:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) while preserving image quality. F-3DGS uses factorization techniques to represent dense clusters of Gaussians with a significantly smaller number of elements, achieving a 90% reduction in storage size. The method is demonstrated to be efficient and achieves comparable quality in rendered images.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that leverages SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3, enabling the processing of complete human colonoscopies in real-time with improved tracking and mapping capabilities.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Pyramidal 3D Gaussian Splatting (PyGS) to address the challenges of large-scale scene representation, achieving significant performance and rendering speedups by introducing a hierarchical pyramidal structure and NeRF initialization.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a RGB-only SLAM system with a densely deformable 3D Gaussian map representation, combining frame-to-frame tracking, loop closure, and global bundle adjustment for accurate scene reconstruction and rendering while achieving competitive tracking and map sizes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that improves sparse-view reconstruction of 360 3D scenes using pre-trained 2D diffusion models fine-tuned to fill in missing details and clean novel views, achieving significant performance improvements over existing methods.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a continuous and differentiable terrain model, enabling efficient path planning and elevation estimation from aerial imagery.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NeB-SLAM, a scalable and real-time dense RGB-D SLAM system for unknown scenarios, which utilizes a divide-and-conquer mapping strategy and adaptive map growth to efficiently represent unknown scenes with efficient memory usage.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art methods while significantly reducing training and inference times.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a 3D Gaussian Splatting (3DGS) steganography framework that embeds 3D scenes and images into original point cloud files, offering robust security, high fidelity, large capacity, and versatility, and demonstrates its effectiveness through extensive experiments.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method to enhance the accuracy of initialization in Stereo Visual-Inertial SLAM (VI-SLAM) systems, which is a critical issue that affects the accuracy and usability of VI-SLAM. The method, called ETA, improves translation accuracy during initialization by using a 3-DoF Bundle Adjustment (BA) while keeping the rotation estimate fixed, and updates the rotation estimate by taking into account IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents a novel approach to Neural Radiance Fields (NeRFs) that uses ray tracing to render highly specular objects, solving issues with inconsistent reflections and computationally expensive neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces SynCHMR, a synergistic approach that jointly reconstructs metric-scale camera poses, human meshes, and dense scene point clouds from monocular videos, leveraging human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like encoding for neural radiance fields (NeRF) that accurately models view-dependent effects, including specular high-lights and glossy interreflections, and achieves fast evaluation, outperforming the state-of-the-art on view synthesis of specular objects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, implemented with a hash-encoded NeRF to boost pose optimization, and a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen gradient computing.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a pioneering comprehensive real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, distinct spatial viewpoints, and diverse sensor modalities, to facilitate research on multi-modal cooperative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The research explores minimizing human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning, and investigating how to transfer the insights gained from vision-based label-efficient panoptic segmentation to 3D point clouds.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, introducing a tensorial SDF representation and gradient-based mesh optimization layer for efficient and high-quality 3D generation.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, which achieves superior compression and quality for dynamic scenes with large motions and long durations.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) models in a distributed manner using Alternating Direction Method of Multipliers (ADMM), accelerating training time by 6+ times for large-scale scenes while achieving state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes MG-SLAM, a monocular SLAM system using 3D Gaussian representation, which achieves high-fidelity reconstruction and drift-corrected tracking, and introduces a language-extended loop closure module for global optimization and high-level understanding.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that reconstructs 3D scenes with vastly varying appearances by modeling time-dependent Gaussian primitives with lightweight neural networks, achieving state-of-the-art rendering fidelity and being 100 times faster than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper introduces Motion-Based 3D Clothed Humans Synthesis (MOSS), a framework that uses kinematic information to achieve motion-aware Gaussian split for realistic clothing deformation and joint details, improving human 3D reconstruction from monocular videos with state-of-the-art visual quality.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper presents a novel method to estimate the 6D pose of an unknown target spacecraft relative to a monocular camera, enabling autonomous rendezvous and proximity operations for Active Debris Removal missions. The key contributions are:* A novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) models.* The method trains a NeRF model using a sparse collection of images that depict the target, generating a large dataset that captures the diversity of both pose distribution and illumination conditions.* The paper demonstrates the successful training of an off-the-shelf pose estimation network from a sparse set of images, and shows that a network trained using this method performs similarly to a model trained on synthetic images generated using the CAD model of the target.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM in multifloor environments, which extracts normal vectors for enhanced point cloud registration, addresses degeneracy situations, and includes a viewpoint-based loop closure module for robust performance.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
