
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeRF-Supervised Masked Auto Encoder (NS-MAE), a self-supervised pre-training paradigm for transferable multi-modal representation learning, enabling efficient and high-performance fine-tuning of multi-modal perception models for autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper are:1. **Hybrid representation**: A combination of deformation fields, hash encoding, and 3D-Gaussian representation, which reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.2. **Denoising mask**: A learnable denoising mask that effectively identifies and removes noise points from the scene, enhancing rendering quality and reducing storage requirements.3. **Static constraints and motion consistency constraints**: Static constraints distinguish between static and dynamic points, and motion consistency constraints promote more consistent motion trends in dynamic scenes.These contributions lead to a method that outperforms existing approaches in terms of rendering quality and speed, while reducing storage requirements.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction challenges from spatial and temporal frequency perspectives, incorporating deformation fields and high-frequency emphasis reconstruction to achieve superior rendering quality.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a single sentence summarizing the key contributions of the paper:The paper proposes a method for manipulating 3D Gaussian Splatting representations utilizing a triangular mesh, enabling large deformation, local manipulation, and soft body simulations while maintaining high-quality rendering.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by factorizing dense clusters of Gaussians, enabling efficient representation and rendering of large-scale 3D scenes while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that can process complete human colonoscopies in real-time, overcoming tracking losses by replacing ORB features with SIFT and using brute-force matching, achieving longer sub-maps and higher mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting, which addresses challenges in scaling 3D Gaussian Splatting to large-scale scenes by representing scenes with a hierarchical assembly of Gaussians and using NeRF initialization to achieve rapid rendering performance.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an RGB-only SLAM system using 3D Gaussian Splatting, which achieves superior or on-par performance in tracking, mapping, and rendering accuracy, while yielding small map sizes and fast runtimes, and addresses the limitations of existing methods.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that leverages pretrained 2D diffusion models for sparse-view 360-degree scene reconstruction, achieving high-quality results with as few as 9 input views, by using iterative updates to fuse generated pseudo novel views with existing scene representations.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to generate a 2.5D continuous and differentiable terrain model that can be trained from imagery, allowing for real-time path planning and obstacle avoidance in challenging terrain scenarios.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown scenes, using a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive scene reconstruction and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a new framework for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, surpassing state-of-the-art methods in terms of inference speed and performance.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point cloud files in an invisible manner, ensuring security, fidelity, capacity, and flexibility while achieving real-time rendering speeds.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:The authors propose a new initialization method for Stereo Visual-Inertial SLAM, which aims to enhance translation accuracy by refining the translation estimate using a 3-DOF Bundle Adjustment, independently, while keeping the rotation estimate fixed. This approach differs from the current ORB-SLAM3 method, which uses a 6-DOF BA and updates the rotation estimate directly from stereo visual odometry, which can lead to limited accuracy. The proposed method also incorporates IMU measurements and gyroscope bias into the rotation estimate.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces a novel approach to Neural Radiance Fields (NeRFs) that leverages ray tracing to render accurate and consistent reflections of both nearby and distant scene content, improving upon prior methods' limitations in view-dependent appearance modeling and rendering efficiency.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Synergistic Camera and Human Reconstruction (SynCHMR), a novel framework that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos, leveraging human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for rendering specular objects, which combines feature-grid-based spatial encoding with cone-tracing to model high-frequency angular signals and capture complex reflections and interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizing a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, distinct spatial viewpoints, and diverse sensor modalities, to facilitate research in multi-modal collaborative perception and push the frontier of high-level scene understanding.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The author's research explores efficient and label-efficient methods for robotic vision systems to adapt to new environments and tasks, including continual learning, panoptic segmentation, and LiDAR-based mapping, to enable widespread adoption in real-world scenarios.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose LDM, a novel feed-forward framework that generates high-quality, illumination-decoupled 3D mesh assets with textured surface details from a single image or text prompts in just a few seconds, using a combination of multi-view diffusion, transformer-based models, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a concise summary of the paper's key contributions:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving superior quality and compression efficiency, with a compact residual feature grid, coefficient feature grid, and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed method for training 3D Gaussian Splatting (3DGS) models on large-scale scenes, reducing training time by 6+ times while achieving state-of-the-art rendering quality and improving memory usage.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without requiring RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives with discrete time embedding vectors, achieving state-of-the-art rendering fidelity and 100 times faster rendering speed than NeRF-based methods.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a framework that uses kinematic information to achieve motion-aware Gaussian split on the human surface, improving 3D clothed human synthesis by 33.94% and 16.75% in LPIPS and visual quality, respectively, while addressing local occlusions and preserving realistic clothing folds.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables the estimation of the 6D pose of an unknown target spacecraft using a monocular camera, by training a Neural Radiance Field (NeRF) model with a sparse set of images and then using it to generate a large dataset for training an off-the-shelf pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments with multifloor structures, enhancing point cloud registration performance through normal vector correspondence search and degeneracy detection.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present MVSGaussian, a novel generalizable 3D Gaussian representation approach that leverages Multi-View Stereo and efficient rendering to achieve real-time rendering with state-of-the-art performance and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* A comprehensive overview of the integration of Neural Radiance Field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks.* The importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks.* The potential of NeRF and 3D-GS to provide photorealistic rendering results for complex scenes.* The challenges of transmitting and reconstructing 3D contents over wireless networks, particularly in terms of storage and transmission requirements.* The need for new interdisciplinary design approaches, combining techniques from wireless communications, computer vision, computer graphics, and AI.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
