
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Factorized 3D Gaussian Splatting (F-3DGS) method significantly reduces storage requirements while maintaining image quality by employing structured coordinates and decomposed representations of Gaussians through factorization, particularly from canonical polyadic and vector-matrix decompositions.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a monocular V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling successful map merging and relocation in real-time for human colonoscopies.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Pyramidal 3D Gaussian Splatting (PyGS) presents a hierarchical assembly of Gaussians, initialized using a rapidly trained NeRF, and optimized for large-scale scenes, achieving significant performance improvements and accelerated rendering times compared to existing state-of-the-art approaches.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel RGB-only SLAM system that utilizes dynamically deforming 3D Gaussian maps, refining depth updates with a monocular depth estimator, and achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that uses latent diffusion models to improve the reconstruction of 360 3D scenes from sparse views, achieving high-quality results with details coherent with the observed inputs.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for lightweight representation of terrain through an implicit continuous and differentiable height field.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* The ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods, as demonstrated through experiments on simulated and real-world terrain imagery.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes that achieves real-time, scalable, and predictive performance using a divide-and-conquer mapping strategy and adaptive map growth strategy.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which renders HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed GS-Hider framework enables effective and flexible steganography for 3D Gaussian Splatting, allowing for the concealment and extraction of messages in 3D scenes and images while ensuring security, robustness, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a new method, called ETA, to enhance translation accuracy during the initialization stage of stereo Visual-Inertial SLAM (VI-SLAM) systems.* ETA improves translation estimation using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA), conducted independently, while keeping the rotation estimate fixed, unlike ORB-SLAM3's 6-DoF BA.* ETA also updates the rotation estimate by taking into account IMU measurements and gyroscope bias, unlike ORB-SLAM3's rotation, which is directly obtained from stereo visual odometry.* The authors evaluate ETA on the public benchmark, the EuRoC dataset, demonstrating that ETA excels in accuracy and performs comparable to Stereo-NEC, a more complex method, while maintaining a runtime similar to that of ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces a novel approach to Neural Radiance Fields (NeRFs) that addresses the issue of reconstructing highly specular objects by leveraging ray tracing, allowing for consistent rendering of reflections and reducing the reliance on large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and dense scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities by marrying visual SLAM and human motion reconstruction.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like approach that accurately models view-dependent appearance and global illumination effects for rendering specular objects, outperforming the state-of-the-art methods while achieving fast inference speeds.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, utilizing a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process, achieving state-of-the-art results in camera relocalization under varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a comprehensive real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities, filling a significant research gap in the field of multi-robot collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes novel methods for efficient robot learning, focusing on leveraging continual learning (CL) and reducing human annotations for improved performance in previously unseen environments.* The research explores the use of vision foundation models for extremely label-efficient training, allowing for panoptic segmentation with minimal annotations.* The paper also addresses the challenge of automatic calibration for camera-LiDAR systems without human supervision or special data collection.* The author plans to extend the label-efficient segmentation techniques to 3D point clouds and combine them with robot mapping for semantic representations of an environment.Note: The above summary is under 50 words and only highlights the main contributions from the abstract and introduction.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, introducing a tensorial SDF representation and adaptive conversion strategy to improve convergence speed and quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by employing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining high rendering quality, by decomposing scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consensus.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which uses 3D Gaussian representation to guide scene geometry estimation and a CLIP feature-based loop closure module for drift error correction, outperforming existing methods.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a lightweight neural method for real-time rendering of 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity, 100 times faster than NeRF-based methods, and enabling smooth appearance interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework that incorporates kinematic information to achieve motion-aware Gaussian split on the human surface, addressing limitations in current methodologies by propagating global motion across the body surface and detecting local occlusions.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRFs) to generate a large dataset of images depicting the target under varying illumination conditions.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, which addresses challenges in point cloud registration due to rapid changes and repetitive structural features, and achieves robust registration through normal vector extraction and degeneracy detection.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents MVSGaussian, a generalizable Gaussian Splatting method derived from Multi-View Stereo, which leverages MVS to encode geometry-aware Gaussian representations, integrates an efficient volume rendering design for novel view synthesis, and introduces a multi-view geometric consistent aggregation strategy to support fast fine-tuning for specific scenes.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a comprehensive overview on the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents. The main contributions are:1. A review of the basics of radiance field rendering techniques, highlighting their applications and implementation challenges over wireless networks.2. An exploration of over-the-air training of NeRF and 3D-GS models using federated learning techniques, with a focus on hierarchical device-edge-cloud architecture.3. Presentation of practical rendering architectures for NeRF and 3D-GS models at wireless network edges, including model compression approaches and joint computation and communication designs.4. Introduction of a new semantic communication-enabled 3D content transmission design, leveraging radiance field models as a semantic knowledge base for reduced communication overhead.5. Discussion of the utilization of radiance field rendering in wireless applications such as radio mapping and radio imaging.These contributions aim to address the challenges of efficient representation, transmission, and reconstruction of 3D contents in 6G wireless networks, enabling immersive communications and merging virtual and physical worlds.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly models point light attenuation and raytraces cast shadows, and optimizes a fully neural material renderer to achieve accurate 3D shape estimation.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a "Judge" mechanism to assess and refine the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Developing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments.* Proposing a two-stage framework that accurately models signal propagation and transmission from the transmitter to the RIS and from the RIS to the receiver.* Integrating NeRF with ray tracing techniques to enable precise prediction of signal strength and direction at various receiver locations under different RIS placements.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising of ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to enable robust mapping in diverse scenarios and dynamic real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
