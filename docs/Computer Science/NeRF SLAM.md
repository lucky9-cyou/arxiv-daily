
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3DGS by factorizing coordinates and attributes, allowing for efficient representation of dense clusters of Gaussians with significantly fewer parameters while preserving image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a novel V-SLAM system that uses SIFT features and brute-force matching to overcome tracking losses in human colonoscopies, achieving real-time performance and significantly improving map merging and relocation capabilities compared to ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), which leverages a hierarchical assembly of Gaussians and NeRF initialization to render large-scale scenes with high-fidelity details and accelerated rendering performance, achieving a significant leap in performance and speed over state-of-the-art methods.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel RGB-only SLAM system that uses 3D Gaussian splatting as a map representation, dynamically adapting to keyframe pose and depth updates, and refining depth updates with a monocular depth estimator, achieving superior or on-par performance with existing RGB-only SLAM methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view 360-degree scene reconstruction, filling in missing details and cleaning novel views, and achieves better performance than existing methods on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.These contributions aim to address the limitations of traditional terrain representations, such as Digital Elevation Models (DEMs), and develop a more robust and versatile navigation solution for autonomous ground robots.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The authors propose NeB-SLAM, a neural block-based, scalable, and real-time RGB-D SLAM method for unknown scenes, which adopts a divide-and-conquer mapping strategy and adaptive map growth to achieve efficient scene coverage and hole-filling.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose HDR-GS, a novel framework for 3D high dynamic range imaging, which offers efficient rendering, controllable exposure time, and improved visual quality, outperforming state-of-the-art NeRF-based methods in terms of PSNR, SSIM, and LPIPS.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original GS point clouds, ensuring security, fidelity, and flexibility, with capabilities to hide multiple messages and extract them accurately.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are: a method to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM, which uses a 3-DoF Bundle Adjustment (BA) to improve translation estimate, keeps rotation estimate fixed, and updates rotation estimate by considering IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents an approach to improve Neural Radiance Fields (NeRFs) by introducing ray tracing, which efficiently renders consistent reflections of nearby and distant content, and renders higher-quality specular reflections without relying on large and computationally expensive neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a framework that combines visual SLAM and human mesh reconstruction to jointly reconstruct camera trajectories, human meshes, and scene point clouds in a common world frame, addressing ambiguities in depth, scale, and dynamic scenes.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of this paper are: Neural Directional Encoding (NDE), a feature-grid-like encoding for modeling high-frequency view-dependent appearance and global illumination effects in rendering specular objects, which outperforms the state of the art in view synthesis and achieves fast (real-time) inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper's key contributions are a two-staged pipeline for camera relocalization under varying lighting conditions, a hash-encoded NeRF for fast training and robust camera pose refinement, and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration with distinct spatial viewpoints, sensor modalities, and coverage ranges, which caters to diverse research interests and enables the study of multi-modal collaborative perception using real-world data.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:1. Investigating how to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning.2. Exploring the use of vision foundation models for extremely label-efficient training to achieve competitive results with fully supervised learning methods.3. Developing a novel panoptic segmentation approach that requires as few as ten annotated images and can be used as a plug-in for existing methods.4. Introducing a method for automatic target-less camera-LiDAR calibration that requires neither human initialization nor special data recording.5. Investigating the use of multi-agent collaboration for efficient robot learning.These contributions aim to address the limitations of existing methods that rely on large amounts of densely labeled training data and instead aim to achieve efficient learning with minimal human annotations.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality triangular meshes with illumination-decoupled textures from text or single images, utilizing multi-view diffusion models, transformer-based models, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which achieves superior quality and compression efficiency by employing a compact residual feature grid and a coefficient feature grid, and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that splits scenes into blocks, uses Alternating Direction Method of Multipliers (ADMM) for consistency, and achieves 6+ times faster training and state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MG-SLAM, a monocular SLAM system that combines 3D Gaussian Splatting with a language-extended loop closure module based on CLIP features to achieve drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, enabling accurate reconstructions of scenes with vastly varying appearances and achieving state-of-the-art rendering fidelity.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MOSS, a framework that addresses the challenge of reconstructing 3D clothed humans by incorporating kinematic information to guide Gaussian split and detect local deformations, resulting in state-of-the-art visual quality and real-time rendering.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, using a Neural Radiance Field (NeRF) model to generate a large training set from a sparse collection of spaceborne images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework that solves the challenges of LIO algorithms in indoor multifloor environments by utilizing normal vectors from LiDAR scans for correspondence search, mitigating degeneracy through normal vector direction distribution analysis, and implementing viewpoint-based loop closure to ensure robust registration.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The key contributions from the paper's abstract and introduction are the development of MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo to efficiently reconstruct unseen scenes, and proposes a hybrid Gaussian rendering and a consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper explores the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G wireless networks to support immersive communication applications. The authors discuss the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks, and highlight the potential of NeRF and 3D-GS to provide photorealistic rendering results for complex scenes. The paper also emphasizes the need for new distributed training and inference methods for NeRF and 3D-GS models, as well as joint computation and communication designs to minimize end-to-end latency while preserving quality of experience (QoE) requirements.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions of the paper are:* A novel multi-view photometric stereo method that leverages per-pixel intensity renderings rather than relying mainly on estimated normals.* A method that models point light attenuation and explicitly raytraces cast shadows in order to best approximate each point's incoming radiance.* A fully neural material renderer that uses minimal prior assumptions and is jointly optimized with the surface.* The ability to achieve competitive reconstruction accuracy using only 6 lights and match the SOTA performance when all lights and normal map information is also fused.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a Judge to evaluate object realism and ensure that generated objects are both adversarial and realistic.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Proposing a novel two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, which accurately characterizes signal dynamics.* Integrating NeRF-based ray tracing techniques with electromagnetic physics to model the signal field for any specified RIS placement and receiver location.* Validating the effectiveness of the proposed method through simulations and measured data, demonstrating superior prediction performance compared to NeRF2 and traditional MRI and MLP methods.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work in diverse scenarios, featuring fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to address the challenges of real-world robotic services and SLAM competitions.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
