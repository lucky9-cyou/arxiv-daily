
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by factorizing 3D Gaussians using efficient decomposition techniques, allowing for high-quality rendering at a fraction of the storage cost of traditional 3DGS methods.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The authors present CudaSIFT-SLAM, a novel monocular V-SLAM system that successfully processes human colonoscopies in real-time, overcoming limitations of previous top-performing V-SLAM systems by using SIFT features and brute-force matching, and achieving a 70% improvement in mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization, a method that leverages hierarchical pyramidal Gaussians and dynamic weighting to efficiently model large-scale scenes, achieving rendering speeds over 400 times faster than state-of-the-art approaches.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a globally optimized RGB-only SLAM system utilizing 3D Gaussian Splatting, which combines the strengths of frame-to-frame tracking and 3D Gaussian map representations, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that utilizes pre-trained 2D diffusion models with fine-tuning to reconstruct 360-degree scenes from sparse views, achieving multi-view consistent scene representations with coherent details and outperforming existing methods.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model, leveraging imagery as a low-cost data source.* NEMOs can be readily generated from imagery, providing a lightweight representation of terrain through an implicit continuous and differentiable height field.* The authors introduce a novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* They also propose a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.* Experimental results show that NEMOs can generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM approach for unknown scenes, which uses a divide-and-conquer mapping strategy and an adaptive map growth strategy to achieve efficient and real-time mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods in terms of quality and speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is the summarized key contribution from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a 3D Gaussian Splatting (3DGS) steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files, ensuring security, fidelity, and capacity while hiding multiple messages, and demonstrates its effectiveness through extensive experiments.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* A new initialization method for Stereo Visual-Inertial SLAM that enhances translation accuracy during the initialization stage, using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) while keeping the rotation estimate fixed.* This method is designed to overcome the limitations of previous methods, including ORB-SLAM3 and Stereo-NEC, by providing more accurate initialization for Stereo Visual-Inertial SLAM systems.* The method is evaluated on the public benchmark, the EuRoC dataset, and is shown to outperform previous methods in terms of accuracy.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a ray tracing-based approach to Neural Radiance Fields (NeRFs) that improves view synthesis of shiny objects by casting reflection rays and tracing them through the NeRF representation, enabling consistent reflections of nearby and distant content while reducing computational cost.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a pipeline that jointly reconstructs 3D human motion, camera trajectories, and scene point clouds from monocular videos by integrating human-aware metric SLAM and scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is the summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a feature-grid-like neural radiance field that models view-dependent appearance of specular objects, achieving high-quality rendering and fast evaluation, outperforming state-of-the-art methods on engaging novel-view synthesis.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summarized sentence with key contributions from the abstract and introduction, under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizes a hash-encoded NeRF for fast training and robust pose refinement, and introduces a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique for smoothened gradient computing.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, heterogeneous sensors, and complementary mobilities, which is designed to facilitate research on multi-modal collaborative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The paper's abstract and introduction highlight the importance of holistic scene understanding for autonomous robotic agents and the goal to develop a perception-based robotic system that can adapt to previously unseen environments with minimal human effort. The research focuses on two key contributions: 1) continual learning and 2) label-efficient learning. The paper aims to leverage these concepts to enable robots to adapt to new environments and learn from scratch with minimal human supervision.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The authors propose LDM, a novel feed-forward framework for generating high-fidelity, illumination-decoupled textured mesh from a single image or text prompts, overcoming the limitations of previous NeRF and 3D Gaussian representations.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's main contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving significantly improved quality and compression efficiency by utilizing a compact residual feature grid, sequential feature compression, and end-to-end training.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that splits scenes into blocks, uses Alternating Direction Method of Multipliers (ADMM) for consensus, and accelerates training by 6+ times while maintaining rendering quality and stability.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a CLIP feature-based loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without relying on depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives and decomposes color models for improved geometric consistency, achieving state-of-the-art rendering fidelity and outperforming NeRF-based counterparts in efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:MOSS proposes a framework that uses kinematic information to achieve motion-aware Gaussian split on human surfaces, addressing limitations of current methods, and improves upon existing approaches by incorporating global motion factors, hierarchical structure constraints, and occlusion handling.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) to generate a large dataset from a sparse set of images, demonstrating its feasibility on realistic images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NV-LIO, a normal vector-based LiDAR-inertial odometry framework that enhances point cloud registration performance in indoor environments with multifloor structures by extracting normal vectors and analyzing their distribution to adjust matching uncertainty.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes a new generalizable 3D Gaussian representation approach, MVSGaussian, derived from Multi-View Stereo, which can efficiently reconstruct unseen scenes with real-time rendering and fast per-scene optimization, outperforming other generalizable methods and achieving comparable performance to longer optimization times.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper provides a comprehensive overview of integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) into 6G networks to support immersive communications, with a focus on efficient representation, transmission, and reconstruction of 3D contents over wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and jointly optimizes a fully neural material renderer with a surface to achieve competitive reconstruction accuracy.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method to generate realistic-looking adversarial objects for testing autonomous driving systems, by introducing a 'Judge' mechanism that assesses the realism of generated objects and refines their texture to ensure they are both adversarial and realistic.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel two-stage framework using Neural Radiance Fields (NeRF) and ray tracing to model dynamic electromagnetic fields in Reconfigurable Intelligent Surface (RIS)-enabled wireless environments, enabling accurate prediction of signal field for any specified RIS placement and receiver location.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that rapidly segments ground points, employs outlier-robust registration and hierarchical multi-session SLAM, and builds instance-aware static maps to handle diverse and changing real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
