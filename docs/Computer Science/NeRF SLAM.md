
### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining image quality by factorizing Gaussian coordinates and attributes, enabling fast rendering speeds and compact storage.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper presents CudaSIFT-SLAM, a real-time V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling successful merging and relocation in challenging colonoscopy environments.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The paper introduces Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that addresses the challenges of scaling 3D Gaussian Splatting to large-scale scenes, particularly in terms of handling multiple scales, viewpoints, and initialization from large datasets.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summarizing sentence under 50 words:The authors propose a novel RGB-only SLAM system that combines frame-to-frame tracking with a deformable 3D Gaussian map representation, achieving high-quality surface reconstruction, accurate tracking, and efficient renderings while leveraging monocular depth estimation to refine depth updates.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360 scenes, demonstrating improved performance and detail coherence using an iterative update strategy.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* The use of aerial imagery to generate a lightweight representation of terrain through an implicit continuous and differentiable height field.* The ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which divides the scene into sub-maps using a divide-and-conquer strategy and an adaptive map growth strategy, providing real-time, scalable, and predictive performance in mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, achieving better PSNR, SSIM, and LPIPS performance with faster inference speed and shorter training time than existing NeRF-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a 3D Gaussian Splatting steganography framework that embeds 3D scenes and images into 3D point cloud files, enabling invisible and accurate extraction, with robust security, high fidelity, large capacity, and versatility in copyright protection and encrypted communication.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* Proposing a novel initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) that enhances translation accuracy, improving upon the existing methods of ORB-SLAM3 and Stereo-NEC.* Introducing a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) approach to refine the translation estimate independently, while keeping the rotation estimate fixed.* Using IMU measurements and gyroscope bias to update the rotation estimate, unlike ORB-SLAM3, which directly obtains rotation from stereo visual odometry.* Demonstrating the efficacy of the proposed method through extensive evaluations on the EuRoC dataset, outperforming existing methods in accuracy while maintaining a comparable runtime.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a ray-tracing-based approach to Neural Radiance Fields (NeRF) that improves rendering of shiny objects by synthesizing consistent reflections of nearby and distant content, outperforming prior methods while requiring comparable optimization time and being more efficient.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces SynCHMR, a synergistic approach combining SLAM and HMR to reconstruct camera trajectories, human meshes, and scene point clouds in a common world frame from monocular videos, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce Neural Directional Encoding (NDE), a view-dependent appearance encoding method for rendering specular objects, which improves the state of the art on view synthesis of shiny objects and achieves fast inference speeds without compromising quality.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline for camera relocalization, which normalizes images with varying lighting conditions using a hash-encoded NeRF and addresses the noisy image gradient problem using a re-designed filter and gradient averaging technique, achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents the first real-world multi-robot collaborative perception dataset collected using ground and aerial robots, featuring diverse sensor viewpoints, robot mobilities, and sensor modalities, and provides pose estimation and high-level perception annotation for various research tasks.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The research investigates the development of human-effort minimizing robotic systems by leveraging continual learning and reducing human annotations for efficient learning, focusing on robotic vision, mapping, and segmentation tasks.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, leveraging a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Fields (NeRF) representation and compression, achieving improved quality and compression efficiency for streaming dynamic and long-sequence NeRF.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The key contributions from the paper's abstract and introduction are the proposal of DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, reducing training time by 6+ times, while achieving state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, achieving drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without requiring RGB-D inputs or pre-defined bounding boxes.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Gaussian Time Machine (GTM) method achieves state-of-the-art rendering fidelity and real-time rendering capabilities (100 times faster than NeRF-based methods) for reconstructing 3D scenes with varying appearances using discrete training images and a lightweight neural network.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents MOSS, a framework that extracts global motion factors to guide 3D Gaussian split on the human surface, enabling state-of-the-art 3D clothed human synthesis from monocular videos, improving upon existing methods in both visual quality and real-time rendering capabilities.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target spacecraft by leveraging a Neural Radiance Field (NeRF) model, which represents the target's appearance in varying illumination conditions, allowing for pose estimation from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework designed for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, which extracts normal vectors from LiDAR scans to enhance point cloud registration performance and addresses degeneracy and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable Gaussian Splatting method that uses Multi-View Stereo and a pixel-aligned Gaussian representation, achieving real-time rendering with better view synthesis quality and faster fine-tuning for specific scenes.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper discusses the integration of Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks to enable efficient representation, transmission, and reconstruction of 3D contents. The contributions include:* A comprehensive overview of NeRF and 3D-GS, highlighting their applications, implementation challenges, and strengths and weaknesses.* An analysis of the limitations of traditional 3D representation approaches and the advantages of NeRF and 3D-GS in providing photorealistic rendering results.* A discussion of the technical challenges involved in integrating NeRF and 3D-GS in 6G networks, including storage and transmission overhead, computational complexity, and end-to-end latency.* A proposal for federated learning design over a hierarchical device-edge-cloud architecture to train NeRF and 3D-GS models.* An introduction to joint computation and communication designs to enhance rendering efficiency and minimize end-to-end latency.* A review of semantic communication-enabled 3D content transmission designs, which exploit radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* A discussion of the applications of NeRF and 3D-GS in wireless networks, including radio mapping and radio imaging.Overall, the paper aims to provide a comprehensive understanding of the integration of NeRF and 3D-GS in 6G networks and their potential applications in immersive communication and other wireless applications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learnt renderers. The main contributions are:1. The proposed method uses per-pixel intensity renderings to estimate 3D shape from photometric stereo images, rather than relying on estimated normals. This approach is robust to poor normal estimates and outperforms previous methods.2. The method models point light attenuation and explicitly raytraces cast shadows to accurately approximate each point's incoming radiance.3. The authors use a fully neural material renderer that uses minimal prior assumptions and is jointly optimized with the surface.4. The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.The paper reviews the evolution of photometric stereo methods, from single-view to multi-view approaches, and highlights the limitations of prior methods that focused on normal-based reconstruction.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems. The method integrates a Judge, an evaluative mechanism that assesses the realism of generated objects, to ensure that the adversarial objects can seamlessly blend into real-world environments without detection. The Judge assigns a probability score to the object's realism, which is then integrated into the loss function to encourage the generation of realistic and adversarial textures. The paper analyzes four strategies for developing a robust Judge and presents experimental results.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to model electromagnetic fields in RIS-enabled environments, enabling accurate signal field prediction and RIS deployment optimization, which has been validated through simulated and measured data.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising of ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to enable robust mapping in diverse scenarios and dynamic real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
