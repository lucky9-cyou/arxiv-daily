
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|The paper proposes a self-supervised method, S3Gaussian, for decomposing dynamic and static 3D Gaussians in street scenes without requiring explicit 3D annotations, and achieves state-of-the-art rendering quality on scene reconstruction and novel view synthesis tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The paper introduces TetSphere splatting, a Lagrangian geometry representation that efficiently reconstructs high-quality meshes by deforming tetrahedral spheres, outperforming existing representations in terms of optimization speed, mesh quality, and thin structure preservation.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive subjective quality assessment study of Neural Radiance Fields (NeRF) view synthesis methods, evaluating the impact of different artifacts on perceived quality, and analyzing the performance of various objective image and video quality metrics.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes IReNe, a novel approach that enables instant and accurate color editing of Neural Radiance Fields (NeRF) by selectively fine-tuning the last layer of the network, leveraging a pre-trained NeRF model and a single training image with user-applied color edits.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|The paper proposes HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, using symmetry prior, regularization constraints, and training cues from large human datasets, achieving a 15% PSNR improvement over previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper are:1. A novel approach to lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation using Neural Radiance Fields (NeRF) with ultrametric feature fields.2. A feature field within a NeRF representing a 3D scene, whose segmentation structure can be revealed at different scales by simply using different thresholds on feature distances.3. A method that produces a hierarchy of 3D-consistent segmentations as output, which can be used for view-inconsistent segmentations at multiple levels of granularity.4. A novel formulation for 3D scene segmentation using ultrametric feature fields, which is not only view-consistent but also hierarchical.The paper also evaluates the method on synthetic datasets with multi-view images and multi-granular segmentation, showcasing improved accuracy and viewpoint consistency. Additionally, the paper presents new evaluation metrics, including Normalized Covering (NC) score, Segmentation Injectivity (SI) score, and View Consistency (VC) score, to quantify the quality of hierarchical segmentation outcomes.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel method that uses neural radiance fields (NeRF) to synthesize photo-realistic images of the stomach from novel viewpoints, addressing view sparsity and noise in monocular gastroscopic images by incorporating geometry-based loss and depth smoothness loss.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NeRF On-the-go, a method that enables robust novel view synthesis in complex, real-world scenes with distractors by removing distractors and achieving faster convergence speed, outperforming state-of-the-art techniques in diverse scenarios.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is the summarized key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents NeRF-Supervised Masked Auto Encoder (NS-MAE), a self-supervised pre-training paradigm that learns transferable multi-modal representations for multi-modal and single-modal perception models in autonomous driving, achieving robustness and generalization across various tasks and scenarios.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* Refining 3D Gaussian Splatting (3D-GS) for high-quality dynamic scene reconstruction, mitigating the storage consumption associated with 3D-GS and introducing a novel view synthesis method tailored for dynamic mapping.* Proposing a hybrid representation combining deformation fields, hash encoding, and 3D-GS to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* Introducing a learnable denoising mask with denoising loss to effectively identify and remove noise points from the scene, enhancing rendering quality.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.Note that the abstract and introduction primarily highlight the contributions to the field of 3D reconstruction and rendering, focusing on the proposed methodology and its advantages.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, which addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction, achieving superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of this paper are:* A method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling controllable and high-quality photo-realistic rendering.* A self-adapting triangle shape-aware Gaussian binding strategy that allows for maintaining rendering quality even after manipulation.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements while preserving image quality by efficiently factorizing dense clusters of Gaussians using canonical polyadic and vector-matrix decompositions.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization, a hierarchical approach that balances fine details and rendering speed, outperforming state-of-the-art methods on large-scale datasets, and achieving a rendering time over 400 times faster.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a method, SparseSplat360, that leverages pre-trained 2D diffusion models to improve 360-degree 3D scene reconstruction from sparse views, using a cascade of in-painting and artifact removal models, and iterative updates to create a multi-view consistent scene representation.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Elevation Models (NEMos), which combine Neural Radiance Fields with a height field to generate continuous and differentiable terrain representations for autonomous navigation, allowing for efficient and smooth path planning.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS) for novel view synthesis, achieving photo-realistic images with a wider dynamic range, faster inference speed, and shorter training time, while tackling issues such as color distortion and exposure control.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) point clouds, enabling the secure embedding and extraction of messages, including 3D scenes and images, while maintaining rendering quality and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The contribution of this paper is a novel approach to improving Neural Radiance Fields (NeRFs) by introducing ray tracing to render consistent reflections of nearby and distant scene content, while reducing the burden of large MLPs and increasing rendering speed.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The paper introduces Neural Directional Encoding (NDE), a novel approach for rendering specular objects by encoding view-dependent appearance with learnable feature-grid-based spatial encoding in the angular domain. NDE outperforms the state-of-the-art on view synthesis of specular objects and allows for fast inference, making it suitable for real-time applications.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline for camera relocalization that normalizes images with varying lighting and shadow conditions using a hash-encoded NeRF and a re-devised truncating dynamic low-pass filter, achieving state-of-the-art results in camera relocalization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a single sentence summarizing the key contributions: The authors propose LDM, a novel feed-forward framework generating high-quality textured mesh assets from a single image or text prompts, leveraging a multi-view diffusion model, a transformer-based SDF predictor, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, achieving improved quality and compression efficiency for rendering dynamic and long-sequence radiance fields.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces the training time by 6+ times for large-scale scenes while maintaining high-fidelity rendering quality, by decomposing scenes into blocks and applying Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that efficiently models time-dependent attributes of Gaussian primitives, effectively disentangling appearance changes from geometry, and achieves state-of-the-art rendering fidelity and speed on 3 datasets.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present MOSS, a framework for reconstructing clothed humans from single-view videos, which employs kinematic information to achieve motion-aware Gaussian splitting, improving joint details, clothing folds, and surface deformation under global motion constraints.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a novel method that enables the training of an off-the-shelf spacecraft pose estimation network from a sparse set of images, using a Neural Radiance Field (NeRF) trained on a small number of images to generate a diverse training set, applicable to unknown target spaceships.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable Gaussian Splatting method that encodes geometry-aware Gaussian representations using Multi-View Stereo, integrates a hybrid Gaussian rendering approach, and introduces a consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here are the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper discusses the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) techniques in 6G networks for efficient representation, transmission, and reconstruction of 3D contents, exploring new distributed training and inference methods for radiance fields and proposing a new semantic communication enabled 3D content transmission design.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly models point light attenuation, and uses a fully neural material renderer to achieve competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
