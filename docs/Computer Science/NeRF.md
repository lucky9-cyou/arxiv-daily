
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that uses structured coordinates and decomposed representations of Gaussians to reduce spatial redundancy and achieve high-performance, compact storage, and fast rendering in 3D scene representation.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS), a scalable and efficient method that overcomes the challenges of rendering large-scale scenes by incorporating a hierarchical Gaussian structure, dynamic weighting, and rapid NeRF initialization, achieving a significant performance leap.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a novel method that uses pretrained 2D diffusion models for sparse-view reconstruction of 360-degree scenes, effectively filling in missing details and generating novel views through iterative updates and 2D-to-3D distillation.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here are the key contributions from the paper's abstract and introduction:* The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* NEMos can be generated from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.* The paper proposes a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm is introduced that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.* The paper presents experiments on simulated and real-world terrain imagery, demonstrating NEMos' ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.These contributions aim to address the limitations of traditional terrain representations, such as digital elevation models (DEMs), by providing a more efficient and effective way to generate and utilize terrain information for autonomous ground robots.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The key contributions of the paper are the proposal of High Dynamic Range Gaussian Splatting (HDR-GS) framework for 3D HDR imaging, which can render novel HDR views and reconstruct LDR images with a user input exposure time, achieving superior performance on HDR novel view synthesis while enjoying 1000x faster inference speed and reduced training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The key contributions of the paper can be summarized as follows: the authors propose a novel steganography framework, GS-Hider, specifically designed for 3D Gaussian Splatting (3DGS) that enables the hiding of messages in 3D scenes and images while ensuring high fidelity, security, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a ray tracing-based approach that outperforms existing methods for rendering view-dependent appearance and reflections in shiny objects, using a small and inexpensive network to decode feature vectors, while reducing optimization and rendering time.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a novel view-dependent appearance encoding method for rendering specular objects, which improves modeling of high-frequency angular signals and efficiently handles interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting and shadow conditions using a hash-encoded NeRF, which achieves state-of-the-art results under varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts by leveraging a multi-view diffusion model, a transformer-based model, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by employing a compact residual feature grid, coefficient feature grid, and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for Large-scale 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times, ensures training convergence, and achieves state-of-the-art rendering quality, while maintaining a single global 3DGS model during inference.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a real-time rendering method that models time-dependent Gaussian primitives and decomposes color for improved geometric consistency, achieving state-of-the-art rendering fidelity on 3 datasets and 100x faster rendering speed than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework that leverages kinematic information to achieve motion-aware 3D clothed human synthesis, improving surface deformation, joint details, and clothing folds, and outperforming existing methods in visual quality and efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, enabling autonomous rendezvous and proximity operations for Active Debris Removal missions. The method leverages an in-the-wild Neural Radiance Field (NeRF) to generate a large dataset of images with diverse viewpoints and illumination conditions, which is then used to train an off-the-shelf spacecraft pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach derived from Multi-View Stereo (MVS) that efficiently reconstructs unseen scenes by encoding geometry-aware Gaussian representations, decoding them into Gaussian parameters, and proposing a hybrid Gaussian rendering and a multi-view geometric consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The paper discusses the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks, particularly for immersive communication applications such as extended reality (XR), telepresence, and metaverse.* Neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) are introduced as promising 3D representation techniques that can provide photorealistic rendering results for complex scenes.* The paper highlights the challenges of integrating NeRF and 3D-GS in 6G networks, including the need for new distributed training and inference methods, joint computation and communication designs, and efficient transmission and storage of radiance field models.* The authors propose a comprehensive overview of the integration of NeRF and 3D-GS in 6G, including model compression, rendering acceleration, and joint computation and communication designs.* The paper emphasizes the importance of embracing radiance field rendering in 6G networks to support emerging 3D applications with enhanced quality of experience.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learned renderers.* Unlike previous methods, this approach explicitly uses per-pixel intensity renderings rather than relying mainly on estimated normals.* The method models point light attenuation and explicitly ray-traces cast shadows to best approximate each point's incoming radiance.* The estimated normal and segmentation maps can also be incorporated to maximize surface accuracy.* The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.* The approach is among the first to outperform the classical DiLiGenT-MV method, achieving an average Chamfer distance of 0.2mm for objects imaged at 1.5m distance with a 400x400 resolution.Please note that this is a single sentence summary under 50 words.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summarized response in a single sentence under 50 words:This paper proposes a gradient-based texture optimization method using an evaluative mechanism called the "Judge" to craft realistic-looking adversarial objects for autonomous driving systems, aiming to ensure adversarial objects can blend seamlessly into real-world environments without detection.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in one sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to model dynamic electromagnetic fields in RIS-enabled environments, accurately capturing complex propagation dynamics and signal field for any specified RIS placement and receiver location, enhancing RIS deployment for efficient communication.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving accurate real-time tracking, high-fidelity reconstruction, and state-of-the-art performance on indoor RGB-D datasets with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive overview of methodologies enabling Large Language Models (LLMs) to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction in AI systems, and discussing challenges and future research directions.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:1. Developing a procedure to convert between implicit representations of scenes, such as neural radiance fields (NeRFs), and explicit representations, such as Gaussian splatting (GS).2. Showcasing the benefits of this conversion, including the ability to achieve the best of both worlds: the high rendering quality of NeRFs and the fast rendering speed of GS.3. Demonstrating the efficacy of this approach on a variety of datasets, including those with sparse views, and on views recorded from an ego-centric camera along hiking trails.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an in-depth analysis of Dynamic NeRF, a novel implicit method for 3D reconstruction and representation with high resolution, highlighting its development history, key methods, and comparison of features, and discusses its potential applications and future directions.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a method that synergistically integrates a coordinate-based network and a tensorial feature network to improve the performance of Neural Radiance Fields (NeRFs) from sparse inputs.* The method captures low-frequency details using coordinate-based features and fine-grained details using multi-plane features, allowing for efficient and effective representation of radiance fields.* The authors show that the proposed method outperforms other state-of-the-art methods, including explicit representation methods, in terms of reconstruction quality and rendering speed.* The method reduces the number of parameters by avoiding the need for a spatial low-resolution grid and replacing it with coordinate-based features.Note that the abstract and introduction are concise and provide an overview of the paper's main contributions, but do not fully reveal the technical details of the proposed method.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module, enhancing NeRF-based scene editing tasks by addressing object movement variability and empty regions, achieving state-of-the-art performance in 3D object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a framework for real-time 3D facial reconstruction using LiDAR augmented augmented reality, enabling high-fidelity, interactive, and immersive holographic experiences on portable devices like the iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|This paper proposes Truncated Depth-NeRF (TD-NeRF), a method that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses using monocular depth priors, achieving superior performance and more accurate depth geometry on three datasets.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LIVE, a novel design method to create interactive LaTeX graphic items, enabling the design of more dynamic and informative figures and tables, and aims to improve the writing of traditional papers, particularly review papers, by adding interactive elements.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes SketchDream, a text-driven 3D content generation and editing method that supports NeRF generation from hand-drawn sketches and achieves free-view sketch-based local editing, addressing challenges in 2D-to-3D translation, text-based control, and local editing.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
