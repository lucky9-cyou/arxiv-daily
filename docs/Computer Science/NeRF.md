
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose S3Gaussian, a self-supervised method that decomposes dynamic and static elements from 3D street scenes without requiring 3D annotations, achieving state-of-the-art rendering quality in scene reconstruction and novel view synthesis tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes TetSphere splatting, an explicit, Lagrangian geometry representation that reconstructs 3D shapes with high-quality geometry, outperforming existing Eulerian representations in terms of optimization speed, mesh quality, and reliable preservation of thin structures.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|The key contributions from the paper's abstract and introduction are:* Creation of a new dataset of front-facing and 360-degree real and synthetic visual scenes with camera poses, allowing for the evaluation of NeRF view synthesis methods in a consistent way.* Conducting a subjective quality assessment study to evaluate the impact of NeRF view synthesis methods on perceived quality, using a well-known and reliable methodology.* Evaluating the performance of state-of-the-art conventional and learning-based full-reference 2D image and video quality assessment metrics on NeRF view synthesis quality assessment.* Providing a comparative evaluation of several NeRF view synthesis methods and objective quality metrics across different classes of visual scenes, including real and synthetic content for front-face and 360-degree camera trajectories.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:IReNe, a novel approach, addresses the challenges of efficiently editing Neural Radiance Fields (NeRF) while retaining photorealism by introducing a trainable segmentation module, selective fine-tuning of the last network layer, and automated classification of neuron types, enabling swift and accurate color edits with object boundary control.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HINT, a NeRF-based algorithm that learns detailed and complete human models from limited viewing angles, using symmetry prior, regularization constraints, and training cues from large human datasets, achieving a 15% PSNR improvement over the previous state-of-the-art.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|Key Contributions:1. A novel formulation of 3D scene segmentation using ultrametric feature fields.2. Distilling view-inconsistent 2D masks into a 3D representation that is both view-consistent and hierarchical.3. A synthetic dataset with hierarchical segmentation annotations based on the NeRF Blender Dataset.Evaluation Metrics:1. Normalized Covering Score (NC) to measure the quality of hierarchical segmentation.2. Segmentation Injectivity (SI) score to measure the injectivity of segmentations at different levels of granularity.3. View Consistency (VC) score to evaluate the consistency of image segmentations across different views.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel approach to novel view synthesis within the stomach using monocular gastroscopic images, leveraging neural radiance fields (NeRF) and incorporating geometry priors from a pre-reconstructed point cloud to enhance the rendering quality and address view sparsity.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper introduces NeRF On-the-go, a simple and effective approach to synthesize novel views from casually captured image sequences in complex, dynamic real-world scenes, achieving robust distractor elimination and fast convergence speed, outperforming state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning, which learns to reconstruct missing or corrupted input data across multiple modalities, demonstrating promising transferability across diverse multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper are:1. A hybrid representation that combines deformation fields, hash encoding, and 3D Gaussian Splatting to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.2. A learnable denoising mask that can effectively identify and remove noise points in 3D Gaussian Splatting, enhancing rendering quality.3. Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction challenges by incorporating deformation fields and spatial and temporal high-frequency emphasis reconstruction modules, achieving superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The paper proposes a method to manipulate and edit 3D content using a triangular mesh-based Gaussian Splatting manipulation approach, achieving high-quality and photo-realistic rendering results, with a tolerance for mesh accuracy and various manipulation types.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) while maintaining excellent image quality. Inspired by classical matrix and tensor factorization techniques, F-3DGS represents dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, enabling the encoding of a substantially large number of Gaussians using a relatively small number of elements.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The authors present Pyramidal 3D Gaussian Splatting (PyGS), a novel approach that represents scenes with a hierarchical assembly of Gaussians, initialized by a rapidly trained grid-based NeRF in a pyramidal fashion, enabling efficient rendering and high-fidelity visual results.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses a cascade of 2D diffusion models to reconstruct a 360-degree scene from sparse views, improving performance by leveraging pre-trained 2D models and an iterative update strategy.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model. NEMos can be generated from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.The contributions of the paper can be summarized as follows:1. **NEMo framework**: The paper proposes a novel framework that integrates a NeRF component with a height field, allowing for the simultaneous training of both models.2. **Joint training**: The paper introduces a novel method for jointly training the NeRF and height field using quantile regression, allowing the NeRF to be supervised by the height network.3. **Path planning**: The paper demonstrates a path planning algorithm that leverages the continuous and differentiable nature of the height field to plan smoother and more efficient paths.4. **Real-world applications**: The paper highlights the potential applications of NEMos in real-world scenarios, such as autonomous ground robots operating in challenging terrain.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, to embed 3D scenes and images into original 3D Gaussian Splatting (3DGS) point cloud files in an invisible manner, achieving robust security, high fidelity, large capacity, and versatility for copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present a ray tracing approach for Neural Radiance Fields (NeRFs) to improve view synthesis of scenes containing shiny objects, featuring efficient rendering of highly-specular appearances while reducing computational cost and increasing quality.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Neural Directional Encoding (NDE), a feature-grid-like neural network that accurately models the appearance of shiny objects by encoding view-dependent effects into learnable feature vectors, allowing for fast and high-quality rendering of specular objects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summarized sentence under 50 words:The paper proposes a two-staged pipeline, normalizing images with varied lighting and shadows for robust camera relocalization using a hash-encoded NeRF, and introduces a low-pass filter and numerical gradient averaging technique to improve accuracy and speed.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The key contributions of the paper are: proposing a novel feed-forward framework, LDM, that generates high-quality, illumination-decoupled textured meshes from a single image or text prompts within seconds, and introducing tensorial representation to accurately represent illumination-decoupled SDF fields, enhancing convergence speed.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summarized sentence under 50 words:The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving superior quality and compression efficiency by utilizing a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality on large-scale scenes, while also addressing the challenges of memory consumption and training efficiency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Gaussian Time Machine (GTM), a real-time rendering method for 3D scenes with vastly varying appearances, achieving state-of-the-art reconstruction quality, 100 times faster than NeRF-based methods, and enabling smooth appearance interpolation by disentangling appearance from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework that leverages kinematic information to achieve motion-aware Gaussian split for 3D clothed human synthesis, improving the realism of reconstructed surfaces and achieving state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target. This is achieved by leveraging a Neural Radiance Field (NeRF) model to generate a large dataset that captures the diversity of both the pose distribution and illumination conditions encountered in orbit. The method involves three steps: (1) tele-operated approach of the chaser spacecraft to take pictures of the target, (2) on-ground processing to train a Neural Radiance Field (NeRF) model from a sparse set of images, and (3) uploading the trained model weights on the chaser spacecraft to perform autonomous proximity operations.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a new generalizable 3D Gaussian representation approach that uses Multi-View Stereo for geometry-aware Gaussian encoding and decoding, with a hybrid Gaussian rendering approach and consistent aggregation strategy for fast fine-tuning.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions mentioned in the paper's abstract and introduction are:1. Integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) approaches in 6G networks for efficient representation, transmission, and reconstruction of 3D contents.2. Overview of radiance field rendering techniques, including their applications and implementation challenges in wireless networks.3. Investigation of over-the-air training of NeRF and 3D-GS models using federated learning techniques.4. Discussion of three practical rendering architectures for NeRF and 3D-GS models at wireless network edges.5. Proposal of a new semantic communication enabled 3D content transmission design, leveraging radiance field models as semantic knowledge bases.6. Exploration of radiance field rendering in wireless applications such as radio mapping and radio imaging.7. Examination of the integration of radiance field rendering with edge computing and mobile edge computing (MEC) to support immersive communications.8. Investigation of joint computation and communication designs for radiance field rendering in 6G networks.9. Analysis of the challenges and opportunities presented by radiance field rendering in 6G networks, including latency, quality of experience (QoE), and storage and transmission requirements.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and an explicitly modeled point light attenuation to achieve state-of-the-art reconstruction accuracy, outperforming classical approaches like DiLiGenT-MV.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
