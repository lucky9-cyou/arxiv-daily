
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a self-supervised 3D Gaussian Splatting method called S3Gaussian, which decomposes dynamic and static elements from 4D consistency using a spatial-temporal field network without requiring 3D annotations or tracked bounding boxes.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is the summary in a single sentence under 50 words:TetSphere splatting, a Lagrangian representation, directly reconstructs 3D shapes by deforming tetrahedral spheres, enabling high-quality meshes with superior computational and memory efficiency, and demonstrated superiority over Eulerian representations in mesh quality and reconstruction speed.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a comprehensive evaluation of Neural Radiance Fields (NeRF) view synthesis methods, including a subjective quality assessment study, evaluation of objective quality metrics, and creation of a new dataset for assessing NVS methods, to overcome the challenges of assessing NeRF quality and identifying strengths and weaknesses of popular NeRF solutions.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|The paper's abstract and introduction highlight the key contributions of the Instant Recoloring of Neural Radiance Fields (IReNe), a novel approach that efficiently and accurately edits neural radiance fields in near real-time. The IReNe approach addresses three primary limitations of current NeRF color editing methods: slow processing, inaccurate object boundary control, and inconsistent edits across views. IReNe achieves this through a pre-trained NeRF model, a trainable segmentation module, and automatic classification of neurons responsible for diffuse and view-dependent appearance. The method demonstrates significant quantitative and qualitative advancements over competitors, accelerating editing speeds by 5x to 500x.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, introducing a symmetry prior, regularization constraints, and training cues from large human datasets, achieving improved results by 15% PSNR and 34% LPIPS over the previous state of the art.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper's abstract and introduction are:The paper proposes a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation. Specifically, it learns a novel feature field within a Neural Radiance Field (NeRF) representing a 3D scene, whose segmentation structure can be revealed at different scales by simply using different thresholds on feature distance. This method is designed to address the challenging task of demonstrating a hierarchical structure in 3D scene understanding, where segmentation is often required to be view-consistent and multi-granular.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel application of neural radiance fields (NeRF) to monocular gastroscopic data for synthesizing high-quality, photo-realistic images of the stomach from novel viewpoints, incorporating geometry-based supervision using a pre-reconstructed point cloud.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple and effective approach for synthesizing novel views in complex, real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving faster convergence speed and improved render quality compared to state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training framework for multi-modal representation learning, which uses masked auto-encoder and neural radiance fields to learn transferable representations and outperforms state-of-the-art methods on 3D perception tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Based on the abstract and introduction, the key contributions of the paper are:* A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian Splatting, which reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask that effectively identifies and removes noise points, enhancing rendering quality.* Static constraints and motion consistency constraints that mitigate noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.These contributions demonstrate the effectiveness of the proposed method in addressing the challenges of dynamic scene reconstruction, including rendering speed, memory usage, and noise reduction.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction issues from spatial and temporal frequency perspectives, utilizing deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction to achieve superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Key Contributions:*** The paper proposes a method to manipulate 3D Gaussian Splatting (3DGS) directly using a triangular mesh, enabling controllable and photo-realistic rendering.* The method uses a "triangle shape aware Gaussian binding strategy with self-adaptation" to achieve high-quality rendering despite mesh inaccuracies.* The approach supports various 3DGS manipulations, including large deformation, local manipulation, and soft body simulation.* The paper demonstrates state-of-the-art results on the NeRF synthetic dataset and showcases the effectiveness of the proposed method.Note that the paper presents a relatively detailed overview of the proposed method and its components, but the abstract primarily highlights the main contributions and limitations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that drastically reduces storage requirements while preserving image quality by efficiently representing dense 3D Gaussians using a limited number of elements. F-3DGS employs a factorized coordinate scheme and decomposed representations of Gaussians through factorization, inspired by classical tensor or matrix factorization techniques. The method is designed to alleviate the high computational costs of traditional neural radiance fields (NeRF) by exploiting structural patterns and redundancies in 3DGS.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that addresses the challenges of scaling 3D Gaussian Splatting to large-scale scenes by introducing a hierarchical pyramidal Gaussian structure and dynamic weighting network, achieving a significant performance leap and 400x faster rendering time.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models and a cascade of in-painting and artifact removal models to reconstruct a 360 3D scene from sparse views, achieving high-quality results with only 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper are:1. Introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a continuous and differentiable terrain model.2. A novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.3. A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.4. Demonstration of experiments on simulated and real-world terrain imagery, showing that NEMos can generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D high dynamic range (HDR) imaging, which surpasses state-of-the-art NeRF-based methods by 3.84 dB on LDR and 1.91 dB on HDR novel view synthesis tasks while enjoying 1000x faster inference speed and 6.3% faster training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in the abstract and introduction:The proposed GS-Hider embeds 3D scenes or images into original GS point clouds in an invisible manner, accurately extracts hidden messages, and provides a new steganography method for 3D scene representation, ensuring the security and fidelity of the original scene while hiding messages in explicit 3D points, with exceptional security, robustness, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes a novel approach to Neural Radiance Fields (NeRF) that addresses the issue of rendering high-frequency view-dependent appearance and consistent reflections of nearby content by introducing ray tracing, reducing the reliance on large neural networks and enabling more efficient and high-quality rendering.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summarized description of the paper's abstract and introduction in a sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a novel view-dependent appearance encoding method for neural radiance fields (NeRF) that models high-frequency angular signals, allowing for accurate rendering of specular objects with fast inference speed.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline, hash-encoded NeRF scene representation, and re-designed low-pass filter and numerical gradient averaging technique to tackle camera relocalization with varying lighting conditions, achieving state-of-the-art results in camera relocalization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality 3D meshes with illumination-decoupled textures from single images or text prompts, utilizing a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is the key summary in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme that combines novel dynamic NeRF representation and compression, which achieves superior quality and compression efficiency in rendering volumetric videos with significant motions and long durations.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose DoGaussian, a distributed method that trains 3D Gaussian Splatting (3DGS) efficiently on large-scale scenes by decomposing the scene into blocks, applying Alternating Direction Method of Multipliers (ADMM) for consistency, and achieving 6+ times faster training time while maintaining rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The researchers propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes with discrete time embedding vectors to disentangle scene variations, achieving state-of-the-art fidelity and rendering speed.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Motion-Based 3D Clothed Humans Synthesis (MOSS), a novel framework that employs kinematic information to achieve motion-aware Gaussian split on the human surface, leading to state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a novel method to estimate the pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field, which enables the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors present MVSGaussian, a novel generalizable 3D Gaussian representation approach that leverages Multi-View Stereo to encode geometry-aware Gaussian representations,decode them into Gaussian parameters, and achieve real-time rendering with better view synthesis quality and faster per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions mentioned in the paper's abstract and introduction are:1. Providing a comprehensive overview of integrating Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) techniques in 6G networks for efficient representation, transmission, and reconstruction of 3D contents.2. Discussing the pros and cons of NeRF and 3D-GS, including their application in various areas such as computer vision, computer graphics, and artificial intelligence.3. Exploring the challenges and opportunities of embracing radiance field rendering in 6G networks, including the need for distributed training and inference methods for radiance fields considering practical constraints on communication, computation, and storage resources.4. Proposing a new semantic communication enabled 3D content transmission design to reduce the communication overhead for distributed inference.5. Investigating the utilization of radiance field rendering in wireless applications such as radio mapping and radio imaging.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that uses neural representation and learned renderers, explicitly modeling point light attenuation and cast shadows, achieving competitive reconstruction accuracy with minimal prior assumptions.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
