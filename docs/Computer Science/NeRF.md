
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NS-MAE, a self-supervised pre-training framework for multi-modal representation learning in autonomous driving, which can transfer representations to both multi-modal and single-modal perception models for tasks such as 3D object detection and BEV map segmentation.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here are the key contributions summarized in a single sentence under 50 words:The paper presents a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, combining deformation fields, hash encoding, and denoising masks to achieve efficient rendering of dynamic scenes with reduced memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses challenges in spatial and temporal frequency perspectives, achieving superior rendering quality and addressing under-reconstruction in both static and dynamic scenes.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a single sentence summarizing the key contributions of the paper:The authors propose a novel method, Mani-GS, that utilizes a triangular mesh to directly manipulate 3D Gaussian Splatting (GS) representations while maintaining photo-realistic rendering quality and has a high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting by factorizing dense clusters of Gaussians, allowing for efficient representation and rendering of 3D scenes with significantly fewer Gaussians.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors present Pyramidal 3D Gaussian Splatting (PyGS), a method that combines the benefits of 3D Gaussian Splatting with NeRF initialization to model large-scale scenes, achieving high-fidelity visuals and accelerated rendering performance with over 400 times speedup compared to state-of-the-art NeRF-based methods.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses 2D diffusion models to improve 360 scene reconstruction from sparse views by filling in missing details and cleaning images, outperforming existing methods on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model. NEMos can be generated from imagery, providing a lightweight representation of terrain through an implicit continuous and differentiable height field.The paper proposes a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression. Additionally, the paper introduces a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.The paper highlights the advantages of NEMos, which include faster generation, denser reconstruction, and a compact yet continuous and differentiable representation. The paper also discusses the limitations of traditional terrain representations, such as Digital Elevation Models, and the potential benefits of combining NeRFs with DEMs.The paper's main focus is on demonstrating the capabilities of NEMos for terrain representation and path planning, with two experiments on simulated and real-world terrain scenes, showing high-quality reconstructions and smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that outperforms state-of-the-art NeRF-based methods in terms of PSNR, SSIM, and LPIPS performance while achieving 1000x faster inference speed and only 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) that embeds and extracts 3D scenes and images in an invisible manner, ensuring security, fidelity, capacity, and flexibility, with applications in copyright protection and encrypted communication.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The authors address the limitations of Neural Radiance Fields (NeRFs) in reconstructing and rendering highly specular objects by introducing ray tracing to synthesize consistent reflections and reduce the need for large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents Neural Directional Encoding (NDE), a feature-grid-like approach that efficiently models high-frequency view-dependent appearance and captures global illumination effects, including reflections of other objects, for rendering specular objects with fast inference speeds.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in under 50 words:The paper proposes LDM, a novel feed-forward framework generating high-fidelity, illumination-decoupled textured meshes from single images or text prompts within seconds, leveraging a multi-view diffusion model, SDF representation, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Fields (NeRF), achieving improved quality and compression efficiency by representing the 4D radiance field as a series of residual feature grids and compressing the features using an entropy-minimization method.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed method for training 3D Gaussian Splatting (3DGS) on large-scale scenes, which reduces training time by 6+ times while achieving state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) is proposed to reconstruct 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity and efficiency through a lightweight neural network, decomposed color model, and real-time rendering capability.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a motion-aware Gaussian split framework that incorporates kinematic information to achieve realistic clothing deformation and joint details in 3D clothed human synthesis from monocular videos, outperforming existing methods by 33.94% and 16.75% in LPIPS and Gaussian Splatting respectively.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper's abstract and introduction state that the authors present a novel method for estimating the 6D pose of an unknown target spacecraft using a monocular camera. The method leverages an in-the-wild Neural Radiance Field (NeRF) to generate a large dataset of images, which is then used to train an off-the-shelf spacecraft pose estimation (SPE) network. The authors demonstrate the method's effectiveness on Hardware-in-the-Loop images and show that it outperforms existing model-based and model-agnostic methods on unknown targets.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents MVSGaussian, a new generalizable Gaussian representation approach that efficiently reconstructs unseen scenes by leveraging Multi-View Stereo and proposing a hybrid Gaussian rendering and consistent aggregation strategy.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The paper provides a comprehensive overview of the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G wireless networks, focusing on the efficient representation, transmission, and reconstruction of 3D contents.* The authors highlight the importance of embracing NeRF and 3D-GS in 6G networks to support emerging 3D applications with enhanced quality of experience.* The paper reviews the basics of radiance field rendering techniques and discusses the applications and implementation challenges over wireless networks.* The authors propose a new semantic communication-enabled 3D content transmission design, which exploits radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* The paper also explores the utilization of radiance field rendering in wireless applications such as radio mapping and radio imaging, and discusses the technical challenges and opportunities in integrating NeRF and 3D-GS with 6G wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summarized version of the abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages neural shape representations and learnt renderers to achieve high accuracy in estimating 3D shape from photometric stereo images, robust to poor normal estimates and showcasing competitive reconstruction accuracy.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems, using a novel "Judge" mechanism to assess and optimize the realism of generated objects, with potential applications in testing and improving the resilience of self-driving systems.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Developing a novel two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments.* Proposing a NeRF-based ray tracing method to model dynamic electromagnetic fields, enabling accurate characterization of signal dynamics.* Validating the effectiveness of the proposed method through simulated and measured data, demonstrating superior performance compared to existing methods.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity mapping and tracking with reduced memory usage and state-of-the-art performance on RGB-D datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the integration of large language models (LLMs) with 3D spatial data, highlighting the potential for advanced spatial comprehension and interaction, and presenting current methodologies, applications, and challenges in this emerging domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* A novel procedure to convert between implicit representations (Neural Radiance Fields, NeRFs) and explicit representations (Gaussian Splatting, GS) of 3D scenes.* The procedure can convert NeRFs to GS for real-time rendering and modifying the scene representation, and conversely, convert GS to NeRFs for updating the map and distilled features.* The approach achieves the best of both worlds: superior PSNR, SSIM, and LPIPS scores on dissimilar views, while maintaining a compact representation of the scene, and allowing for real-time rendering.* The computational cost of these conversions is minor compared to training the models from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper reviews the development and implementation principles of Dynamic Neural Radiance Field (NeRF), a novel approach for achieving high-resolution 3D reconstruction and representation, with a focus on its history, key methods, and features, and analyzes its potential relevance in practical applications.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a method that synergistically integrates the multi-plane representation with a coordinate-based network to improve the performance of NeRFs from sparse inputs.* The multi-plane representation is used to capture fine-grained details, while the coordinate-based network is used to capture low-frequency signals.* The method achieves comparable results to explicit encoding with fewer parameters and outperforms others in dynamic NeRFs with sparse inputs.Note that the abstract and introduction do not provide the specific details of the methods, such as the architecture of the network, the training process, and the hyperparameters. The details can be found in the subsequent sections of the paper.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling module (DNR) to enable direct manipulation of 3D object poses and effective inpainting of empty regions in NeRF models, achieving state-of-the-art performance in object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
