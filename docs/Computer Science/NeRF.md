
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos), a novel terrain representation that adapts Neural Radiance Fields to a continuous and differentiable height field, enabling efficient and accurate path planning in challenging terrain environments.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR imaging, which can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art methods in both performance and speed.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and flexibility while hiding multiple messages in a single 3D scene.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose an approach that introduces ray tracing into Neural Radiance Fields (NeRFs), allowing for efficient and detailed rendering of highly specular objects, particularly reflections of nearby content, while reducing optimization and rendering time.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel approach that combines feature-grid-based spatial encoding with angular domain encoding to faithfully render specular objects with high-frequency angular signals, outperforming state-of-the-art methods in view synthesis and achieving fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality, illumination-decoupled textured meshes from single images or text prompts, leveraging a tensorial SDF representation and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes JointRF, an end-to-end learned scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior quality and compression efficiency, using a compact residual feature grid and sequential feature compression, and outperforming previous methods.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting that reduces training time by 6+ times on large-scale scenes while maintaining high-fidelity rendering quality, and introduce a recursive approach to split scenes into balanced blocks.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a real-time rendering method for scenes with vastly varying appearances, which models time-dependent attributes of Gaussian primitives, adjusts opacity, and incorporates a decomposed color model for improved geometric consistency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework for single-view clothed human reconstruction that propagates kinematic information to Gaussian distributions to enhance realism and handle occlusions, achieving state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions in the paper's abstract and introduction:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimation network to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) to generate a large training set from a sparse collection of images, allowing for autonomous rendezvous and proximity operations.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MVSGaussian, a generalizable Gaussian Splatting method that leverages Multi-View Stereo to efficiently reconstruct unseen scenes with real-time rendering, fast fine-tuning, and better synthesis quality, outperforming previous generalizable methods.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper discusses the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents. The authors highlight the advantages of NeRF and 3D-GS in providing photorealistic rendering results for complex scenes, but also point out their limitations, such as requiring substantial computation resources and having large data storage requirements. The paper aims to explore new distributed training and inference methods for NeRF and 3D-GS, taking into account the practical constraints on communication, computation, and storage resources at distributed nodes.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the abstract and introduction are:* A novel multi-view photometric stereo (PS) method that explicitly leverages per-pixel intensity renderings, rather than relying mainly on estimated normals.* The method models point light attenuation, explicitly raytraces cast shadows, and optimizes a fully neural material renderer.* The approach achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.* The method is robust to poor normals in low light count scenarios, achieving a Chamfer distance of 0.27mm when pixel rendering is used instead of estimated normals.* The approach uses a neural SDF parameterization and a volumetric rendering method similar to VolSDF, with ray sampling and alpha blending used to accumulate depth, normals, and rendered intensity at each ray.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing an evaluative mechanism, called the "Judge," to assess the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* A novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in Reconfigurable Intelligent Surface (RIS)-enabled wireless environments.* A two-stage framework that accurately captures the complete signal path from the transmitter to the RIS and from the RIS to the receiver, modeling the complex interactions of electromagnetic waves.* Integration of NeRF-based ray tracing techniques with electromagnetic physics to model the signal field for any specified RIS placement and receiver location.* Experimental evaluations using both simulated and real-world data demonstrate the effectiveness of the proposed method, outperforming other methods in terms of prediction accuracy.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS to achieve real-time tracking, high-fidelity reconstruction, and reduced memory usage, outperforming existing methods in tracking, mapping, and rendering.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper provides a comprehensive survey on integrating large language models with 3D spatial data, highlighting the unique advantages of LLMs and examining their potential for advancing spatial comprehension and interaction within embodied AI systems.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions from the paper's abstract and introduction are:* The authors develop a procedure to convert between implicit representations of scenes, such as Neural Radiance Fields (NeRFs), and explicit representations, such as Gaussian Splatting (GS).* This approach allows for the best of both worlds: the generality and compactness of NeRFs, and the real-time rendering and ease of modification of GS.* The authors demonstrate the effectiveness of their approach on several datasets and applications, including robotics, scene understanding, and simulation.* The conversion process is shown to be efficient, with minor computational cost compared to training the two representations from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This review provides a comprehensive analysis of the development and implementation principles of Dynamic Neural Radiance Field (NeRF), highlighting its potential in practical applications, key methods for implementation, and comparing features of various Dynamic NeRF projects.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions of the paper are:1. The authors propose a method that synergistically integrates multi-plane representation with a coordinate-based network to capture both low-frequency and high-frequency details in Neural Radiance Fields (NeRFs) from sparse inputs.2. The proposed method uses residual connections to concatenate the coordinate-based features with the multi-plane features, allowing them to retain their inherent properties and facilitating efficient parameter allocation.3. The authors demonstrate that the proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms other methods in dynamic NeRFs from sparse inputs.4. The method reduces the number of parameters by skipping the allocation of a spatial low-resolution grid and replacing it with coordinate-based features, making it more efficient and applicable to real-world scenarios.5. The authors conduct extensive experiments to validate the effectiveness of the proposed method and demonstrate its ability to improve NeRFs from sparse inputs.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module (DNR) to enable direct manipulation of 3D object pose and inpainting of empty regions in NeRF-based scene editing tasks, achieving state-of-the-art performance in 3D object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The proposed application creates real-time holographic overlays using LiDAR augmented 3D reconstruction, aiming to provide high-fidelity facial reconstructions on portable devices, such as the iPhone 14 Pro.The proposed approach involves three attempts to achieve real-time 3D facial reconstructions: monocular depth estimation, LiDAR + TrueDepth, and template modeling. Each attempt involves various techniques, such as ViT backbone for depth estimation, LiDAR + TrueDepth data fusion, and deep learning-based methods like SRCNN and MICA.The main engineering constraints imposed are: (1) monocular estimation, (2) portability, (3) high fidelity, and (4) instantaneous rendering (at least 30 FPS).|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, improving convergence speed, accuracy, and robustness in 3D reconstruction and SLAM tasks.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LIVE, a novel design method for interactive LaTeX graphic items, which allows for the creation of dynamic and interactive figures and tables, and facilitates analysis of citation relationships between multiple papers, enhancing the reading experience and presentation of academic papers.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a brief summary of the key contributions from the paper's abstract and introduction:The key contributions are:* A text-driven 3D content generation and editing method, called SketchDream, which supports NeRF generation from given hand-drawn sketches and achieves free-view sketch-based local editing.* A sketch-based multi-view image generation diffusion model that utilizes depth guidance to establish spatial correspondence, and a 3D attention control module to ensure 3D consistency.* A coarse-to-fine editing framework that allows for local editing of 3D models while preserving unedited regions.These contributions aim to address the challenges of sketch-based 3D generation and editing, including the need for more detailed geometry control and the difficulty of achieving high-quality results that are faithful to the input sketches.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
|**2024-05-10**|**Aerial-NeRF: Adaptive Spatial Partitioning and Sampling for Large-Scale Aerial Rendering**|Xiaohan Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Aerial-NeRF, a novel approach that adapts NeRF to large-scale aerial rendering by designing an adaptive spatial partitioning and selection method, utilizing similarity of poses for rendering speedup, and developing an adaptive sampling approach to cover the entire buildings at different heights, achieving state-of-the-art results on two public large-scale aerial datasets and a new SCUTic dataset.|[2405.06214v1](http://arxiv.org/abs/2405.06214v1)|null|
|**2024-05-10**|**Residual-NeRF: Learning Residual NeRFs for Transparent Object Manipulation**|Bardienus P. Duisterhof et.al.|The paper proposes Residual-NeRF, a method that improves depth perception and training speed for transparent objects by learning a background NeRF of the scene and combining it with residual RGB values and densities to mitigate ambiguity.|[2405.06181v1](http://arxiv.org/abs/2405.06181v1)|null|
|**2024-05-09**|**DragGaussian: Enabling Drag-style Manipulation on 3D Gaussian Representation**|Sitian Shen et.al.|The paper proposes DragGaussian, a 3D object drag-editing framework using 3D Gaussian Splatting and diffusion models, enabling interactive, point-based 3D editing with open-vocabulary input and introducing a new task in 3D object editing.|[2405.05800v1](http://arxiv.org/abs/2405.05800v1)|null|
