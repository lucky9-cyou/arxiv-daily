
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel deep learning approach, using neural radiance fields (NeRF), to enable the synthesis of arbitrarily novel viewpoint images within a patient's stomach from pre-captured monocular gastroscopic images, incorporating geometry priors from a pre-reconstructed point cloud to address view sparsity.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|The paper proposes NeRF On-the-go, a novel approach that enables robust synthesis of novel views in complex, real-world scenes from casually captured image sequences, effectively eliminating distractors and achieving faster convergence speed, surpassing state-of-the-art techniques in various scenes.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|The key contributions of this paper are:* Proposing a self-supervised pre-training framework for multi-modal representation learning, called NS-MAE, for autonomous driving.* Designing a unified optimization framework that enables effective transferability of multi-modal representations across different modalities and tasks.* Developing a plug-and-play component for transferable representation learning, leveraging Neural Radiance Fields (NeRF) for multi-modal perception pre-training.* Verifying the transferability of multi-modal representation learned via NS-MAE for diverse 3D perception tasks with different amounts of fine-tuning data.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* Developing a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, addressing the concerns of rendering quality, speed, and memory usage in 3D Gaussian Splatting (3D-GS) and NeRF.* Introducing a hybrid representation combining deformation fields, hash encoding, and 3D-GS to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* Implementing a learnable denoising mask to effectively identify and remove noise points in the scene, enhancing rendering quality.* Introducing static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The key contributions of the paper are the introduction of HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) representations using a triangular mesh, enabling large deformation, local manipulation, and soft body simulations while maintaining high-quality rendering and having a high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a method that reduces storage requirements by factorizing 3D Gaussians using efficiency-oriented techniques, achieving a 90% reduction in storage while maintaining comparable image quality and fast rendering speeds.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), which addresses the challenges of scaling 3D Gaussian Splatting by introducing a hierarchical pyramidal structure and dynamic weighting of each level's contribution, achieving a significant performance leap and rendering time acceleration.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a method called SparseSplat360 that leverages pre-trained 2D diffusion models and explicit 3D Gaussian scene representations to reconstruct and fill in missing details in 360-degree views from as few as 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce Neural Elevation Models (NEMos), a novel representation that adapts Neural Radiance Fields to a continuous and differentiable terrain model, allowing for high-quality reconstructions and smoother paths, and proposing a novel approach for joint training of a height field and radiance field within a NeRF framework.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and flexibility for copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents an approach to improve Neural Radiance Fields (NeRF) for rendering highly specular objects by introducing ray tracing, which synthesizes consistent reflections of both nearby and distant content and renders higher quality specular reflections at a lower computational cost.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, enabling accurate modeling of high-frequency angular signals and fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, utilizing a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts, leveraging a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by reducing redundancy and utilizing a compact residual feature grid and entropy-minimization compression method.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times on large-scale scenes while maintaining state-of-the-art rendering quality, using a recursive block splitting approach and Alternating Direction Method of Multipliers (ADMM).|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a novel rendering method that models time-dependent attributes of Gaussian primitives to reconstruct 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity and real-time rendering capabilities 100 times faster than NeRF-based methods.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Motion-Based 3D Clothed Humans Synthesis (MOSS), a framework that leverages kinematic information to achieve motion-aware Gaussian split on the human surface, improving realism and accuracy in single-view clothed human reconstruction, particularly in scenes with large-scale human motion.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, enabling autonomous rendezvous and proximity operations for future Active Debris Removal (ADR) missions. The method leverages Neural Radiance Fields (NeRFs) to generate a large dataset of images capturing the diversity of both the pose distribution and illumination conditions encountered in orbit, from which an off-the-shelf spacecraft pose estimation (SPE) network can be trained.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The key contributions of the paper are: a generalizable 3D Gaussian representation approach derived from Multi-View Stereo that efficiently reconstructs unseen scenes, a hybrid Gaussian rendering approach for novel view synthesis, and a multi-view geometric consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper explores the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques in 6G networks, focusing on efficient representation, transmission, and reconstruction of 3D contents, and discussing the challenges and opportunities in embracing NeRF and 3D-GS in 6G communications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo method that leverages neural shape representations and learnt renderers to model point light attenuation and explicitly ray-trace cast shadows, achieving competitive reconstruction accuracy using only 6 lights and matching state-of-the-art performance when all lights and normal map information are also fused.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a "Judge" mechanism that evaluates the realism of generated objects and incorporates it into the loss function, and presents four strategies for optimizing the Judge's realism assessment.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to accurately model dynamic electromagnetic fields in RIS-enabled environments, enabling the prediction of signal fields for any specified RIS placement and receiver location.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving high-fidelity scene representation, real-time tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive survey of methodologies and applications that integrate Large Language Models (LLMs) with 3D data, highlighting the unique strengths of LLMs for spatial comprehension and interaction within embodied AI systems, while also discussing challenges and potential future directions.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions mentioned in the paper's abstract and introduction:* The authors develop a procedure to convert between parametric representations (Neural Radiance Fields, NeRFs) and non-parametric ones (Gaussian Splatting, GS) for robotics and computer vision applications.* The conversion procedure allows for the benefits of both approaches: NeRFs' ability to generalize well to new views and GS' ability to render quickly and modify easily.* The authors demonstrate the effectiveness of this approach using a number of existing datasets and applications, including robotics, localization, mapping, and feature distillation.* The results show that the approach achieves the best of both worlds, with improved rendering quality and faster rendering times compared to standalone NeRFs and GS.* The computational cost of the conversions is minor compared to training the models from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper reviews the development and implementation principles of Dynamic NeRF, from its origins in 2021 to 2023, comparing and analyzing its features and key methods for practical applications, highlighting its potential in editable NeRF and dynamic 3D modeling.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
