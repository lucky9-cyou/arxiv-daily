
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel method that reduces storage requirements while preserving image quality by representing dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, achieving a 90% reduction in storage while maintaining image quality.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization improves large-scale scene representation by arranging Gaussians in a hierarchical pyramid and dynamically weighting their contributions, achieving a significant performance leap and over 400 times faster rendering time than current state-of-the-art approaches.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a novel method for reconstructing 360-degree scenes from sparse views by leveraging pre-trained 2D diffusion models and 3D Gaussians, achieving superior performance and multi-view consistency with few input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions mentioned in the abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos) which combine Neural Radiance Fields with a continuous and differentiable height field, enabling the generation of terrain from imagery and allowing for smoother path planning.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction as a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS) for novel view synthesis, a framework that can efficiently render HDR images and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art methods with shorter training time and faster inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The paper's abstract and introduction highlight the need for steganography techniques tailored for 3D Gaussian Splatting (3DGS), which requires protecting the copyright and privacy of 3D scenes while hiding messages into the 3DGS point cloud files in an invisible manner, ensuring security, fidelity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents an approach that introduces ray tracing into Neural Radiance Fields (NeRF) to improve rendering of highly specular objects, synthesizing consistent reflections of nearby and distant content, and rendering high-quality specular reflections with increased efficiency.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a novel method that efficiently models high-frequency view-dependent appearance and interreflection effects in specular objects, outperforming the state-of-the-art on view synthesis tasks while allowing for fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a novel two-staged pipeline for camera relocalization under varying lighting conditions, utilizing neural radiance fields (NeRFs) and a hash-encoded NeRF representation to normalize images with different lighting conditions and achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a single sentence summarizing the key contributions of the paper: The paper proposes LDM, a novel feed-forward framework generating high-quality triangular meshes with illumination-decoupled textures from text or single images in seconds, introducing a tensorial SDF representation and adaptive conversion strategy, and integrating a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field representation and compression, which achieves superior quality and compression efficiency for volumetric videos with large motions and long durations.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly using Alternating Direction Method of Multipliers (ADMM) to accelerate training on large-scale scenes while maintaining rendering performance, reducing training time by 6+ times.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes and decomposes rendering color into static and dynamic terms to reconstruct 3D scenes with vastly varying appearances efficiently and accurately.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a single-sentence summary of the key contributions from the paper's abstract and introduction:The authors propose Motion-Based 3D Clothed Humans Synthesis (MOSS), an innovative framework that incorporates kinematic information to achieve motion-aware Gaussian split on human surfaces, improving 3D clothed human reconstruction with state-of-the-art visual quality and efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper's abstract and introduction key contributions are:* The development of a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target without requiring the CAD model of the target.* The use of an in-the-wild Neural Radiance Field (NeRF) to represent the target spacecraft and generate a large dataset of images with varying illumination conditions.* The ability to train a pose estimation network from a sparse set of images, which can be used for autonomous rendezvous and proximity operations during Active Debris Removal missions.* The validation of the method on realistic Hardware-In-the-Loop (HIL) images from the SPEED+ dataset, demonstrating its feasibility for practical applications.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MVSGaussian, a new generalizable 3D Gaussian representation approach that uses Multi-View Stereo for efficient reconstruction, hybrid Gaussian rendering for enhanced generalization, and a consistent aggregation strategy for fast per-scene optimization, achieving real-time rendering and better view synthesis quality.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here are the key contributions summarized in a single sentence under 50 words:The paper provides a comprehensive overview of integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G wireless networks, addressing technical challenges and proposing novel solutions for efficient 3D content representation, transmission, and reconstruction.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and optimizes a fully neural material renderer to achieve competitive reconstruction accuracy.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a "Judge" mechanism that assesses the realism of objects and integrates their scores into the loss function to optimize for both adversarial effectiveness and visual realism.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions from the paper's abstract and introduction are:* Developing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments.* Proposing a two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.* Introducing a subtly designed framework that properly tracks the entire transmission path, enhancing our understanding of signal behavior in real-world scenarios.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve high-fidelity scene representation, accurate real-time tracking, and high-performance rendering while reducing memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This survey provides a comprehensive overview of integrating Large Language Models (LLMs) with 3D spatial data, highlighting their potential to advance spatial comprehension and interaction in embodied AI systems, and discussing current methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* Developing a procedure to convert between implicit representations (NeRFs) and explicit representations (Gaussian splatting) in a way that achieves the best of both worlds: superior rendering quality and real-time rendering speed.* Demonstrating that this conversion can be done efficiently, with minor computational cost compared to training the two representations from scratch.* Showcasing the effectiveness of this approach through experiments on various datasets and scenarios, including situations with sparse views and changing scenes.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive review of Dynamic Neural Radiance Field (NeRF) developments, analyzing the principles, techniques, and most recent projects from 2021 to 2023, highlighting its potential applications and providing a detailed comparison of various features and implementation methods.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The proposed method synergistically integrates a coordinate-based network with a multi-plane representation to improve neural radiance fields (NeRFs) from sparse inputs.* The coordinate-based network captures low-frequency context, while the multi-plane representation captures fine-grained details, allowing for a model less sensitive to hyperparameters and performance variations.* The proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms others for static and dynamic NeRFs with sparse inputs.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose an implicit ray transformation strategy and a differentiable neural-point resampling (DNR) module, enabling point-based editable NeRF pipeline (PR^2T-NeRF) for scene object removal and inpainting tasks, achieving state-of-the-art performance with high-quality rendering visualization.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction.* The approaches are designed to run on a portable device like iPhone 14 Pro, which requires novel engineering constraints, including monocular estimation, portability, high fidelity, and instantaneous rendering.* The paper introduces three high-fidelity reconstruction tools that can handle dynamic scenes and provide metric accurate facial reconstructions.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, and introduces three key advancements: depth-based ray sampling, coarse-to-fine training, and robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LIVE, a novel method to design interactive LaTeX graphic items, overcoming the limitations of traditional static content, and enabling the creation of dynamic and interactive components for academic papers, while maintaining objectivity and scientificity.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a single sentence summarizing the contributions from the paper's abstract and introduction:The authors propose SketchDream, a text-driven 3D content generation and editing method that leverages sketches and text prompts to generate high-quality 3D models and supports detailed editing of reconstructed or generated models.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
