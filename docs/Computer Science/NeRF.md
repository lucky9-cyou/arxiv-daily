
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* Neural Elevation Models (NEMos) which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model, allowing for the generation of high-quality reconstructions of terrain from imagery and compact representation of terrain geometry.* A novel approach for jointly training NeRF and height field using quantile regression, allowing for the estimation of terrain elevation from images alongside density distribution.* A path planning algorithm that utilizes the continuous and differentiable nature of the height field to achieve smoother paths compared to discrete planning over equivalent Digital Elevation Models (DEMs).|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying much faster training and inference speed.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, which embeds 3D scenes and images into 3D Gaussian Splatting (3DGS) point cloud files without compromising rendering quality, featuring robust security, high fidelity, large capacity, and versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper addresses issues in Neural Radiance Fields (NeRFs) by introducing ray tracing to render view-dependent appearance, overcoming limitations in modeling detailed reflections of nearby scene content and reducing reliance on large MLPs.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for neural radiance fields (NeRF) that accurately models high-frequency angular signals and interreflection effects in rendering specular objects, outperforming state-of-the-art methods.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizing a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique for robust pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed LDM framework generates high-quality, textured 3D meshes from single images or text prompts, utilizing a novel feed-forward pipeline combining multi-view diffusion, transformer-based SDF prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's introduction and abstract in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end optimization scheme for compressing and representing dynamic Neural Radiance Fields (NeRF) to improve quality and compression efficiency for volumetric videos, addressing the challenges of rendering and storing dynamic scenes with large motions and long durations.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed method for training 3D Gaussian Splatting on large-scale scenes, which splits scenes into blocks, uses ADMM to ensure consistency between blocks, and reduces the training time by 6+ times while achieving state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The Gaussian Time Machine (GTM) presents a novel real-time rendering method that models time-dependent attributes of Gaussian primitives using discrete time embedding vectors, achieving state-of-the-art rendering fidelity and efficiency, while disentangling appearance changes from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework that employs kinematic information to achieve motion-aware 3D clothed human reconstruction, which improves realism and local deformation accuracy, and achieves state-of-the-art visual quality in 3D human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper proposes a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, a crucial step for autonomous rendezvous and proximity operations required by future Active Debris Removal missions. The method leverages an in-the-wild Neural Radiance Field (NeRF) trained on a sparse set of images to generate a large, diverse training set for an off-the-shelf spacecraft pose estimation network. This approach enables the training of a model that can estimate the pose of an unknown target with high accuracy, even when the target's CAD model is not available.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo and a pixel-aligned Gaussian representation, achieving real-time rendering with better synthesis quality, and fast per-scene optimization with 13.3x less training computational cost.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The authors introduce the concept of radiance field rendering, which is a technique for representing 3D contents using neural networks and Gaussian functions.* They highlight the importance of radiance field rendering in 6G networks, which aim to provide immersive communication experiences.* The authors discuss the pros and cons of two promising radiance field representation techniques, NeRF and 3D-GS, and how they can be integrated into 6G networks.* They emphasize the need for distributed training and inference methods for radiance fields, considering the practical constraints on communication, computation, and storage resources in 6G networks.* The authors also discuss the importance of joint computation and communication designs for radiance field rendering, and how they can be used to improve the rendering efficiency and quality.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction, condensed into a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and optimizes a fully neural material renderer to achieve competitive reconstruction accuracy using few lights and surpassing state-of-the-art methods.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The abstract and introduction of the paper summarize the key contributions as:* A modified gradient-based texture optimization method to discover realistic-looking adversarial objects.* The integration of an evaluative mechanism, referred to as the 'Judge', which assesses and refines the realism of generated objects.* Four strategies for developing a reliable Judge: leveraging cutting-edge vision-language models, fine-tuning open-sourced vision-language models, pretraining neurosymbolic systems, and utilizing traditional image processing techniques.* The paper provides a detailed analysis of the Judge's effectiveness, concluding that strategies 1) and 4) yield less reliable outcomes, pointing towards strategies 2) or 3) as more promising directions for future research.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Developing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.* Proposing a two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, capturing the complex interactions between the RIS, transmitter, and receiver.* Illustrating the effectiveness of the proposed method through experimental results using both simulated and real-world data, showcasing superior performance compared to other methods.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, named MotionGS, featuring deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving state-of-the-art performance in tracking, mapping, and rendering with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive overview of methodologies enabling Large Language Models (LLMs) to process, understand, and generate 3D spatial data, highlighting the potential of LLMs to significantly advance spatial comprehension and interaction within embodied AI systems.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|According to the abstract and introduction, the key contributions are:* A procedure for converting between parametric representation models (Neural Radiance Fields, NeRF) and non-parametric representation models (Gaussian Splatting, GS)* A method for efficiently converting a NeRF-based representation to a GS-based representation and vice versa, which achieves the benefits of both models (accurate representation, fast rendering) without having to train models from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive review of Dynamic Neural Radiance Field (NeRF), a novel implicit method for 3D reconstruction and representation, analyzing its development history, principles, and techniques, and discussing its potential applications and key implementation methods.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The proposed method synergistically integrates a coordinate-based network with a multi-plane representation to capture both low-frequency and high-frequency details in Neural Radiance Fields (NeRFs) from sparse inputs.* The method combines the strengths of both approaches, using the coordinate-based network to capture global context and the multi-plane representation to capture fine-grained details.* The method achieves superior results compared to existing methods, especially in dynamic scenes with sparse input views.* The proposed method reduces the number of parameters required, making it more efficient and easier to implement.In summary, the paper proposes a new approach for improving NeRFs from sparse inputs by integrating a coordinate-based network with a multi-plane representation, which achieves better results and requires fewer parameters.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling module to facilitate object removal and scene inpainting in NeRF models, achieving state-of-the-art performance and supporting high-quality rendering without extra supervision.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes an application that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, enabling interactive and immersive holographic experiences. The main contributions include:1. Three approaches to generating real-time 3D facial reconstructions, which are novel in the context of monocular estimation, LiDAR and TrueDepth sensor fusion, and template modeling.2. A hybrid approach that combines different techniques, such as classical image projections, depth estimation, LiDAR and TrueDepth sensor fusion, and template modeling, to achieve high-fidelity facial reconstructions.3. The use of engineering constraints, such as monocular estimation, portability, high fidelity, and instantaneous rendering, to ensure that the engineered solutions are novel and challenging to implement.4. The demonstration of real-time 3D facial reconstruction on a portable device, such as an iPhone 14 Pro, using LiDAR and TrueDepth sensor data, and showcasing the results in figures 2-4.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LIVE, a novel design method for creating interactive LaTeX graphic items, enhancing the traditional static representation of academic papers with interactive features, and improving the efficiency of designing interactive components through automatic citation relationship analysis.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes SketchDream, a text-driven 3D content generation and editing method that integrates sketches and text prompts to achieve detailed control over geometry and appearance, and supports local editing and editing of existing 3D models.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
|**2024-05-10**|**Aerial-NeRF: Adaptive Spatial Partitioning and Sampling for Large-Scale Aerial Rendering**|Xiaohan Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Aerial-NeRF, a novel approach that jointly adapts NeRF for large-scale aerial rendering by designing an adaptive spatial partitioning and selection method, utilizing similarity of poses for rendering speedup, and developing an adaptive sampling approach for rendering performance improvement.|[2405.06214v1](http://arxiv.org/abs/2405.06214v1)|null|
|**2024-05-10**|**Residual-NeRF: Learning Residual NeRFs for Transparent Object Manipulation**|Bardienus P. Duisterhof et.al.|The Residual-NeRF method improves depth perception and training speed for transparent objects by learning a background scene model and combining it with residual RGB values and densities to provide more accurate and robust depth maps.|[2405.06181v1](http://arxiv.org/abs/2405.06181v1)|null|
|**2024-05-09**|**DragGaussian: Enabling Drag-style Manipulation on 3D Gaussian Representation**|Sitian Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DragGaussian, a 3D object editing framework that utilizes 3D Gaussian Splatting and diffusion models for interactive image editing with open-vocabulary input, introducing a new task and developing a point-based 3D editing system.|[2405.05800v1](http://arxiv.org/abs/2405.05800v1)|null|
