
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a self-supervised 3D Gaussian Splatting method, S3Gaussian, that decomposes dynamic and static elements from 4D consistency without tracked 3D vehicle bounding boxes, enabling efficient scene reconstruction without costly annotations.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents TetSphere splatting, an explicit, Lagrangian geometry representation that efficiently reconstructs high-quality meshes by deforming tetrahedral spheres, outperforming existing methods in terms of mesh quality, optimization speed, and reliable preservation of thin structures.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|The key contributions of this paper are:* Creation of a new set of synthetic and real visual scenes with camera poses, which can be used to assess NVS methods.* Evaluation of the impact of NVS on perceived quality using a well-known and reliable subjective assessment methodology.* Evaluation of the performance of state-of-the-art IQA and VQA metrics, including learning-based metrics, in assessing NVS quality.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces IReNe, a novel approach that enables instant recoloring of Neural Radiance Fields (NeRF) by selectively fine-tuning the last layer of the network, leveraging a trainable segmentation module, and automatically classifying neurons for diffuse appearance, achieving swift and accurate color editing.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose HINT, a NeRF-based method that learns detailed and complete human models from limited viewing angles, achieving improved results by introducing symmetry prior, regularization constraints, and training cues from large human datasets.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation using ultrametric feature fields within a Neural Radiance Field (NeRF), achieving improved accuracy and view consistency.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel method for synthesizing photo-realistic images for novel viewpoints within the stomach using monocular gastroscopic images, by incorporating a geometry-based loss that exploits a pre-reconstructed point cloud and generating unobserved views to address view sparsity.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple yet effective approach for novel view synthesis in complex, in-the-wild scenes from casually captured image sequences, efficiently eliminating distractors and achieving faster convergence speed while demonstrating significant improvement over state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a self-supervised pre-training framework, NS-MAE, for transferable multi-modal representation learning, which combines masked auto-encoder with neural radiance fields for efficient and high-performance fine-tuning of multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian Splatting to significantly reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask in conjunction with noise loss to effectively identify and remove noise points in 3D Gaussian Splatting, enhancing rendering quality.* Static constraints and motion consistency constraints to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.Here is a single sentence summarizing the contributions under 50 words:The paper presents a hybrid framework that combines deformation fields, hash encoding, and 3D Gaussian Splatting to reduce memory usage and achieve high-quality rendering of dynamic scenes, while introducing learnable denoising masks and static constraints for improved performance.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction issues from spatial and temporal frequency perspectives, incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction, achieving superior rendering quality in extensive experiments.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summarization of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a method for manipulating 3D Gaussian Splatting (3DGS) representations using a triangular mesh, enabling large deformations, local manipulations, and soft body simulations while maintaining high-quality rendering.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements while preserving image quality by factorizing 3D Gaussians using structured coordinates and decomposed representations, achieving a significant reduction of over 90% in storage costs while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Pyramidal 3D Gaussian Splatting (PyGS) method efficiently scales 3D scene modeling by introducing a hierarchical assembly of Gaussians, leveraging NeRF initialization, and dynamically weighting each level's contribution for fast and high-fidelity rendering.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360Â° scenes, achieving state-of-the-art results by leveraging a cascade of in-painting and artifact removal models and an iterative update strategy to fuse generated novel views with existing scene representations.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), a novel representation that combines Neural Radiance Fields (NeRFs) with a height field to enable the generation of continuous and differentiable terrain models from images.* The ability of NEMos to generate high-quality reconstructions of complex terrain scenes without requiring additional depth data or high-fidelity surveys.* The proposed method for jointly training a NeRF and a height field using quantile regression, which allows for the learning of a height field that is continuous and differentiable.* The development of a path planning algorithm that leverages the continuous and differentiable nature of the height field to optimize for distance, slope, and control effort.Overall, the paper presents a novel approach to terrain modeling and path planning that has the potential to enable more efficient and effective navigation in complex environments.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, surpassing state-of-the-art NeRF-based methods in terms of inference speed and training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a novel steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point cloud files while ensuring security, fidelity, and flexibility, with large capacity and versatility for hiding multiple messages.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents a novel approach to Neural Radiance Fields (NeRFs) that leverages ray tracing to render view-dependent, high-frequency appearance and consistent reflections of nearby scene content, achieved by casting reflection rays into the NeRF geometry and decoding feature vectors into reflected color using a small MLP.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Neural Directional Encoding (NDE), a novel method for view-dependent appearance encoding of neural radiance fields (NeRF) that achieves high-quality modeling of view-dependent effects and fast evaluation, enabling real-time inference and accurate rendering of specular objects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-stage pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, using a hash-encoded NeRF with a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique, achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-quality 3D mesh assets with illumination-decoupled RGB textures from single images or text prompts, utilizing a multi-view diffusion model, a transformer-based SDF field predictor, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, which achieves significantly improved quality and compression efficiency compared to previous methods.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The paper proposes DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly by decomposing a scene into blocks, introducing Alternating Direction Method of Multipliers (ADMM) to ensure consistency, and achieving a 6+ times reduction in training time for large-scale scenes while maintaining state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a single sentence summarizing the key contributions of the paper:The paper presents Gaussian Time Machine (GTM), a lightweight real-time rendering method that models time-dependent Gaussian primitives and disentangles appearance changes for accurate and efficient reconstruction of complex 3D scenes with varying weather and lighting conditions.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Motion-Based 3D Clothed Humans Synthesis (MOSS), a framework that achieves motion-aware Gaussian split on the human surface by employing kinematic information to control Gaussian deformation and address local occlusions, resulting in state-of-the-art visual quality in 3D clothed human synthesis.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimation network to be applied on an unknown target by leveraging a Neural Radiance Field (NeRF) trained on a sparse set of images, allowing autonomous rendezvous and proximity operations in Active Debris Removal missions.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes through a pixel-aligned Gaussian representation, hybrid Gaussian rendering, and consistent aggregation strategy, outperforming previous generalizable methods in terms of quality, speed, and computational cost.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The contributions of this paper can be summarized as follows:* The paper reviews and discusses the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks, particularly in the context of immersive communications and 3D content transmission and reconstruction.* The paper highlights the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks and the potential benefits of NeRF and 3D-GS in achieving this goal.* The paper presents an overview of the radiance field rendering techniques, highlighting their applications and implementation challenges in wireless networks.* The paper discusses the training of NeRF and 3D-GS models over wireless networks, including federated learning approaches and compression techniques to facilitate the transmission of large-scale 3D models.* The paper also presents practical rendering architectures for NeRF and 3D-GS models at the wireless network edge, as well as joint computation and communication designs to enhance rendering efficiency.* The paper proposes a new semantic communication enabled 3D content transmission design, which exploits the radiance field models as a semantic knowledge base to reduce communication overhead for distributed inference.* The paper also discusses the utilization of radiance field rendering in wireless applications, such as radio mapping and radio imaging.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel neural multi-view photometric stereo (MV-PS) method that leverages per-pixel intensity renderings, models point light attenuation, and explicitly raytraces cast shadows to estimate 3D shape from images, achieving competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
