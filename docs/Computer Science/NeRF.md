
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes a novel NeRF-based method for monocular gastroscopic data that integrates geometry priors from pre-reconstructed point clouds into the training of NeRF, addressing the limitations of view sparsity in local regions and resulting in high-fidelity image renderings from novel viewpoints.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple yet effective approach that enables robust synthesis of novel views in complex, in-the-wild scenes from casually captured images, efficiently eliminating distractors and achieving faster convergence speed and improved render quality.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:NS-MAE, a self-supervised pre-training paradigm, proposes a unified framework for transferable multi-modal representation learning, leveraging masked multi-modal reconstruction in neural radiance fields, to enhance robustness and transferability across diverse multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here are the key contributions:* A hybrid representation combines deformation fields, hash encoding, and 3D-GS, significantly reducing memory usage while achieving efficient and realistic rendering of dynamic scenes.* A learnable denoising mask is proposed, which can effectively identify and remove noise points in 3D-GS, enhancing rendering quality.* Static constraints and motion consistency constraints are introduced to minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.These contributions are summarized in a single sentence: A refined 3D Gaussian representation is proposed, combining deformation fields, hash encoding, and denoising masks to achieve high-quality dynamic scene reconstruction while reducing memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed HFGS approach addresses under-reconstruction in endoscopic reconstruction by incorporating deformation fields and frequency regulations, introducing Spatial High-Frequency Emphasis Reconstruction (SHF) and Temporal High-Frequency Emphasis Reconstruction (THF) modules for superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of the paper are:* A method that enables 3DGS manipulation, achieving high-quality and photo-realistic rendering, by using a triangular mesh as the proxy.* A triangle shape-aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction: The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining quality in rendered images by factorizing 3D Gaussians through efficient coordinate and attribute representations.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting, a method that combines hierarchical Gaussian representations with NeRF initialization to efficiently model large-scale scenes with high-frequency details, achieving a significant performance leap and rendering time speedup over state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pretrained 2D latent diffusion models to improve sparse-view reconstruction of 360 3D scenes by filling in missing details and cleaning novel views, outperforming existing methods and generating high-quality scenes from as few as 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* NEMos can be generated from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.* The paper proposes a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm is introduced that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.Note that the paper's abstract and introduction focus on introducing the concept of NEMos and its potential applications in terrain mapping and path planning, rather than providing a detailed technical description of the methods used.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which renders HDR views and reconstructs LDR images with controllable exposure time, surpassing state-of-the-art methods while enjoying faster inference speed and training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction within a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for embedding 3D scenes and images into 3D Gaussian Splatting point clouds while maintaining security, fidelity, and capacity, demonstrating its effectiveness in copyright protection and secret communication.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents an approach that incorporates ray tracing into Neural Radiance Fields (NeRF) to improve rendering of highly specular objects and nearby scene content, using a small MLP to decode features sampled along reflected rays, achieving higher quality and efficiency in view synthesis.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like approach that efficiently models high-frequency view-dependent appearance and captures complex reflections in shiny objects, outperforming the state of the art and achieving fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting conditions to improve pose optimization, leveraging a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a feed-forward framework generating high-quality textured meshes with illumination-decoupled RGB textures from a single image or text prompts, introducing a novel SDF representation and adaptive conversion strategy to enhance convergence speed.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency through a compact residual feature grid and entropy-minimization compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while ensuring high-fidelity rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, achieving state-of-the-art rendering fidelity, 100x faster rendering than NeRF-based methods, and disentangling appearance variations for smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|The paper introduces MOSS, a novel framework for 3D clothed human synthesis that incorporates kinematic information to achieve motion-aware surface deformation, thereby improving reconstruction quality and realism.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The authors present a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied to an unknown target spacecraft without requiring knowledge of its CAD model. The method trains a Neural Radiance Field (NeRF) from a sparse collection of spaceborne images, which represents the target spacecraft in 3D space under various illumination conditions. This training set is then used to train an off-the-shelf pose estimation network that can estimate the pose of the target spacecraft from its images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a novel generalizable 3D Gaussian representation approach that achieves real-time rendering with better synthesis quality, faster per-scene optimization, and reduced training computational cost, outperforming existing generalizable methods.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The importance of representing, transmitting, and reconstructing 3D contents efficiently over wireless networks, specifically in the context of 6G networks.* The emergence of two promising 3D representation techniques, Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS), which provide photorealistic rendering results for complex scenes.* The need to integrate these techniques into 6G networks, which requires overcoming challenges such as distributed training and inference, storage and transmission overhead, and latency requirements.* The focus on developing joint computation and communication designs to optimize the performance of NeRF and 3D-GS models over wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the paper's abstract and introduction are:* A novel multi-view photometric stereo method that leverages per-pixel intensity renderings rather than relying mainly on estimated normals.* The method explicitly models point light attenuation and raytraces cast shadows to better approximate each point's incoming radiance.* The method uses a fully neural material renderer with minimal prior assumptions and is jointly optimized with the surface.* The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are also fused.* The method is robust to poor normals in low light count scenarios.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems, focusing on the importance of both adversarial effectiveness and visual realism. The core innovation is the introduction of a "Judge" mechanism that assesses the realism of generated objects, encouraging the optimization process to produce objects that are both adversarial and realistic.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to model dynamic electromagnetic fields in RIS-enabled environments, accurately capturing complex propagation dynamics and enabling efficient RIS deployment for improved communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:A new 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, is proposed, which integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving high-fidelity reconstruction, accurate tracking, and low memory usage in real-time SLAM applications.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|The paper's key contributions are a comprehensive survey of methodologies for integrating Large Language Models (LLMs) with 3D spatial data, highlighting the potential of LLMs for spatial comprehension and interaction within embodied AI systems, while also underscoring the need for novel approaches to harness their full potential.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions from the paper's abstract and introduction are:The paper develops a procedure to convert between implicit representations of scenes, such as neural radiance fields (NeRFs), and explicit representations, such as Gaussian splatting (GS). This allows the authors to leverage the strengths of both approaches, achieving superior rendering quality and compact representation of the scene. The procedure is shown to be efficient, with conversion times minor compared to training the representations from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an extensive overview of the principles and techniques of Dynamic Neural Radiance Field (Dynamic NeRF), analyzing its development history, implementation methods, and key features from 2021 to 2023, highlighting its potential for practical applications in 3D modeling, representation, and reconstruction.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
