
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a self-supervised street Gaussian method ($\textit{S}^3$Gaussian) that decomposes dynamic and static elements in 3D scenes from 4D consistency, achieving state-of-the-art rendering quality on scene reconstruction and novel view synthesis tasks without requiring 3D annotations.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|The TetSphere splatting approach presents an explicit, Lagrangian representation for reconstructing 3D shapes with high-quality geometry, achieving faster optimization and reduced computational cost compared to existing Eulerian representations.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|Here are the key contributions and summaries from the paper's abstract and introduction:Key contributions:* Creation of a new set of synthetic and real visual scenes with corresponding camera poses for assessing Nerf view synthesis methods* Subjective evaluation of the impact of Nerf view synthesis on perceived quality using a well-known and reliable subjective assessment methodology* Evaluation of objective quality assessment metrics developed for 2D images and video in a Nerf view synthesis contextSummary:The paper introduces Nerf view synthesis (NVS) as a groundbreaking technology for generating high-quality, immersive visual content from multiple viewpoints. However, evaluating NVS methods poses several challenges, including a lack of comprehensive datasets, reliable assessment methodologies, and objective quality metrics. The paper aims to address these challenges by conducting a rigorous subjective quality assessment test for several scene classes and recently proposed NVS methods. The paper also evaluates the performance of a wide range of state-of-the-art conventional and learning-based full-reference 2D image and video quality assessment metrics against subjective scores.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper introduces IReNe, a novel approach that enables swift, near real-time color editing in NeRF, addressing three primary limitations of current methods, including slow editing times, lack of precision at object boundaries, and struggle with multi-view consistency, by leveraging a pre-trained NeRF model, a trainable segmentation module, and an automated classification approach to fine-tune weights of diffuse neurons.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|The paper proposes HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, using symmetry prior, regularization constraints, and training cues from large human datasets, achieving a 15% PSNR improvement over state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces a novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation using Neural Radiance Fields (NeRF).* The method uses ultrametric feature fields to capture hierarchical relationships between segmentations at different levels of granularity.* The authors evaluate their method on synthetic datasets with multi-view images and multi-granular segmentation, showcasing improved accuracy and viewpoint-consistency compared to existing baselines.Note: The reply is a single sentence under 50 words.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the abstract and introduction in a single sentence under 50 words:The paper proposes a novel approach to synthesize high-quality images of the stomach from novel viewpoints using neural radiance fields (NeRF) with geometry-based loss, enabling practitioners to freely adjust the viewing trajectory to obtain the best observations inside the stomach.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple yet effective approach that enables robust novel view synthesis in complex, in-the-wild scenes from casually captured image sequences, efficiently eliminating distractors and achieving faster convergence speed.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NS-MAE, a self-supervised pre-training framework for transferable multi-modal representation learning, which leverages masked multi-modal reconstruction in neural radiance fields to enhance robustness in autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, addressing the concerns of memory consumption and rendering speed.* The method combines deformation fields, hash encoding, and 3D Gaussian Splatting (3D-GS) to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.* The learnable denoising mask is introduced to filter out noise points from the scene, further compressing 3D-GS and enhancing rendering quality.* The paper also introduces static constraints and motion consistency constraints to mitigate motion artifacts in points, ensuring the accuracy and efficiency of the rendering framework for dynamic scenes.* The method is evaluated on three datasets: synthetic datasets D-NeRF [5] and a monocular synthetic dataset, as well as two real-world datasets, HyperNeRF [15] and NeRF-DS [34], using metrics such as Peak Signal-to-Noise Ratio (PSNR), Structural Similarity (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) [?].|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields and spatial and temporal high-frequency emphasis reconstruction.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh as a proxy, allowing for large deformations, local manipulations, and soft body simulations while maintaining high-quality rendering and high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) by up to 90% while maintaining comparable image quality, by factorizing coordinates and attributes of Gaussians, and employs a binary mask to further accelerate rendering.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that leverages NeRF initialization to model large-scale scenes with high-frequency details and accelerated rendering performance, overcoming challenges of traditional 3D Gaussian Splatting and NeRF-based methods.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a method, SparseSplat360, that uses pre-trained 2D diffusion models and a cascade of in-painting and artifact removal models to improve sparse-view reconstruction of 360-degree scenes, outperforming existing methods in 360 scene reconstruction.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* Neural Elevation Models (NEMos) are proposed, which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* NEMos can be generated from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.* A novel method is introduced for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm is proposed that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* The authors demonstrate the ability of NEMos to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while achieving 1000x faster inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed GS-Hider is a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds while ensuring security, fidelity, and robustness, and can hide multiple messages, including 3D scenes and images, into a single 3D scene.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present a novel approach to expanding Neural Radiance Fields' (NeRFs) ability to render realistic view-dependent appearance, particularly specular reflections, by introducing ray tracing and decoding feature vectors into color using a small network.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are: Neural Directional Encoding (NDE), a feature-grid-like encoding that accurately models the appearance of shiny objects, and the cone-tracing technique for modeling near-field interreflections, allowing for real-time inference and high-quality modeling of view-dependent effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality, textured meshes from a single image or text input in seconds, utilizing a multi-view diffusion model, transformer-based SDF prediction, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field representation and compression, achieving superior quality and compression efficiency for volumetric videos with large motions.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The paper proposes DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly, saving training time by 6+ times on large-scale scenes while maintaining state-of-the-art rendering quality, and solves two challenges: huge memory footprint and long training time, by splitting scenes into blocks and consensus on shared 3D Gaussians.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Gaussian Time Machine (GTM) achieves state-of-the-art rendering fidelity and real-time rendering capabilities for dynamic scenes with varying appearances by modeling time-dependent attributes of Gaussian primitives and decomposing color into static and dynamic terms.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a framework that leverages kinematic information to achieve motion-aware 3D clothed human synthesis, incorporating modules for Gaussian control and local deformation detection to produce high-quality, realistic reconstructions.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel method for estimating the 6D pose of an unknown spacecraft relative to a monocular camera, which is a crucial step for autonomous rendezvous and proximity operations (RPOs) in Active Debris Removal missions. The method leverages Neural Radiance Fields (NeRF) to generate a large dataset of diverse images, which is then used to train an off-the-shelf spacecraft pose estimation network, enabling the estimation of the target's pose without prior knowledge of its CAD model.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes through Multi-View Stereo, hybrid Gaussian rendering, and a consistent aggregation strategy, achieving real-time rendering with better synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The contributions from the paper's abstract and introduction are:* A comprehensive overview of the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in Sixth-Generation (6G) networks for efficient representation, transmission, and reconstruction of 3D contents.* A review of the basics of radiance field rendering techniques, highlighting their applications and implementation challenges over wireless networks.* An investigation of over-the-air training of NeRF and 3D-GS models over wireless networks, exploring various learning techniques, including federated learning design over a hierarchical device-edge-cloud architecture.* Discussion of three practical rendering architectures of NeRF and 3D-GS models at wireless network edges, including model compression approaches to facilitate transmission, and rendering acceleration approaches to enhance efficiency.* Proposal of a new semantic communication-enabled 3D content transmission design, leveraging radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learned renderers to estimate 3D shape from images. The method explicitly models point light attenuation and raytraces cast shadows to best approximate each point's incoming radiance, and uses a fully neural material renderer to jointly optimize the surface. The paper achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are used.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
