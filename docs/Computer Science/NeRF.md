
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:The authors introduce Neural Elevation Models (NEMos), a novel representation that adapts Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for efficient generation of terrain maps from aerial imagery. They propose a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression. Additionally, they introduce a path planning algorithm that leverages the differentiability of the height field to optimize for smooth and efficient paths.The NEMo framework combines the strengths of NeRFs in capturing complex terrain detail with DEMs' suitability for path planning, enabling more robust and versatile navigation solutions. The authors demonstrate initial results on simulated and real-world terrain imagery, showing high-quality reconstructions and smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds in an invisible manner, ensuring security, fidelity, capacity, and flexibility, and demonstrating robustness and high-quality rendering.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces a novel approach to Neural Radiance Fields (NeRFs) that leverages ray tracing to render accurate and consistent reflections of both nearby and distant scene content, improving upon prior methods' limitations in rendering shiny objects and reducing computational costs.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for neural radiance fields (NeRF) that can accurately model high-frequency angular signals and interreflection effects in rendering specular objects like shiny metals or glossy paints.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizing a hash-encoded NeRF and novel techniques to improve pose optimization and robustness under changing lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts using a tensorial SDF representation, adaptive conversion, and gradient-based mesh optimization, outperforming previous methods in speed and quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving superior rate-distortion performance and eliminating the need for multi-stage training.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed method that trains 3D Gaussian Splatting (3DGS) models in parallel, reducing training time by 6+ times for large-scale scenes while maintaining high-fidelity rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Gaussian Time Machine (GTM) presents a novel real-time rendering method for 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity and efficiency (100 times faster than NeRF-based methods) with a lightweight neural network and decomposed color model.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Motion-Based 3D Clothed Humans Synthesis (MOSS), a novel framework that employs kinematic information to achieve motion-aware Gaussian split on the human surface, improving the reconstruction quality of clothed humans in scenes with substantial human motion.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method to estimate the 6D pose of an unknown target spacecraft relative to a monocular camera, leveraging Neural Radiance Fields (NeRFs) to extend the scope of existing pose estimation methods to unknown targets.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable Gaussian Splatting method that uses Multi-View Stereo and a pixel-aligned Gaussian representation, achieving real-time rendering with better view synthesis quality and faster fine-tuning for specific scenes.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper discusses the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks for immersive communications, focusing on the efficient representation, transmission, and reconstruction of 3D contents. The key contributions are:* A comprehensive overview of the integration of NeRF and 3D-GS in 6G networks, highlighting their applications and implementation challenges.* An investigation into the over-the-air training of NeRF and 3D-GS models over wireless networks using various learning techniques, including federated learning.* The presentation of three practical rendering architectures of NeRF and 3D-GS models at wireless network edges, along with model compression approaches to facilitate transmission and rendering acceleration techniques.* A new semantic communication-enabled 3D content transmission design, where radiance field models are exploited as semantic knowledge bases to reduce communication overhead for distributed inference.* The utilization of radiance field rendering in wireless applications like radio mapping and radio imaging.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learned renderers. The method explicitly models point light attenuation, raytraces cast shadows, and optimizes a fully neural material renderer. This approach outperforms classical methods, achieving average Chamfer distances of 0.2mm at a distance of 1.5m with 400x400 resolution.The key innovations include:* Using per-pixel intensity renderings instead of relying on estimated normals* Modeling point light attenuation and explicitly raytracing cast shadows* Optimizing a fully neural material renderer* Achieving robustness to poor normals in low light count scenariosThe paper also reviews the related work in photometric stereo and multi-view stereo, highlighting the limitations of existing approaches and the importance of leveraging photometric information for accurate shape estimation.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems.* The method introduces an evaluative mechanism, called the 'Judge', which assesses the realism of generated objects and integrates into the loss function to encourage the creation of adversarial objects that are both realistic and effective.* The paper explores various strategies for developing a reliable Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced vision-language models, pretraining neurosymbolic systems, and utilizing traditional image processing techniques.The paper's abstract and introduction emphasize the importance of generating realistic-looking adversarial objects that can effectively test the robustness of autonomous driving systems, and introduce a novel method to achieve this goal.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of the paper can be summarized as follows:* The authors propose a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments, which accurately model the entire transmission path from the transmitter to the receiver.* The authors introduce a two-stage framework that precisely tracks the electromagnetic signal propagation dynamics, using the coordinates of the RIS, transmitter, and receiver as inputs to predict the signal at various receiver positions under different RIS placement strategies.* Experimental results from simulations and measured data demonstrate the effectiveness of the proposed method, achieving accurate signal strength prediction with a Mean Absolute Error (MAE) of 5.61 dB.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep visual feature extraction, dual keyframe selection, and 3DGS to achieve high-fidelity scene representation and real-time tracking.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This survey comprehensively reviews methodologies enabling Large Language Models (LLMs) to process, understand, and generate 3D data, identifying strengths such as in-context learning and potential for advancing spatial comprehension and interaction within embodied AI systems.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here are the key contributions from the paper's abstract and introduction:* The paper develops a procedure to convert between implicit representations like Neural Radiance Fields (NeRFs) and explicit representations like Gaussian Splatting (GS).* The proposed approach achieves the best of both worlds: NeRFs' superior PSNR, SSIM, and LPIPS for dissimilar views and GS's real-time rendering and ability to easily modify the representation.* The conversion process is minor compared to training the two from scratch, making it a efficient and practical solution for robotics applications.Let me know if you'd like me to summarize the results or methodology as well!|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper reviews the development and implementation principles of Dynamic Neural Radiance Field (Dynamic NeRF), analyzing the main principles and techniques from 2021-2023, and comparing features of various Dynamic NeRF projects.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed method synergistically integrates coordinate-based networks and multi-plane representations to improve Neural Radiance Fields (NeRFs) from sparse inputs, achieving comparable results to explicit encoding with fewer parameters and outperforming other approaches for static and dynamic NeRFs under sparse inputs.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module, differentiable neural-point resampling (DNR), to enable efficient object removal and scene inpainting tasks in NeRF-aided editing, achieving state-of-the-art performance and high-quality rendering visualization without extra supervision.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three novel approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction, monocular depth estimation, and template modeling, aiming to achieve high-fidelity, portable, and instantaneous reconstruction on a portable device like an iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel approach, Truncated Depth NeRF (TD-NeRF), that jointly optimizes camera poses and radiance fields using depth priors, with three key advancements: a novel depth-based ray sampling strategy, a coarse-to-fine training strategy, and a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|The key contributions from the paper's abstract and introduction are the proposal of LIVE, a novel design method for interactive LaTex graphic items, and the analysis of more efficient methods to design interactive components with automatic citation analysis and improved design efficiency.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summarization of the key contributions in the abstract and introduction in a single sentence under 50 words:Our approach, SketchDream, is a text-driven 3D content generation and editing method that integrates hand-drawn sketches and textual prompts to generate high-quality, photo-realistic models, enabling detailed control of geometry and appearance, with optional local editing capabilities.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
|**2024-05-10**|**Aerial-NeRF: Adaptive Spatial Partitioning and Sampling for Large-Scale Aerial Rendering**|Xiaohan Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose Aerial-NeRF, a novel method that adapts Neural Radiance Fields (NeRF) for large-scale aerial rendering, addressing two critical problems: insufficient sampling range for complex scenes and slow rendering due to large-scale datasets.|[2405.06214v1](http://arxiv.org/abs/2405.06214v1)|null|
|**2024-05-10**|**Residual-NeRF: Learning Residual NeRFs for Transparent Object Manipulation**|Bardienus P. Duisterhof et.al.|The authors propose Residual-NeRF, a method that improves depth perception and training speed for transparent objects by learning a background scene NeRF and combining it with residual NeRFs to infer residual RGB values and densities.|[2405.06181v1](http://arxiv.org/abs/2405.06181v1)|null|
|**2024-05-09**|**DragGaussian: Enabling Drag-style Manipulation on 3D Gaussian Representation**|Sitian Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose DragGaussian, a frame-work for interactive 3D object editing using 3D Gaussian Splatting and diffusion models, introducing a new task and developing a point-based 3D editing system that enables users to modify pre-trained 3D object models with open-vocabulary input.|[2405.05800v1](http://arxiv.org/abs/2405.05800v1)|null|
