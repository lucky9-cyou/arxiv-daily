
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that drastically reduces storage requirements while preserving image quality by representing and approximating dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, achieving a storage reduction of over 90% and maintaining comparable image quality compared to 3DGS.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Pyramidal 3D Gaussian Splatting (PyGS), which combines hierarchical Gaussian arrangement with NeRF initialization to represent large-scale scenes with high-fidelity and accelerated rendering performance, outperforming current state-of-the-art approaches by over 400 times.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360-degree scenes, achieving multi-view consistency and coherent details with only 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.The paper proposes NEMos as a novel representation for terrain mapping, which leverages the advantages of NeRFs in fast generation solely from imagery and rich visual reconstruction, while also capturing compact terrain geometry in the form of a continuous and differentiable height field. The paper introduces a new method for jointly training a height field and radiance field, which allows the NeRF to benefit from height supervision. The path planning algorithm is designed to optimize the continuous cost function, which takes into account distance, slope changes, and control effort.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), that efficiently renders novel HDR views and reconstructs LDR images with controlled exposure time, outperforming state-of-the-art NeRF-based methods in terms of quality and speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in one sentence under 50 words:The proposed GS-Hider framework is a steganography method that embeds 3D scenes and images into original 3DGS point cloud files in an invisible manner, ensuring robust security, high fidelity, large capacity, and versatility, with applications in copyright protection, encrypted communication, and 3DGS compression.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a ray tracing-based approach to improve Neural Radiance Fields (NeRFs) for rendering high-frequency view-dependent appearance of shiny objects by casting reflection rays and decoding feature vectors into color, outperforming prior methods and requiring comparable optimization time.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Neural Directional Encoding (NDE), a feature-grid-like method that efficiently models high-frequency view-dependent appearance and complex interreflection effects in NeRF, achieving state-of-the-art results in rendering specular objects and fast evaluation speeds.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting conditions, using a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality textured meshes with decoupled illumination from text or single images in seconds, utilizing a multi-view diffusion model, transformer-based SDF predictor, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end learning scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior rate-distortion performance, efficient representation, and entropy-minimization compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed method that accelerates the training of 3D Gaussian Splatting (3DGS) on large-scale scenes by 6+ times while achieving state-of-the-art rendering quality, by splitting scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives to reconstruct 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity and speed, and disentangling appearance changes from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework for single-view clothed human reconstruction, which incorporates kinematic information to achieve motion-aware Gaussian split and detects local occlusions to restore realistic joint details and fine clothing folds.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper proposes a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF). The key contributions are:* A model-agnostic method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target, without requiring the knowledge of the target's CAD model.* A NeRF model trained on a sparse collection of images depicting the target, which is then used to generate a large dataset that captures the diversity of both the pose distribution and illumination conditions encountered in orbit.* The successful validation of the proposed method on Hardware-In-the-Loop images of SPEED+, which emulates lighting conditions close to those encountered on orbit.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo, efficient hybrid Gaussian rendering, and a consistent aggregation strategy to achieve real-time rendering with better synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper focuses on the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks to support immersive communication applications that require the transmission and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summarized version of the paper's abstract and introduction in a single sentence under 50 words:The authors present a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and explicitly models point light attenuation and casts shadows, achieving competitive accuracy despite relying on minimal prior assumptions and using neural shape representations.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems.* The introduction of a Judge, an evaluative mechanism, to assess the realism of generated objects.* The use of four strategies to develop a reliable Judge: leveraging cutting-edge vision-language models, fine-tuning open-sourced models, pre-training neurosymbolic systems, and utilizing traditional image processing techniques.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel Neural Radiance Field (NeRF) based ray tracing method, called R-NeRF, to accurately model and visualize electromagnetic signal propagation in Reconfigurable Intelligent Surface (RIS) enabled wireless environments.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel dense visual SLAM approach called MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian Splatting (3DGS) to achieve state-of-the-art performance in tracking, mapping, and rendering with reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper provides a comprehensive survey of methodologies enabling Large Language Models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction in embodied AI systems, and charts a course for future research in this area.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper proposes a procedure to convert between implicit representation of scenes, such as neural radiance fields (NeRFs), and explicit representation, such as Gaussian splatting (GS). The approach aims to leverage the strengths of both representations, achieving the best of both worlds: superior rendering quality on dissimilar views and real-time rendering capabilities.Key contributions:* Development of a procedure to convert between NeRFs and GS* Achieving superior rendering quality on dissimilar views with NeRFs* Real-time rendering capabilities with GS* Minor computational cost for conversions compared to training from scratch|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|This review summarizes the development and implementation principles of Dynamic NeRF, which improves upon the original NeRF method to achieve dynamic 3D reconstruction and representation with high resolution.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The multi-plane representation has limitations in capturing low-frequency details and tends to overuse parameters, leading to instability and inefficiency when training with sparse inputs.* A novel approach is proposed to integrate the multi-plane representation with a coordinate-based network to capture both low-frequency context and fine-grained details.* The proposed method achieves comparable results to explicit encoding with fewer parameters, and outperforms other methods in dynamic NeRFs from sparse inputs.* The method leverages residual connections to synergistically combine the strengths of the two networks, and progressive training is used to disentangle the features.* The approach has implications for improving NeRFs from sparse inputs, reducing the need for complex architectures and large datasets.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes PR^2T-NeRF, an editable NeRF pipeline that enables direct manipulation of 3D object pose through implicit ray transformation and features a plug-and-play inpainting module (DNR) for effective removal and inpainting of objects in 3D scenes.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three real-time 3D facial reconstruction approaches using LiDAR, TrueDepth, and monocular depth estimation, which can run on a portable device like an iPhone 14 Pro, enabling interactive and immersive holographic experiences for various applications.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, with three key advancements: improved ray sampling, coarse-to-fine training, and robust inter-frame point constraint, achieving superior performance in pose estimation and depth geometry.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|The paper proposes LIVE, a novel design method for interactive LaTex graphic items, which can be used to design arbitrary graphics and easily analyze the citation relationships among multiple papers, aiming to improve the reading experience and vitality of traditional papers, with the code available open-source on GitHub.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes SketchDream, a text-driven 3D content generation and editing method that integrates sketches and text for generating high-quality 3D objects with detailed control over geometry and appearance, and enables free-view sketch-based local editing.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
