
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The contributions of this work are: * A self-supervised pre-training framework (NS-MAE) for multi-modal representation learning in autonomous driving, applicable to both multi-modal and single-modal perception models. * A unified optimization of transferable multi-modal representations via plug-and-play designs in the spirit of multi-modal reconstruction in Neural Radiance Fields (NeRF). * Experimentally verifying the transferability of multi-modal representations derived via NS-MAE on diverse 3D perception tasks with varying amounts of fine-tuning data.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:1. A hybrid representation of explicit and implicit features for dynamic scene rendering.2. A learnable denoising mask to filter out noise points from the scene.3. Static constraints and motion consistency constraints to improve the accuracy and efficiency of the rendering framework.4. The proposed method is capable of rendering high-quality dynamic scenes while significantly reducing memory usage.The paper focuses on improving the rendering quality and efficiency of dynamic scenes using Gaussian splatting, which is a novel and effective technique for reconstructing 3D scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes, while introducing Spatial High-Frequency Emphasis Reconstruction and Temporal High-Frequency Emphasis Reconstruction modules to minimize discrepancies in spatial and temporal frequency spectra.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Mani-GS, a method that enables controllable and high-quality Gaussian Splatting (GS) manipulation using a triangular mesh, allowing for various 3DGS manipulations, including large deformations, local manipulation, and soft body simulation.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements while maintaining image quality by factorizing dense clusters of Gaussians using efficient factorization techniques, achieving a 90% reduction in storage space.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS), a method that represents large-scale scenes with a hierarchical assembly of Gaussians, initialized by rapidly trained NeRF, and achieves a rendering speedup of over 400 times compared to state-of-the-art NeRF-based methods.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pretrained 2D diffusion models to improve sparse-view reconstruction of a 360 3D scene by filling in missing details and generating novel views, outperforming existing methods and achieving high-quality reconstructions from limited input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Key contributions:* The paper proposes Neural Elevation Models (NEMos), a novel representation that combines a Neural Radiance Field with a height field to efficiently model and navigate complex 2.5D terrains.* NEMos are trained using imagery and camera poses, producing a compact, continuous, and differentiable height field that can be used for path planning.* A novel method is introduced to jointly train the NeRF and height field using quantile regression, which results in a cleaner NeRF representation with fewer artifacts and accurate elevation estimation.* A path planning algorithm is developed that leverages the continuous and differentiable height field to generate smoother paths than traditional discrete path planning methods.* Experimental results demonstrate the effectiveness of NEMos in generating high-quality reconstructions and smooth paths for terrain navigation tasks.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes a high dynamic range (HDR) novel view synthesis (NVS) method, HDR-GS, which efficiently renders novel HDR views and reconstructs LDR images with a user input exposure time, surpassing the state-of-the-art NeRF-based method by 3.84 dB on LDR NVS and 1.91 dB on HDR NVS.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The authors propose a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) that can embed 3D scenes and images into original 3DGS point cloud files in an invisible manner and accurately extract the hidden messages.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce a ray-tracing approach to improve Neural Radiance Fields' ability to render detailed, view-dependent appearance of shiny objects, enabling consistent reflections of nearby and distant content while reducing computational expense and improving optimization speed.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding for rendering specular objects like shiny metals or glossy paints, which outperforms the state of the art and achieves fast inference. NDE transfers feature-grid-based spatial encoding to the angular domain, improving ability to model high-frequency angular signals, and cone-tracing spatial features to capture multi-bounce reflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, utilizing a hash-encoded NeRF representation and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process, achieving state-of-the-art results in camera relocalization under varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework generating high-quality textured meshes with illumination-decoupled RGB textures from single images or text prompts, with key contributions in tensorial SDF representation and adaptive Î² adjusting schedule.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving superior quality and compression efficiency by introducing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method called DoGaussian, which accelerates the training of 3D Gaussian Splatting (3DGS) by 6+ times for large-scale scenes while maintaining state-of-the-art rendering quality, through the introduction of a distributed training approach and 3D Gaussian consensus.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent Gaussian primitives with a lightweight MLP, enabling reconstruction of scenes with varying appearances while achieving state-of-the-art rendering fidelity and 100 times faster rendering than NeRF-based methods.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose MOSS, an innovative framework that uses kinematic information to achieve motion-aware Gaussian splitting for 3D clothed human synthesis, addressing limitations of current methods by incorporating global motion and local occlusion constraints to improve realism and accuracy.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a novel method that enables the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images of an unknown target spacecraft, leveraging Neural Radiance Fields (NeRF) to generate a large dataset that captures the diversity of viewpoint and illumination conditions encountered in orbit.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes, leveraging Multi-View Stereo and Gaussian Splatting, and introduces a hybrid rendering design and a geometric consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper introduces the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques in 6G wireless networks, which enables the efficient representation, transmission, and reconstruction of 3D contents. The key contributions include:* A comprehensive overview of NeRF and 3D-GS techniques and their applications in wireless networks.* A proposal for embracing NeRF and 3D-GS in 6G networks to support emerging 3D applications with enhanced quality of experience.* A discussion on the challenges and opportunities of integrating NeRF and 3D-GS in 6G networks, including over-the-air training and inference, and joint computation and communication designs.These contributions aim to facilitate the efficient transmission and reconstruction of 3D contents in 6G networks, enabling immersive communication experiences and highlighting the importance of embracing NeRF and 3D-GS in 6G wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (PS) method that leverages per-pixel intensity renderings and learned renderers to estimate 3D shape from images. The method models point light attenuation and explicitly raytraces cast shadows to approximate each point's incoming radiance. The paper shows that this approach outperforms the classical DiLiGenT-MV method, achieving an average Chamfer distance of 0.2mm at a distance of 1.5m with a resolution of 400x400.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The authors propose a new approach to generating realistic-looking adversarial objects for autonomous driving systems, which combines gradient-based texture optimization with an evaluative mechanism called the "Judge" to assess the realism of generated objects.* The Judge assesses the realism of objects by assigning a probability score based on criteria such as color similarity, adherence to traffic laws, real-life appearance, and ease of recreation.* The authors demonstrate the effectiveness of the proposed approach by evaluating four different images of objects (a STOP sign, a car, a traffic cone, and a street light) and provide scores based on the Judge's evaluation.Note that the paper does not include a single sentence summary, so the above summary is condensed from the abstract and introduction.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The paper proposes a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in Reconfigurable Intelligent Surface (RIS)-enabled wireless environments. The key contributions are:1. A two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.2. A novel R-NeRF method to model the signal field for any specified RIS placement and receiver location, utilizing PE and ray tracing.3. Experimental results validating the effectiveness of the method in accurately modeling electromagnetic signal propagation, outperforming NeRF2 and traditional methods.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving state-of-the-art performance in tracking, mapping, and rendering while reducing memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in under 50 words:The paper surveys the integration of large language models (LLMs) with 3D spatial data (3D-LLMs), highlighting the unique advantages of LLMs' in-context learning, reasoning, and world knowledge to advance spatial comprehension and interaction in embodied AI systems.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here are the key contributions summarized in a single sentence under 50 words:The authors develop a procedure to convert between implicit representations of scenes, such as Neural Radiance Fields (NeRFs), and explicit representations, such as Gaussian Splatting (GS), achieving the best of both worlds in terms of quality and efficiency.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This review provides a comprehensive analysis of the development and implementation principles of Dynamic NeRF, highlighting its potential in practical applications and comparing various features of Dynamic NeRF projects from 2021 to 2023.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here are the key contributions from the paper's abstract and introduction:* The paper proposes a synergistic integration of a coordinate-based network and a multi-plane representation to improve neural radiance fields (NeRFs) from sparse inputs.* The approach combines the strengths of both methods, with the coordinate-based network capturing low-frequency details and the multi-plane representation focusing on capturing fine-grained details.* The proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms other methods in dynamic NeRFs from sparse inputs.* The key benefits of the approach are: (1) alignment with distinct spectral biases, (2) stable training through gradual changes in spectral biases, and (3) efficient parameter allocation by replacing the need for a low-resolution grid with coordinate-based features.Note: The abstract and introduction do not provide a comprehensive summary of the related work, but rather focus on highlighting the contributions and benefits of the proposed method.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module, dubbed DNR, to enable object removal and scene inpainting tasks in NeRF models, achieving state-of-the-art performance and high-quality rendering visualization without extra supervision.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
