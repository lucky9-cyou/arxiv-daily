
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel application of Neural Radiance Fields (NeRF) to monocular gastroscopic data, incorporating geometry-based loss from pre-reconstructed point clouds to improve novel view synthesis, achieving high-quality results in rendering RGB images and depth maps.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple yet effective approach that enables robust synthesis of novel views in complex, in-the-wild scenes with distractors, achieving faster convergence and improved render quality, and significantly outperforming state-of-the-art techniques in various scenes.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction, under 50 words:The paper proposes a self-supervised pre-training framework, NS-MAE, for transferable multi-modal representation learning in autonomous driving, combining masked autoencoder (MAE) with neural radiance fields (NeRF) for efficient and high-performance fine-tuning.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The paper presents a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, which combines deformation fields, hash encoding, and denoising masks to reduce storage usage and improve rendering quality while addressing challenges in dynamic scene rendering.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction by introducing spatial and temporal frequency regularization, achieving superior rendering quality and dynamic awareness in neural rendering.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling large deformations, local manipulations, and soft body simulations while maintaining high-quality rendering, and achieves state-of-the-art results on the NeRF synthetic dataset.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions of the paper's abstract and introduction are: introducing Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements of 3D Gaussian Splatting (3DGS) by factorizing coordinates and features, while preserving image quality; reducing the storage costs of 3DGS by more than 90% using F-3DGS; achieving high performance, compact storage, and fast rendering capabilities.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The Pyramidal 3D Gaussian Splatting (PyGS) approach, which represents scenes with a hierarchical assembly of Gaussians, achieves a significant performance leap across multiple large-scale datasets and rendering times over 400 times faster than current state-of-the-art NeRF-based methods.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve 360-degree scene reconstruction from sparse views by filling in missing details and removing artifacts, achieving improved performance on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, enabling the generation of high-quality reconstructions from imagery and the creation of a lightweight representation of terrain.* The proposal of a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* The introduction of a path planning algorithm that leverages the continuous and differentiable nature of the height field to generate smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS) for novel view synthesis, achieving better performance, faster inference speed, and shorter training time than state-of-the-art NeRF-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a 3D steganography framework, GS-Hider, for encrypting and hiding 3D scenes, images, and messages in 3D Gaussian Splatting (3DGS) point cloud files, achieving robust security, fidelity, large capacity, and versatility while preserving the original scene's integrity and functionality.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes an approach that combines Neural Radiance Fields (NeRF) with ray tracing to improve view synthesis of scenes with shiny objects, outputting photorealistic specular appearance and reflections while reducing computational cost.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents Neural Directional Encoding (NDE), a novel view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects. NDE transfers the concept of feature-grid-based spatial encoding to the angular domain, significantly improving the ability to model high-frequency angular signals by encoding view-dependent effects into feature grids with better interreflection parameterization.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction, under 50 words:The paper proposes a two-stage pipeline that normalizes images for varying lighting conditions, employs a hash-encoded NeRF for fast training, and introduces a revised low-pass filter and numerical gradient averaging technique to improve camera relocalization under changing lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LDM, a novel, feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts, introducing a tensorial SDF representation and adaptive conversion strategy to improve convergence speed and quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end approach that jointly optimizes dynamic NeRF representation and compression, achieving superior quality and compression efficiency by representing dynamic NeRF with compact residual feature grids and sequential compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that distributes the training of 3D Gaussian Splatting for large-scale scenes across multiple nodes, reducing training time by 6+ times while maintaining rendering quality and state-of-the-art results.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The key contributions of the paper are the introduction of Gaussian Time Machine (GTM), a novel method for rendering real-world 3D scenes with varying appearances in real-time, and its ability to achieve state-of-the-art rendering fidelity and efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The authors introduce MOSS, a novel framework for 3D clothed human synthesis from monocular videos, that leverages kinematic information to achieve motion-aware Gaussian split and improve surface deformation, resulting in state-of-the-art visual quality with enhanced realism and detail.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summary of the key contributions from the paper's abstract and introduction:The authors propose a novel method that enables the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images, leveraging Neural Radiance Fields (NeRF) to generate a large dataset that captures the diversity of both pose distribution and illumination conditions encountered in orbit, and successfully demonstrates the feasibility of this approach on realistic images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes, achieving real-time rendering with better view synthesis quality, while leveraging Multi-View Stereo and a new hybrid Gaussian rendering approach.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here are the key contributions from the paper's abstract and introduction summarized in a single sentence under 50 words:The paper explores the integration of neural radiance fields (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents, emphasizing distributed training and inference, joint computation and communication, and model compression techniques.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and explicit raytracing to cast shadows, achieving state-of-the-art performance in estimating 3D shape and material properties from multi-view images.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel approach to generating realistic-looking adversarial objects for autonomous driving systems by introducing a 'Judge' mechanism that assesses the realism of textures and integrates it into the adversarial generation process to create more sophisticated and transferable attacks.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The authors propose a novel method, called R-NeRF, which uses Neural Radiance Fields (NeRF) to model electromagnetic signal propagation in RIS-enabled wireless environments, effectively capturing complex signal dynamics and predicting signal fields at any specified RIS placement and receiver location.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS to achieve high-fidelity tracking, mapping, and rendering with reduced memory usage, outperforming existing methods in various datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper surveys large language models (LLMs) integrated with 3D spatial data, highlighting the potential of LLMs for spatial comprehension and interaction, and examining methodologies, applications, and challenges in this area to chart a course for future research.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here are the key contributions from the paper's abstract and introduction:The authors develop a technique to convert between implicit representations (Neural Radiance Fields) and explicit representations (Gaussian Splatting) of a scene, enabling the best of both worlds: the generality of NeRFs and the speed of GS. This approach is useful for robotics applications where there is a limited number of views, particularly in cases where views are significantly different from those in the training data. The conversion process is computationally efficient, taking only minor computational resources compared to training the models from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|The paper reviews the development and implementation principles of Dynamic NeRF, a novel method for 3D reconstruction and representation with high resolution, from 2021 to 2023, and analyzes the key methods to implement a Dynamic NeRF.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
