
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:1. Neural Elevation Models (NEMos), which integrate a Neural Radiance Field (NeRF) alongside a height field, and adapt NeRF to a 2.5D continuous and differentiable terrain model.2. A novel method for jointly training a height field and radiance field within a NeRF framework using quantile regression.3. A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while achieving faster training and inference speeds.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a steganography framework, dubbed GS-Hider, to embed 3D scenes and images into original 3D Gaussian Splatting (3DGS) point cloud files, ensuring security, fidelity, and versatility while protecting copyright and privacy of 3D assets.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces an approach that uses ray tracing to address NeRF's limitations in rendering highly specular objects by tracing reflection rays and decoding feature vectors into color, outperforming prior methods and rendering photorealistic specular appearance and reflections.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the development of Neural Directional Encoding (NDE), a feature-grid-like encoding method for modeling view-dependent appearance, and the presentation of a novel spatio-spatial parameterization by cone-tracing a spatial feature grid to encode near-field reflections, allowing for high-quality modeling of view-dependent effects and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, and implement a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes LDM, a novel feed-forward framework that generates high-quality, illumination-decoupled textured meshes from a single image or text prompts, leveraging a multi-view diffusion model, transformer-based model, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:JointRF proposes a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by representing the 4D radiance field with compact residual feature grids and sequentially compressing features with entropy-minimization.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly, decomposing scenes into blocks and using ADMM to ensure consistency and convergence, reducing training time by 6+ times while maintaining rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives with discrete time embedding vectors, achieving state-of-the-art rendering fidelity and efficiency, with the ability to disentangle appearance changes and render smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors introduce a novel framework, MOSS, that synthesizes 3D clothed humans from single-view videos by incorporating kinematic information to achieve motion-aware Gaussian split and surface deformation detection.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimation network to be trained on a sparse set of images of an unknown target spacecraft, leveraging a Neural Radiance Field (NeRF) model to capture the diversity of both pose distribution and illumination conditions encountered in orbit, thereby making it possible to perform autonomous rendezvous and proximity operations for Active Debris Removal missions.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The authors propose MVSGaussian, a novel 3D Gaussian representation approach that uses Multi-View Stereo (MVS) to efficiently reconstruct unseen scenes, achieving real-time rendering with better synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper discusses the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) techniques in 6G networks for efficient representation, transmission, and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The novel multi-view photometric stereo (PS) method leverages neural shape representations and learnt renderers to estimate 3D shape from Photometric Stereo images, fully incorporating pixel intensity information. The method models point light attenuation, explicitly raytraces cast shadows, and optimizes a fully neural material renderer. This approach achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.(The text is under 50 words.)|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a method for generating realistic-looking adversarial objects for autonomous driving systems by introducing a Judge that evaluates the realism of adversarial objects, enhancing their effectiveness and visual plausibility.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summation of the key contributions in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method for dynamic electromagnetic field modeling in RIS-enabled wireless environments, enabling accurate signal propagation prediction and efficient RIS deployment for improved communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, combining deep visual features, dual keyframe selection, and 3DGS, which outperforms existing methods in tracking and mapping, with improved rendering quality and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction under 50 words:The survey explores the intersection of Large Language Models (LLMs) with 3D data, highlighting their potential to advance spatial comprehension and interaction, while discussing methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:1. A procedure to convert between implicit representations of scenes (NeRFs) and explicit representations (Gaussian Splatting (GS)) efficiently.2. The ability to achieve the best of both worlds, combining the advantages of NeRFs (superior PSNR, SSIM, and LPIPS on dissimilar views, and a compact representation) and GS (real-time rendering and ability for easily modifying the representation).3. The computational cost of these conversions is minor compared to training the two from scratch.The paper develops an approach to convert between NeRFs and GS, enabling the conversion of explicit representations into implicit ones and vice versa, and achieving the best of both worlds in terms of rendering speed, localization, and mapping.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|The paper reviews the development and implementation principles of Dynamic NeRF, from 2021 to 2023, highlighting its potential in practical applications and comparing its features, and discusses the key methods to implement a Dynamic NeRF.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a method that synergistically integrates multi-plane representation with a coordinate-based network to improve NeRFs from sparse inputs.* The method uses residual connections to combine the features from the two networks, allowing them to preserve their inherent properties and achieve efficient parameter allocation.* The authors demonstrate that their method achieves comparable results to explicit encoding with fewer parameters, and outperforms baselines in dynamic NeRFs from sparse inputs.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling (DNR) module to address challenges in NeRF-aided editing tasks, enabling object removal, inpainting, and location transformation while achieving state-of-the-art performance.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction, which is a novel application of hologram technology. The key contributions are:1. Attempts to estimate depth maps using monocular depth estimation, LiDAR sensor data, and TrueDepth sensor data from the iPhone 14 Pro.2. Develops a hybrid approach that combines LiDAR and TrueDepth data streamed from the iPhone 14 Pro's front-facing sensors, upscales the data using a custom-trained SRCNN model, and fuses the data using weighted averaging.3. Proposes a deep-learning-based approach using a modified MICA model that tracks facial landmarks on a face and renders a 3D mesh, which is retrained on a custom dataset with additional depth information.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, introducing a novel sampling strategy, coarse-to-fine training, and a robust inter-frame point constraint to improve pose estimation and depth geometry accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose LIVE, a novel design method for interactive LaTeX graphic items, enabling the creation of dynamic and interactive components that can enhance the reading experience, and demonstrate its application in designing interactive tables and figures with Lucid representation, intent on addressing the limitations of traditional LaTeX design methods.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:SketchDream is a text-to-3D generation and editing method that integrates sketches and text prompts to generate high-quality 3D models with detailed control over geometry and appearance.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
|**2024-05-10**|**Aerial-NeRF: Adaptive Spatial Partitioning and Sampling for Large-Scale Aerial Rendering**|Xiaohan Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Aerial-NeRF, a novel approach that extends Neural Radiance Fields to large-scale aerial rendering by adapting to different flight trajectories, utilizing pose similarity for rendering speedup, and developing an adaptive sampling approach for performance improvement.|[2405.06214v1](http://arxiv.org/abs/2405.06214v1)|null|
|**2024-05-10**|**Residual-NeRF: Learning Residual NeRFs for Transparent Object Manipulation**|Bardienus P. Duisterhof et.al.|The paper proposes Residual-NeRF, a method to improve depth perception and training speed for transparent objects by combining background and residual Neural Radiance Fields (NeRFs) and outperforms baselines in synthetic and real-world experiments.|[2405.06181v1](http://arxiv.org/abs/2405.06181v1)|null|
|**2024-05-09**|**DragGaussian: Enabling Drag-style Manipulation on 3D Gaussian Representation**|Sitian Shen et.al.|The paper proposes DragGaussian, a 3D object drag-editing framework that leverages 3D Gaussian Splatting and diffusion models for interactive image editing with open-vocabulary input, enabling users to perform precise editing tasks with ease.|[2405.05800v1](http://arxiv.org/abs/2405.05800v1)|null|
