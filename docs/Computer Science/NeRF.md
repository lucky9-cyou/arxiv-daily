
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model. This allows for the generation of terrain representations from imagery, which are lightweight, continuous, and differentiable. The authors propose a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression. Additionally, they introduce a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.The main contributions of the paper are:1. Introduction of NEMos, which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.2. Novel method for jointly training a height field and radiance field within a NeRF framework, utilizing quantile regression.3. Path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.4. Experimental results demonstrating the effectiveness of NEMos in generating high-quality reconstructions and producing smoother paths compared to discrete path planning methods.Overall, the paper presents a new terrain representation and path planning approach that leverages the strengths of Neural Radiance Fields and quantile regression in capturing terrain geometry and minimizing path errors.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, offering 1.91 dB PSNR improvements and 1000x inference speed, while requiring only 6.3% training time.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, dubbed GS-Hider, which embeds 3D scenes and images into original GS point clouds, allowing for secure and invisible transmission, robust, high-fidelity, and large-capacity message extraction, and demonstrating exceptional security, robustness, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents an approach that combines Neural Radiance Fields (NeRFs) with ray tracing to improve the rendering of highly specular objects, addressing the limitations of prior methods in synthesizing consistent reflections of nearby content and reducing the need for large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE) for rendering specular objects, which encodes directional information in a feature-grid-like structure and cone-traces spatial features to model high-frequency angular signals and interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a two-staged pipeline for camera relocalization, normalizing images with varying lighting and shadow conditions, utilizing a hash-encoded NeRF representation, and introducing a reordered dynamic low-pass filter and numerical gradient averaging technique for improved pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summarized version of the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework generating high-fidelity, illumination-decoupled textured mesh from single images or text prompts, improving upon existing methods by addressing issues of geometry smoothness and convergence speed.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which achieves improved quality and compression efficiency by representing the radiance field as a compact residual feature grid and applying sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly, reducing training time by 6+ times and achieving state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The Gaussian Time Machine (GTM) proposes a novel real-time rendering method for scenes with vastly varying appearances, combining high fidelity, real-time rendering, and consistency, achieving state-of-the-art reconstruction quality and 100 times faster rendering speed than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces MOSS, a novel framework that combines kinematic information with Gaussian distributions to synthesize realistic 3D clothed humans from single-view videos, enhancing joint details and clothing folds, and achieving state-of-the-art visual quality and real-time rendering.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables the estimation of the 6D pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF) model, which can be trained from a sparse set of images and allows for autonomous rendezvous and proximity operations.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summary of the paper's abstract and introduction (< 50 words):The paper proposes MVSGaussian, a fast and generalizable 3D Gaussian representation method that leverages Multi-View Stereo and a pixel-aligned Gaussian representation for efficient novel view synthesis, achieving state-of-the-art performance with real-time rendering speed and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper focuses on integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques for representing and transmitting 3D contents in 6G wireless networks. The paper highlights the importance of efficiently representing, transmitting, and reconstructing 3D contents in immersive communication scenarios, such as telepresence, immersive gaming, and metaverse. The key contributions of the paper are:1. Comprehensive review of NeRF and 3D-GS techniques for 3D representation and transmission.2. Discussion of the challenges and opportunities of integrating NeRF and 3D-GS in 6G wireless networks.3. Overview of the design considerations for wireless transmission of 3D contents, including joint computation and communication, and end-to-end latency requirements.4. Potential applications of NeRF and 3D-GS in 6G wireless networks, such as radiance field rendering, virtual and augmented reality, and 3D modeling and reconstruction.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the paper's abstract and introduction are:* The proposed method is a novel multi-view photometric stereo (MVPS) approach that leverages per-pixel intensity renderings to estimate 3D shape from MVPS images, achieving competitive reconstruction accuracy using only 6 lights and matching the state-of-the-art performance when all lights and normal map information are fused.* The method explicitly models point light attenuation and casts shadows, and optimizes a fully neural material renderer, allowing it to perform robustly even with poor normals in low light count scenarios.* The paper introduces a new neural surface representation using a Signed Distance Field (SDF) parameterization, which is used to render images and compute losses, and demonstrates the effectiveness of the method on the DiLiGenT-MV benchmark.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a Judge mechanism to assess and refine the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of the paper are:* A novel two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.* The integration of NeRF-based ray tracing techniques with electromagnetic physics to model the signal field for any specified RIS placement and receiver location.* Experimental results demonstrating the effectiveness of the proposed method in predicting signal strength and visualizing the signal field in RIS-enabled environments.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep visual features, dual keyframe selection, and 3DGS to achieve high-fidelity scene representation, accurate tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:Researchers explore the intersection of Large Language Models (LLMs) with 3D spatial data, highlighting the advantages of LLMs in processing, understanding, and generating 3D data, and charting a course for future research to harness LLMs' full potential in understanding and interacting with the complex 3D world.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* Developing a procedure to convert between implicit representations (Neural Radiance Fields, NeRFs) and explicit representations (Gaussian Splatting, GS) in a way that achieves the best of both worlds, i.e., superior PSNR, SSIM, and LPIPS on dissimilar views, and a compact representation.* Showing that the proposed procedure can be used to achieve real-time rendering and easy modification of the representation, which is useful for robotics applications where there is a limited number of views and the scene needs to be updated frequently.* Evaluating the quality and efficiency of the proposed approach using a number of existing datasets and showing that it can be used to handle situations with sparse views, which are commonly encountered in robotics.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an in-depth analysis of the development and implementation principles of Dynamic NeRF, a novel implicit method for 3D reconstruction and representation, exploring its potential in practical applications and highlighting its advantages over static NeRF.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a synergistic integration of coordinate networks and multi-plane representations to improve NeRFs from sparse inputs, achieving comparable results to sinusoidal encoding with fewer parameters and outperforming others in static and dynamic NeRF tasks.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose an implicit ray transformation strategy and a differentiable neural-point resampling module to enable point-based editable NeRF pipelines for 3D object removal and inpainting tasks with improved performance and high-quality rendering.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents an application that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, proposing three high-fidelity reconstruction tools that can run on a portable device like the iPhone 14 Pro, enabling interactive and immersive holographic experiences for a wide range of applications.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, and introduces three key advancements: depth-based ray sampling, coarse-to-fine training, and inter-frame point constraint to achieve superior performance in pose estimation and NeRF reconstruction.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LIVE, a novel design method for creating interactive LaTeX graphic items, enabling the design of dynamic and interactive components that preserve the scientificity and objectivity of traditional papers while providing a more engaging reading experience.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed SketchDream method integrates sketch and text inputs for 3D content generation and editing, addressing the challenges of 2D-to-3D translation, multi-modal condition integration, and local editing, generating high-quality results with detailed control.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
|**2024-05-10**|**Aerial-NeRF: Adaptive Spatial Partitioning and Sampling for Large-Scale Aerial Rendering**|Xiaohan Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Aerial-NeRF, a novel method that addresses the challenges of large-scale aerial rendering by designing adaptive spatial partitioning, pose-based region selection, and sampling strategies to achieve high-precision rendering and fast rendering speed.|[2405.06214v1](http://arxiv.org/abs/2405.06214v1)|null|
|**2024-05-10**|**Residual-NeRF: Learning Residual NeRFs for Transparent Object Manipulation**|Bardienus P. Duisterhof et.al.|The paper proposes Residual-NeRF, a method that improves depth perception and training speed for transparent objects by pre-learning a background scene NeRF and using two additional networks to infer residual RGB values and densities, outperforming baselines on synthetic and real-world experiments.|[2405.06181v1](http://arxiv.org/abs/2405.06181v1)|null|
|**2024-05-09**|**DragGaussian: Enabling Drag-style Manipulation on 3D Gaussian Representation**|Sitian Shen et.al.|The paper proposes DragGaussian, a 3D object editing framework that leverages 3D Gaussian Splatting and diffusion models for interactive image editing with open-vocabulary input, enabling users to perform precise and flexible editing tasks.|[2405.05800v1](http://arxiv.org/abs/2405.05800v1)|null|
