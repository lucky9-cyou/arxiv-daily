
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a single sentence summarizing the key contributions:This paper proposes a novel application of neural radiance fields (NeRF) to monocular gastroscopy data for synthesizing photo-realistic images of the stomach from novel viewpoints, addressing the issue of view sparsity in local regions and leveraging a geometry-based loss to constrain the learned geometry based on a pre-reconstructed point cloud.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeRF On-the-go introduces a simple yet effective method for synthesizing photorealistic views in complex, dynamic scenes from casually captured images, efficiently eliminating distractors while achieving faster convergence speed and significant improvement over state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed NeRF-Supervised Masked Auto Encoder (NS-MAE) framework pre-trains a multi-modal representation that is transferable to both multi-modal and single-modal perception models, enabling robust and efficient fine-tuning for diverse 3D perception tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:1. A hybrid representation that combines deformation fields, hash encoding, and 3D Gaussian Splatting to reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.2. A learnable denoising mask that can effectively identify and remove noise points in 3D Gaussian Splatting, enhancing rendering quality.3. Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.In summary, the paper presents a novel method for rendering dynamic scenes using 3D Gaussian Splatting, which combines deformation fields, hash encoding, and a learnable denoising mask to achieve high-quality and efficient rendering while reducing memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, which incorporates deformation fields to handle dynamic scenes and introduces Spatial High-Frequency Emphasis Reconstruction (SHF) and Temporal High-Frequency Emphasis Reconstruction (THF) to enhance rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The paper proposes a method to manipulate 3D Gaussian Splatting (3DGS) models using triangular meshes while maintaining high-quality rendering. The key contributions include:* Proposing a triangle shape-aware Gaussian binding strategy with self-adaptation, which allows for direct transfer of mesh manipulation to 3DGS and high-quality rendering.* Achieving state-of-the-art results in various 3DGS manipulation tasks, including large deformation, local manipulation, and soft body simulation.* Demonstrating the effectiveness of the method in handling inaccurate meshes and maintaining high-quality rendering.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that utilizes factorization techniques to reduce the storage requirements of 3D Gaussian Splatting while maintaining high-quality rendering, achieving a significant reduction in storage costs while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS) that achieves high-fidelity visual results with accelerated rendering performance by introducing a hierarchical pyramidal structure and dynamic weighting of Gaussian levels, significantly outperforming current state-of-the-art approaches.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360-degree scenes with low-cost fine-tuning, achieving high-quality results with details coherent with the observed inputs.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), a novel representation that combines Neural Radiance Fields (NeRFs) with a continuous and differentiable height field, allowing for both high-quality reconstructions and smooth path planning.* The ability to generate high-quality terrain reconstructions from imagery, without the need for expensive and time-consuming 3D sensors, using a joint training approach that incorporates quantile regression.* The development of a novel path planning algorithm that leverages the continuous and differentiable nature of the height field to produce smoother paths, while minimizing distance, slope changes, and control effort.* The demonstration of the effectiveness of NEMos in two real-world terrain scenes, one from simulated imagery and one from real-world imagery, with promising results in terms of path planning and reconstruction quality.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), for 3D HDR imaging, which efficiently renders novel HDR views and reconstructs LDR images with a controllable exposure time, surpassing state-of-the-art NeRF-based methods by 3.84 and 1.91 dB.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) point clouds, which can embed 3D scenes and images into original point clouds invisibly, accurately extract hidden messages, and ensure security, fidelity, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces an approach that leverages ray tracing to improve Neural Radiance Fields (NeRF) in rendering highly specular objects, addressing issues of inconsistent reflections of nearby content and computationally expensive neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The paper presents Neural Directional Encoding (NDE), a novel approach to view-dependent appearance encoding for neural radiance fields (NeRF) that enables accurate modeling of high-frequency angular signals and far-field reflections, improving the rendering of specular objects like shiny metals or glossy paints.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-stage pipeline for camera relocalization, normalizing images with varying lighting and shadows using a hash-encoded NeRF, and introduces a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique for pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured mesh from a single image or text prompts, introducing tensorial SDF representation and decoupled color field, and integrating a gradient-based mesh optimization layer for efficient convergence.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving significantly improved quality and compression efficiency by leveraging a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes DoGaussian, a method that distributes the training of 3D Gaussian Splatting (3DGS) across multiple nodes, achieving a 6+ times faster training time while maintaining high-fidelity rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives using lightweight neural networks, achieving state-of-the-art rendering fidelity on 3 datasets and outperforming NeRF-based methods in terms of rendering speed and quality.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper introduces MOSS, a framework for single-view clothed human reconstruction that uses kinematic information to achieve motion-aware Gaussian split, optimizing surface deformation, and addressing local occlusions, resulting in state-of-the-art visual quality with real-time rendering.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, which is a key step towards autonomous rendezvous and proximity operations in Active Debris Removal missions. They leverage a Neural Radiance Field (NeRF) model trained on a sparse set of images depicting the target to generate a large dataset of images that captures the diversity of pose distribution and illumination conditions encountered in orbit. This allows the training of an "off-the-shelf" spacecraft pose estimation network on a small number of spaceborne images. The authors demonstrate the effectiveness of their method on realistic images from the SPEED+ dataset and validate its performance on a challenging scenario, making it a promising approach for unknown target pose estimation.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable Gaussian Splatting method that encodes geometry-aware representations using Multi-View Stereo, integrates efficient volume rendering, and introduces a consistent aggregation strategy for fast per-scene optimization, achieving real-time rendering and better synthesis quality.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:The paper aims to provide a comprehensive overview of the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for immersive communications. The paper highlights the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks and discusses the challenges of integrating NeRF and 3D-GS in these networks. The authors also propose joint computation and communication designs, model compression approaches, and semantic communication-enabled 3D content transmission designs to facilitate the transmission of radiance field models over wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The paper's abstract and introduction highlight the following key contributions:The paper presents a novel multi-view photometric stereo (PS) method that leverages per-pixel intensity renderings rather than relying on estimated normals. The approach models point light attenuation and explicitly raytraces cast shadows to approximate each point's incoming radiance, using a fully neural material renderer that is jointly optimized with the surface. The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when normal maps are also incorporated.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* **Abstract:** The paper proposes a method to generate realistic-looking adversarial objects that can be used to test autonomous driving systems. The method uses a neural network to optimize the texture of an object to make it adversarial, while also ensuring that it appears realistic to a human evaluator.* **Introduction:** The paper discusses the importance of ensuring the robustness of autonomous driving systems against adversarial attacks, particularly those involving physical objects. Previous research has focused on generating adversarial examples that can disrupt AI models, but these examples often lack realism. The paper proposes a new approach that uses a neural network to generate adversarial objects that are both effective and realistic.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summarized key contribution in one sentence under 50 words:The paper proposes a novel NeRF-based ray tracing method to model electromagnetic signal propagation in RIS-enabled wireless environments, enabling accurate modeling of complex signal dynamics and offering guidance for efficient RIS deployment.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, 'MotionGS', which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting for improved tracking, rendering, and mapping performance with reduced memory usage and high-fidelity scene representation.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This survey paper provides a comprehensive overview of methodologies enabling Large Language Models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction within embodied AI systems, while identifying challenges and outlining a course for future research.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions from the paper's abstract and introduction are:The authors present a procedure for converting between implicit representations, such as Neural Radiance Fields (NeRF), and explicit representations, like Gaussian Splatting (GS), to achieve the best of both worlds - superior performance on dissimilar views with NeRF-like quality, and real-time rendering capabilities with GS.The main idea is to convert between NeRF-SH, a trained Neural Radiance Field, and NeRFGS, a explicit representation of the scene in terms of 3D Gaussian Splatting, to enable editing and rendering of the scene.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions: The paper reviews the development and implementation principles of Dynamic Neural Radiance Field (NeRF), highlighting its potential in practical applications, and offers a comprehensive analysis and comparison of its features and key methods for implementation, with a focus on the period from 2021 to 2023.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
