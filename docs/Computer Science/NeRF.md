
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is the summary of the key contributions from the paper's abstract and introduction:* The authors propose a novel method for synthesizing photo-realistic images for novel viewpoints within the stomach from pre-captured monocular gastroscopic images.* The method is based on neural radiance fields (NeRF) and incorporates geometry priors from pre-reconstructed point clouds to address view sparsity in local regions.* The proposed geometry-based loss effectively constrains the learned geometry by using the point cloud pre-reconstructed by structure-from-motion (SfM).* The method achieves high-fidelity image renderings from novel viewpoints both qualitatively and quantitatively, outperforming other recent NeRF methods.* The experimental results demonstrate the effectiveness of the proposed method for synthesizing high-quality RGB images for novel viewpoints not included in the training.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces NeRF On-the-go, a simple and effective approach for robustly synthesizing novel views from casually captured image sequences in dynamic, real-world environments, achieving better convergence speed and eliminating distractors more efficiently.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions:The paper proposes a self-supervised pre-training framework, NeRF-Supervised Masked Auto Encoder (NS-MAE), that enables transferable multi-modal representation learning for autonomous driving, leveraging neural radiance fields to learn rich visual representations from masked multi-modal inputs.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The paper presents a refined 3D Gaussian representation for high-quality dynamic scene reconstruction, addressing the concerns of increased memory usage and rendering dynamic scenes in 3D Gaussian Splatting (3D-GS) by introducing a deformation field to capture dynamic offsets, a denoising mask to eliminate noise points, and motion consistency constraints to minimize motion artifacts.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by introducing spatial and temporal frequency emphasis modules, achieving superior rendering quality.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a single sentence summary of the key contributions from the paper's abstract and introduction:The authors propose Mani-GS, a method that enables controllable 3D Gaussian Splatting (3DGS) manipulation by binding 3DGS to a triangular mesh, allowing for large deformations, local manipulations, and soft body simulations while maintaining high-quality rendering, and outperforming state-of-the-art methods in terms of PSNR, SSIM, and LPIPS metrics.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions from the paper's abstract and introduction can be summarized in a single sentence under 50 words: The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that drastically reduces storage requirements while maintaining image quality by approximating dense clusters of Gaussians through efficient factorization and compression.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Pyramidal 3D Gaussian Splatting (PyGS) improves 3D scene modeling by introducing a hierarchical assembly of Gaussians, achieving a rendering time that is over 400 times faster than state-of-the-art NeRF-based methods, while preserving high-fidelity visual results and capturing intricate details.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a novel method, SparseSplat360, that uses a cascade of in-painting and artifact removal models, fine-tuned with 2D diffusion models, to reconstruct 360-degree scenes from sparse views, achieving state-of-the-art results and generating scenes with high detail from as few as 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The key contributions include:1. A novel terrain representation, called Neural Elevation Models (NEMos), which adapts Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.2. A method for jointly training a height field and radiance field within a NeRF framework using quantile regression.3. A path planning algorithm that uses the differentiability of the height field to perform gradient-based optimization of a continuous cost function, minimizing distance, slope changes, and control effort.4. Experimental results demonstrating the ability of NEMos to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.Overall, the paper proposes a new approach for representing and navigating terrain using neural networks, which can be more efficient and effective than traditional methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with a user input exposure time, outperforming state-of-the-art NeRF-based methods while achieving faster inference speed and reduced training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files in an invisible manner, ensuring security, fidelity, and versatility, with features including coupled secured feature attributes, scene and message decoders, and robust capacity for hiding multiple messages.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a novel approach that introduces ray tracing into Neural Radiance Fields (NeRFs) to render highly specular objects and synthesize consistent reflections of nearby and distant content, achieving improved efficiency and quality.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The authors introduce Neural Directional Encoding (NDE), a feature-grid-like neural rendering approach for modeling high-frequency angular signals and capturing effects of interreflection in synthetic and real-world datasets with view synthesis of specular objects, outperforming previous state-of-the-art methods with real-time inference potential.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the paper's abstract and introduction in under 50 words:The authors propose a two-staged pipeline for camera relocalization, accounting for lighting changes and shadows, by normalizing images and utilizing a hash-encoded NeRF with a truncated dynamic low-pass filter and numerical gradient averaging technique to optimize pose refinement.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes LDM, a feed-forward framework for generating high-fidelity, illumination-decoupled textured meshes from single images or text prompts, with key contributions including introducing a novel tensorial SDF representation, adaptive conversion of SDF to density, and gradient-based mesh optimization layer to improve smoothness and quality of generated geometries.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which improves quality and compression efficiency compared to previous methods.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times for large-scale scenes while achieving state-of-the-art rendering quality, leveraging scene decomposition and Alternating Direction Method of Multipliers (ADMM) for consistency and convergence.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) proposes a real-time rendering method that disentangles appearance changes from geometry, achieving state-of-the-art reconstruction quality and 100x faster rendering speed than NeRF-based methods, while handling scenes with vastly varying appearances and weather conditions.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce Motion-Based 3D Clothed Humans Synthesis (MOSS), a framework that employs kinematic information to achieve motion-aware surface deformation, improving human body reconstruction in large-scale motion and fine clothing folds with state-of-the-art visual quality.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, enabling autonomous rendezvous and proximity operations for Active Debris Removal missions. The method relies on an in-the-wild Neural Radiance Field (NeRF) trained on a sparse collection of images depicting the target spacecraft, generating a large dataset that captures the diversity of both pose distribution and illumination conditions. This dataset is then used to train an off-the-shelf spacecraft pose estimation network, allowing for autonomous operation without requiring prior knowledge of the target's CAD model. The authors demonstrate the feasibility of their method on Hardware-In-the-Loop images of SPEED+, showcasing its effectiveness in estimating the pose of an unknown target spacecraft.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors present MVSGaussian, a generalizable 3D Gaussian representation approach that encodes geometry-aware Gaussian representations from Multi-View Stereo and decodes them into Gaussian parameters, achieving fast fine-tuning for specific scenes and real-time rendering.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper discusses the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents, highlighting the challenges and opportunities for distributed training, inference, and rendering over wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the paper's abstract and introduction are:* The paper presents a novel multi-view photometric stereo (PS) method that leverages per-pixel intensity renderings rather than relying mainly on estimated normals.* The method models point light attenuation, explicitly raytraces cast shadows, and optimizes a fully neural material renderer.* The method is able to achieve competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information is fused.* The paper introduces a new neural surface representation using Signed Distance Function (SDF) with a neural material renderer and discusses various limitations and assumptions made in the approach.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems. The approach involves introducing a novel entity called the 'Judge', which assesses the realism of generated objects and incorporates its evaluation into the loss function to encourage the renderer to produce realistic and adversarial textures simultaneously.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions from the paper's abstract and introduction are:* Proposing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments.* Introducing a two-stage framework that captures the complete signal pathways from the transmitter to the RIS and from the RIS to the receiver, enabling accurate characterization of multiple complex transmission paths.* Utilizing the coordinates of the RIS, the transmitter, and the receiver as inputs, enabling the prediction of the signal field for any specified RIS placement and receiver location.* Providing experimental evaluations using both simulated and real-world data that validate the significant benefits of the proposed methodology.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, named MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving state-of-the-art performance in tracking, mapping, and rendering, with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This survey explores the integration of Large Language Models (LLMs) with 3D-data, highlighting the potential of LLMs to enhance spatial comprehension and interaction within embodied AI systems, and offering a comprehensive overview of current methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper proposes a procedure to convert back and forth between implicit representations of a scene, such as Neural Radiance Fields (NeRFs), and explicit representations, such as Gaussian Splatting (GS). This allows for a compact representation of the scene that generalizes well to new views, as well as real-time rendering and easy modification of the representation. The conversion process is minor compared to training the two from scratch, and the approach achieves the best of both worlds in terms of quality and efficiency.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an in-depth analysis of Dynamic NeRF, a novel implicit method for 3D reconstruction and representation, highlighting its development history, key principles, and features, as well as a comparison of various Dynamic NeRF projects.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
