
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning, which leverages masked multi-modal reconstruction in neural radiance fields to learn robust and generalizable representations for diverse multi-modal and single-modal perception models in autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines the advantages of NeRF and 3D-GS, introducing a hybrid representation of explicit and implicit features.* The key contributions are:	+ A hybrid representation that significantly reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.	+ A learnable denoising mask that effectively identifies and removes noise points, enhancing rendering quality.	+ Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.Note that the paper's abstract and introduction provide an overview of the problem, the related work, and the proposed solution, but do not explicitly state the key contributions. However, the key contributions can be inferred from the abstract and introduction.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose HFGS, a novel approach for deformable endoscopic reconstruction, addressing under-reconstruction by incorporating deformation fields and spatial/temporal frequency emphasis modules, achieving superior rendering quality in experiments on two widely used benchmarks.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions from the paper's abstract and introduction are:* A method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, which enables direct transfer of mesh manipulation to 3DGS and maintains high-quality rendering.* A triangle shape-aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations, including large deformations, local manipulations, and soft body simulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by factorizing dense clusters of Gaussians, enabling efficient representation of detailed 3D scenes while maintaining image quality and fast rendering speeds.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors propose Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that combines 3D Gaussians with NeRF initialization to better model large-scale scenes, achieving faster rendering times and improved fine details.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that uses a cascade of models to improve the reconstruction of a 360-degree scene from sparse views, leveraging pre-trained 2D diffusion models with fine-tuning to fill in missing details and clean novel views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:1. The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.2. The ability to generate NEMos from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.3. A novel method for jointly training a height field and radiance field within a NeRF framework using quantile regression.4. The introduction of a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.5. Experimental results demonstrating the ability of NEMOs to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summary of the paper's key contributions:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods in terms of performance and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring invisible and secure transmission of multimodal messages with exceptional security, robustness, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The key contributions of this paper are a ray tracing-based approach to render detailed specular appearance and consistent reflections in Neural Radiance Fields (NeRFs), which Improves the efficiency of rendering view-dependent appearance and outperforms prior methods for view synthesis of scenes containing shiny objects.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The paper introduces Neural Directional Encoding (NDE) for view-dependent appearance encoding in neural radiance fields (NeRF) for rendering specular objects, which accurately models high-frequency angular signals and addresses interreflection effects through a novel spatio-spatial parameterization via cone-tracing.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, combining hash-encoded neural radiance fields with a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel feed-forward framework, called LDM, that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts within seconds, introducing a tensorial SDF representation and adaptive conversion strategy for smooth geometry and texture production.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end learning scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior rate-distortion performance and eliminating the need for multi-stage training.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality by splitting scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) proposes a lightweight neural rendering method for real-time rendering of 3D scenes with vastly varying appearances, achieving state-of-the-art rendering fidelity, 100 times faster than NeRF-based counterparts, and disentangling appearance changes for smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Motion-Based 3D Clothed Humans Synthesis (MOSS), an innovative framework that incorporates kinematic information to achieve motion-aware Gaussian splitting and address local occlusions in single-view clothed human reconstruction, resulting in state-of-the-art visual quality and improved efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper's abstract and introduction describe a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, which is crucial for autonomous rendezvous and proximity operations in Active Debris Removal missions. The method leverages a Neural Radiance Field (NeRF) to represent the target spacecraft's appearance and generate a large dataset of diverse images, which is then used to train an off-the-shelf pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The paper presents MVSGaussian, a novel generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes by leveraging Multi-View Stereo (MVS) encoding, pixel-aligned Gaussian representations, and a hybrid Gaussian rendering approach, achieving real-time rendering with high synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions of the paper are:* Integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques with 6G wireless networks to enable efficient representation, transmission, and reconstruction of 3D contents.* Reviewing the basics of radiance field rendering techniques, including their applications and implementation challenges over wireless networks.* Proposing a new semantic communication enabled 3D content transmission design, which exploits radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* Discussing the integration of 3D-GS and NeRF with 6G networks, including over-the-air training and rendering, model compression, and rendering acceleration techniques.* Highlighting the importance of joint computation and communication designs to minimize end-to-end latency while preserving the quality of experience (QoE) requirements for immersive communications applications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and raytraces cast shadows to estimate 3D shape from photometric stereo images, achieving competitive reconstruction accuracy and robustness to poorly estimated normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a "Judge" mechanism to assess and refine the realism of generated objects, and explores various strategies to optimize the evaluation process.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The authors propose a novel approach using Neural Radiance Fields (NeRF) to model the complex dynamics of electromagnetic fields in Reconfigurable Intelligent Surfaces (RIS)-enabled environments. The method leverages ray tracing to capture the intricate interactions between spatial position and received signal, enabling accurate characterization of signal propagation. Experimental results validate the effectiveness of the approach in predicting signal strengths in different RIS placement scenarios, with a 94.13% error rate using simulation data and a 7.42 dB mean absolute error (MAE) using measured data.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper provides a comprehensive survey of methodologies enabling large language models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction within embodied AI systems and underscoring the need for novel approaches to harness their full potential.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here are the key contributions from the paper's abstract and introduction:* A procedure to convert between neural radiance fields (NeRFs) and 3D Gaussian splatting (GS) models, which allows for achieving the best of both representations: the superior rendering quality of NeRFs on dissimilar views and the real-time rendering and editability of GS.* The converted models can achieve better results than training each model from scratch, making it more efficient and accurate.* The approach demonstrates the effectiveness of using neural radiance fields for dense scene representations and 3D Gaussian splatting for real-time rendering.Note: The abstract provides a summary of the contributions, and the introduction further elaborates on the idea and motivation behind the procedure.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an comprehensive overview of Dynamic Neural Radiance Field (NeRF) developments from 2021 to 2023, describing its principles, techniques, and implementations, and analyzing the challenges and potential applications of this dynamic and editable 3D modeling technology.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The authors propose a method that synergistically integrates the coordinate-based network with the multi-plane representation to improve NeRFs from sparse inputs.* The multi-plane representation constructs features via projection onto learnable grids and interpolating adjacent vertices, but tends to overuse parameters for low-frequency features due to its bias toward fine details.* The proposed method uses residual connections between the coordinate-based network and the multi-plane representation to maintain their inherent properties, enabling the coordination of low-frequency context and fine-grained details.* The authors demonstrate that the proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms baselines for static and dynamic NeRFs with sparse inputs.(Note: The paper's abstract and introduction are rather lengthy, so this summary focuses on the key points.)|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling module to enable editable NeRF modeling for object removal and inpainting tasks, achieving state-of-the-art performance and efficient rendering visualization without extra supervision.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
