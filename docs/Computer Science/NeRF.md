
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-30**|**$\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous Driving**|Nan Huang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a self-supervised 3D Gaussian Splatting method, called S3Gaussian, that decomposes dynamic and static elements without costly annotations, using a spatial-temporal field network to compactly model 4D dynamics and achieve state-of-the-art rendering quality in scene reconstruction and novel view synthesis tasks.|[2405.20323v1](http://arxiv.org/abs/2405.20323v1)|[link](https://github.com/nnanhuang/s3gaussian)|
|**2024-05-30**|**TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes**|Minghao Guo et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:TetSphere splatting, a Lagrangian geometry representation, efficiently reconstructs high-quality meshes by deforming tetrahedral spheres, outperforming existing Eulerian representations in terms of mesh quality, optimization speed, and handling thin structures.|[2405.20283v1](http://arxiv.org/abs/2405.20283v1)|null|
|**2024-05-30**|**NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics Evaluation**|Pedro Martin et.al.|The key contributions of the paper, as mentioned in the introduction, are:* The creation of a new dataset of FF synthetic and real visual scenes with camera poses, which can be used to assess NVS methods.* A subjective evaluation of the impact of NVS on perceived quality, considering an extensive range of real and synthetic 3D scenes, including FF and 360ยบ camera acquisitions, and several recently proposed NVS methods.* The evaluation of the performance of state-of-the-art IQA and VQA metrics in assessing the quality of NVS methods, considering the results of the subjective assessment study.|[2405.20078v1](http://arxiv.org/abs/2405.20078v1)|null|
|**2024-05-30**|**IReNe: Instant Recoloring in Neural Radiance Fields**|Alessio Mazzucchelli et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:IReNe is a novel approach that enables swift, near real-time color editing in NeRF by fine-tuning the last layer of a pre-trained model, leveraging a trainable segmentation module, and automated neuron classification to accelerate training and ensure consistent color edits.|[2405.19876v1](http://arxiv.org/abs/2405.19876v1)|null|
|**2024-05-30**|**HINT: Learning Complete Human Neural Representations from Limited Viewpoints**|Alessandro Sanvito et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces HINT, a NeRF-based algorithm that learns a detailed and complete human model from limited viewing angles, utilizing symmetry prior, regularization constraints, and training cues from large human datasets, achieving improved results by 15% PSNR and 34% LPIPS compared to previous state-of-the-art algorithms.|[2405.19712v1](http://arxiv.org/abs/2405.19712v1)|null|
|**2024-05-30**|**View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature Fields**|Haodi He et.al.|The paper's abstract and introduction present the following key contributions:* A novel method for lifting multi-granular and view-inconsistent image segmentations into a hierarchical and 3D-consistent representation using a Neural Radiance Field (NeRF).* The introduction of an ultrametric feature space, which is inherently hierarchical and transitive, allowing for the creation of a hierarchical segmentation structure.The method learns an ultrametric feature field within a NeRF, representing a 3D scene, and produces a hierarchy of 3D-consistent segmentations by thresholding the feature distance. The method is trained using a contrastive loss function that encourages the feature distances to be ultrametric.The paper evaluates the method on synthetic datasets with multi-view images and multi-granular segmentation, showing improved accuracy and viewpoint consistency compared to baseline methods.|[2405.19678v1](http://arxiv.org/abs/2405.19678v1)|null|
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a concise summary of the key contributions in the abstract and introduction:The abstract and introduction highlight the authors' contribution to enabling the synthesis of arbitrarily novel viewpoint images within a patient's stomach from pre-captured monocular gastroscopic images. They propose a novel approach that incorporates geometry priors from a pre-reconstructed point cloud into the training of neural radiance fields (NeRF), leading to high-fidelity image renderings from novel viewpoints.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|The key contributions of the paper are a simple yet effective NeRF approach, NeRF On-the-go, that enables robust synthesis of novel views in complex, dynamic real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving faster convergence speed.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|[link](https://github.com/cvg/nerf-on-the-go)|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training framework for multi-modal representation learning, which enables the transferability of multi-modal representations across diverse multi-modal and single-modal perception models for autonomous driving applications.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Key contributions from the paper's abstract and introduction:* Introducing a dynamic scene rendering framework that combines the benefits of NeRF and 3D-GS, addressing the storage consumption issue and introducing a novel view synthesis method tailored for dynamic mapping.* The framework employs deformation fields and hash encoding to capture the dynamic offset of Gaussian points, express the color features of points through hash encoding and tiny MLP, and reduce storage consumption.* A learnable denoising mask is proposed to remove noise points from the scene, further compressing 3D Gaussian representation.* Static constraints and motion consistency constraints are introduced to reduce noise in points during motion, ensuring the accuracy and efficiency of the rendering framework when processing dynamic scenes.* Experimental results demonstrate the effectiveness of the proposed method in rendering high-quality dynamic scenes with reduced storage consumption, outperforming existing approaches.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose HFGS, a novel approach that addresses under-reconstruction in endoscopic 3D reconstruction by incorporating deformation fields and frequency regularization modules, achieving superior rendering quality in static and dynamic scenes.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of the paper can be summarized as:* Proposing a method to manipulate 3D Gaussian Splatting (3DGS) using a triangular mesh, allowing for direct transfer of mesh manipulation to 3DGS with 3DGS self-adaptation.* Introducing a triangle shape-aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations.* Evaluating the method on the NeRF synthetic dataset, demonstrating state-of-the-art results and showcasing various 3DGS manipulations, including large deformations, local manipulations, and soft body simulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) by factorizing coordinates and features, achieving a significant reduction in storage costs while maintaining comparable image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical and dynamically weighted approach that achieves high-fidelity visual results and accelerated rendering performance for large-scale scenes, addressing challenges of object integration, initialization, and rendering speed.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a method, SparseSplat360, that uses 2D diffusion models to improve sparse-view reconstruction of 360-degree scenes with low-cost fine-tuning, achieving high-quality scene reconstruction with details coherent with observed inputs.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here are the key contributions summarized in a single sentence under 50 words:The paper introduces Neural Elevation Models (NEMos) that combine Neural Radiance Fields with a height field, enabling a compact and differentiable representation of terrain for path planning and navigation.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that achieves better performance, faster training time, and faster inference speed than state-of-the-art NeRF-based methods, by integrating 3D Gaussian splatting with tone mapping and parallel differentiable rasterization.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS), enabling the embedding and extraction of 3D scenes, images, and messages in an invisible manner, achieving robust security, high fidelity, large capacity, and flexible versatility for various 3D applications.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The key contributions of the paper are the introduction of ray tracing into Neural Radiance Fields (NeRFs) to improve the rendering of highly specular objects, introducing a new approach that synthesizes consistent reflections of nearby and distant content and reduces the computational burden of representing view-dependent functions.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like neural radiance field (NeRF) that efficiently models high-frequency view-dependent appearance and interreflections of specular objects, achieving high-quality rendering and fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a single sentence summarizing the key contributions: The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, leveraging a hash-encoded NeRF and two novel techniques to address noisy image gradient computing.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, using a tensorial SDF representation, adaptive conversion of SDF to density, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, improving quality and compression efficiency for volumetric videos with dynamic scenes.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining state-of-the-art rendering quality, by decomposing scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for distributed training.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a novel real-time rendering method that disentangles appearance changes from geometry, enabling efficient reconstruction of 3D scenes with vastly varying appearances, while achieving state-of-the-art rendering fidelity and speed.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a framework that uses kinematic information to achieve motion-aware Gaussian split on the human surface, addressing current limitations in clothed human reconstruction with realistic clothing deformation and restoring detailed joints and fine clothing folds.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The key contributions of the paper are:* A new method for estimating the 6D pose of an unknown target spacecraft using a monocular camera, which extends the applicability of off-the-shelf pose estimation networks to unknown targets by leveraging Neural Radiance Fields (NeRFs).* A novel approach for training a pose estimation network from a sparse set of images depicting the target spacecraft, without assuming prior knowledge of the target's CAD model.* Experimental validation on Hardware-In-the-Loop images of SPEED+, which demonstrates the feasibility of the proposed method in estimating the pose of an unknown target spacecraft.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summarized sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes by leveraging MVS, integrating a hybrid Gaussian rendering design, and introducing a multi-view geometric consistent aggregation strategy for real-time rendering.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:1. **Integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS)**: The authors propose embracing NeRF and 3D-GS as new 3D representation techniques for wireless communication networks, enabling photorealistic rendering results for complex scenes.2. **Over-the-air training of NeRF and 3D-GS models**: The authors introduce various learning techniques for over-the-air training of NeRF and 3D-GS models, including federated learning designs over a hierarchical device-edge-cloud architecture.3. **Practical rendering architectures**: The authors discuss three practical rendering architectures for NeRF and 3D-GS models at wireless network edges, including model compression approaches and joint computation and communication designs to enhance rendering efficiency.4. **Semantic communication-enabled 3D content transmission**: The authors propose a new design for transmitting 3D contents using radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and a fully neural material renderer to estimate 3D shape from photometric stereo images, achieving competitive reconstruction accuracy using only 6 lights and outperforming state-of-the-art methods on the DiLiGenT-MV benchmark.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
