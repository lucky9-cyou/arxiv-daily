
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes NS-MAE, a self-supervised pre-training paradigm for multi-modal representation learning that enables transferable and robust representations for autonomous driving, incorporating masked multi-modal reconstruction in neural radiance fields and leveraging NeRF for unified and interpretable multi-modal representation learning.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:* A novel 3D Gaussian Splatting (3D-GS) representation that combines the advantages of explicit and implicit features to enable efficient and realistic rendering of dynamic scenes.* The introduction of a learnable denoising mask and denoising loss function to eliminate noise points in the scene and enhance rendering quality.* The proposal of static constraints and motion consistency constraints to mitigate the impact of static points on dynamic points and ensure more accurate and efficient rendering.* The demonstration of significant improvements in rendering quality, speed, and memory usage compared to existing methods.* The ability to reduce storage usage and achieve high-quality rendering of dynamic scenes.Note that the specific contributions are not explicitly summarized in a single sentence in the abstract and introduction. However, the above bullet points capture the main points of the paper's claims and contributions.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes a novel approach called HFGS for deformable endoscopic tissues reconstruction, which addresses under-reconstruction from spatial and temporal frequency perspectives by introducing Spatial High-Frequency Emphasis Reconstruction (SHF) and Temporal High-Frequency Emphasis Reconstruction (THF) modules, achieving superior rendering quality compared to existing methods.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method for 3D Gaussian Splatting manipulation using a triangular mesh as a proxy, enabling large deformation, local manipulation, and soft body simulation while maintaining high-quality rendering, and outperforms existing methods in various 3D manipulation tasks.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The proposed Factorized 3D Gaussian Splatting (F-3DGS) method reduces storage requirements by downsizing 3DGS by over 90% while maintaining comparable image quality, offering a significant improvement in spatial efficiency. Factorization techniques are employed to decompose Gaussian attributes and coordinates, significantly reducing the model size while preserving the essential characteristics of each Gaussian. Experimental results validate the effectiveness of F-3DGS, demonstrating its ability to achieve real-time rendering at a fraction of the original storage size.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that combines 3D Gaussian Splatting with NeRF initialization to address challenges in large-scale scene modeling, including object-scale variability and initialization efficiency.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that uses pre-trained 2D latent diffusion models to improve reconstruction of 360-degree scenes from sparse views, resulting in a multi-view consistent scene representation with detailed foreground and background.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Abstract:*** Introduction of Neural Elevation Models (NEMos) that adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* Presentation of a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* Introduction of a path planning algorithm that optimizes a continuous cost function for minimizing distance, slope changes, and control effort.**Introduction:*** Importance of navigation methods for autonomous ground robots operating in challenging terrain.* Limitations of traditional terrain representations, such as digital elevation models (DEMs), which require expensive sensors and are limited by their discrete nature.* Advantage of using camera images to model terrain, such as with multi-view stereo (MVS) and photogrammetry, but these methods are sensitive to image quality and computationally demanding.* Potential benefits of combining the strengths of NeRFs and DEMs to create more robust and versatile navigation solutions.Note that the introduction provides additional background information on the problem of navigation in challenging terrain and the related limitations of traditional terrain representations.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which surpasses state-of-the-art NeRF-based methods by 3.84 and 1.91 dB on LDR and HDR novel view synthesis, while achieving 1000x inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and flexibility, with applications in copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce an approach that addresses issues with Neural Radiance Fields (NeRF) by incorporating ray tracing, allowing for consistent and detailed reflections of nearby and distant content while reducing computational complexity, leading to improved view synthesis and specular reflection rendering.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Neural Directional Encoding (NDE), a novel view-dependent appearance encoding of Neural Radiance Fields (NeRF) for rendering specular objects, which accurately models high-frequency angular signals and near-field interreflections, and demonstrates fast and accurate view synthesis with small networks.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The key contributions of this paper are the proposal of a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, and the implementation of a hash-encoded NeRF for fast training and robust camera pose refinement, featuring a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve the pose optimization process.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, utilizing a multi-view diffusion model, a transformer-based model, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, achieving improved quality and compression efficiency for volumetric videos by representing the 4D radiance field as a series of residual feature grids and applying entropy-minimization compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The paper's key contributions are: proposing a distributed training method, DoGaussian, for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times, improves training convergence, and achieves state-of-the-art rendering quality, while maintaining the rendering performance of 3DGS during inference.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives using a lightweight neural network, achieving state-of-the-art rendering fidelity and efficiency on three datasets.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|The paper introduces MOSS, a framework for motion-aware 3D clothed human synthesis from monocular videos, which overcomes limitations of current methods by employing kinematic information to guide Gaussian split on the human surface and detects local occlusions to ensure realistic deformation.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method that enables the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images, leveraging an Neural Radiance Field (NeRF) model and a three-step approach, to extend the scope of existing pose estimation methods to unknown targets.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes MVSGaussian, a generalizable 3D Gaussian representation approach derived from Multi-View Stereo that efficiently reconstructs unseen scenes, achieves real-time rendering, and outperforms previous generalizable methods with better synthesis quality, less training computational cost, and faster per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The paper provides a comprehensive overview of integrating Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) techniques in 6G wireless networks to support immersive communication experiences.* The abstract highlights the need for efficient representation, transmission, and reconstruction of 3D contents over wireless networks, and introduces NeRF and 3D-GS as promising solutions.* The introduction discusses the paradigm shift in 6G networks from connected everything to connected intelligence, and emphasizes the importance of embracing radiance field rendering techniques to support immersive applications such as virtual and augmented reality.* The paper identifies technical challenges in integrating NeRF and 3D-GS with 6G wireless networks, including large data sizes, storage and transmission constraints, and computational complexity.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and optimizes a fully neural material renderer, achieving competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method to generate adversarial objects for autonomous driving systems that are both effective and realistic. The method uses a "Judge" mechanism to evaluate the realism of the generated objects. The Judge assesses the realism of the objects based on three criteria: color similarity, law of traffic, and real-life appearance. The paper also explores various strategies for creating a reliable Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced vision-language models, pretraining neurosymbolic systems, and utilizing traditional image processing techniques. The authors argue that the proposed method can help improve the robustness of autonomous driving systems against adversarial attacks.Note that this summary only captures the main points from the abstract and introduction, and does not include the detailed evaluation and results presented in the rest of the paper.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The key contributions of the paper are: proposing a novel 3DGS-based SLAM approach with deep visual feature extraction, dual keyframe selection, and joint optimization of pose and 3D Gaussian, and achieving state-of-the-art performance in tracking, rendering, and mapping with less memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive overview of methodologies enabling Large Language Models (LLMs) to process, understand, and generate 3D data, highlighting the unique advantages of LLMs in 3D spatial data processing and applications.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions from the abstract and introduction are:* The development of a procedure to convert between neural radiance fields (NeRFs) and Gaussian splatting (GS), allowing for the best of both worlds: superior rendering quality and real-time rendering capabilities.* The ability to convert NeRFs to GS, which can be modified easily and allow for real-time rendering, but are limited in their generalizability to new views.* The ability to convert GS to NeRFs, which can achieve high rendering quality, but require expensive re-training.* The proposed approach achieves state-of-the-art performance on dissimilar views, with significant improvements in PSNR, SSIM, and LPIPS.* The conversion between NeRFs and GS is accomplished with minor computational cost compared to training the models from scratch.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides a comprehensive analysis of the development and implementation principles of Dynamic Neural Radiance Field (NeRF), highlighting its potential in practical applications and its complex implementation process, while also comparing and analyzing various features and methods.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a method that synergistically integrates multi-plane representation with a coordinate-based network to improve NeRFs from sparse inputs.* The method uses residual connections to combine the strengths of both networks, allowing for the capture of low-frequency details and fine-grained details.* The proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms others in dynamic NeRFs under sparse inputs.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling module for editable NeRFs, enabling efficient object removal and scene inpainting tasks with state-of-the-art performance and high-quality rendering visualization.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
