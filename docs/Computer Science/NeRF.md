
### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements by factorizing 3D Gaussians using structured coordinates and decomposed representations, enabling fast rendering speeds and compact storage while maintaining high-quality image rendering.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS) that achieves high-fidelity scene representations and accelerated rendering performance, overcoming challenges in large-scale scenes through a pyramidal Gaussian structure and dynamic weighting of each level's contribution.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that leverages latent diffusion models to reconstruct 360 3D scenes from sparse views, achieving multi-view consistency and coherent details by iteratively updating a 3D Gaussian representation with generated pseudo novel views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, and can be generated from imagery and provide a lightweight representation of terrain.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.Note that this summary is under 50 words.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HDR-GS, a novel framework for 3D HDR imaging, which achieves better performance than existing NeRF-based methods on HDR novel view synthesis, while enjoying faster training and inference speeds, and controlling exposure time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and versatility by replacing original coefficients with coupled secured features and using parallel decoders.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes a ray tracing-based approach to address limitations in Neural Radiance Fields (NeRFs) for rendering high-frequency view-dependent appearance, particularly specular reflections, by casting reflection rays into the NeRF geometry rather than querying an expensive neural network for outgoing radiance.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Neural Directional Encoding (NDE) is proposed to model high-frequency view-dependent appearances of specular objects, using a feature-grid-like encoding of directional information that captures both far-field reflections and near-field interreflections, achieving high-quality rendering and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting and shadow conditions, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter, and achieves state-of-the-art results on datasets with varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The key contributions of the paper are: a novel feed-forward framework, LDM, that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, introducing a tensorial SDF representation, and an adaptive conversion strategy to enhance convergence speed.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which achieves improved quality and compression efficiency by utilizing a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The key contributions from the paper's abstract and introduction are the proposal of DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, reducing training time by 6+ times while achieving state-of-the-art rendering quality, and introducing a recursive approach to split scenes into blocks with balanced sizes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, enabling accurate reconstructions of 3D scenes with varying appearances, 100 times faster than NeRF-based methods, and achieving state-of-the-art rendering fidelity on several datasets.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:MOSS introduces a novel framework that combines kinematic information with Gaussian split for motion-aware 3D clothed human reconstruction, improving realism and detail in large-scale motion, and achieving state-of-the-art visual quality in 3D human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied to an unknown target by leveraging Neural Radiance Fields (NeRFs) to generate a large and diverse dataset of images that capture the target's appearance under varying illumination conditions, allowing for successful pose estimation from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that achieves real-time rendering with better synthesis quality, fast fine-tuning, and improved view synthesis, leveraging Multi-View Stereo, efficient hybrid Gaussian rendering, and a consistent aggregation strategy.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper reviews and discusses the integration of Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks, highlighting their applications, challenges, and potential solutions for efficient representation, transmission, and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and a fully neural material renderer to estimate 3D shape from photometric stereo images, achieving competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The paper's abstract and introduction outline a new approach to generate realistic-looking adversarial objects for autonomous driving systems, building upon previous research on generating transferable adversarial simulation scenarios. The main contributions are:* Proposing a modified gradient-based texture optimization method to discover realistic-looking adversarial objects.* Introducing a "Judge" mechanism that evaluates the realism of adversarial objects produced by the neural object renderer.* Investigating various strategies for optimizing the evaluation process of the Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced models, and utilizing traditional image processing techniques.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel NeRF-based ray tracing method, R-NeRF, to accurately model dynamic electromagnetic fields in RIS-enabled environments, capturing complex signal propagation dynamics and enabling efficient RIS deployment for improved communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity reconstruction, accurate real-time tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the integration of large language models with 3D spatial data, highlighting the advantages of LLMs in processing and understanding 3D data, and presenting a comprehensive overview of methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* Developing a procedure to convert between implicit representations (Neural Radiance Fields, NeRFs) and explicit representations (Gaussian Splatting, GS) with minor computational cost compared to training from scratch.* Achieving the best of both worlds by combining the advantages of NeRFs (superior PSNR, SSIM, and LPIPS on dissimilar views, and compact representation) and GS (real-time rendering and ability for easily modifying the representation).* Evaluating the quality and efficiency of the approach using existing datasets and real-world views recorded from an ego-centric camera.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|This review discusses the development and implementation principles of Dynamic Neural Radiance Fields (NeRF), a novel approach to 3D reconstruction and representation, with a focus on its potential applications and advantages over traditional static NeRF methods.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a method that synergistically integrates multi-plane representation with a coordinate-based network to improve NeRFs from sparse inputs.* The method uses residual connections between the coordinate-based network and the multi-plane representation to preserve their inherent properties and achieve efficient parameter allocation.* The proposed method is shown to achieve comparable results to explicit encoding with fewer parameters, and outperforms other methods in dynamic NeRFs from sparse inputs.(Note: Please let me know if you would like me to clarify or expand on these points!)|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module, dubbed DNR, to enable NeRF-based editing tasks, particularly 3D object removal and inpainting, with improved performance and mutual information.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR and TrueDepth sensors, leveraging monocular depth estimation, LiDAR and TrueDepth fusion, and template modeling, to achieve high-fidelity facial reconstructions on a portable device like an iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, leveraging a novel depth-based ray sampling strategy, coarse-to-fine training, and robust inter-frame point constraint to improve pose estimation accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LIVE, a novel design method for interactive LaTeX graphic items, enabling the creation of dynamic and informative figures and tables, which can improve the reading experience and add vitality to traditional papers, especially review papers.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes SketchDream, a method for sketch-based text-to-3D generation and editing, which integrates sketch and text prompts to generate high-quality 3D objects with detailed control and editing capabilities.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
