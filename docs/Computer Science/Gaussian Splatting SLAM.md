
### Gaussian Splatting SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings, utilizing neural parametric head models and per-Gaussian latent features to achieve increased dynamic expressivity and photo-realistic rendering.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DGD, a unified 3D representation that captures per-point semantics, color, and geometric properties for dynamic scenes, enabling novel view synthesis and dense semantic 3D object tracking with a simple and intuitive interface.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|The paper proposes a novel clustered differentially private federated learning (DPFL) algorithm that effectively identifies clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees, addressing performance disparities and disparate impact in DPFL.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The authors introduce a framework employing a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker-Planck equation, offering both low computational costs and excellent capability in exploring multiple metastable states.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors develop a polynomial-gaussian expansion in the field-following coordinate to construct a localized description of ion temperature gradient (ITG) driven modes, capturing wave-particle and magnetic drift resonant effects and field-line dependence, leading to a semi-analytical formula for the spectrum.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method, $E^3$Gen, for efficient, expressive, and editable digital avatar generation using a generative UV features plane representation and a part-aware deformation module, which addresses the challenges of unstructured 3D Gaussian and expressive animation in a generative setting.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper implements a model-agnostic Gaussian process regression to reconstruct the universe's expansion history, using SN-Ia data and BAO measurements, and finds hints of a quintessence-like dark energy scenario and a phantom-crossing in higher redshifts, while inconsistent results arise when including different SN-Ia compilations.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a new neural operator called DeepOKAN that uses Kolmogorov-Arnold networks (KANs) with Gaussian radial basis functions (RBFs) instead of MLPs, demonstrating improved performance and efficiency in approximating solutions to partial differential equations.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a Prior-guided Bayesian Optimization (P-BO) algorithm that leverages a surrogate model as a function prior in black-box adversarial attacks, achieving higher attack success rates and reducing query counts compared to state-of-the-art methods.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions from the paper's abstract and introduction can be summarized as follows:* The paper proposes a measurement-based method to directly implement general, multi-mode, and higher-order non-Gaussian gates using only fixed non-Gaussian ancillary states and adaptive linear optics.* The method allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates that are important for various applications in optical quantum technology.* The paper demonstrates the efficiency of the method by applying it to several important examples, including the cubic quantum non-demolition gate and the three-mode continuous-variable Toffoli gate, and their higher-order extensions.Overall, the paper presents a new approach to implementing high-order multi-mode non-Gaussian gates, which has the potential to expedite the progress toward fault-tolerant universal quantum computing and efficient quantum simulation.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors develop a novel framework to evaluate the effectiveness of stochastic continuous gravitational-wave (CW) follow-ups and demonstrate a 10-fold reduction in computing cost for a well-established follow-up method, ptemcee, applied to realistic data from the LIGO-Virgo-KAGRA collaboration.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Multi-scale Deep Feature Statistics (MDFS) model integrates deep features from pre-trained visual models with a statistical analysis model to achieve opinion-unaware blind image quality assessment (OU-BIQA) without relying on human rating data, improving training efficiency while maintaining high consistency with human visual perception.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Learning-to-Prune 3D Gaussian Splatting (LP-3DGS), a trainable binary mask method that learns the optimal pruning ratio automatically, instead of requiring manual tuning, to balance efficiency and rendering quality in novel view synthesis.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is a summary of the key contributions in under 50 words:The paper proposes a Markov chain Monte Carlo algorithm, Plug-and-Play Diffusion Models (PnP-DM), that rigorously solves Bayesian inverse problems using diffusion models (DMs) as expressive image priors, avoiding approximations and offering more accurate reconstructions and posterior estimation.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|Here is a summary of the contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes LMO-DP, a novel non-Gaussian mechanism for privately fine-tuning language models, providing strong (ε, δ)-DP guarantees, and significantly boosting accuracy compared to existing methods, including DP-SGD and its variants.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|The key contributions from the paper's abstract and introduction are:The authors propose a novel methodology, Deep Bayesian Filtering (DBF), for data assimilation in nonlinear state space models (SSMs) that allows for learning unknown system parameters from data.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes using boson sampling and Gaussian boson sampling to solve the biclustering problem in machine learning, demonstrating the potential of quantum computing for unsupervised learning and showcasing the first applications of these models to biclustering.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Conformal Confidence Regions (CCR), a novel approach that uses conformal prediction intervals for model outputs to establish confidence regions for model parameters, providing finite-sample validity under minimal assumptions on data distribution and noise.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The study investigates the transition from quantum to classical mechanics using a one-dimensional free particle model, finding that classical and quantum probability densities coincide initially, but differing for superpositions due to quantum interference, and proposes a novel approach to recover classical distribution using truncated Fourier analysis.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper introduces a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components, which is shown to be superior to universal threshold and sample covariance estimators in nonstationary settings.* The paper contributes to the emerging literature on operator estimation and learning, emphasizing the importance of exploiting structural assumptions in the design and analysis of estimators.* The paper focuses on the infinite-dimensional setting, which reveals the key dimension-free quantities that control the estimation error and explains how the correlation lengthscale and marginal variance function affect the estimation problem.* The authors consider a novel class of covariance operators that satisfy a weighted ℓq-sparsity condition, which allows for covariance models with unbounded marginal variance functions.* The paper provides a bound on the operator norm error of the adaptive threshold estimator in terms of two dimension-free quantities: the sparsity level and the expected supremum of the normalized field.* The authors compare their adaptive threshold estimator with other estimators of interest, namely the universal threshold and sample covariance estimators, and show that the adaptive threshold estimator outperforms them in the challenging case where the lengthscale is small and the range of marginal variances is large.In a single sentence, the key contributions of the paper can be summarized as:The paper introduces an adaptive threshold estimator for sparse covariance operator estimation in infinite-dimensional nonstationary Gaussian processes, which outperforms universal threshold and sample covariance estimators in small correlation lengthscale and large marginal variance range settings, and provides a bound on the operator norm error in terms of dimension-free quantities.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proves that a class of analytic radial basis functions (RBFs) vanishing at infinity, including Gaussians, Generalized Inverse MultiQuadrics, and Matern RBFs, ensure the almost sure invertibility of unsymmetric Kansa collocation matrices for the Poisson equation with Dirichlet boundary conditions.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|The paper's abstract and introduction describe the key contributions of modeling the effects of dark matter subhalos on the velocity distributions of stars in thin stellar streams, with the goal of constraining the nature of galactic dark matter using stream measurements.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The paper's abstract and introduction provide the following key contributions:* The authors propose a general theoretical description of spin self-diffusion under nonlinear gradient fields, extending the effective phase diffusion method for linear gradient fields.* They reveal three types of phase evolutions: phase diffusion, float phase evolution, and shift-based phase evolution, which significantly affect the NMR signal under nonlinear gradient fields.* The authors show that the diffusing and float phase evolutions come from the first and second derivatives of the gradient field, respectively.* They obtain expressions for the phase variance and corresponding NMR signal attenuation, which demonstrate that the signal attenuation obeys Gaussian, Lorentzian, or Mittag-Leffler function attenuations, depending on the time and nonlinear gradient field.* The authors perform random walk simulations to support their theoretical results and demonstrate the versatility of their method for handling random order nonlinear gradient fields.* The proposed method can be applied to develop advanced experimental techniques for NMR and MRI, providing increased contrast factors for diffusion coefficient and time.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper derives closed-form expressions for Bayes optimal decision boundaries in overlapping Gaussian mixture model data and shows that deep neural networks trained for classification approximate these optimal classifiers, revealing insights into neural networks' ability to perform probabilistic inference.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|Here are the key contributions from the paper's abstract and introduction:* The paper introduces a new framework, GFlow, that reconstructs dynamic 4D scenes from a single, uncalibrated video input without camera parameters.* GFlow uses 2D priors such as depth and optical flow to lift a video to a 4D explicit representation, enabling scene clustering, camera pose estimation, and object tracking.* The paper proposes a new pixel-wise densification strategy to integrate new visual content into the scene representation.* Results show that GFlow can achieve high-quality reconstruction, object segmentation, and camera pose estimation on challenging video datasets, including DAVIS and Tanks and Temples.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes 3DitScene, a novel and unified scene editing framework that leverages language-guided disentangled Gaussian Splatting for seamless editing from 2D to 3D, enabling precise control over scene composition and individual objects with both global and individual level manipulation.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|The key contributions from the paper's abstract and introduction are the introduction of StreetUnveiler, a novel 3D reconstruction method for unveiling an empty street scene from in-car camera videos, and its innovations, including a hard-label semantic 2D Gaussian Splatting representation, a rendered alpha map for identifying unobserved regions, and a time-reversal inpainting framework to enhance temporal consistency.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here are the key contributions from the paper's abstract and introduction summarized in a single sentence under 50 words:The paper presents a perturbation approach to calculate the short-time propagator of the one-dimensional Fokker-Planck equation to arbitrary order in time, ensuring probability exactness, and derives perturbative formulas for moments, Kramers-Moyal coefficients, and entropy production rate, outperforming the Gaussian approximation.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction are:* Iterative methods for scaling hyperparameter optimisation in Gaussian processes* Improvements to existing methods: pathwise gradient estimator, warm starting, and early stopping of linear system solvers* These improvements lead to speed-ups of up to 72x and decrease in average residual norm by up to 7xThe key findings are:* Pathwise gradient estimator reduces the required number of solver iterations and amortises the computational cost of making predictions* Warm starting linear system solvers leads to faster convergence* Early stopping linear system solvers after a limited computational budget allows solver progress to accumulate over multiple marginal likelihood steps* These methods are applied to different linear system solvers, including conjugate gradients, alternating projections, and stochastic gradient descent|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction are:* The authors consider iterative methods for Gaussian process marginal likelihood optimisation, which allow for a trade-off between computational cost and accuracy.* They propose a three-level hierarchy for marginal likelihood optimisation, which involves iterative linear system solvers to approximate marginal likelihood gradients.* They introduce a "warm start" approach, where the solution from the previous iteration is used as an initialisation for the next iteration, which can speed up the optimisation process.* They demonstrate the effectiveness of the warm start approach on regression tasks, achieving the same results as the conventional procedure while providing a significant speed-up.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
