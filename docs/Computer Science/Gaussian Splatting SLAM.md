
### Gaussian Splatting SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings, leveraging 3D Gaussian Splatting and a neural parametric head model for efficient rendering and increased dynamic expressivity.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a summary of the paper's key contributions in one sentence under 50 words:The paper presents DGD, a unified 3D representation that captures both dynamic and semantic properties of a scene, enabling the tracking of 3D semantic entities in real-time using a simple interface for specifying objects, with high-quality results demonstrated on various scenes.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel clustered differential private federated learning (DPFL) algorithm that effectively identifies clients' clusters in highly heterogeneous settings while maintaining high accuracy with DP guarantees, addressing performance disparities and disparate impact in FL settings.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a weak generative sampler (WGS) framework that uses deep learning to estimate the stationary Fokker-Planck equation and directly sample from the invariant distribution without requiring the computation of Jacobian determinants or the invertibility of the transformation map.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|The key contributions of the paper can be summarized in a single sentence under 50 words as: A new model is constructed to describe localized Ion Temperature Gradient (ITG) modes in stellarators, retaining wave-particle and magnetic drift resonant effects, and resolving the problem with a polynomial-gaussian expansion in the field-following coordinate.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|The paper proposes a novel method, $E^3$Gen, for efficient, expressive, and editable digital avatar generation using a 3D Gaussian representation, which is projected into a structured 2D UV space to enable generative learning and deformation control.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a single-sentence summary of the key contributions from the paper's abstract and introduction under 50 words: The authors implement Gaussian process regression to reconstruct the universe's expansion history, incorporating SN-Ia compilations and BAO measurements, providing evidence for a quintessence-like dark energy scenario and constraints on Hr_d, highlighting discrepancies between data sets.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces DeepOKAN, a novel neural operator that utilizes Kolmogorov-Arnold networks (KANs) and Gaussian radial basis functions (RBFs) to efficiently handle complex engineering problems, outperforming traditional DeepONets with comparable accuracy.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a Prior-guided Bayesian Optimization (P-BO) algorithm that leverages a surrogate model as a global function prior to improve query efficiency and attack success rates in black-box adversarial attacks, outperforming state-of-the-art methods on various datasets.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a measurement-based method to implement general, multi-mode, and higher-order non-Gaussian gates using fixed non-Gaussian ancillary states and adaptive linear optics.* The method allows for a more resource-efficient and experimentally feasible implementation of multi-mode gates that are important for various applications in optical quantum technology.* The authors show that their method can be used to implement multi-mode cubic quantum non-demolition gates and CV Toffoli gates, which are important for fault-tolerant universal quantum computing and efficient quantum simulation.The paper proposes a general methodology to implement high-order multi-mode non-Gaussian gates, requiring only offline preparation of fixed ancillary states and adaptive linear optics. The authors also propose some heuristic approaches to reduce the number of ancillary modes using mathematical tools such as Chow decomposition.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel framework for evaluating the effectiveness of continuous gravitational-wave (CW) follow-ups, enabling a ten-fold reduction in computing cost and simplifying multi-stage follow-up schemes, which will increase the sensitivity of all-sky searches for unknown neutron stars in the forthcoming observing runs of the LIGO-Virgo-KAGRA collaboration.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes the Multi-scale Deep Feature Statistics (MDFS) model, which integrates deep features from pre-trained visual models with a statistical analysis model to achieve opinion-unaware blind image quality assessment (BIQA) without relying on human rating data.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The key contributions include:* Proposing a learning-to-prune 3D Gaussian Splatting (LP-3DGS) method that learns a trainable binary mask to find the optimal pruning ratio for each scene automatically, eliminating the need for manual tuning.* Redesigning the masking function to leverage the Gumbel-Sigmoid method, making it differentiable and compatible with the existing training process of 3DGS.* Conducting comprehensive experiments on state-of-the-art 3D scene datasets, comparing the proposed method with existing pruning methods, and showing that the proposed method can learn an optimal pruning ratio and achieves better performance than the traditional pruning methods.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|The paper proposes a Markov chain Monte Carlo (MCMC) algorithm, Plug-and-Play Diffusion Models (PnP-DM), that leverages diffusion models (DMs) as priors for posterior sampling in Bayesian inverse problems. The key contributions are: (1) a principled Bayesian method that integrates DMs with the imaging inverse problem without approximations, (2) a connection between the Bayesian denoising problem and the unconditional image generation problem under a general DM formulation, and (3) a demonstration of PnP-DM's strong empirical performance on six inverse problems, including a real-world black hole imaging problem.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|Here is a summary of the key contributions mentioned in the abstract and introduction:* The paper proposes a Language Model-based Optimal Differential Privacy (LMO-DP) mechanism that can accurately fine-tune large language models with strong privacy guarantees.* LMO-DP is the first non-Gaussian mechanism that generates sub-optimal noise to ensure strong DP, and the first mechanism to support large language models.* The paper shows that LMO-DP can significantly boost the performance (accuracy and convergence) of DP-SGD and other variants with high noise reduction.* LMO-DP is also the first solution to accurately fine-tune Llama-2 with strong differential privacy guarantees.* The paper presents a meticulous search space of PDFs, which enables to formulate privacy and utility within a unified framework for searching the noise parameters.* The authors establish a novel method for generating sub-optimal noise, which is derived from a Laplace distribution and contains a linear combination of Gamma, Exponential, and Uniform distributions.* The LMO-DP mechanism is shown to work effectively on both small and large language models, and can be integrated with existing methods to improve system performance.* The paper demonstrates that LMO-DP can achieve high accuracy (e.g., 92.20%) with strong DP guarantees (e.g., ϵ = 0.3, δ = 10^(-10)) on the SST-2 dataset for sentiment classification.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Deep Bayesian Filtering (DBF), a novel methodology that constructs Gaussian posteriors on a new latent space to handle non-Gaussian posteriors in nonlinear state space models, outperforming existing methods in various tasks and conditions.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|The paper proposes using boson sampling and Gaussian boson sampling (GBS) to address the problem of biclustering in machine learning, a technique to group rows and columns of a dataset according to certain criteria, and demonstrates promising results through simulations.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|The paper introduces a novel approach, CCR, that combines conformal prediction intervals for model outputs to establish confidence regions for model parameters, offering finite-sample validity under minimal assumptions and valid in the finite sample regime.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|The paper investigates the transition from quantum to classical mechanics using a one-dimensional free particle model. Key contributions include: 1. A theoretical analysis showing that the classical distribution of final positions in a one-dimensional free particle can be obtained from a quantum mechanical wave function.2. A comparison between classical and quantum results showing that, for certain cases, the quantum probability density coincides with the classical normal distribution of the final position.3. An investigation into the emergence of classical behavior from a superposition of Gaussian distributions, which demonstrates the importance of quantum interference in this context.4. The development of a novel approach, using truncated Fourier analysis, to recover the classical probability density from the quantum probability density when quantum interference occurs.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Key Contributions:*** The paper studies sparse covariance operator estimation for nonstationary Gaussian processes with sharply varying marginal variance and small correlation lengthscale.* A covariance operator estimator is introduced that adaptively thresholds the sample covariance function using an estimate of the variance components.* The operator norm bound on the estimation error is derived in terms of the sparsity level of the covariance and the expected supremum of the normalized process.* The theory and numerical simulations demonstrate the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings.The paper's introduction motivates the study by highlighting the importance of sparse covariance operator estimation in infinite-dimensional function spaces, particularly in the nonstationary regime where the marginal variance varies widely and the correlation lengthscale is small. The paper also reviews the related work in finite-dimensional thresholded covariance estimation and infinite-dimensional covariance estimation in Gaussian processes.Let me know if you'd like me to summarize anything else!|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|The key contributions of the paper can be summarized as:The main theorem establishes that a class of analytic RBF (Gaussian, Generalized Inverse MultiQuadric and Matern RBF) used in the unsymmetric Kansa collocation method for solving the Poisson equation with Dirichlet boundary conditions has almost surely invertible matrices.Additionally, the Corollary 1 extends this result to Gaussian, Generalized Inverse MultiQuadric, and Matern RBF, making the existing Kansa collocation matrix nonsingular.No summary.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|The paper's key contributions include the development of a method to measure the distribution of random velocities in stellar streams by simulating the effect of dark matter subhalos on stellar streams in WDM and CDM cosmologies, and the finding that the radial velocity distributions of long, thin, streams are well-modeled as a sum of a Gaussian and an exponential distribution.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The paper proposes a general theoretical description of spin self-diffusion under nonlinear gradient fields, which extends the effective phase diffusion method for linear gradient fields. The key contributions are:1. Theoretical framework: The paper develops a theoretical framework for spin self-diffusion under nonlinear gradient fields, which includes the phase diffusion, float phase evolution, and shift-based phase evolutions.2. Nonlinear gradient fields: The paper investigates the effects of nonlinear gradient fields on spin self-diffusion, including the parabolic and cubic fields.3. Phase evolutions: The paper shows that the phase evolutions under nonlinear gradient fields are different from those under linear gradient fields, and that the phase evolutions are closely related to the order of the gradient field.4. Signal attenuation: The paper derives the phase variance and corresponding NMR signal attenuation, which is found to obey Gaussian, Lorentzian, or Mittag-Leffler function attenuations, depending on the time and the order of the gradient field.5. Random walk simulations: The paper performs random walk simulations to verify the theoretical results, which support the obtained theoretical expressions.6. General expressions: The paper provides general expressions for spin self-diffusion under nonlinear gradient fields, which can be applied to calculate the signal attenuation for spins starting diffusion from random positions.In summary, the paper provides a comprehensive theoretical framework for spin self-diffusion under nonlinear gradient fields, which is essential for the development of advanced experimental techniques for NMR and MRI.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper derives closed-form expressions for Bayes optimal decision boundaries in binary classification of high-dimensional overlapping Gaussian mixture model (GMM) data, and demonstrates that deep neural networks can approximate these optimal classifiers.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GFlow, a novel framework that leverages explicit 3D Gaussian Splatting to reconstruct 4D scenes from single monocular videos without camera parameters, enabling accurate reconstruction, camera pose estimation, and object segmentation.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction under 50 words:The authors propose 3DitScene, a unified scene editing framework that leverages language-guided disentangled Gaussian Splatting for precise control over scene composition and individual objects, enabling editing from 2D to 3D with granularity.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce StreetUnveiler, a novel method for 3D reconstruction of an empty street from in-car camera videos, addressing challenges in object removal, temporal consistency, and scalability through hard-label semantic 2D Gaussian Splatting and a time-reversal inpainting framework.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The authors present a perturbation approach to calculate the short-time propagator of the one-dimensional Fokker-Planck equation to arbitrary order in the time increment, which preserves probability exactly and allows for accurate evaluation of expectation values, and demonstrate its superiority over the Gaussian approximation through validation with an explicit multiplicative-noise system.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|Here are the key contributions summarized in a single sentence under 50 words:The authors propose three improvements to iterative Gaussian process methods, including a pathwise gradient estimator, warm starting, and early stopping, which lead to speed-ups of up to 72x and decreased average residual norms.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a three-level hierarchy of marginal likelihood optimisation for iterative Gaussian processes, which allows for a trade-off between computational cost and accuracy.* They introduce a warm start method, which reuses the solution of the previous step as an initialisation for the next step, reducing the computational cost of solving linear systems.* The authors show that the warm start method achieves the same results as the conventional procedure, but with a significant speed-up, up to 16 times faster on average.* They also provide empirical results on various datasets, showing the effectiveness of the warm start method in reducing the computational cost and improving the convergence of the marginal likelihood optimisation process.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
