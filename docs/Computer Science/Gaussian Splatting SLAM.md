
### Gaussian Splatting SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a single sentence summarizing the paper's key contributions:The authors propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable digital avatars from multi-view video recordings, which conditions dynamics on neural parametric head models and introduces latent features for increased dynamic expressivity.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents DGD, a unified 3D representation that captures dynamic, semantic, and appearance properties of a scene, allowing for novel view synthesis, dense semantic 3D object tracking, and high-quality rendering, all from a single monocular video.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel clustered differentially private federated learning (DPFL) algorithm that identifies clients' clusters based on model updates and training loss values, while maintaining high accuracy and privacy guarantees, and demonstrates its effectiveness in mitigating disparate impact and achieving performance fairness.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a weak generative sampler framework that employs deep learning to directly generate independent and identically distributed samples from the invariant distribution of a stochastic differential equation, bypassing the need for finding the zero eigenstate of the Fokker-Planck operator.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|The paper constructs a description of Ion Temperature Gradient (ITG) driven localized modes that retains wave-particle and magnetic drift resonant effects while capturing the field-line dependence of the electrostatic potential, using a polynomial-gaussian expansion in the field-following coordinate and a semi-analytical formula for the mode spectrum.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|Here is a single sentence summarizing the key contributions:The paper proposes $E^3$Gen, a novel method that addresses the challenges of 3D Gaussian avatar generation by introducing a novel generative UV features plane representation and a part-aware deformation module, achieving efficient, expressive, and editable avatar generation.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors use Gaussian process regression to reconstruct the universe's expansion history, combining Pantheon-Plus SN-Ia data with BAO measurements, finding evidence for a quintessence-like dark energy scenario and modeling constraints that hint at a discrepancy between different data sets.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce DeepOKAN, a neural operator that utilizes Kolmogorov-Arnold networks (KANs) and Gaussian radial basis functions (RBFs) to approximate complex engineering problems, outperforming traditional MLP-based DeepONets and achieving comparable accuracy with fewer learnable parameters.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|The key contributions of the paper are:* Proposing Prior-guided Bayesian Optimization (P-BO) algorithm, which integrates the surrogate model as a function prior into Bayesian optimization to improve the efficiency of black-box adversarial attacks.* Showing that the function prior provides useful prior information for black-box attacks, outperforming vanilla Bayesian optimization.* Experimentally demonstrating the effectiveness of P-BO on various models, including image classifiers, large vision-language models, and defense models, achieving higher attack success rates and requiring fewer queries.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions from the paper's abstract and introduction can be summarized as follows:* The paper proposes a measurement-based method to implement general, multi-mode, and higher-order non-Gaussian gates using only fixed non-Gaussian ancillary states and adaptive linear optics.* The method is more resource-efficient and experimentally feasible compared to existing methods, allowing for the implementation of important examples such as the cubic quantum non-demolition gate and the CV Toffoli gate and their higher-order extensions.* The paper provides a general methodology for implementing higher-order gates and proposes heuristic approaches to reduce the number of ancillary modes using mathematical tools such as Chow decomposition.* The results demonstrate the resource-efficiency of the proposed scheme compared to conventional schemes and has implications for optical quantum information processing and fault-tolerant universal quantum computing.Note that the paper is quite technical and assumes a strong background in quantum mechanics and linear algebra. Additionally, it appears to be a research article rather than a tutorial or an introduction to the subject.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel framework to evaluate the effectiveness of stochastic continuous gravitational-wave follow-ups, achieving a ten-fold reduction in computing cost and simplifying multi-stage follow-ups by removing the need for parameter-space metrics.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed Multi-scale Deep Feature Statistics (MDFS) model integrates deep features from pre-trained visual models with a statistical analysis model for opinion-unaware blind image quality assessment, eliminating the reliance on human rating data and achieving superior consistency and generalizability.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a learning-to-prune 3D Gaussian Splatting (LP-3DGS) method that automatically determines the optimal pruning ratio for minimizing the model size while maintaining rendering quality, overcoming the need for manual hyperparameter tuning and empirical importance score thresholds.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a Markov chain Monte Carlo algorithm, Plug-and-Play Diffusion Models (PnP-DM), that leverages diffusion models as priors for posterior sampling in Bayesian inverse problems, allowing for accurate sample distributions and reliable imaging inverse solvers.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|According to the abstract and introduction, the key contributions of the paper are:1. A novel Language Model-based Optimal Differential Privacy (LMO-DP) mechanism that enables accurate private fine-tuning of large language models, even in strong privacy settings (e.g., ϵ < 3, δ = 10^(-10)), using a non-Gaussian mechanism.2. The first mechanism that can generate sub-optimal noise to ensure strong DP and the first mechanism to support Large Language Models (LLMs).3. A novel offline optimal noise search method to efficiently derive the sub-optimal DP that reduces noise magnitude, achieving superior convergence rates in diverse tasks.Note that the summary is under 50 words.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Deep Bayesian Filtering (DBF), a novel methodology for data assimilation that assumes a state space model with linear dynamics and nonlinear observations, and learns a Gaussian inverse observation operator using neural networks to compute the filter distribution analytically.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper explores the application of boson sampling and Gaussian boson sampling to the problem of biclustering, proposing a heuristic to find clusters in a dataset using Gaussian boson sampling and simulating promising results for future exploration.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Conformal Confidence Regions (CCR), a novel approach that combines conformal prediction intervals for outputs to construct confidence regions for model parameters under minimal assumptions, providing finite-sample guarantees and applicability to various machine learning methods, including black-box approaches.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:Key Contributes:* The paper investigates the transition from quantum to classical mechanics using a one-dimensional free particle model.* It considers the classical analysis of the particle's final position using random initial conditions, and finds that the classical probability density coincides with the quantum probability density for a single Gaussian initial wave function.* The paper also studies the case of superpositions of Gaussian wave packets, showing that quantum interference leads to a divergence between classical and quantum descriptions.* A novel approach is proposed to recover the classical distribution from the quantum one using truncated Fourier transform analysis, which effectively removes high-frequency components associated with quantum interference.These contributions enhance our understanding of the classical-quantum correspondence and the mechanisms underlying the emergence of classicality from quantum systems.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|The key contributions from the paper's abstract and introduction are:* The paper introduces a covariance operator estimator that adaptively thresholds the sample covariance function using estimates of the variance components.* The paper derives an operator norm bound on the estimation error in terms of the sparsity level of the covariance and the expected supremum of the normalized process.* The paper demonstrates the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings.* The paper focuses on the infinite-dimensional setting, where the traditional approach in functional data analysis is to discretize the data, but instead, the authors develop a theory that delays introducing discretization.* The paper uses recent results from empirical process theory to control the error in the estimation of the variance components.The key contribution is the introduction of a new covariance operator estimator that adaptively thresholds the sample covariance function using estimates of the variance components, which leads to improved estimation error bounds in nonstationary settings.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proves the almost sure invertibility of unsymmetric random Kansa collocation matrices for the Poisson equation with Dirichlet boundary conditions, using a class of analytic RBFs that include popular positive definite instances like Gaussians and Matern RBFs.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors study how dark matter subhalos perturb stellar streams in galactic halos, resulting in non-Gaussian velocity distributions, and investigate the prospects for using stream velocity measurements to constrain the nature of dark matter.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The key contributions from the paper's abstract and introduction are:1. A general theoretical description of spin self-diffusion under nonlinear gradient fields is proposed, which extends the effective phase diffusion method for linear gradient fields.2. The proposed method reveals the general features of phase evolutions in nonlinear gradient fields, including phase diffusion, float phase evolution, and shift based on the starting position.3. The method shows that the diffusing and float phase evolutions come from the first and second derivatives of the gradient field, and obtains the phase variance and corresponding NMR signal attenuation.4. The results indicate that signal attenuation obeys Gaussian attenuation for a short time, then changes to Lorentzian or Mittag-Leffler function attenuations when time increases, significantly different from Gaussian attenuation.5. The method can handle random order nonlinear gradient fields and is applicable to various situations, including higher-order gradient fields and fractional diffusion.The authors also outline the challenges in existing theories, including discrepancies in reported results, limits in applicability, and the need for a more general and versatile theoretical treatment. The proposed method aims to address these challenges and provide a broader view of phase evolution under the influence of nonlinear gradient fields.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|The paper deriving closed-form expressions for optimal decision boundaries in high-dimensional overlapping Gaussian mixture model GMM) data and providing insights on how deep neural networks learn to approximate Bayesian optimal classifiers.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of a new framework called GFlow, which can reconstruct dynamic 4D scenes from a single monocular video input without any camera parameters or prior knowledge.* The use of explicit representation through 3D Gaussian Splatting to model the 4D world, which allows for a more accurate and efficient reconstruction of dynamic scenes.* The ability to cluster Gaussian points into moving and still categories, and to optimize camera poses and Gaussian points in a sequential manner to ensure fidelity among neighboring points and smooth movement across frames.* The ability to densify Gaussian points in areas where new content is revealed, which allows for a more accurate and detailed reconstruction of dynamic scenes.* The ability to track points across frames in 3D world coordinates without prior training or segmentation, which enables the segmentation of moving objects from the scene in an unsupervised manner.The contributions are stated in the abstract as "we introduce GFlow, a novel framework that leverages the explicit representation power of 3D Gaussian Splatting and conceptualizes the video content as a fluid flow of Gaussian points through space and time" and "GFlow has demonstrated not just its potential as a tool for 3D scene recovery but as a transformative force in video analysis and manipulation".|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes 3DitScene, a unified scene editing framework that leverages language-guided disentangled Gaussian Splatting to enable seamless editing from 2D to 3D, allowing precise control over scene composition and individual objects at both global and local levels.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce StreetUnveiler, a method that learns a 3D representation of an empty street from crowded in-car camera videos using hard-label semantic 2D Gaussian Splatting, a novel time-reversal inpainting framework, and alpha maps to reconstruct an empty street with high accuracy and temporal consistency.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a perturbation approach to calculate the short-time propagator of the one-dimensional Fokker-Planck equation to arbitrary order in the time increment, providing a normalization-preserving propagator that allows for the evaluation of expectation values to arbitrary accuracy.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|Here are the key contributions summarized in a single sentence:The paper proposes three techniques to improve the scalability of iterative Gaussian processes: pathwise gradient estimation, warm starting linear system solvers, and early stopping of linear system solvers with a limited compute budget.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions of the paper are:1. Introducing a three-level hierarchy of marginal likelihood optimisation for iterative Gaussian processes, which involves iterative optimisers, gradient estimators, and linear system solvers.2. Proposing the use of warm starts, where the solution from the previous step is used as an initialisation for the next step, to accelerate the optimisation process.3. Showcasing the effectiveness of warm starts by achieving the same results as the conventional procedure while providing an average speed-up of 16 times among datasets.The paper also presents the algorithmic framework, empirical results, and an analysis of the required number of linear system solver iterations at each step of marginal likelihood optimisation. The empirical results demonstrate that warm starts can significantly improve the convergence rate and reduction of computational costs of iterative Gaussian processes.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
