
### Gaussian Splatting SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach for creating high-fidelity, controllable avatars from multi-view video recordings, which outperforms the previous state-of-the-art by 2.6 PSNR on self-reenactment tasks and enables accurate animation from real-world monocular videos.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a unified 3D representation, Dynamic 3D Gaussians Distillation (DGD), that captures per-point semantics, color, and geometric properties for dynamic 3D scenes and enables the segmentation and tracking of 3D semantic entities using a simple and intuitive interface.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a novel clustered differentially private federated learning algorithm that addresses performance disparities in heterogeneous settings by clustering clients based on model updates and loss values, while maintaining high accuracy with differential privacy guarantees.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|The key contributions of the paper are:**Sampling invariant distributions from Ito diffusion processes**: A framework employing a weak generative sampler (WGS) to directly generate independent and identically distributed (iid) samples induced by a transformation map derived from the stationary Fokker-Planck equation.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|The key contributions of the paper are the development of a new model that describes Ion Temperature Gradient (ITG) driven localized modes, capturing both wave-particle and magnetic drift resonant effects, and the derivation of a simple semi-analytical formula for the spectrum of the mode, which captures long wavelength Landau damping, ion-scale Larmor radius stabilization, weakening of Larmor radius effects at short-wavelengths, and magnetic-drift resonant stabilization.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|The key contributions of this paper are the introduction of a novel generative UV features plane representation that encodes unstructured 3D Gaussian onto a structured 2D UV space, enabling efficient and expressive avatar generation, and the proposal of a part-aware deformation module for robust and accurate full-body pose control.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper implements Gaussian process regression to reconstruct the universe's expansion history, using SN-Ia data and BAO measurements, and finds evidence for a quintessence-like dark energy scenario and hints of a phantom-crossing, while also constraining the Hubble parameter and providing alternatives to the Lambda-CDM model.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a new neural operator called DeepOKAN, which uses Kolmogorov-Arnold networks (KANs) instead of conventional neural network architectures, and achieves comparable accuracy with fewer learnable parameters, making it a promising approach for efficient solution of complex engineering problems.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:The proposed Prior-guided Bayesian Optimization (P-BO) algorithm integrates the surrogate model as a function prior into Bayesian optimization, which improves the query efficiency of black-box adversarial attacks. The algorithm initializes the mean function of the Gaussian process with the surrogate model's loss and updates the posterior distribution given the observed values of the objective function. Theoretical analysis shows that the performance of P-BO may be affected by a bad prior, so an adaptive integration strategy is proposed to automatically adjust a coefficient on the function prior by minimizing the regret bound.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions of the paper can be summarized as follows:1. **Measurement-based implementation of general, multi-mode, and higher-order non-Gaussian gates**: The authors propose a method to implement high-order multi-mode non-Gaussian gates using only fixed non-Gaussian ancillary states and adaptive linear optics.2. **Reduction of required resources**: The authors show that their method requires fewer gates compared to existing methods that decompose non-Gaussian gates into single-mode non-Gaussian gates and Gaussian gates.3. **Optimization of CV quantum circuit**: The authors' method allows for a better understanding of complex multi-mode quantum dynamics and opens up new possibilities for CV quantum circuit optimization.4. **Generalized Chow decomposition**: The authors provide a new decomposition method, known as Chow decomposition, for general polynomials, which allows for a more efficient representation of high-order non-Gaussian gates.In summary, the paper proposes a new method for implementing high-order multi-mode non-Gaussian gates, reduces the required resources, and optimizes CV quantum circuits.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|The paper proposes a novel framework to evaluate the effectiveness of stochastic continuous gravitational-wave (CW) follow-ups, which leads to a ten-fold reduction in computing cost using pyfstat. The framework simplifies the setup of multi-stage follow-ups by removing the need for parameter-space metrics.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes a novel Multi-scale Deep Feature Statistics (MDFS) model for opinion-unaware blind image quality assessment, integrating deep features from pre-trained models with a statistical analysis model, achieving superior performance and cost-effectiveness in training.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a learning-to-prune 3D Gaussian Splatting (LP-3DGS) method that automatically determines the optimal pruning ratio for each scene by applying a trainable mask to the importance score, eliminating the need for manual tuning and allowing for efficient and high-quality novel view synthesis.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a Markov chain Monte Carlo algorithm, PnP-DM, that leverages diffusion models (DMs) to perform posterior sampling for general imaging inverse problems by reducing it to sampling the posterior of a Gaussian denoising problem, achieving more accurate reconstructions and posterior estimation.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:**Key Contributions:**1. **Language Model-based Optimal Differential Privacy (LMO-DP)**: A novel non-Gaussian DP mechanism that achieves tight composition using the RÃ©nyi Accountant, ensuring strong DP guarantees.2. **First non-Gaussian DP mechanism for LM fine-tuning**: LMO-DP is the first mechanism to generate sub-optimal noise for accurately fine-tuning large language models with strong DP guarantees.3. **First mechanism to support LLMs with strong DP guarantees**: LMO-DP takes the first step to fine-tune large language models (LLMs) with strong DP guarantees, specifically Llama-2 with 7 billion parameters.4. **Significant boost in accuracy**: LMO-DP can significantly boost the performance of DP-SGD and other variants with high noise reduction, achieving accuracy of 92.20% in fine-tuning RoBERTa-large on the SST-2 dataset.Let me know if you need any further clarification!|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|The key contributions from the paper's abstract and introduction are:1. Proposing Deep Bayesian Filtering (DBF) for data assimilation on nonlinear state space models (SSMs), which constructs new latent variables on a new latent ("fancy") space and assimilates observations using Gaussian inverse observation operators.2. Assumptions are made on Gaussian posteriors on physical space, which become non-Gaussian when posteriors are computed on (fancy) space.3. DBF seeks an approximate posteriors using a Gaussian inverse observation operator and learns the dynamics matrix to remain Gaussian for posteriors.4. Analytic formula for recursive computation of posteriors is provided, avoiding accumulation of Monte-Carlo sampling errors over time steps.5. Experiments show DBF outperforms model-based approaches and latent assimilation methods in various tasks and conditions.6. DBF is a variational auto-encoder (VAE) faithful to the Markov property for SSMs with nonlinear dynamics, providing an analytic formula for the recursive computation of posteriors.7. DBF generalizes the Kalman Filter and allows for non-Gaussian posteriors on physical space, enabling the representation of complex nonlinear dynamics.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|The key contributions from the paper are: proposing the application of boson sampling and Gaussian boson sampling to biclustering, developing algorithms for boson sampling-based and GBS-based clustering, and conducting preliminary simulations to study the effectiveness of these approaches.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Conformal Confidence Regions (CCR), a novel approach that uses conformal prediction intervals for model outputs to establish confidence regions for model parameters, providing finite-sample validity under minimal assumptions and applicable to various methodologies and data settings.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper investigates the transition from quantum to classical mechanics using a one-dimensional free particle model, demonstrating that quantum probability density coincides with classical normal distribution for initial Gaussian distributions, but deviates for superpositions, introducing a novel approach to recover classical distribution using truncated Fourier analysis.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|The key contributions from the paper's abstract and introduction are:1. Introducing a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components.2. Deriving an operator norm bound on the estimation error in terms of the sparsity level of the covariance and the expected supremum of the normalized process.3. Demonstrating the advantage of adaptive threshold estimators over universal threshold and sample covariance estimators in nonstationary settings.Specifically, the paper studies sparse covariance operator estimation for nonstationary Gaussian processes with sharply varying marginal variance and small correlation lengthscale, focusing on the infinite-dimensional setting. The authors introduce a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components and prove a bound on the operator norm error in terms of two dimension-free quantities: the sparsity level and the expected supremum of the normalized field. This shows that adaptive thresholding can lead to an exponential improvement in sample complexity over sample covariance estimators in challenging regimes.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proves that unsymmetric random Kansa collocation matrices are almost surely invertible for the Poisson equation with Dirichlet boundary conditions, using a class of analytic RBFs that includes popular instances such as Gaussians, Generalized Inverse MultiQuadrics, and Matern RBFs.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The study models the effect of dark matter subhalos on the velocity distributions of stellar streams in simulated Milky Way-like halos, finding that the velocity distributions exhibit non-Gaussian wings due to subhalo perturbations, which can be used to constrain the nature of dark matter.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The key contributions of the paper are:1. The authors propose a general theoretical description of spin self-diffusion under nonlinear gradient fields, which extends the effective phase diffusion method for linear gradient fields.2. They reveal that there are three types of phase evolutions: phase diffusion, float phase evolution, and shift based on the starting position.3. The authors show that the phase from float phase evolution is missed or misplaced in traditional methods, which leads to incorrect NMR signal attenuation or phase shift.4. They provide a general expression for the phase variance and corresponding NMR signal attenuation, which demonstrates that signal attenuation obeys Gaussian attenuation for a short time, then changes to Lorentzian or Mittag-Leffler function attenuations when time increases.5. The authors also discuss the limitations of existing theories, such as the need to develop new theoretical treatments for nonlinear gradient fields, and the importance of considering higher-order gradient fields.6. They propose a method for calculating the signal attenuation for spins starting diffusion from a random position, and provide a general expression for the average phase shift in all even-order gradient fields.7. The authors verify their theoretical results using random walk simulations, which support the obtained theoretical expressions.8. They provide a broader view of phase evolution under the influence of a nonlinear gradient field, including various aspects such as phase diffusion coefficient, phase variance, phase distribution, and signal attenuation.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|Here is a single-sentence summary of the key contributions from the paper's abstract and introduction under 50 words:The paper derives closed-form expressions for Bayes optimal decision boundaries in binary classification of high-dimensional overlapping Gaussian mixture model data, and empirically demonstrates that deep neural networks trained for classification learn predictors that approximate these optimal classifiers.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:* The paper introduces GFlow, a novel framework that enables the reconstruction of dynamic 4D worlds from single, uncalibrated monocular video inputs without relying on multi-view video, known camera parameters, or static scenes.* GFlow utilizes a flow of 3D Gaussian points to model the video content, and leverages explicit representation to lift a video from 3D to 4D.* The framework includes a new pixel-wise densification strategy to integrate new visual content, and can track any points across frames in 3D world coordinates without prior training.* The paper presents a comprehensive evaluation of GFlow on two challenging video datasets, including DAVIS and Tanks and Temples, and shows significant advantages in reconstruction quality, object segmentation, and camera pose estimation compared to state-of-the-art methods.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|The key contributions from the paper's abstract and introduction are the proposal of a novel and unified scene editing framework called 3DitScene, which enables seamless editing from 2D to 3D and precise control over scene composition and individual objects, revolutionizing creative expression and empowering control over scenes and objects.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces StreetUnveiler, a method that reconstructs an empty street scene from in-car camera videos by using hard-label semantic 2D Gaussian Splatting and a time-reversal inpainting framework to remove unwanted objects and maintain temporal consistency.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors present a perturbation approach to calculate the short-time propagator, or transition density, of the one-dimensional Fokker-Planck equation to arbitrary order in the time increment, preserving probability exactly and allowing for the evaluation of expectation values of analytical observables to arbitrary accuracy.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions of the paper are:1. **Pathwise Gradient Estimator**: A new estimator that reduces the required number of solver iterations and amortises the computational cost of making predictions.2. **Warm Starting Linear System Solvers**: Reusing linear system solutions to initialise the solver in the subsequent step, which results in faster convergence.3. **Early Stopping Linear System Solvers**: Stopping the solver early and reusing the solution to initialise the solver in the subsequent step, which synergises with warm starting and allows solver progress to accumulate over multiple marginal likelihood steps.These techniques provide speed-ups of up to 72Ã when solving to tolerance, and decrease the average residual norm by up to 7Ã when stopping early. They are applicable across different linear system solvers, including conjugate gradients, alternating projections, and stochastic gradient descent.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction are:1. The paper proposes a three-level hierarchy for marginal likelihood optimisation in iterative Gaussian processes, which can be divided into iterative optimiser, gradient estimator, and linear system solver.2. The authors identify that the computational costs are dominated by solving sequential batches of large positive-definite systems of linear equations, and propose to amortise computations by reusing solutions of linear system solvers as initialisations in the next step, providing a warm start.3. The warm start approach allows for a trade-off between compute time and accuracy of a solution, and can achieve up to a 16Ã average speed-up among datasets while providing the same results as the conventional procedure.In summary, the paper presents a new approach to marginal likelihood optimisation in iterative Gaussian processes, which can significantly reduce computational costs by reusing solutions of linear system solvers.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
