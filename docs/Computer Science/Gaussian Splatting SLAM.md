
### Gaussian Splatting SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**NPGA: Neural Parametric Gaussian Avatars**|Simon Giebenhain et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Neural Parametric Gaussian Avatars (NPGA) that utilizes a neural parametric head model to create high-fidelity, controllable avatars from multi-view video recordings, significantly outperforming previous state-of-the-art avatars in self-reenactment and monocular video animation tasks.|[2405.19331v1](http://arxiv.org/abs/2405.19331v1)|null|
|**2024-05-29**|**DGD: Dynamic 3D Gaussians Distillation**|Isaac Labe et.al.|The paper proposes a method, called Dynamic Gaussians Distillation (DGD), for learning a dynamic 3D semantic radiance field from a single monocular video. DGD represents the 3D scene using a unified 3D representation that captures per-point semantics, color, and geometric properties. This representation is optimized over time, jointly considering both color and semantic information. The key innovation is the joint optimization of appearance and semantic attributes, which affects the geometric properties of the scene. The method enables dense 3D object tracking and semantic segmentation, allowing users to track and manipulate objects in a dynamic 3D scene using a simple and intuitive interface.|[2405.19321v1](http://arxiv.org/abs/2405.19321v1)|null|
|**2024-05-29**|**Mitigating Disparate Impact of Differential Privacy in Federated Learning through Robust Clustering**|Saber Malekmohammadi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel clustered differentially private federated learning (DPFL) algorithm that effectively identifies clients' clusters in highly heterogeneous settings while maintaining high accuracy and privacy guarantees, and empirically demonstrates its effectiveness in mitigating disparate impact across diverse datasets and scenarios.|[2405.19272v1](http://arxiv.org/abs/2405.19272v1)|null|
|**2024-05-29**|**Weak Generative Sampler to Efficiently Sample Invariant Distribution of Stochastic Differential Equation**|Zhiqiang Cai et.al.|Here is a summary of the key contributions from the abstract and introduction:* The paper proposes a framework for estimating the density distribution and sampling the invariant distribution of stochastic differential equations (SDEs) using a weak generative sampler (WGS).* The WGS is based on a novel loss function that utilizes the weak form of the Fokker-Planck equation and normalizing flows to characterize the invariant distribution.* The proposed method does not require the computation of the Jacobian determinant or the invertibility of the transformation map, unlike traditional generative models.* The paper introduces an adaptively chosen family of test functions in the form of Gaussian kernel functions with centers selected from the generated data samples.* Experimental results on several benchmark examples demonstrate the effectiveness of the method, offering both low computational costs and excellent capability in exploring multiple metastable states.|[2405.19256v1](http://arxiv.org/abs/2405.19256v1)|null|
|**2024-05-29**|**The Kinetic Ion-Temperature-Gradient-driven instability and its localisation**|Eduardo Rodriguez et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper develops a semi-analytical model for Ion Temperature Gradient (ITG) driven localized modes, incorporating wave-particle and magnetic drift resonant effects, and captures the field-line dependence of the electrostatic potential, providing a qualitative framework for interpreting numerical simulations.|[2405.19235v1](http://arxiv.org/abs/2405.19235v1)|null|
|**2024-05-29**|**$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation**|Weitian Zhang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction, under 50 words:The authors introduce $E^3$Gen, a novel avatar generation method that efficiently addresses the challenges of 3D Gaussian representation in generative settings, featuring a novel UV features plane representation and part-aware deformation module for expressive full-body pose control and editing.|[2405.19203v1](http://arxiv.org/abs/2405.19203v1)|null|
|**2024-05-29**|**Model-independent cosmological inference post DESI DR1 BAO measurements**|Purba Mukherjee et.al.|The key contributions from the paper's abstract and introduction are: the implementation of Gaussian process regression to reconstruct the universe's expansion history in a model-agnostic manner using SN-Ia and BAO measurements, and the exploration of dark energy scenarios, including the possibility of quintessence-like dark energy and phantom-crossing, as well as the constraint on the Hubble constant and its relation to the total energy density of the universe.|[2405.19178v1](http://arxiv.org/abs/2405.19178v1)|null|
|**2024-05-29**|**DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for Mechanics Problems**|Diab W. Abueidda et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces DeepOKAN, a new neural operator that uses Kolmogorov-Arnold networks with Gaussian radial basis functions instead of traditional MLPs, demonstrating improved performance and accuracy in solving mechanics problems while reducing the number of learnable parameters.|[2405.19143v1](http://arxiv.org/abs/2405.19143v1)|null|
|**2024-05-29**|**Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior**|Shuyu Cheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a Prior-guided Bayesian Optimization (P-BO) algorithm that leverages a surrogate model as a global function prior in black-box adversarial attacks. The P-BO algorithm initializes the mean function of a Gaussian process with the surrogate model's loss and updates the posterior distribution given the observed values of the objective function at sampled locations. The paper also proposes an adaptive integration strategy to automatically adjust a coefficient on the function prior by minimizing the regret bound.|[2405.19098v1](http://arxiv.org/abs/2405.19098v1)|[link](https://github.com/yibo-miao/pbo-attack)|
|**2024-05-29**|**Implementing arbitrary multi-mode continuous-variable quantum gates with fixed non-Gaussian states and adaptive linear optics**|Fumiya Hanamura et.al.|The key contributions from the paper's abstract and introduction are:* The proposal of a measurement-based method to implement general, multi-mode, and higher-order non-Gaussian gates using fixed non-Gaussian ancillary states and adaptive linear optics.* The importance of multi-mode and higher-order non-Gaussian gates for various applications in optical quantum technology, such as fault-tolerant universal quantum computing and quantum simulation.* The limitation of existing methods for implementing these gates, which often require a large number of CPGs and Gaussian operations, leading to noisy and inefficient implementations.* The goal of the paper is to provide a more resource-efficient and experimentally feasible method for implementing these gates.The paper's methodology is based on the following key ideas:* The decomposition of a general Hamiltonian into quadrature gates, which can be measured using linear optics and homodyne measurements.* The use of measurement-based implementation of quadrature gates, which allows for a more efficient and resource-light implementation of non-Gaussian gates.* The proposed method allows for the reduction of the number of required Gaussian and non-Gaussian ancillary modes, making it more efficient and practical for implementation.The paper also provides several examples and applications of the proposed method, including the implementation of multi-mode cubic quantum non-demolition gates and three-mode continuous-variable Toffoli gates.|[2405.19067v1](http://arxiv.org/abs/2405.19067v1)|null|
|**2024-05-29**|**Towards a computationally-efficient follow-up pipeline for blind continuous gravitational-wave searches**|Lorenzo Mirasola et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors develop a novel framework to evaluate the effectiveness of a generic CW follow-up as a function of signal mismatch and computing cost, achieving a ten-fold reduction in computing cost and simplifying the setup of multi-stage follow-ups.|[2405.18934v1](http://arxiv.org/abs/2405.18934v1)|null|
|**2024-05-29**|**Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep Feature Statistics**|Zhangkai Ni et.al.|The key contributions of this paper are the proposed Multi-scale Deep Feature Statistics (MDFS) model, which integrates deep features extracted from pre-trained visual models with a statistical analysis model, enabling opinion-unaware Blind Image Quality Assessment (OU-BIQA) without reliance on human rating data.|[2405.18790v1](http://arxiv.org/abs/2405.18790v1)|[link](https://github.com/eezkni/mdfs)|
|**2024-05-29**|**LP-3DGS: Learning to Prune 3D Gaussian Splatting**|Zhaoliang Zhang et.al.|The key contributions from the paper's abstract and introduction are:* The proposal of a learning-to-prune 3D Gaussian Splatting (LP-3DGS) method that learns a trainable mask to apply to the importance score of each Gaussian point, enabling automatic determination of the optimal pruning ratio for each scene.* The use of the Gumbel-Sigmoid method to make the masking function differentiable and compatible with the existing training process of 3DGS, allowing the model to learn the optimal pruning ratio in one training session.* The ability of LP-3DGS to produce a good balance between efficiency and high-quality rendering, making it a more efficient and effective method than traditional pruning methods that require manual tuning of the pruning ratio.|[2405.18784v1](http://arxiv.org/abs/2405.18784v1)|null|
|**2024-05-29**|**Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play Priors**|Zihui Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a Markov chain Monte Carlo algorithm, Plug-and-Play Diffusion Models (PnP-DM), that integrates diffusion models as priors in a principled way, enabling rigorous posterior sampling for general inverse problems without approximation, and outperforms existing methods on six inverse problems.|[2405.18782v1](http://arxiv.org/abs/2405.18782v1)|null|
|**2024-05-29**|**LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models**|Qin Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Language Model-based Optimal Differential Privacy (LMO-DP), a novel non-Gaussian mechanism for fine-tuning large language models with strong differential privacy guarantees, which achieves accurate results and outperforms existing methods.|[2405.18776v1](http://arxiv.org/abs/2405.18776v1)|null|
|**2024-05-29**|**Deep Bayesian Filter for Bayes-faithful Data Assimilation**|Yuta Tarumi et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Deep Bayesian Filtering (DBF) proposes a novel methodology for data assimilation on nonlinear state space models, which constructs new latent variables and learns a Gaussian inverse observation operator to ensure Gaussian posteriors, and outperforms existing methods in various tasks and conditions.|[2405.18674v1](http://arxiv.org/abs/2405.18674v1)|null|
|**2024-05-28**|**Biclustering a dataset using photonic quantum computing**|Ajinkya Borle et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction: The paper proposes the application of boson and Gaussian boson sampling to the problem of biclustering, using unitary dilation and Autonne-Takagi decomposition to embed datasets and simulate annealing to find clusters, with promising preliminary simulation results.|[2405.18622v1](http://arxiv.org/abs/2405.18622v1)|null|
|**2024-05-28**|**From Conformal Predictions to Confidence Regions**|Charles Guille-Escuret et.al.|The paper introduces Conformal Coverage Regions (CCR), a novel approach that employs conformal prediction intervals for model outputs to establish confidence regions for model parameters, providing finite-sample validity under minimal assumptions on the data distribution, and is applicable to both split conformal predictions and black-box methodologies.|[2405.18601v1](http://arxiv.org/abs/2405.18601v1)|null|
|**2024-05-28**|**Exploring the transition between Quantum and Classical Mechanics**|E. Aldo Arroyo et.al.|Here is a single sentence summarizing the key contributions of the paper:The study investigates the transition from quantum to classical mechanics using a one-dimensional free particle model, finding that the quantum probability density can be equivalent to the classical distribution of final positions, but only when there is no quantum interference, and proposes a novel method to recover the classical probability density from the quantum one using truncated Fourier analysis, which is relevant to the physical phenomenon of decoherence.|[2405.18564v1](http://arxiv.org/abs/2405.18564v1)|null|
|**2024-05-28**|**Covariance Operator Estimation via Adaptive Thresholding**|Omar Al-Ghattas et.al.|The key contributions from the paper's abstract and introduction are:* Introducing a covariance operator estimator that adaptively thresholds the sample covariance function using an estimate of the variance components.* Deriving an operator norm bound on the estimation error in terms of the sparsity level of the covariance and the expected supremum of the normalized process.* Showing that the adaptive threshold estimator outperforms the universal threshold and sample covariance estimators in nonstationary settings.* Focusing on the infinite-dimensional setting, where the paper reveals key dimension-free quantities that control the estimation error.* Highlighting the importance of exploiting structural assumptions in the design and analysis of estimators.In summary, the paper proposes a new estimator for sparse covariance operator estimation in infinite-dimensional function space, which adaptively thresholds the sample covariance function based on an estimate of the variance components. The paper derives an operator norm bound on the estimation error and shows that the adaptive threshold estimator outperforms universal threshold and sample covariance estimators in nonstationary settings.|[2405.18562v1](http://arxiv.org/abs/2405.18562v1)|null|
|**2024-05-28**|**Unisolvence of unsymmetric random Kansa collocation by Gaussians and other analytic RBF vanishing at infinity**|Alvise Sommariva et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proves that unsymmetric random Kansa collocation matrices are almost surely invertible for the Poisson equation with Dirichlet boundary conditions when using a class of analytic RBFs that vanish at infinity, including popular Positive Definite instances such as Gaussians, Generalized Inverse MultiQuadrics, and Matern RBFs.|[2405.18550v1](http://arxiv.org/abs/2405.18550v1)|null|
|**2024-05-28**|**Star Stream Velocity Distributions in CDM and WDM Galactic Halos**|Raymond G. Carlberg et.al.|The paper's abstract and introduction summarize the key contributions as: the development of non-Gaussian wings in stellar stream velocities due to dark matter subhalos, the measurement of these distributions in simulated Milky Way-like halos with different cosmologies, and the discussion of observational prospects to constrain the nature of galactic dark matter using stream measurements.|[2405.18522v1](http://arxiv.org/abs/2405.18522v1)|null|
|**2024-05-28**|**Effective phase diffusion for spin phase evolution under random nonlinear magnetic field**|Guoxing Lin et.al.|The key contributions from the paper's abstract and introduction are:1. A general theoretical description of spin self-diffusion under nonlinear gradient fields is proposed, extending the effective phase diffusion method for linear gradient fields.2. The proposed method reveals the general features of phase evolutions in nonlinear gradient fields, including phase diffusion, float phase evolution, and shift based on the starting position.3. The method shows that the diffusing and float phase evolutions come from the first and second derivatives of the gradient field, respectively.4. The phase variance and corresponding NMR signal attenuation are obtained, and demonstrated by calculating the phase diffusions under parabolic and cubic fields.5. The results indicate that signal attenuation obeys Gaussian attenuation for a short time, then changes to Lorentzian or Mittag-Leffler function attenuations when time increases.6. The method is versatile and can handle random order nonlinear gradient fields.7. The results can help develop advanced experimental techniques for NMR and MRI.The paper aims to provide a general theoretical framework for understanding spin self-diffusion under nonlinear gradient fields, which is important for interpreting experimental results and developing new techniques for NMR and MRI.|[2405.18514v1](http://arxiv.org/abs/2405.18514v1)|null|
|**2024-05-28**|**Classifying Overlapping Gaussian Mixtures in High Dimensions: From Optimal Classifiers to Neural Nets**|Khen Cohen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper derives closed-form expressions for Bayes optimal decision boundaries in binary classification of high-dimensional Gaussian mixture model (GMM) data, shows how they depend on eigenvectors of class covariances, and empirically demonstrates that deep neural networks approximate these optimal classifiers in both synthetic and real-world data.|[2405.18427v1](http://arxiv.org/abs/2405.18427v1)|null|
|**2024-05-28**|**GFlow: Recovering 4D World from Monocular Video**|Shizun Wang et.al.|Here are the key contributions from the paper's abstract, introduction, and body:* The paper proposes a novel framework, GFlow, that can reconstruct dynamic 4D scenes from a single monocular video input without any camera parameters or known camera poses.* GFlow uses 2D priors (depth and optical flow) to lift a video to a 4D explicit representation, allowing it to model the dynamic content and camera movements accurately.* The paper introduces a new pixel-wise densification strategy to integrate new visual content and a sequential optimization process to optimize camera poses and 3D Gaussian points.* GFlow can track any points across frames in 3D world coordinates without prior training and segment moving objects from the scene in an unsupervised manner.* The paper demonstrates the effectiveness of GFlow on two challenging video datasets, DAVIS and Tanks and Temples, and shows its capabilities in video reconstruction, object segmentation, and point tracking.|[2405.18426v1](http://arxiv.org/abs/2405.18426v1)|null|
|**2024-05-28**|**3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian Splatting**|Qihang Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes 3DitScene, a unified scene editing framework that leverages language-guided disentangled Gaussian Splatting to enable seamless editing from 2D to 3D, allowing precise control over scene composition and individual objects at different levels of granularity.|[2405.18424v1](http://arxiv.org/abs/2405.18424v1)|null|
|**2024-05-28**|**3D StreetUnveiler with Semantic-Aware 2DGS**|Jingwei Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces StreetUnveiler, a 3D reconstruction method that uses hard-label semantic 2D Gaussian Splatting and a novel time-reversal inpainting framework to remove objects from in-car camera videos and reconstruct an empty street scene.|[2405.18416v1](http://arxiv.org/abs/2405.18416v1)|null|
|**2024-05-28**|**Short-time Fokker-Planck propagator beyond the Gaussian approximation**|Julian Kappler et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a perturbation approach to calculate the short-time propagator of the one-dimensional Fokker-Planck equation to arbitrary order, preserving probability exactly, and derive perturbative expansions for expectation values, moments, and entropy production rates.|[2405.18381v1](http://arxiv.org/abs/2405.18381v1)|null|
|**2024-05-28**|**Improving Linear System Solvers for Hyperparameter Optimisation in Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The key contributions from the paper's abstract and introduction can be summarized as follows:1. The paper introduces three improvements to iterative methods for Gaussian process regression:	* A pathwise gradient estimator, which reduces the required number of solver iterations and amortises the computational cost of making predictions.	* Warm starting linear system solvers with the solution from the previous step, which leads to faster solver convergence at the cost of negligible bias.	* Early stopping linear system solvers after a limited computational budget, which synergises with warm starting, allowing solver progress to accumulate over multiple marginal likelihood steps.2. The paper demonstrates that these improvements can provide speed-ups of up to 72x when solving to tolerance and decrease the average residual norm by up to 7x when stopping early.3. The paper introduces a hierarchical view of marginal likelihood optimisation for iterative GPs, which involves bi-level optimisation with an outer-loop optimiser, a gradient estimator, and a linear system solver.4. The paper presents results on several datasets, including 3DROAD, SONG, BUZZ, and HOUSE, using different linear system solvers (conjugate gradients, alternating projections, and stochastic gradient descent) and pathwise or standard gradient estimators with or without warm starting.5. The paper evaluates the performance of the different methods in terms of relative residual norms, test root-mean-square errors, and test log-likelihoods, and shows that the proposed improvements can lead to better performance and faster convergence.|[2405.18457v1](http://arxiv.org/abs/2405.18457v1)|null|
|**2024-05-28**|**Warm Start Marginal Likelihood Optimisation for Iterative Gaussian Processes**|Jihao Andreas Lin et.al.|The paper's main contributions can be summarized as follows:1. Iterative marginal likelihood optimization: The paper proposes a three-level hierarchy of marginal likelihood optimization for iterative Gaussian processes, which leverages the use of iterative linear system solvers to approximate marginal likelihood gradients up to a specified numerical precision.2. Warm start: The paper introduces a warm start approach, where the solutions of previous iterations are used as initializations for subsequent iterations, providing a computational speedup while maintaining similar performance to the conventional method.3. Empirical results: The paper provides empirical results on various regression tasks, showing that warm start optimization achieves similar results to conventional optimization while reducing computational costs, with speedups of up to 16x.4. Analysis: The paper presents an analysis of the effectiveness of the warm start approach, highlighting the benefits and limitations of the method, and demonstrates the importance of choosing a suitable linear system solver.|[2405.18328v1](http://arxiv.org/abs/2405.18328v1)|null|
