# arxiv-daily
 Automated deployment @ 2024-05-28 20:11:14 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements for 3D Gaussian Splatting (3DGS) by approximating dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, achieving comparable image quality while decreasing storage costs.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling real-time processing of complete human colonoscopies, and achieving a 70% improvement in mapping coverage over ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization, a method that improves 3D scene modeling by representing scenes with a hierarchical assembly of Gaussians, using a compact weighting network to dynamically determine the influence of each pyramid level during rendering.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes the first RGB-only SLAM system with a dense 3D Gaussian map representation that leverages global optimization and online map deformations at loop closure and global bundle adjustment, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve the sparse-view reconstruction of 360-degree scenes with low-cost fine-tuning, achieving multi-view consistent scenes with coherent details.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model that can be generated from imagery.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* Demonstrating experiments on simulated and real-world terrain imagery, showing that NEMos can generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.Note: This summary is under 50 words.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown scenes, which uses a divide-and-conquer mapping strategy and an adaptive map growth strategy to represent the scene as a set of neural blocks, achieving scalability and competitive performance in both mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HDR-GS, a novel 3D Gaussian Splatting-based framework for high dynamic range novel view synthesis, outperforming state-of-the-art NeRF-based methods by 3.84 and 1.91 dB while enjoying 1000x inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a novel steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point cloud files in an invisible manner, with robust security, high fidelity, large capacity, and versatility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper's abstract and introduction are:* The authors propose a new method for enhancing translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM systems, which is essential for accurate state estimation.* The method improves translation estimation using a 3-DoF Bundle Adjustment, while keeping the rotation estimate fixed, unlike traditional 6-DoF Bundle Adjustment.* The authors also update the rotation estimate by taking into account IMU measurements and gyroscope bias, which is not done in traditional ORB-SLAM3.* The method aims to achieve performance comparable to Stereo-NEC while maintaining a runtime similar to that of ORB-SLAM3.* The authors provide an overview of the Visual-Inertial SLAM system, its limitations, and the importance of accurate initialization.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes an approach that addresses the limitations of Neural Radiance Fields (NeRFs) in rendering high-frequency view-dependent appearance by introducing ray tracing into the rendering model, enabling consistent and high-quality reflection synthesis of nearby and distant scene content, while reducing the need for large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in under 50 words:The paper introduces SynCHMR, a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos in a common global coordinate system, leveraging human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel method for rendering specular objects that captures both geometry and view-dependent appearance, achieving high-quality modeling and fast evaluation, outperforming state-of-the-art methods on both synthetic and real datasets.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting conditions to improve camera relocalization, using a hash-encoded NeRF and novel techniques to address noisy image gradient computing and degraded pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring raw sensor input, pose estimation, and high-level perception annotation, to facilitate the study of multi-robot perception algorithms and scene understanding.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:Key contributions:* Developing approaches to minimize human effort in deploying perception-based robotic systems to previously unseen environments through continual learning and reducing human annotations.* Investigating the use of vision foundation models for extremely label-efficient training in robotic use cases.* Proposing novel methods for automatic target-less camera-LiDAR calibration, label-efficient panoptic segmentation, and collaborative robot mapping.* Exploring the concept of "continual SLAM" for lifelong simultaneous localization and mapping in real-world domains.Note: The research focuses on reducing the need for human annotations and developing more efficient methods for robotic perception and mapping tasks.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts within seconds, representing a significant improvement over existing methods.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency, and introducing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) on large-scale scenes, which reduces training time by 6+ times and achieves state-of-the-art rendering quality while maintaining high-fidelity rendering performance.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces MG-SLAM, a monocular Gaussian SLAM system with a CLIP feature-based loop closure module, which enables real-time mapping, high-fidelity reconstruction, and a high-level understanding of the environment, without requiring RGB-D inputs or depth sensors.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a novel real-time rendering method that disentangles appearance changes from geometry, achieving state-of-the-art rendering fidelity on 3 datasets and 100 times faster rendering speed than NeRF-based methods.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a framework for single-view clothed human reconstruction, which employs kinematic information to achieve motion-aware Gaussian split and surface deformation detection, improving reconstruction quality and realism, and achieving state-of-the-art results in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables the estimation of the 6D pose of an unknown target spacecraft relative to a monocular camera, using a neural radiance field (NeRF) to generate a large dataset of images, and trains an off-the-shelf pose estimation network on this dataset.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed NV-LIO framework uses normal vectors from LiDAR point clouds to enhance point cloud registration in indoor environments with multifloor structures, addressing degeneracy and loop closure issues using a tightly-coupled LIO approach.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present MVSGaussian, a generalizable Gaussian Splatting method that combines Multi-View Stereo and pixel-aligned Gaussian representations, achieves real-time rendering with better synthesis quality, and demonstrates state-of-the-art performance on multiple datasets.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper aims to integrate neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents. The contributions include:* A comprehensive overview of NeRF and 3D-GS, including their applications, implementation challenges, and benefits.* A discussion on the challenges of integrating NeRF and 3D-GS in 6G networks, including storage and transmission constraints, computational complexity, and latency requirements.* A proposed federated learning design for training NeRF and 3D-GS models over wireless networks, which takes into account the practical constraints on communication, computation, and storage resources.* A proposed joint computation and communication design for rendering and transmitting NeRF and 3D-GS models, which aims to minimize end-to-end latency while preserving quality of experience requirements.* A new semantic communication enabled 3D content transmission design, which exploits radiance field models as a semantic knowledge base to reduce communication overhead for distributed inference.* The utilization of radiance field rendering in wireless applications such as radio mapping and radio imaging.Overall, the paper provides a comprehensive overview of the integration of NeRF and 3D-GS in 6G networks and presents novel solutions to address the challenges of efficient representation, transmission, and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly models point light attenuation, and optimizes a fully neural material renderer to estimate 3D shape from photometric stereo images with high accuracy.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions from the paper's abstract and introduction are:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems, using a modified gradient-based texture optimization method and an evaluative mechanism called the 'Judge'. The Judge assesses the realism of the generated objects and can be optimized using different strategies. The paper also discusses the importance of generating realistic adversarial objects that can blend in with real-world environments, as existing methods often lack realism.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions of the paper in a single sentence under 50 words:The authors propose a NeRF-based ray tracing method to model electromagnetic fields in RIS-enabled environments, achieving accurate characterization of signal dynamics and enabling efficient RIS deployment, with experimental results from simulations and measured data demonstrating its effectiveness.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that combines ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to enable reliable localization and mapping in diverse scenarios and dynamic environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The paper's abstract and introduction discuss the limitations of 3D Gaussian Splatting (3DGS), which achieves rapid rendering speeds while maintaining excellent image quality but requires substantial storage and large memory footprints due to the numerous 3D Gaussians involved. The authors propose Factorized 3D Gaussian Splatting (F-3DGS), which significantly reduces storage costs by employing factorization techniques, including canonical polyadic and vector-matrix decompositions, to represent dense 3D Gaussians using fewer Gaussians. The approach achieves a 90% reduction in storage usage while maintaining comparable image quality, making it a feasible solution for real-time applications with limited resources.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that scales 3D Gaussian Splatting to large scenes by arranging Gaussians in a pyramidal structure, initializing them with a rapidly trained NeRF, and dynamically weighting their contributions for efficient rendering.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that leverages pretrained 2D diffusion models with low-cost fine-tuning to reconstruct 360-degree scenes from sparse views, using an iterative update strategy to fuse generated views with initial sparse inputs.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here are the key contributions summarized in a single sentence under 50 words:The paper introduces Neural Elevation Models (NEMos), which integrate Neural Radiance Fields with a height field for terrain representation, enabling continuous and differentiable terrain mapping and path planning using joint training and quantile regression.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that can embed 3D scenes and images into original point cloud files, ensuring security, fidelity, and high capacity, with applications in copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes an approach to improve Neural Radiance Fields (NeRFs) by introducing ray tracing to render high-frequency view-dependent appearance, particularly for objects with shiny reflections, while reducing computational expense and increasing rendering speed.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the introduction of Neural Directional Encoding (NDE) and its application to novel-view synthesis of specular objects, achieving both high-quality modeling of view-dependent effects and fast evaluation, and proposing a novel spatio-spatial parameterization to encode near-field interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions, implements a hash-encoded NeRF for fast training and robust camera pose refinement, and addresses noisy image gradient computing issues through a re-devised filter and gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Light-Directional Mesh (LDM), a novel feed-forward framework generating high-fidelity, textured 3D mesh from a single image or text prompts, utilizing a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, achieving improved quality and compression efficiency, particularly in handling large motions and long-duration sequences.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that splits scenes into blocks, trains 3DGS locally on each block, and guarantees consistency through a shared 3D Gaussian model, achieving 6+ times faster training time while maintaining high rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, achieving state-of-the-art rendering fidelity, 100 times faster rendering than NeRF-based methods, and disentangling appearance changes for smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|The paper introduces an innovative framework, Motion-Based 3D Clothed Humans Synthesis (MOSS), which employs kinematic information to achieve motion-aware Gaussian split on the human surface, overcoming limitations of current methodologies that neglect the influence of motion on surface deformation.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The key contributions from the paper's abstract and introduction are:The development of a novel method that enables an "off-the-shelf" spacecraft pose estimation model to be applied on an unknown target, which is a key step towards autonomous rendezvous and proximity operations in Active Debris Removal missions. The method uses a Neural Radiance Field (NeRF) to generate a large and diverse dataset from a sparse set of spaceborne images, which is then used to train an off-the-shelf pose estimation network. The method is validated on Hardware-In-the-Loop images of SPEED+, demonstrating the ability to successfully estimate the pose of an unknown target using a model-agnostic pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:MVSGaussian introduces a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo and a hybrid Gaussian rendering method, achieving real-time rendering with better synthesis quality, 13.3x less training computational cost, and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions of the paper's abstract and introduction are:* The integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) techniques in 6G wireless networks for immersive communication experiences.* A comprehensive overview of the basics of radiance field rendering techniques, their applications, and implementation challenges over wireless networks.* The over-the-air training of NeRF and 3D-GS models over wireless networks using various learning techniques, with a focus on federated learning design over a hierarchical device-edge-cloud architecture.* The discussion of three practical rendering architectures of NeRF and 3D-GS models at wireless network edges, model compression approaches, and joint computation and communication designs to enhance rendering efficiency.* The proposal of a new semantic communication-enabled 3D content transmission design, where radiance field models are exploited as semantic knowledge bases to reduce communication overhead for distributed inference.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and optimizes a fully neural material renderer to achieve competitive reconstruction accuracy using only 6 lights.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing an evaluative mechanism called the "Judge" to assess and refine the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to accurately model dynamic electromagnetic fields in RIS-enabled wireless environments, enabling efficient RIS deployment and improving communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve high-fidelity scene representation, accurate real-time tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive survey of methodologies enabling large language models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction within embodied AI systems, and identifying challenges and future research directions.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The paper presents a method to convert between implicit scene representations, such as neural radiance fields (NeRFs), and explicit scene representations, such as Gaussian splatting (GS). The authors demonstrate that their approach can achieve the best of both worlds, providing both superior rendering quality and real-time rendering capability. The approach is illustrated through a number of examples, including rendering images from training views, fitting or updating a NeRF, and modifying the NeRF to update the map and distilled features.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The paper reviews the development and implementation principles of Dynamic NeRF, an implicit method for 3D reconstruction and representation with high resolution, highlighting its potential in practical applications and future research directions.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The proposed method synergistically integrates a coordinate-based network with a multi-plane representation to improve the performance of neural radiance fields (NeRFs) from sparse inputs.* The method uses residual connections to combine the two features, allowing them to preserve their inherent properties and improving the stability and efficiency of training.* The proposed method outperforms existing methods in dynamic NeRFs from sparse inputs, achieving comparable results to explicit encoding with fewer parameters.* The method reduces the number of parameters by skipping the allocation of a spatial low-resolution grid and replacing it with coordinate-based features.* The proposed method is effective in capturing low-frequency details and reducing overfitting, making it suitable for real-world applications.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling (DNR) module to enable point-based editable NeRF pipeline PR^2T-NeRF, allowing for direct object pose manipulation and inpainting of empty regions, achieving state-of-the-art performance in 3D object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces a novel approach to generating real-time 3D facial reconstructions using LiDAR augmented reconstruction, leveraging monocular depth estimation, LiDAR + TrueDepth, and template modeling techniques to achieve high-fidelity and interactive holographic overlays.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The contributions of this paper are a novel approach, Truncated Depth NeRF (TD-NeRF), that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses, and employs a robust inter-frame point constraint that enhances robustness against depth noise during training, resulting in superior performance and more accurate depth geometry.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce LIVE, a novel design method for interactive LaTeX graphic items, enabling the creation of dynamic and interactive components, such as Gitems, to enhance the reading experience and efficiency of academic papers, with open-source code available on GitHub.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|The key contributions from the paper's abstract and introduction are:* proposing a text-driven 3D content generation and editing method, SketchDream, which supports NeRF generation from given hand-drawn sketches and achieves free-view sketch-based local editing;* introducing a sketch-based multi-view image generation diffusion model that utilizes depth guidance to establish spatial correspondence and ensures 3D consistency;* proposing a coarse-to-fine editing approach that generates realistic results with refined details by local enhancement;* showcasing the ability of SketchDream to generate high-quality 3D objects under generalized categories and support detailed editing of reconstructed or generated NeRFs.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The paper presents CudaSIFT-SLAM, a novel monocular Visual Simultaneous Localization and Mapping (V-SLAM) system that processes complete human colonoscopies in real-time, overcoming frequent tracking losses and occlusions by using SIFT features and brute-force matching, achieving 88% mapping coverage in the C3VD dataset and 53% in a real screening colonoscopy.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel RGB-only SLAM system that combines frame-to-frame tracking with a dense deformable 3D Gaussian map, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM system for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed method, ETA, enhances translation accuracy during visual-inertial SLAM initialization by using a 3-DoF bundle adjustment and incorporating IMU measurements and gyroscope bias, demonstrating improved performance and robustness in challenging scenarios.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The SynCHMR approach jointly reconstructs camera trajectories, human meshes, and dense scene point clouds in common world frames by combining human-aware metric SLAM with scene-aware SMPL denoising, addressing depth, scale, and dynamic ambiguities in monocular videos.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The key contributions of the paper include the creation of a real-world multi-robot collaborative perception dataset, featuring both indoor and outdoor sequences, multiple sensor spatial viewpoints, robot types, multi-rate and multi-modal data, and coverage ranges, catering to diverse research needs through raw sensor data streams, pose estimation, and high-level perception annotation.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are as follows:* The researcher aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning.* The paper introduces novel methods for efficient robot learning, including:	+ Continual learning for robotics: enables an autonomous agent to automatically adapt to unseen domains while retaining high performance on previous domains.	+ Label-Efficient Panoptic Segmentation: allows for extremely label-efficient training of panoptic segmentation networks using semantic rich image features from a frozen vision foundation model.	+ Collaborative Robot Mapping: utilizes multi-agent collaboration to share information and enable frequent updates to capture structural changes in the environment.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces MG-SLAM, a monocular Gaussian SLAM system with a CLIP feature-based loop closure module, which enables real-time mapping, high-fidelity reconstruction, and a high-level understanding of the environment, without requiring RGB-D inputs or pre-defined bounding boxes.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel LiDAR-inertial odometry framework, NV-LIO, which utilizes normal vectors from LiDAR scans to enhance point cloud registration and overcome challenges in indoor environments with multifloor structures.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work in diverse scenarios, utilizing ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to overcome common challenges in robotic vision and SLAM.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper presents a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving accurate real-time tracking and high-fidelity reconstruction while reducing memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a lightweight circular convolutional Transformer network (CCTNet) that improves place recognition by capturing structural information in point clouds and facilitating cross-dimensional interaction, achieving better performance than comparable methods on several datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes an optimization-based SLAM approach that simultaneously optimizes the robot trajectory and occupancy map using 2D laser scans and odometry information, differing from existing approaches that first estimate robot poses before mapping.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|The key contributions of this paper are the introduction of IPC, a consensus-based method that incrementally builds a good approximation of the maximally consistent set of loop closure measurements, and its evaluation on standard datasets, showcasing its ability to handle large numbers of outliers while providing online performances.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents OverlapMamba, a novel network for LiDAR-based place recognition that utilizes raw range views as input, achieving robustness, speed, and real-time efficiency in detecting loop closures and place recognition, outperforming typical LiDAR and multi-view combination methods.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes SceneFactory, a workflow-centric and unified framework for incremental scene modeling, which supports various applications, including SLAM, multi-view depth estimation, LiDAR completion, and 3D reconstruction, with contributions in modeling, representation, and implementation.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|The paper's abstract and introduction highlight the contributions of a novel visual SLAM system called NGD-SLAM, which achieves real-time performance on a single CPU without GPU support and maintains high localization accuracy in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents an innovative approach to generating real-time 3D facial reconstructions using LiDAR augmented reconstruction, leveraging monocular depth estimation, LiDAR+TrueDepth data, and template modeling to achieve high-fidelity, interactive, and immersive holographic overlays on a portable device like an iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, introducing a novel sampling strategy, coarse-to-fine training, and inter-frame point constraint to improve pose estimation accuracy and robustness.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel framework that integrates sparse visual odometry with 3D Gaussian Splatting for dense visual simultaneous localization and mapping, eliminating the need for depth maps and enhancing tracking robustness, achieving state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose NeuRSS, a novel framework for sidescan sonar-based simultaneous localization and mapping (SLAM) that incorporates neural rendering to estimate bathymetry and leverages loop closures to improve positioning and mapping accuracy, addressing the limitation of dead reckoning errors in autonomous underwater vehicles.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NGM-SLAM, a 3D Gaussian Splatting (3DGS) SLAM system that uses neural radiance field submaps for progressive scene expression, high-quality hole filling, and real-time loop closure detection, achieving state-of-the-art scene reconstruction and tracking performance.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey and analysis of Neural Radiance Fields (NeRF) for enhancing the capabilities of autonomous robots, focusing on perception, localization, navigation, and decision-making, and explores promising avenues for future research and development.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper aims to bridge the gap in place recognition (PR) technology by highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, seeking to develop scalable, adaptable, and efficient PR solutions integrating advanced artificial intelligence (AI) technologies.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the key contributions in a single sentence under 50 words: The authors propose a neural mapping framework, anchoring lightweight neural fields to a pose graph, integrating loop closure constraints while limiting reintegration, and showing improved scalability and quality compared to existing state-of-the-art methods.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|The paper proposes a hybrid visual SLAM system that combines deep feature extraction and deep matching methods to enhance adaptability in challenging environments, showcasing its superiority in terms of localization accuracy and tracking robustness over traditional approaches.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose X-SLAM, a real-time and differentiable dense SLAM system that leverages the complex-step finite difference method for efficient numerical derivatives, enabling real-time task-aware optimization and achieving better accuracy and faster convergence.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose Panoptic-SLAM, a novel visual SLAM system that uses panoptic segmentation to detect and filter moving objects, including unknown and unlabeled objects, achieving robust localization in dynamic environments.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:1. **Cooperative MP-SLAM**: The authors propose a Bayesian particle-based Sum-Product Algorithm (SPA) for cooperative MP-SLAM, enabling data fusion over different observations of map features (VAs) by different MTs and cooperative MT-to-MT measurements using RF signals.2. **Integrated IMU**: The authors fully integrate an Inertial Measurement Unit (IMU) as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation, allowing to cope with complex trajectories.3. **Analysis of VA data fusion and cooperative measurements**: The authors analyze the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulation.Note that the abstract and introduction provide an overview of the paper's contributions, whereas the paper itself is a technical presentation of the methodology and results.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Real-time Gaussian SLAM (RTG-SLAM) system achieves real-time 3D reconstruction at scale using a compact Gaussian representation and on-the-fly optimization, demonstrating comparable quality to state-of-the-art NeRF-based SLAM while significantly reducing memory and computation cost.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
