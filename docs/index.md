# arxiv-daily
 Automated deployment @ 2024-05-29 08:18:42 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining high-quality rendering by factoring out redundant information in 3D Gaussian representations, improving rendering speed and efficiency.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The paper presents CudaSIFT-SLAM, a V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling real-time processing of human colonoscopies and achieving longer sub-maps and higher mapping coverage, with a 70% improvement over ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The key contributions of the paper are the introduction of Pyramidal 3D Gaussian Splatting (PyGS), which achieves high-fidelity visual results and accelerated rendering performance on large-scale scenes, through a hierarchical assembly of Gaussians and dynamic weighting of each level's contribution.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes an RGB-only SLAM system that combines a frame-to-frame tracker with global consistency and a dense deformable 3D Gaussian map, achieving high-quality reconstruction and rendering while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes a novel method, SparseSplat360, that uses pretrained 2D diffusion models to improve sparse-view 360° scene reconstruction, filling in missing details and cleaning novel views through a cascade of in-painting and artifact removal models.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model that can be generated from imagery.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework using quantile regression.* Developing a path planning algorithm that leverages the continuous and differentiable nature of the height field to optimize for distance, slope changes, and control effort.* Demonstrate the effectiveness of NEMos on simulated and real-world terrain imagery, showing high-quality reconstructions and smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in one sentence under 50 words:The authors propose NeB-SLAM, a neural block-based RGB-D SLAM system that adapts to unknown scenes using a divide-and-conquer mapping strategy and adaptive map growth, enabling real-time, scalable, and predictive mapping and tracking performance.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that renders HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The contributions of the paper can be summarized as: proposing the first 3DGS steganography framework (GS-Hider) for embedding and extracting 3D scenes and images, ensuring security, fidelity, and versatility, and experimenting on the 3DGS dataset to demonstrate robustness and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* Proposing a new method called ETA that enhances translation accuracy during the initialization stage in stereo Visual-Inertial SLAM (VI-SLAM) systems, independently estimating translation using 3-DoF bundle adjustment while keeping rotation estimate fixed.* Improving upon existing methods, including ORB-SLAM3 and Stereo-NEC, by providing comparable performance with reduced runtime and enhanced accuracy in challenging scenarios.* Focusing on the disjoint method for initialization, which typically yields more accurate results than the joint method, and building on Stereo-NEC by separately estimating rotation using IMU integration and leveraging precise rotation estimates to enhance translation estimation.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper addresses the limitations of Neural Radiance Fields (NeRFs) in rendering high-frequency view-dependent appearance of shiny objects, specifically by introducing ray tracing to synthesize consistent reflections of nearby and distant content using a small and inexpensive network.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), which combines best practices from visual SLAM and Human Mesh Recovery (HMR) to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame from monocular videos, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a view-dependent appearance encoding of Neural Radiance Fields (NeRF) for rendering specular objects, which captures both geometry and view-dependent appearance, and outperforms state-of-the-art methods while achieving fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizing a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, heterogeneous sensor modalities, and diverse spatial viewpoints, to facilitate research in multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The development of techniques for efficient and label-efficient deployment of perception-based robotic systems in previously unseen environments.* The application of continual learning and domain adaptation concepts to improve the performance of robotic systems in adapting to new domains.* The use of vision foundation models to leverage semantically rich image representations for training downstream tasks with minimal human annotations.* The proposal of novel methods for camera-LiDAR calibration, panoptic segmentation, and mapping in robotics.(Note: The abstract and introduction provide a brief overview of the paper's contributions, but do not exhaustively summarize all the research results.)|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes LDM, a novel feed-forward framework that generates high-quality mesh assets with illumination-decoupled textures from single images or text prompts, enabling fast and efficient 3D content creation.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end learning scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior rate-distortion performance and efficient representation of dynamic and long-sequence radiance fields.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality by decomposing scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the paper's key contributions:This paper presents MG-SLAM, a monocular Gaussian SLAM system that utilizes a language-extended loop closure module based on CLIP features to correct drift errors, achieve high-fidelity reconstruction, and perform real-time mapping with depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent Gaussian primitives and decomposes rendering color to achieve accurate reconstruction of dynamic scenes with vastly varying appearances, outperforming state-of-the-art methods in terms of both quality and efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework for single-view clothed human reconstruction that incorporates kinematic information to achieve motion-aware Gaussian split on the human surface, enabling realistic clothing deformation and improving visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions in the abstract and introduction:The authors propose a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, which is essential for autonomous rendezvous and proximity operations in Active Debris Removal missions. The method leverages a Neural Radiance Field (NeRF) to generate a large dataset of diverse images from a small set of images taken by the spacecraft, allowing an off-the-shelf pose estimation network to be trained on the target spacecraft without knowing its CAD model.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose NV-LIO, a normal vector-based LiDAR-inertial odometry framework designed for simultaneous localization and mapping in indoor environments with multifloor structures, addressing challenges in point cloud registration and loop closure, and achieving robust registration and mapping capabilities.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a novel generalizable Gaussian Splatting method derived from Multi-View Stereo, which efficiently reconstructs unseen scenes with real-time rendering, better synthesis quality, and fast per-scene optimization, achieving state-of-the-art performance on multiple datasets.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the abstract and introduction:The key contributions of the paper can be summarized as follows:* The paper provides an overview of the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for immersive communication applications.* The paper highlights the importance of representing 3D contents in a efficient manner for transmitting and reconstructing them over wireless networks.* It discusses the pros and cons of NeRF and 3D-GS as 3D representation approaches, including their computational resources, storage requirements, and rendering efficiency.* It proposes a new semantic communication enabled 3D content transmission design, which uses radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* It also proposes a new joint computation and communication design for distributed radiance field rendering.* The paper reviews the relevant literature on NeRF and 3D-GS, including their applications and implementation challenges over wireless networks.* It discusses the importance of embracing NeRF and 3D-GS in 6G networks for immersive communication applications, including telepresence and immersive gaming.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions of the paper can be summarized in one sentence:The authors propose a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly models point light attenuation and raytraces cast shadows, and optimizes a fully neural material renderer to estimate 3D shape and texture from photometric stereo images.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems, which can evade detection and pose a realistic threat to the system's robustness.* The method introduces a novel entity called the 'Judge' that assesses the realism of adversarial objects and integrates this evaluation into the loss function to encourage the neural object renderer to produce realistic and adversarial textures.* The Judge is designed to evaluate objects based on three criteria: color similarity, law of traffic, and real-life appearance, with each criterion having a different weight.* The paper explores various strategies for optimizing the Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced vision-language models, pretraining neurosymbolic systems, and utilizing traditional image processing techniques.* The authors highlight the limitations of using adversarial objects with minor textural adjustments, such as stickers or color changes, and propose a new approach to generating more sophisticated and realistic adversarial objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions from the paper's abstract and introduction can be summarized as:* A novel Neural Radiance Fields (NeRF) based ray tracing method for modeling electromagnetic signals in Reconfigurable Intelligent Surface (RIS) enabled wireless environments.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that combines fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to overcome the limitations of conventional SLAM approaches in diverse scenarios.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel method that reduces storage requirements while preserving image quality by representing dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, achieving a 90% reduction in storage while maintaining image quality.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization improves large-scale scene representation by arranging Gaussians in a hierarchical pyramid and dynamically weighting their contributions, achieving a significant performance leap and over 400 times faster rendering time than current state-of-the-art approaches.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a novel method for reconstructing 360-degree scenes from sparse views by leveraging pre-trained 2D diffusion models and 3D Gaussians, achieving superior performance and multi-view consistency with few input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions mentioned in the abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos) which combine Neural Radiance Fields with a continuous and differentiable height field, enabling the generation of terrain from imagery and allowing for smoother path planning.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction as a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS) for novel view synthesis, a framework that can efficiently render HDR images and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art methods with shorter training time and faster inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The paper's abstract and introduction highlight the need for steganography techniques tailored for 3D Gaussian Splatting (3DGS), which requires protecting the copyright and privacy of 3D scenes while hiding messages into the 3DGS point cloud files in an invisible manner, ensuring security, fidelity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents an approach that introduces ray tracing into Neural Radiance Fields (NeRF) to improve rendering of highly specular objects, synthesizing consistent reflections of nearby and distant content, and rendering high-quality specular reflections with increased efficiency.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a novel method that efficiently models high-frequency view-dependent appearance and interreflection effects in specular objects, outperforming the state-of-the-art on view synthesis tasks while allowing for fast inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a novel two-staged pipeline for camera relocalization under varying lighting conditions, utilizing neural radiance fields (NeRFs) and a hash-encoded NeRF representation to normalize images with different lighting conditions and achieve state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a single sentence summarizing the key contributions of the paper: The paper proposes LDM, a novel feed-forward framework generating high-quality triangular meshes with illumination-decoupled textures from text or single images in seconds, introducing a tensorial SDF representation and adaptive conversion strategy, and integrating a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field representation and compression, which achieves superior quality and compression efficiency for volumetric videos with large motions and long durations.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly using Alternating Direction Method of Multipliers (ADMM) to accelerate training on large-scale scenes while maintaining rendering performance, reducing training time by 6+ times.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes and decomposes rendering color into static and dynamic terms to reconstruct 3D scenes with vastly varying appearances efficiently and accurately.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a single-sentence summary of the key contributions from the paper's abstract and introduction:The authors propose Motion-Based 3D Clothed Humans Synthesis (MOSS), an innovative framework that incorporates kinematic information to achieve motion-aware Gaussian split on human surfaces, improving 3D clothed human reconstruction with state-of-the-art visual quality and efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper's abstract and introduction key contributions are:* The development of a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target without requiring the CAD model of the target.* The use of an in-the-wild Neural Radiance Field (NeRF) to represent the target spacecraft and generate a large dataset of images with varying illumination conditions.* The ability to train a pose estimation network from a sparse set of images, which can be used for autonomous rendezvous and proximity operations during Active Debris Removal missions.* The validation of the method on realistic Hardware-In-the-Loop (HIL) images from the SPEED+ dataset, demonstrating its feasibility for practical applications.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MVSGaussian, a new generalizable 3D Gaussian representation approach that uses Multi-View Stereo for efficient reconstruction, hybrid Gaussian rendering for enhanced generalization, and a consistent aggregation strategy for fast per-scene optimization, achieving real-time rendering and better view synthesis quality.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here are the key contributions summarized in a single sentence under 50 words:The paper provides a comprehensive overview of integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G wireless networks, addressing technical challenges and proposing novel solutions for efficient 3D content representation, transmission, and reconstruction.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and optimizes a fully neural material renderer to achieve competitive reconstruction accuracy.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a "Judge" mechanism that assesses the realism of objects and integrates their scores into the loss function to optimize for both adversarial effectiveness and visual realism.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions from the paper's abstract and introduction are:* Developing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments.* Proposing a two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.* Introducing a subtly designed framework that properly tracks the entire transmission path, enhancing our understanding of signal behavior in real-world scenarios.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve high-fidelity scene representation, accurate real-time tracking, and high-performance rendering while reducing memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This survey provides a comprehensive overview of integrating Large Language Models (LLMs) with 3D spatial data, highlighting their potential to advance spatial comprehension and interaction in embodied AI systems, and discussing current methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* Developing a procedure to convert between implicit representations (NeRFs) and explicit representations (Gaussian splatting) in a way that achieves the best of both worlds: superior rendering quality and real-time rendering speed.* Demonstrating that this conversion can be done efficiently, with minor computational cost compared to training the two representations from scratch.* Showcasing the effectiveness of this approach through experiments on various datasets and scenarios, including situations with sparse views and changing scenes.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive review of Dynamic Neural Radiance Field (NeRF) developments, analyzing the principles, techniques, and most recent projects from 2021 to 2023, highlighting its potential applications and providing a detailed comparison of various features and implementation methods.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The proposed method synergistically integrates a coordinate-based network with a multi-plane representation to improve neural radiance fields (NeRFs) from sparse inputs.* The coordinate-based network captures low-frequency context, while the multi-plane representation captures fine-grained details, allowing for a model less sensitive to hyperparameters and performance variations.* The proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms others for static and dynamic NeRFs with sparse inputs.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose an implicit ray transformation strategy and a differentiable neural-point resampling (DNR) module, enabling point-based editable NeRF pipeline (PR^2T-NeRF) for scene object removal and inpainting tasks, achieving state-of-the-art performance with high-quality rendering visualization.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction.* The approaches are designed to run on a portable device like iPhone 14 Pro, which requires novel engineering constraints, including monocular estimation, portability, high fidelity, and instantaneous rendering.* The paper introduces three high-fidelity reconstruction tools that can handle dynamic scenes and provide metric accurate facial reconstructions.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, and introduces three key advancements: depth-based ray sampling, coarse-to-fine training, and robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LIVE, a novel method to design interactive LaTeX graphic items, overcoming the limitations of traditional static content, and enabling the creation of dynamic and interactive components for academic papers, while maintaining objectivity and scientificity.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a single sentence summarizing the contributions from the paper's abstract and introduction:The authors propose SketchDream, a text-driven 3D content generation and editing method that leverages sketches and text prompts to generate high-quality 3D models and supports detailed editing of reconstructed or generated models.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a novel monocular V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features, brute-force matching, and a GPU implementation, achieving real-time mapping and relocation in challenging colonoscopy scenarios.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel RGB-only SLAM system using 3D Gaussian splatting, which achieves superior or comparable performance with existing methods in tracking, mapping, and rendering accuracy, while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction: The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM system for unknown scenes, which achieves real-time, competitive mapping and tracking performance through a divide-and-conquer mapping strategy and adaptive map growth.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method, ETA, that improves translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM by using a 3-DoF Bundle Adjustment, independently fixing rotation estimates, and considering IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The proposed SynCHMR approach marries static SLAM and human motion reconstruction, reconstructing metric-scale camera poses, scene point clouds, and human meshes in a common world frame using camera-frame HMR as a prior, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a comprehensive real-world dataset for multi-robot collaborative perception, showcasing the potential of air-ground robot collaboration featuring distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper explores efficient robot learning for perception and mapping by minimizing human effort, leveraging continual learning and reducing human annotations through unsupervised adaptation and label-efficient methods for panoptic segmentation and mapping.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summarize of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, capable of performing drift-corrected tracking and high-fidelity reconstruction using 3D Gaussian representation and CLIP feature-based loop closure.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments, tackling issues like point cloud registration and degeneracy in multifloor buildings.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes robust approaches for robotic mapping and localization, including ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to address challenges in real-world environments with changing surroundings and moving objects.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, called MotionGS, which fuses deep visual features, dual keyframe selection, and 3DGS for high-fidelity scene representation and real-time positioning, while reducing memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The paper proposes a lightweight circular convolutional Transformer network, CCTNet, that addresses the issues of "restricted receptive fields" and "excessive focus on local regions" in current range image-based networks for place recognition, achieving superior performance on KITTI and Ford Campus datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry, representing a novel contribution in occupancy mapping by jointly optimizing robot poses and occupancy values together.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents IPC, a consensus-based method that incrementally builds a maximally consistent set of loop closure measurements, outperforming state-of-the-art methods in handling outliers while providing online performances, and releases an open-source implementation of IPC.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes OverlapMamba, a novel network for place recognition that represents input range views as sequences, using a stochastic reconstruction approach to build shift state space models, and outperforms typical LiDAR and multi-view combination methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces SceneFactory, a workflow-centric framework for incremental scene modeling, which supports a wide range of applications with different input combinations, and proposes novel techniques for unposed & uncalibrated multi-view depth estimation, dense SLAM, and 3D reconstruction.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a real-time SLAM system, NGD-SLAM, that achieves high localization accuracy in dynamic environments on a single CPU without GPU support, using a novel mask prediction mechanism and dual-stage optical flow tracking approach.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here are the key contributions summarized:* The paper proposes three approaches to generating real-time 3D facial reconstructions, which can be used for applications such as augmented reality, telepresence, and entertainment.* The first attempt uses monocular depth estimation, which involves using a neural network to estimate depth from a single RGB image.* The second attempt uses LiDAR and TrueDepth sensors from an iPhone 14 Pro to generate high-fidelity facial reconstructions, with a custom-trained SRCNN model used to upscale the LiDAR depth frame.* The third attempt uses a deep-learning approach to render a facial reconstruction and apply texture + mesh transformations directly through an end-to-end approach, with modifications made to the MICA model to use fused and upscaled LiDAR + TrueDepth sensor data.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a method that jointly optimizes camera poses and NeRF models using monocular depth priors, enabling accurate 3D reconstruction and SLAM without requiring known camera poses.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel framework for dense Visual Simultaneous Localization and Mapping (VSLAM) based on Gaussian Splatting, integrating sparse visual odometry with 3D Gaussian Splatting for the first time, eliminating depth map dependency and enhancing tracking robustness.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel framework, NeuRSS, that integrates sidescan sonar (SSS) SLAM with dead reckoning and loop closures to enable accurate bathymetric mapping and improve autonomous underwater vehicle (AUV) navigation.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NGM-SLAM, a novel 3D Gaussian Splatting SLAM system that utilizes neural radiance field submaps for progressive scene expression, achieving high-quality scene expression, accurate hole filling, and online loop closure adjustments, while supporting various input modalities and achieving state-of-the-art performance.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a comprehensive survey and analysis of Neural Radiance Fields (NeRF) for autonomous robots, focusing on its applications in perception, localization, and navigation, as well as decision-making modules, and explores future avenues for integration with advanced technologies.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper aims to bridge the gap in place recognition (PR) technology by highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and presents a comprehensive review of PR's current state-of-the-art advancements, challenges, and applications in robotics, with a focus on scaling, adaptability, and efficiency.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a neural mapping framework that anchors lightweight neural fields to a pose graph, enabling efficient integration of large-scale loop closures, scalability, and outperforming existing state-of-the-art methods in terms of quality and runtime.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a hybrid visual SLAM system that combines deep feature extraction and matching methods to enhance adaptability in challenging environments, outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:X-SLAM, a real-time and differentiable dense SLAM system, leverages the complex-step finite difference method to calculate numerical derivatives, enabling task-oriented optimization and achieving better accuracy and faster convergence.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM, an open-source visual SLAM system, robustly localizes in dynamic environments by using panoptic segmentation to filter unknown moving objects, outperforming state-of-the-art methods in terms of accuracy and robustness.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:1. Model exchange of information between different MTs, allowing for cooperative localization and data fusion of VAs over different MTs.2. Integration of an IMU as an additional sensor for each MT, providing additional information for orientation and state transition estimation, which helps to cope with complex trajectories.3. Analysis of the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulation.The paper also introduces a Bayesian particle-based SPA for cooperative MP-SLAM, which can perform data fusion over different observations of map features (VAs) by different MTs, as well as cooperative MT-to-MT measurements using RF signals.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Real-time Gaussian SLAM (RTG-SLAM) system proposes a compact Gaussian representation and a highly efficient on-the-fly Gaussian optimization scheme, achieving real-time 3D reconstruction at scale with comparable accuracy and superior performance in rendering realism and camera tracking.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
