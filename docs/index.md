# arxiv-daily
 Automated deployment @ 2024-05-28 09:33:00 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Elevation Models (NEMos), a novel representation that combines Neural Radiance Fields with a height field, allowing for continuous and differentiable terrain modeling and path planning, enabling smooth and efficient navigation in challenging terrain.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based dense RGB-D SLAM system for unknown scenarios, which utilizes a divide-and-conquer mapping strategy, adaptive map growth strategy, and neural implicit representations to achieve scalable and real-time SLAM capabilities.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging that can efficiently render novel HDR views and reconstruct LDR images with controllable exposure time, outperforming state-of-the-art methods in terms of quality and speed.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors proposed a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) to embed and extract 3D scenes and images while maintaining security, fidelity, and functionality, with applications in copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* A new method for enhancing translation accuracy during the initialization stage in Stereo Visual-Inertial SLAM (VI-SLAM) systems.* The method improves translation estimate using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) independently while keeping rotation estimate fixed.* Unlike ORB-SLAM3, the rotation estimate is updated by considering IMU measurements and gyroscope bias.* The method is evaluated on the EuRoC dataset, demonstrating improved accuracy.* The paper aims to address the limitations of previous initialization methods, including ORB-SLAM3 and Stereo-NEC, by providing a more accurate and efficient solution for VI-SLAM systems.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper addresses the limitations of Neural Radiance Fields (NeRFs) in rendering highly specular objects with detailed view-dependent appearance, by introducing a ray tracing approach that reduces the reliance on expensive neural networks and enables consistent rendering of reflections of nearby and distant content.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs 3D human and camera motion in a common global coordinate system from monocular videos, addressing depth, scale, and dynamic ambiguities by combining Human-aware Metric SLAM and Scene-aware SMPL Denoiser.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Neural Directional Encoding (NDE), a feature-grid-like encoding for neural radiance fields (NeRF) that accurately models high-frequency angular signals and spatially varying directional effects for rendering specular objects, outperforming the state-of-the-art while achieving fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizing a hash-encoded NeRF to improve pose optimization and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process, achieving state-of-the-art results in camera relocalization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, distinct spatial viewpoints, and complementary sensor modalities, which aims to facilitate research in this area and unlock high-level scene understanding through multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* Developing methods for efficient robot learning, focusing on minimizing human effort in deploying perception-based robotic systems to previously unseen environments.* Investigating the use of continual learning and reducing human annotations for efficient learning.* Contributing to the continual unsupervised adaptation of robotic vision systems to new domains while maintaining performance in prior environments.* Developing label-efficient panoptic segmentation techniques that can be trained with as few as ten annotated images.* Introducing a novel method for automatic target-less camera-LiDAR calibration that requires neither human initialization nor special data recording.* Investigating the use of foundation models for processing LiDAR data and developing a mapping approach that fuses surround view camera data with sparse radar measurements.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a feed-forward framework that generates high-quality, illumination-decoupled textured meshes from single images or text prompts using a novel tensorial SDF representation, adaptively converting SDF to density, and integrating a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme that efficiently represents and compresses dynamic Neural Radiance Fields (NeRF) for photo-realistic volumetric videos, achieving superior quality and compression efficiency compared to previous methods.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner using a recursive block splitting approach, reducing training time by 6+ times and achieving state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|The authors present MG-SLAM, a monocular SLAM system that uses a 3D Gaussian map representation and a language-extended loop closure module, achieving drift-corrected tracking and high-fidelity reconstruction without requiring depth sensors.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Gaussian Time Machine (GTM) is proposed for reconstructing 3D scenes with vastly varying appearances, achieving state-of-the-art rendering fidelity, and real-time rendering at 80FPS, 100 times faster than NeRF-based methods, while disentangling appearance changes and rendering smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The MOSS framework employs kinematic information to achieve motion-aware 3D clothed human synthesis, introducing the KGAS and UID modules to correct for global motion and local occlusions, achieving state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables the training of an "off-the-shelf" spacecraft pose estimation network from a sparse set of images, using a Neural Radiance Field (NeRF) model to generate a large training set that captures the diversity of pose and illumination conditions.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions mentioned in the abstract and introduction in a single sentence under 50 words:The authors propose NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM in multifloor environments, which enhances point cloud registration performance, addresses degeneracy issues, and achieves robustness in narrow indoor spaces.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The key contributions of the paper can be summarized as: Developing a generalizable 3D Gaussian representation approach, MVSGaussian, derived from Multi-View Stereo, which can efficiently reconstruct unseen scenes with real-time rendering and fast fine-tuning.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The authors focus on the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks, which is essential for immersive communication applications requiring photorealistic rendering of 3D contents.* NeRF and 3D-GS are novel radiance field rendering techniques that can provide photorealistic rendering results for complex scenes, but they pose challenges for transmission, storage, and rendering over wireless networks.* The authors aim to bridge the gap by proposing a comprehensive overview of the integration of NeRF and 3D-GS in 6G networks, focusing on representation, transmission, and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learnt renderers to estimate 3D shape from photometric stereo images. The method models point light attenuation and explicitly raytraces cast shadows to best approximate each point's incoming radiance, and jointly optimizes a fully neural material renderer with the surface. The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are used.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a Judge mechanism to assess and enhance the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Developing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments.* Proposing a two-stage framework that accurately captures signal propagation dynamics from the transmitter to the RIS and from the RIS to the receiver.* Experimentally evaluating the effectiveness of the proposed method using simulated and real-world data, demonstrating significant improvements in predicting signal strength and outperforming existing methods.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that combines fast ground segmentation, outlier-robust registration using graduated non-convexity, hierarchical multi-session SLAM, and instance-aware static map building to enable robust localization and mapping in diverse environments and scenarios.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel 3DSG-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve accurate real-time tracking, high-fidelity reconstruction, and state-of-the-art performance on indoor RGB-D datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes the Circular Convolutional Transformer Network (CCTNet) for place recognition using LiDAR point cloud data, addressing issues in previous methods by introducing Circular Convolution and Range Transformer modules to capture structural information and enhance accuracy in varied scenarios.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes a novel optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry information, while traditional methods require pre-estimating robot poses, and evaluates its performance through simulations and publicly available datasets.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This survey paper provides an overview of the methodologies enabling large language models (LLMs) to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction within AI systems, and examining current challenges and applications in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors develop a procedure to convert between implicit representations of scenes, such as Neural Radiance Fields (NeRFs), and explicit representations, such as Gaussian Splatting (GS). This conversion enables the best of both approaches, achieving superior PSNR, SSIM, and LPIPS on dissimilar views, while also allowing for real-time rendering and easy modification of the representation. The authors demonstrate that their approach outperforms both NeRFs and GS-based methods in various robotics applications, such as localization, planning, and scene understanding.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model. This allows for the generation of terrain representations from imagery, which are lightweight, continuous, and differentiable. The authors propose a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression. Additionally, they introduce a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.The main contributions of the paper are:1. Introduction of NEMos, which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.2. Novel method for jointly training a height field and radiance field within a NeRF framework, utilizing quantile regression.3. Path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.4. Experimental results demonstrating the effectiveness of NEMos in generating high-quality reconstructions and producing smoother paths compared to discrete path planning methods.Overall, the paper presents a new terrain representation and path planning approach that leverages the strengths of Neural Radiance Fields and quantile regression in capturing terrain geometry and minimizing path errors.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, offering 1.91 dB PSNR improvements and 1000x inference speed, while requiring only 6.3% training time.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, dubbed GS-Hider, which embeds 3D scenes and images into original GS point clouds, allowing for secure and invisible transmission, robust, high-fidelity, and large-capacity message extraction, and demonstrating exceptional security, robustness, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents an approach that combines Neural Radiance Fields (NeRFs) with ray tracing to improve the rendering of highly specular objects, addressing the limitations of prior methods in synthesizing consistent reflections of nearby content and reducing the need for large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE) for rendering specular objects, which encodes directional information in a feature-grid-like structure and cone-traces spatial features to model high-frequency angular signals and interreflections.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a two-staged pipeline for camera relocalization, normalizing images with varying lighting and shadow conditions, utilizing a hash-encoded NeRF representation, and introducing a reordered dynamic low-pass filter and numerical gradient averaging technique for improved pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summarized version of the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework generating high-fidelity, illumination-decoupled textured mesh from single images or text prompts, improving upon existing methods by addressing issues of geometry smoothness and convergence speed.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which achieves improved quality and compression efficiency by representing the radiance field as a compact residual feature grid and applying sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) distributedly, reducing training time by 6+ times and achieving state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The Gaussian Time Machine (GTM) proposes a novel real-time rendering method for scenes with vastly varying appearances, combining high fidelity, real-time rendering, and consistency, achieving state-of-the-art reconstruction quality and 100 times faster rendering speed than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces MOSS, a novel framework that combines kinematic information with Gaussian distributions to synthesize realistic 3D clothed humans from single-view videos, enhancing joint details and clothing folds, and achieving state-of-the-art visual quality and real-time rendering.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables the estimation of the 6D pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF) model, which can be trained from a sparse set of images and allows for autonomous rendezvous and proximity operations.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summary of the paper's abstract and introduction (< 50 words):The paper proposes MVSGaussian, a fast and generalizable 3D Gaussian representation method that leverages Multi-View Stereo and a pixel-aligned Gaussian representation for efficient novel view synthesis, achieving state-of-the-art performance with real-time rendering speed and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper focuses on integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques for representing and transmitting 3D contents in 6G wireless networks. The paper highlights the importance of efficiently representing, transmitting, and reconstructing 3D contents in immersive communication scenarios, such as telepresence, immersive gaming, and metaverse. The key contributions of the paper are:1. Comprehensive review of NeRF and 3D-GS techniques for 3D representation and transmission.2. Discussion of the challenges and opportunities of integrating NeRF and 3D-GS in 6G wireless networks.3. Overview of the design considerations for wireless transmission of 3D contents, including joint computation and communication, and end-to-end latency requirements.4. Potential applications of NeRF and 3D-GS in 6G wireless networks, such as radiance field rendering, virtual and augmented reality, and 3D modeling and reconstruction.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the paper's abstract and introduction are:* The proposed method is a novel multi-view photometric stereo (MVPS) approach that leverages per-pixel intensity renderings to estimate 3D shape from MVPS images, achieving competitive reconstruction accuracy using only 6 lights and matching the state-of-the-art performance when all lights and normal map information are fused.* The method explicitly models point light attenuation and casts shadows, and optimizes a fully neural material renderer, allowing it to perform robustly even with poor normals in low light count scenarios.* The paper introduces a new neural surface representation using a Signed Distance Field (SDF) parameterization, which is used to render images and compute losses, and demonstrates the effectiveness of the method on the DiLiGenT-MV benchmark.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a Judge mechanism to assess and refine the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of the paper are:* A novel two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.* The integration of NeRF-based ray tracing techniques with electromagnetic physics to model the signal field for any specified RIS placement and receiver location.* Experimental results demonstrating the effectiveness of the proposed method in predicting signal strength and visualizing the signal field in RIS-enabled environments.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep visual features, dual keyframe selection, and 3DGS to achieve high-fidelity scene representation, accurate tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:Researchers explore the intersection of Large Language Models (LLMs) with 3D spatial data, highlighting the advantages of LLMs in processing, understanding, and generating 3D data, and charting a course for future research to harness LLMs' full potential in understanding and interacting with the complex 3D world.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* Developing a procedure to convert between implicit representations (Neural Radiance Fields, NeRFs) and explicit representations (Gaussian Splatting, GS) in a way that achieves the best of both worlds, i.e., superior PSNR, SSIM, and LPIPS on dissimilar views, and a compact representation.* Showing that the proposed procedure can be used to achieve real-time rendering and easy modification of the representation, which is useful for robotics applications where there is a limited number of views and the scene needs to be updated frequently.* Evaluating the quality and efficiency of the proposed approach using a number of existing datasets and showing that it can be used to handle situations with sparse views, which are commonly encountered in robotics.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an in-depth analysis of the development and implementation principles of Dynamic NeRF, a novel implicit method for 3D reconstruction and representation, exploring its potential in practical applications and highlighting its advantages over static NeRF.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a synergistic integration of coordinate networks and multi-plane representations to improve NeRFs from sparse inputs, achieving comparable results to sinusoidal encoding with fewer parameters and outperforming others in static and dynamic NeRF tasks.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose an implicit ray transformation strategy and a differentiable neural-point resampling module to enable point-based editable NeRF pipelines for 3D object removal and inpainting tasks with improved performance and high-quality rendering.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents an application that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, proposing three high-fidelity reconstruction tools that can run on a portable device like the iPhone 14 Pro, enabling interactive and immersive holographic experiences for a wide range of applications.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, and introduces three key advancements: depth-based ray sampling, coarse-to-fine training, and inter-frame point constraint to achieve superior performance in pose estimation and NeRF reconstruction.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LIVE, a novel design method for creating interactive LaTeX graphic items, enabling the design of dynamic and interactive components that preserve the scientificity and objectivity of traditional papers while providing a more engaging reading experience.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed SketchDream method integrates sketch and text inputs for 3D content generation and editing, addressing the challenges of 2D-to-3D translation, multi-modal condition integration, and local editing, generating high-quality results with detailed control.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
|**2024-05-10**|**Aerial-NeRF: Adaptive Spatial Partitioning and Sampling for Large-Scale Aerial Rendering**|Xiaohan Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Aerial-NeRF, a novel method that addresses the challenges of large-scale aerial rendering by designing adaptive spatial partitioning, pose-based region selection, and sampling strategies to achieve high-precision rendering and fast rendering speed.|[2405.06214v1](http://arxiv.org/abs/2405.06214v1)|null|
|**2024-05-10**|**Residual-NeRF: Learning Residual NeRFs for Transparent Object Manipulation**|Bardienus P. Duisterhof et.al.|The paper proposes Residual-NeRF, a method that improves depth perception and training speed for transparent objects by pre-learning a background scene NeRF and using two additional networks to infer residual RGB values and densities, outperforming baselines on synthetic and real-world experiments.|[2405.06181v1](http://arxiv.org/abs/2405.06181v1)|null|
|**2024-05-09**|**DragGaussian: Enabling Drag-style Manipulation on 3D Gaussian Representation**|Sitian Shen et.al.|The paper proposes DragGaussian, a 3D object editing framework that leverages 3D Gaussian Splatting and diffusion models for interactive image editing with open-vocabulary input, enabling users to perform precise and flexible editing tasks.|[2405.05800v1](http://arxiv.org/abs/2405.05800v1)|null|

### Gaussian Splatting SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**Sparse Expansion and Neuronal Disentanglement**|Shashata Sawmya et.al.|The paper contributes to the field of neural network sparsity by introducing a new technique called Sparse Expansion, which improves the inference efficiency of large language models (LLMs) by expanding them into a mixture of sparse experts. The key contributions of the paper are:* The Sparse Expansion technique, which improves the inference efficiency of LLMs by expanding them into a mixture of sparse experts, each specializing in a distinct subset of input values.* The observation that the mixing of sparse experts allows for a disentanglement of neuron output distributions, which leads to improved sparse performance, especially for highly entangled neurons.* The use of the Wasserstein distance to measure the degree of entanglement of a neuron, and the finding that highly entangled neurons are more difficult to sparsify and have a larger impact on model performance.* Experimental results showing that Sparse Expansion outperforms other one-shot sparsification techniques for all LLMs from the Llama and Pythia families, at low accuracy loss, and achieves non-trivial speedups for generative inference.* The demonstration of the effectiveness of Sparse Expansion across multiple model sizes, sparsity levels, and compression schemes.|[2405.15756v1](http://arxiv.org/abs/2405.15756v1)|null|
|**2024-05-24**|**Interaction in the dark sector: a phenomenological approach**|Z. C. Santana et.al.|The paper presents a Bayesian analysis testing three parameterizations of the dark matter energy density variation law, using galaxy cluster gas mass fraction, SNe Ia, Cosmic Chronometers, and BAO data, and finds that the standard evolution law is within 2σ confidence level and there is inconclusive or weak evidence for most scenarios tested.|[2405.15726v1](http://arxiv.org/abs/2405.15726v1)|null|
|**2024-05-24**|**Fast adiabatic preparation of multi-squeezed states by jumping along the path**|Chuan Chen et.al.|The key contributions of the paper are:* The development of a novel shortcuts to adiabaticity (STA) method for the fast preparation of multi-squeezed states, which eliminates the need for counterdiabatic control fields.* The demonstration of high-fidelity and fast preparation of multi-squeezed states and hybrid entangled states between a bosonic mode and a qubit using the STA method.* The ability to prepare quantum states with large phase-space Wigner negativities, interference, and enhanced squeezing, which are valuable non-Gaussian resources in quantum information technology.|[2405.15595v1](http://arxiv.org/abs/2405.15595v1)|null|
|**2024-05-24**|**A graph-space optimal transport FWI approach based on κ-generalized Gaussian distribution**|Sérgio Luiz E. F. da Silva et.al.|The key contributions of the paper are:* Introducing a new objective function for Full-Waveform Inversion (FWI) based on graph-space optimal transport and κ-generalized Gaussian probability distribution, which is robust in mitigating cycle-skipping issues and non-Gaussian errors.Note: The abstract and introduction are summarized in a single sentence under 50 words.|[2405.15536v1](http://arxiv.org/abs/2405.15536v1)|null|
|**2024-05-24**|**A Preference-oriented Diversity Model Based on Mutual-information in Re-ranking for E-commerce Search**|Huimu Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose PODM-MI, a novel re-ranking model that balances accuracy and diversity by utilizing mutual information and multidimensional Gaussian distributions to model user diversity preferences and adaptively match the ranking results with user demands.|[2405.15521v1](http://arxiv.org/abs/2405.15521v1)|null|
|**2024-05-24**|**Feature Splatting for Better Novel View Synthesis with Low Overlap**|T. Berriel Martins et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes Feature Splatting (FeatSplat), a novel approach that encodes scene color information using learned feature vectors instead of spherical harmonics, significantly improving novel view synthesis, especially for low overlap views.|[2405.15518v1](http://arxiv.org/abs/2405.15518v1)|null|
|**2024-05-24**|**Learning to Discretize Denoising Diffusion ODEs**|Vinh Tong et.al.|The paper proposes a lightweight framework called LD3 to learn time discretization for sampling from diffusion probabilistic models (DPMs), which reduces the number of neural function evaluations (NFE) while preserving generation quality, and achieves better sampling efficiency compared to distillation-based methods.|[2405.15506v1](http://arxiv.org/abs/2405.15506v1)|null|
|**2024-05-24**|**GSDeformer: Direct Cage-based Deformation for 3D Gaussian Splatting**|Jiajun Huang et.al.|The paper proposes GSDeformer, a method that enables free-form deformation of 3D Gaussian Splatting (3DGS) without modifying its architecture or requiring additional data, using a novel proxy point cloud representation and a cage-based deformation approach, and demonstrates its ease of use and comparable quality against existing methods.|[2405.15491v1](http://arxiv.org/abs/2405.15491v1)|null|
|**2024-05-24**|**Out of Many, One: Designing and Scaffolding Proteins at the Scale of the Structural Universe with Genie 2**|Yeqing Lin et.al.|The key contributions from the paper's abstract and introduction are:* The development of Genie 2, an improved protein design model that extends the pioneering work of Genie.* Genie 2 can capture a larger and more diverse protein structure space through architectural innovations and massive data augmentation.* The ability to design proteins with multiple independent motifs, also known as multi-motif scaffolding, which enables the development of new enzymes, biosensors, and therapeutics.* State-of-the-art results in designability, diversity, and novelty compared to existing models.* Successful solving of more motif scaffolding problems than other methods and with more unique and varied solutions.|[2405.15489v1](http://arxiv.org/abs/2405.15489v1)|null|
|**2024-05-24**|**Volumetric Primitives for Modeling and Rendering Scattering and Emissive Media**|Jorge Condor et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel volumetric representation based on kernel-based primitives to model scattering and emissive media, introducing closed-form solutions for transmittance and emission, and a ray-tracing-based implementation for efficient rendering and inverse rendering applications.|[2405.15425v1](http://arxiv.org/abs/2405.15425v1)|null|
|**2024-05-24**|**Stochastic SR for Gaussian microtextures**|Emile Pierret et.al.|The paper introduces a new algorithm for stochastic super-resolution of Gaussian microtextures, which is competitive with deep learning state-of-the-art methods in terms of perceptual metrics and execution time, and provides a rigorous framework for discussing the limitations of various reconstruction metrics.|[2405.15399v1](http://arxiv.org/abs/2405.15399v1)|null|
|**2024-05-24**|**Adaptive Finite Element Method for a Nonlinear Helmholtz Equation with High Wave Number**|Run Jiang et.al.|The key contributions of the paper are:* Establishing a priori stability and error estimates for the finite element method (FEM) on shape regular meshes, including the case of locally refined meshes, for the nonlinear Helmholtz equation with high frequencies and corner singularities.* Deriving a posteriori upper and lower bounds using a new residual-type error estimator for the FEM solutions to the nonlinear Helmholtz problem, which is equivalent to the standard estimator.* Proving the convergence and quasi-optimality of the adaptive finite element algorithm (AFEM) for the nonlinear Helmholtz problem with initial mesh size in the preasymptotic regime, which is the first time this has been done for this problem.* Validating the theoretical findings with numerical examples, including the simulation of optical bistability with Gaussian incident waves using the adaptive continuous interior penalty FEM (CIPFEM).|[2405.15344v1](http://arxiv.org/abs/2405.15344v1)|null|
|**2024-05-24**|**Discriminative Estimation of Total Variation Distance: A Fidelity Auditor for Generative Data**|Lan Tao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a discriminative approach to estimate the total variation distance between two distributions as a measure of generative data fidelity, and establishes theoretical results on its convergence rate and dependence on distribution separation.|[2405.15337v1](http://arxiv.org/abs/2405.15337v1)|null|
|**2024-05-24**|**Minimizing UCB: a Better Local Search Strategy in Local Bayesian Optimization**|Zheyi Fan et.al.|The key contributions of the paper are:* Developing the relationship between the gradient descent step and minimizing the Upper Confidence Bound (UCB), and showing that minimizing UCB can be a better strategy than direct gradient descent when a Gaussian process is applied as a surrogate.* Proposing a new local Bayesian optimization algorithm, MinUCB, which replaces the gradient descent step with a step that minimizes the UCB in GIBO.* Improving the local exploration acquisition function of MinUCB through a look-ahead strategy and obtaining a more efficient algorithm, LA-MinUCB.* Providing the theoretical guarantees for the performance of MinUCB and LA-MinUCB, including the convergence rate and Bayesian optimality of LA-MinUCB.|[2405.15285v1](http://arxiv.org/abs/2405.15285v1)|null|
|**2024-05-24**|**DisC-GS: Discontinuity-aware Gaussian Splatting**|Haoxuan Qu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose DisContinuity-aware Gaussian Splatting (DisC-GS), a novel framework that enables Gaussian Splatting to accurately render discontinuities and boundaries in novel view synthesis, addressing a fundamental limitation of Gaussian Splatting, and achieving superior performance on evaluated benchmarks.|[2405.15196v1](http://arxiv.org/abs/2405.15196v1)|null|
|**2024-05-24**|**Addressing Duplicated Data in Point Process Models**|Lingling Chen et.al.|Based on the abstract and introduction, the key contributions of this paper are:* Developing a Modified Minimum Contrast (MMC) method to address the issue of duplicated data in spatial point process models, which can occur when events are snapped to coarse spatial resolutions.* Demonstrating the superiority of the MMC method compared to existing methods, such as jittering, through simulation experiments.* Applying the MMC method to a real-world conflict data set from Afghanistan, showing improved estimation results compared to other methods.|[2405.15192v1](http://arxiv.org/abs/2405.15192v1)|null|
|**2024-05-24**|**Diffusion Actor-Critic with Entropy Regulator**|Yinuo Wang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes the Diffusion Actor-Critic with Entropy Regulator (DACER) algorithm, which leverages the representational capacity of diffusion models to enhance policy performance and achieve state-of-the-art performance in various MuJoCo control tasks.|[2405.15177v1](http://arxiv.org/abs/2405.15177v1)|null|
|**2024-05-24**|**Optimal Reference Nodes Deployment for Positioning Seafloor Anchor Nodes**|Wei Huang et.al.|The key contributions of the paper can be summarized as follows:* The paper proposes an optimal reference node deployment strategy for time-of-arrival (TOA) localization in 3D underwater space, considering the non-uniform distribution of underwater sound speed.* The authors adopt the criterion of minimizing the trace of the inverse Fisher information matrix (FIM) to determine the optimal reference node deployment.* A new semi-closed form solution is found to determine the optimal geometries, which can be used to improve the accuracy of underwater anchor node positioning.* The paper also discusses the error analysis and provides a comprehensive analysis of optimal reference-target geometries in the general circumstance with no restriction on the number of reference nodes, elevation angle, and reference-target range.* The authors demonstrate the findings through both simulations and sea trials on underwater anchor node positioning, and the results are consistent with the theoretical analysis.|[2405.15153v1](http://arxiv.org/abs/2405.15153v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**Fluctuations around the mean-field limit for attractive Riesz potentials in the moderate regime**|Li Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper shows that the fluctuations around the mean-field limit of moderately interacting particles with attractive sub-Coulomb potentials become asymptotically Gaussian, with a central limit theorem scaling of √N, allowing for the first time for such potentials to be considered in this regime.|[2405.15128v1](http://arxiv.org/abs/2405.15128v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a new framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming existing methods while achieving faster training and inference speed.|[2405.15125v1](http://arxiv.org/abs/2405.15125v1)|null|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files, ensuring security, fidelity, and flexibility, and demonstrates its effectiveness in copyright protection, encrypted communication, and compression of 3DGS.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**Efficient Certificates of Anti-Concentration Beyond Gaussians**|Ainesh Bakshi et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper presents a new, application-agnostic formulation of anti-concentration and constructs quasi-polynomial time verifiable sum-of-squares certificates for a broad class of non-Gaussian distributions, including anti-concentrated bounded product distributions and uniform distributions over Lp balls.|[2405.15084v1](http://arxiv.org/abs/2405.15084v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a method, called ETA, to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM, via a 3-DoF Bundle Adjustment, while maintaining runtime similar to ORB-SLAM3 and outperforming previous methods.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Scale-dependent chirality as a smoking gun for Abelian gauge fields during inflation**|Ogan Özsoy et.al.|The paper numerically studies the effects of particle production on cosmological perturbations in axion-inflation models with an Abelian gauge sector, finding significant deviations from approximate analytic results and implications for gravitational wave backgrounds and detectability.|[2405.14963v1](http://arxiv.org/abs/2405.14963v1)|null|
|**2024-05-23**|**EvGGS: A Collaborative Learning Framework for Event-based Generalizable Gaussian Splatting**|Jiaxu Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes EvGGS, a collaborative learning framework that reconstructs 3D scenes from event camera input in a feedforward manner, generalizing to unseen scenarios, outperforming existing event-based methods, and provides a novel event-based 3D dataset for evaluation.|[2405.14959v1](http://arxiv.org/abs/2405.14959v1)|[link](https://github.com/mercerai/evggs)|
|**2024-05-23**|**The NANOGrav 15 yr Data Set: Chromatic Gaussian Process Noise Models for Six Pulsars**|Bjorn Larsen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The study assesses the impact of different chromatic noise models on acechronic noise properties in six pulsars, finding that the choice of model noticeably affects noise properties, particularly in PSR J1713+0747, and identifies potential areas for improving noise models to boost PTA sensitivity to gravitational waves.|[2405.14941v1](http://arxiv.org/abs/2405.14941v1)|null|
|**2024-05-23**|**Universal Robustness via Median Randomized Smoothing for Real-World Super-Resolution**|Zakariya Chaouai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper explores the universality of robustness methods for Super-Resolution (SR) models, finding that Median Randomized Smoothing (MRS) is more general and effective than adversarial learning techniques, and demonstrates its adaptability in handling various adversarial attacks and standard corruptions.|[2405.14934v1](http://arxiv.org/abs/2405.14934v1)|null|
|**2024-05-23**|**Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using Sparse RGB Cameras**|Hanzhang Tu et.al.|The key contributions from the paper's abstract and introduction are:1. A low-budget and high-authenticity bidirectional telepresence system, Tele-Aloha, which utilizes only four sparse RGB cameras, one consumer-grade GPU, and one autostereoscopic screen to achieve high-resolution (2048x2048), real-time (30 fps), low-latency (less than 150ms) and robust distant communication.2. A novel view synthesis algorithm for upper-body communication, which consists of a cascaded disparity estimator, a neural rasterizer, and a refinement module.3. A weighted blending mechanism to refine the decoded image and provide a strong sense of co-presence in real-life experiments.|[2405.14866v1](http://arxiv.org/abs/2405.14866v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper introduces SynCHMR, a novel framework that marries visual SLAM and human mesh reconstruction, enabling the simultaneous reconstruction of camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which utilizes a divide-and-conquer mapping strategy and adaptive map growth strategy to efficiently cover the entire unknown environment while maintaining real-time performance.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* Proposing a new method called ETA that enhances translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM (VI-SLAM) systems by using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) independently of the rotation estimate.* Updating the rotation estimate using IMU measurements and gyroscope bias, unlike traditional methods that directly obtain rotation from stereo visual odometry.* Achieving comparable performance to Stereo-NEC while maintaining a similar runtime speed.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos, addressing scale, depth, and dynamic ambiguities by leveraging camera-frame HMR as a strong prior.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction, within a single sentence under 50 words:This paper presents a pioneering, comprehensive, and real-world multi-robot collaborative perception dataset, featuring distinct spatial viewpoints, complementary robot mobilities, and sensor modalities, intended to boost research in this area.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The paper's contributions can be summarized as:* Developing continual learning and label-efficient learning methods for robot perception and mapping, enabling the deployment of perception-based robotic systems to previously unseen environments with minimal human effort.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system that combines 3D Gaussian Splatting with a language-extended loop closure module, achieving drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper introduces NV-LIO, a novel normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments with multifloor structures, which extracts normal vectors from LiDAR scans for robust point cloud registration and addresses degeneracy situations and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that rejects featureless ground points, uses graduated non-convexity-based outlier-robust registration and hierarchical multi-session SLAM, and instance-aware static map building to handle diverse and dynamic real-world scenarios.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS to achieve accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The key contributions of this paper are the proposal of a lightweight circular convolutional Transformer network (CCTNet) that captures structural information in point clouds, facilitates cross-dimensional interaction of spatial and channel information, and outperforms current range image-based networks.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes a novel optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry information, represented as a continuous occupancy map with evidence values, and uses a variation of the Gauss-Newton method to solve the problem offline.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Incremental Probabilistic Consensus (IPC), a consensus-based approach to robust Pose Graph Optimization (PGO), which incrementally builds a consistent set of loop closure measurements, capable of handling large numbers of outliers while providing online performances.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|The paper proposes OverlapMamba, a novel network for place recognition that represents input range views as sequences, employs a stochastic reconstruction approach to build shift state space models, and compresses the visual representation.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose SceneFactory, a workflow-centric framework that supports a wide range of scene modeling applications, and introduce four building blocks for incremental scene modeling, including a new depth estimation model, a dense SLAM task, and a multi-resolutional neural points representation.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|The paper proposes a novel visual SLAM system for dynamic environments that achieves real-time performance on CPU by incorporating a mask prediction mechanism, allowing parallel operation of deep learning and camera tracking, and introducing a dual-stage optical flow tracking approach and hybrid usage of optical flow and ORB features.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper proposes three approaches for real-time 3D facial reconstruction using LiDAR and LiDAR + TrueDepth data, aiming to achieve high-fidelity, metric-accurate, and instantaneous reconstructions on portable devices like the iPhone 14 Pro, addressing limitations of existing methods such as NeRFs and SLAM.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using monocular depth priors, with three key advancements: a novel depth-based ray sampling strategy, a coarse-to-fine training strategy, and a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel framework that integrates sparse visual odometry with 3D Gaussian Splatting, utilizing a pre-trained MVS depth estimation network, geometric depth smooth loss, and Sparse-Dense Adjustment Ring to achieve accurate dense mapping and pose estimation from RGB images alone.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a framework, NeuRSS, that integrates side-scan sonar (SSS) and simultaneous localization and mapping (SLAM) to estimate bathymetry while addressing the elevation degeneracy issue using neural rendering and submap-based optimization.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces NGM-SLAM, a 3D Gaussian Splatting SLAM system that leverages neural radiance field submaps for progressive scene expression, achieving high-quality scene reconstruction, accurate hole filling, and real-time loop closure detection and correction.|[2405.05702v4](http://arxiv.org/abs/2405.05702v4)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summarized sentence under 50 words:This paper presents a comprehensive survey of Neural Radiance Fields (NeRF) for enhancing autonomous robots' capabilities, covering perception, localization, navigation, and decision-making, and explores future research directions, including integrating NeVF with advanced techniques like 3D Gaussian splatting and large language models.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper aims to bridge the gap in place recognition (PR) for real-world robotic systems by highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0 and providing a comprehensive review of current advancements and challenges in PR.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel neural mapping framework that anchors lightweight neural fields to a pose graph, enabling efficient incorporation of large-scale loop closures and scalable scene representation, which outperforms existing state-of-the-art methods in terms of quality and runtime.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a hybrid visual SLAM system that combines deep feature extraction and matching methods to improve adaptability in challenging environments, outperforming traditional approaches in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents X-SLAM, a real-time differentiable SLAM system that uses the complex-step finite difference method to calculate derivatives, enabling task-aware optimization, and achieves improved accuracy and efficiency in camera relocalization and robotic scanning tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Panoptic-SLAM, a visual SLAM system that uses panoptic segmentation to filter dynamic objects, enabling robust localization and mapping in dynamic environments with unknown and unlabeled moving objects.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The paper introduces a Bayesian particle-based algorithm for cooperative MP-SLAM (multipath-based simultaneous localization and mapping) considering multiple mobile terminals (MTs) with varying observation models, noise levels, and possible measurements.Key contributions include:* Introducing information exchange between different MTs for data fusion and cooperative localization.* Integrating an inertial measurement unit (IMU) for additional information in orientation and state transition estimation.* Analyzing the impact of VA (virtual anchor) data fusion and cooperative measurements for MP-SLAM in multiple-input multiple-output (MIMO) and single-input multiple-output (SIMO) systems through numerical simulation.* Highlighting the relevance of a key challenge, measurement-origin uncertainty, for MP-SLAM scenarios.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|The paper presents Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system that uses Gaussian splatting to reconstruct large-scale environments with high-quality geometry and appearance, achieving comparable results to state-of-the-art NeRF-based SLAM methods at around twice the speed and half the memory cost.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
|**2024-04-29**|**Non-convex Pose Graph Optimization in SLAM via Proximal Linearized Riemannian ADMM**|Xin Chen et.al.|The key contributions from the paper's abstract and introduction are:1. A new pose graph optimization model based on von Mises-Fisher distribution and unit quaternions, which has lower data storage and can be easily projected onto the constraint.2. A proximal linearized Riemannian alternating direction method of multipliers (PieADMM) algorithm, which has low memory requirements, can update poses in parallel, and has an iteration complexity of O(1/ε^2) for finding an ε-stationary solution.3. A novel representation of augmented unit quaternions and their properties, which provides a new way to solve pose graph optimization problems.4. The application of the proposed algorithm to several 3D SLAM benchmark datasets, which demonstrates its efficiency and effectiveness.|[2404.18560v1](http://arxiv.org/abs/2404.18560v1)|null|
|**2024-04-29**|**Mesh-based Photorealistic and Real-time 3D Mapping for Robust Visual Perception of Autonomous Underwater Vehicle**|Jungwoo Lee et.al.|The key contributions of the paper are:* Improving localization performance and photorealistic mapping in real-time using image enhancement and mesh representation.|[2404.18395v1](http://arxiv.org/abs/2404.18395v1)|null|
