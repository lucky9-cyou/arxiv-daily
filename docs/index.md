# arxiv-daily
 Automated deployment @ 2024-05-31 08:56:41 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel approach to enable high-fidelity novel view synthesis within the stomach using monocular gastroscopic images by incorporating geometry priors from a pre-reconstructed point cloud into neural radiance fields (NeRF) training, leading to improved rendering quality and recovered geometry compared to existing methods.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeRF On-the-go introduces a simple yet effective approach to robustly synthesize novel views in complex, real-world scenes from casually captured image sequences, efficiently eliminating distractors and achieving a faster convergence speed compared to state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NS-MAE, a self-supervised pre-training framework for multi-modal representation learning that leverages masked multi-modal reconstruction in neural radiance fields (NeRF) to enable transferable representation learning across diverse multi-modal and single-modal perception models.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions of the paper can be summarized in one sentence as follows:The paper proposes a refined 3D Gaussian representation for dynamic scene reconstruction, which combines deformation fields, hash encoding, and a learnable denoising mask to reduce memory usage and enhance rendering quality, while also introducing static constraints and motion consistency constraints to minimize noise points and artifacts.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes a novel approach, HFGS, for deformable endoscopic reconstruction that addresses under-reconstruction in both spatial and temporal frequency perspectives, achieving superior rendering quality and dynamic awareness through its Frequency Regularization Module and Temporal High-Frequency Emphasis Reconstruction.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Mani-GS, a method for Gaussian Splatting manipulation with triangular mesh, which enables controllable 3DGS manipulation, high-quality rendering, and a high tolerance for mesh accuracy, outperforming existing methods in various scenarios.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions of the paper's abstract and introduction are as follows:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3D Gaussian Splatting (3DGS) while preserving image quality. F-3DGS uses factorization techniques to represent dense clusters of Gaussians with a significantly smaller number of elements, achieving a 90% reduction in storage size. The method is demonstrated to be efficient and achieves comparable quality in rendered images.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that leverages SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3, enabling the processing of complete human colonoscopies in real-time with improved tracking and mapping capabilities.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Pyramidal 3D Gaussian Splatting (PyGS) to address the challenges of large-scale scene representation, achieving significant performance and rendering speedups by introducing a hierarchical pyramidal structure and NeRF initialization.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a RGB-only SLAM system with a densely deformable 3D Gaussian map representation, combining frame-to-frame tracking, loop closure, and global bundle adjustment for accurate scene reconstruction and rendering while achieving competitive tracking and map sizes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that improves sparse-view reconstruction of 360 3D scenes using pre-trained 2D diffusion models fine-tuned to fill in missing details and clean novel views, achieving significant performance improvements over existing methods.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a continuous and differentiable terrain model, enabling efficient path planning and elevation estimation from aerial imagery.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NeB-SLAM, a scalable and real-time dense RGB-D SLAM system for unknown scenarios, which utilizes a divide-and-conquer mapping strategy and adaptive map growth to efficiently represent unknown scenes with efficient memory usage.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art methods while significantly reducing training and inference times.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a 3D Gaussian Splatting (3DGS) steganography framework that embeds 3D scenes and images into original point cloud files, offering robust security, high fidelity, large capacity, and versatility, and demonstrates its effectiveness through extensive experiments.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method to enhance the accuracy of initialization in Stereo Visual-Inertial SLAM (VI-SLAM) systems, which is a critical issue that affects the accuracy and usability of VI-SLAM. The method, called ETA, improves translation accuracy during initialization by using a 3-DoF Bundle Adjustment (BA) while keeping the rotation estimate fixed, and updates the rotation estimate by taking into account IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents a novel approach to Neural Radiance Fields (NeRFs) that uses ray tracing to render highly specular objects, solving issues with inconsistent reflections and computationally expensive neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces SynCHMR, a synergistic approach that jointly reconstructs metric-scale camera poses, human meshes, and dense scene point clouds from monocular videos, leveraging human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like encoding for neural radiance fields (NeRF) that accurately models view-dependent effects, including specular high-lights and glossy interreflections, and achieves fast evaluation, outperforming the state-of-the-art on view synthesis of specular objects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, implemented with a hash-encoded NeRF to boost pose optimization, and a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen gradient computing.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a pioneering comprehensive real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration, distinct spatial viewpoints, and diverse sensor modalities, to facilitate research on multi-modal cooperative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The research explores minimizing human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning, and investigating how to transfer the insights gained from vision-based label-efficient panoptic segmentation to 3D point clouds.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, introducing a tensorial SDF representation and gradient-based mesh optimization layer for efficient and high-quality 3D generation.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, which achieves superior compression and quality for dynamic scenes with large motions and long durations.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) models in a distributed manner using Alternating Direction Method of Multipliers (ADMM), accelerating training time by 6+ times for large-scale scenes while achieving state-of-the-art rendering quality.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes MG-SLAM, a monocular SLAM system using 3D Gaussian representation, which achieves high-fidelity reconstruction and drift-corrected tracking, and introduces a language-extended loop closure module for global optimization and high-level understanding.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The paper proposes Gaussian Time Machine (GTM), a real-time rendering method that reconstructs 3D scenes with vastly varying appearances by modeling time-dependent Gaussian primitives with lightweight neural networks, achieving state-of-the-art rendering fidelity and being 100 times faster than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper introduces Motion-Based 3D Clothed Humans Synthesis (MOSS), a framework that uses kinematic information to achieve motion-aware Gaussian split for realistic clothing deformation and joint details, improving human 3D reconstruction from monocular videos with state-of-the-art visual quality.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper presents a novel method to estimate the 6D pose of an unknown target spacecraft relative to a monocular camera, enabling autonomous rendezvous and proximity operations for Active Debris Removal missions. The key contributions are:* A novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) models.* The method trains a NeRF model using a sparse collection of images that depict the target, generating a large dataset that captures the diversity of both pose distribution and illumination conditions.* The paper demonstrates the successful training of an off-the-shelf pose estimation network from a sparse set of images, and shows that a network trained using this method performs similarly to a model trained on synthetic images generated using the CAD model of the target.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM in multifloor environments, which extracts normal vectors for enhanced point cloud registration, addresses degeneracy situations, and includes a viewpoint-based loop closure module for robust performance.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-29**|**Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy**|Zijie Jiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The key contributions are:* A novel approach to enable the synthesis of arbitrarily novel viewpoint images within a patient's stomach from pre-captured monocular gastroscopic images using neural radiance fields (NeRF).* The incorporation of geometry priors from a pre-reconstructed point cloud into the training of NeRF to address the performance degradation due to view sparsity in local regions of monocular gastroscopy.* A novel geometry-based loss to both pre-captured observed views and generated unobserved views to effectively constrain the learned geometry by using the point cloud pre-reconstructed by SfM.* High-fidelity image renderings from novel viewpoints within the stomach both qualitatively and quantitatively.|[2405.18863v1](http://arxiv.org/abs/2405.18863v1)|null|
|**2024-05-29**|**NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the Wild**|Weining Ren et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NeRF On-the-go, a plug-and-play module for effective distractor removal, allowing robust novel view synthesis in complex, in-the-wild scenes from casually captured images, with a notable improvement over state-of-the-art techniques.|[2405.18715v1](http://arxiv.org/abs/2405.18715v1)|null|
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning in autonomous driving, enabling efficient fine-tuning for diverse multi-modal and single-modal perception models with improved performance on various 3D perception tasks.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|The key contributions from the paper's abstract and introduction are:1. A hybrid representation combining deformation fields, hash encoding, and 3D Gaussian splatting to significantly reduce memory usage while achieving efficient and realistic rendering of dynamic scenes.2. A learnable denoising mask that effectively identifies and removes noise points in 3D Gaussian splatting, thereby enhancing the purity and quality of scene rendering.3. Static constraints and motion consistency constraints introduced to minimize noise in points during motion, ensuring that deformation fields can accurately learn the dynamic offset of points.These contributions aim to address the limitations of existing methods, such as NeRF and 3D-GS, in terms of rendering speed, quality, and memory usage.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose HFGS, a novel approach for deformable endoscopic reconstruction that addresses under-reconstruction in both static and dynamic scenes by incorporating deformation fields, spatial high-frequency emphasis reconstruction, and temporal high-frequency emphasis reconstruction.|[2405.17872v2](http://arxiv.org/abs/2405.17872v2)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions of the paper are:* A method that enables 3DGS manipulation, achieving high-quality and photo-realistic rendering, by using a triangular mesh as a proxy to transfer mesh manipulation to 3DGS with 3DGS self-adaptation.* The introduction of a triangle shape aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The key contributions from the paper's abstract and introduction are:|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes Pyramidal 3D Gaussian Splatting (PyGS) that addresses challenges in large-scale scene modeling by using a hierarchical pyramidal Gaussian structure, dynamic weighting, and NeRF initialization to achieve fast rendering and capture high-frequency details.|[2405.16829v3](http://arxiv.org/abs/2405.16829v3)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that leverages pretrained 2D diffusion models to improve sparse-view reconstruction of 360 3D scenes with low-cost fine-tuning, achieving state-of-the-art results on the challenging Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for lightweight representation of terrain through an implicit continuous height field.* Developing a novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* Proposing a path planning algorithm that leverages the continuous and differentiable nature of the height field to achieve smoother paths compared to discrete path planning methods.* Demonstrating experiments on simulated and real-world terrain imagery, showing NEMOs' ability to generate high-quality reconstructions and produce smoother paths.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for HDR novel view synthesis, which surpasses state-of-the-art NeRF-based methods by 1.91 dB on HDR novel view synthesis, enjoys 1000x inference speed, and requires 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The paper proposes a steganography framework, GS-Hider, to embed 3D scenes and images into original 3D Gaussian Splatting (3DGS) point cloud files in an invisible manner, ensuring the security, fidelity, and flexibility of the hidden messages.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper presents a new approach to Neural Radiance Fields (NeRFs) that uses ray tracing to improve the rendering of highly specular objects with view-dependent appearance, achieving faster computation and higher quality reflections.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Neural Directional Encoding (NDE), a feature-grid-like neural network that accurately models the appearance of shiny objects by transferring spatial encoding to the angular domain, enabling fast and high-quality rendering of specular objects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, using a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to optimize pose refinement.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts, utilizing a multi-view diffusion model, transformer-based SDF field prediction, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field (NeRF) representation and compression, achieving improved quality and compression efficiency through a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The paper's key contributions are the proposal of a distributed training method for 3D Gaussian Splatting (3DGS) called DoGaussian, which accelerates training time by 6+ times on large-scale scenes while maintaining state-of-the-art rendering quality, and introduces a recursive scene splitting approach for distributed training with 3D Gaussian consensus ensuring training convergence and stability.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) method proposes a lightweight, real-time rendering solution for 3D scenes with varying appearances, achieving state-of-the-art reconstruction quality, 100 times faster rendering, and smooth appearance interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework that synthesizes 3D clothed humans by propagating global motion information to guide Gaussian split and detecting local deformations, achieving state-of-the-art visual quality in 3D reconstruction from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions in the paper's abstract and introduction:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) models. The method is capable of estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, a crucial step towards autonomous rendezvous and proximity operations in Active Debris Removal missions.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach derived from Multi-View Stereo, which efficiently reconstructs unseen scenes with real-time rendering and better synthesis quality, while achieving 13.3x less training computational cost compared to vanilla 3D-GS.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:The paper discusses the potential of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques for representing and transmitting 3D contents in 6G networks, aiming to enable immersive communications with high-quality rendering results. The paper highlights the need to efficiently represent, transmit, and reconstruct 3D contents over wireless networks, considering the limitations of current techniques and the requirements of emerging 6G applications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (MV-PS) method that leverages per-pixel intensity renderings, explicitly models point light attenuation and cast shadows, and uses a fully neural material renderer to achieve competitive reconstruction accuracy using only 6 lights and matching the state-of-the-art performance when all lights and normal map information is fused.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction:* The paper proposes a method for generating realistic-looking adversarial objects for autonomous driving systems, which can deceive computer vision-based systems without detection.* The approach is based on a novel modification to the gradient-based texture optimization method, which includes an evaluative mechanism (the "Judge") to assess the realism of the generated objects.* The Judge assigns a probability score to the realism of an object, which is then integrated into the loss function to encourage the object renderer to produce realistic and adversarial textures simultaneously.* The paper explores various strategies for optimizing the Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced vision-language models, pretraining neurosymbolic systems, and utilizing traditional image processing techniques.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of the paper are summarized as follows:* Developing a two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, allowing for accurate characterization of signal dynamics.* Proposing a novel R-NeRF method to model the signal field for any specified RIS placement and receiver location.* Experimental results demonstrating the effectiveness of the proposed method with simulated and measured data.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving high-fidelity scene representation, accurate real-time tracking, and low memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive overview of Large Language Models (LLMs) and 3D spatial data integration, highlighting their potential to advance spatial comprehension and interaction, and discusses current methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions mentioned in the abstract and introduction:The paper presents a procedure to convert between implicit representations of a scene, such as neural radiance fields (NeRFs), and explicit representations, such as Gaussian splatting (GS). This conversion enables the benefits of both approaches, including the generalization of NeRFs to new views and the rendering speed of GS. The proposed method achieves state-of-the-art results in terms of PSNR, SSIM, and LPIPS on dissimilar views, while also reducing the computational cost of training and rendering.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This review aims to provide a comprehensive overview of the development and implementation principles of Dynamic Neural Radiance Field (NeRF), highlighting its potential in practical applications and analyzing the main principles and techniques from 2021 to 2023.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that overcomes limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving real-time processing and significantly longer sub-maps and improved mapping coverage in human colonoscopies.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|The paper proposes the first RGB-only SLAM system that uses a dense 3D Gaussian map representation with global map and pose optimization, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy, while also yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes NeB-SLAM, an end-to-end neural RGB-D SLAM system for unknown scenarios, which uses a divide-and-conquer mapping strategy and adaptive map growth to achieve scalable and predictive performance in real-time.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes a novel method that enhances translation accuracy during initialization in Stereo Visual-Inertial SLAM systems by using a 3-DoF bundle adjustment independently of rotation estimation, achieving improved accuracy and run-time efficiency.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper proposes Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs 3D human bodies and camera motion in a common global coordinate system from monocular videos, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The authors present a pioneering multi-robot collaborative perception dataset, featuring real-world data from both ground and aerial robots with diverse sensor modalities and mobilities, which can aid in the development of robust and accurate perception systems for various applications.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The research aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations, making it possible to adapt to new domains without sacrificing performance on previous ones.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, that achieves drift-corrected tracking, high-fidelity reconstruction, and high-level understanding of the environment using 3D Gaussian representations and CLIP feature-based loop closure.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments with multifloor structures, enhancing point cloud registration performance and addressing degeneracy issues in confined spaces.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a novel robotic mapping system that combines ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to enable a robust and long-term mapping system that can work in diverse, dynamic, and unmodeled scenarios.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3D Gaussian Splatting (3DGS)-based Simultaneous Localization and Mapping (SLAM) approach that integrates deep visual features, dual keyframe selection, and 3DGS, achieving high-fidelity scene representation, accurate tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors propose a lightweight circular convolutional Transformer network, CCTNet, that captures structural information in point clouds and facilitates cross-dimensional interaction, improving place recognition accuracy and handling movable objects in complex scenarios.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an optimization-based SLAM approach that simultaneously optimizes the robot trajectory and occupancy map from 2D laser scans and odometry, while state-of-the-art techniques process these data in two steps and rely on pre-estimated accurate robot poses.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|This paper presents Incremental Probabilistic Consensus (IPC), a method that robustly handles outliers in Pose Graph Optimization (PGO) for Simultaneous Localization and Mapping (SLAM) problems, providing an online and consensus-based approach to build the maximally consistent set of loop closure measurements.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper introduces OverlapMamba, a novel place recognition network that utilizes raw range views (RVs) as input, achieving robust place recognition capabilities and real-time efficiency by leveraging a stochastic reconstruction approach and a state space model, outperforming typical LiDAR and multi-view combination methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose SceneFactory, a workflow-centric and unified framework for incremental scene modeling that supports various applications, including multi-view depth estimation, LiDAR completion, and SLAM, and contributes a robust depth estimation block, dual-purpose multi-resolution neural points representation, and a user-friendly 3D creation process.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU without GPU support, by incorporating a mask prediction mechanism and a dual-stage optical flow tracking approach, demonstrating high localization accuracy and 56 fps tracking rate.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a system for generating real-time 3D facial reconstructions using LiDAR and TrueDepth sensor data from a smartphone, introducing three approaches (monocular depth estimation, LiDAR + TrueDepth fusion, and template modeling) that can run on a portable device like an iPhone 14 Pro, enabling interactive and immersive holographic experiences.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses, and introduces three key advancements: (1) a depth-based ray sampling strategy, (2) a coarse-to-fine training strategy, and (3) a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel framework for dense VSLAM combining sparse visual odometry with Gaussian Splatting, eliminating depth map dependency, enhancing tracking robustness, and achieving state-of-the-art performance in pose estimation and novel view synthesis.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel framework, NeuRSS, for sidescan sonar SLAM that leverages neural rendering to estimate bathymetry and improves AUV positioning accuracy, addressing the elevation degeneracy issue in SSS SLAM and enabling high-quality bathymetric mapping.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|The paper introduces NGM-SLAM, a 3D Gaussian Splatting (3DGS) based SLAM system that leverages neural radiance field submaps for progressive scene expression and loop closure detection, achieving high-quality scene reconstruction, accurate hole filling, and real-time performance.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) in autonomous robotics, examining its applications in perception, localization, navigation, and decision-making, and benchmarks existing methods, highlighting their strengths, limitations, and potential for future integration with advanced techniques.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper highlights the crucial role of place recognition (PR) in Simultaneous Localization and Mapping (SLAM) 2.0, aiming to bridge the gap between PR advancements and real-world robotic systems, by providing a comprehensive review of the current state-of-the-art and remaining challenges in PR.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel neural mapping framework that anchors lightweight neural fields to a pose graph for efficient incorporation of loop closures and scalability, demonstrating improved performance on large-scale scenes and outperforming existing state-of-the-art approaches.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a deep learning-based SLAM system, named SL-SLAM, that combines deep feature extraction and matching methods to enhance adaptability in challenging environments, outperforming state-of-the-art algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|The paper presents X-SLAM, a real-time and differentiable dense SLAM system that leverages the complex-step finite difference method to efficiently calculate numerical derivatives, enabling task-oriented optimization of SLAM parameters.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM, an open-source visual SLAM system, robustly handles dynamic environments and unknown moving objects using panoptic segmentation to filter out dynamic objects during state estimation, outperforming state-of-the-art systems in various datasets and scenarios.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions from the paper's abstract and introduction are:* Modeling the exchange of information between multiple mobile terminals (MTs) to enable cooperative localization and data fusion of map features (Virtual Anchors, VAs) observed by different MTs.* Integrating inertial measurement units (IMUs) as additional sensors for each MT, which provides additional information for orientation and state transition estimation.* Analyzing the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple-input-multiple-output (MIMO) and single-input-multiple-output (SIMO) systems using numerical simulation.The authors introduce a Bayesian particle-based Sum-Product Algorithm (SPA) for cooperative MP-SLAM, which enables data fusion over different observations of map features by different MTs and cooperative localization using probabilistic data association.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The Real-time Gaussian SLAM (RTG-SLAM) system uses Gaussian splatting with a compact representation and on-the-fly Gaussian optimization to achieve real-time 3D reconstruction at scale, outperforming state-of-the-art NeRF-based SLAM methods in terms of speed, memory, and realism.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
