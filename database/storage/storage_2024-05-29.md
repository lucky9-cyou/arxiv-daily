# arxiv-daily
 Automated deployment @ 2024-05-29 09:27:49 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a real-time V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling the system to process complete human colonoscopies in real-time with improved tracking and mapping capabilities.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a RGB-only SLAM system using 3D Gaussian Splatting, which leverages global map and pose optimization, monocular depth estimation, and deformable map updates to achieve superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which represents the entire scene as a set of sub-maps (neural blocks) that can be adaptively allocated and grown during camera tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a new method for enhancing translation accuracy during the initialization stage in Stereo Visual-Inertial SLAM (VI-SLAM) systems. The method, called ETA, separate estimates rotation using IMU integration and then uses it to enhance translation estimation through 3-DoF bundle adjustment. ETA outperforms previous methods, including ORB-SLAM3 and Stereo-NEC, in terms of accuracy and runtime speed.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a novel approach that marries camera and human reconstruction from monocular videos, enabling consistent reconstructions of camera trajectories, human meshes, and dense scene point clouds in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a pioneering real-world multi-robot collaborative perception dataset, which leverages air-ground robot collaboration to enhance overall perception, featuring raw sensor inputs, pose estimation, and optional high-level perception annotation.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summarized version of the key contributions from the abstract and introduction, encapsulated in a single sentence under 50 words:The research aims to minimize human effort in deploying robotic systems to new environments by leveraging continual learning and reducing human annotations, addressing the challenges of adapting to unseen domains while retaining performance on previous environments.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking and high-fidelity reconstruction using 3D Gaussian representation, and its key contributions include a novel CLIP feature-based loop closure module and a real-time mapping approach that initializes and trains 3D Gaussian representation without additional depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, addressing challenges in point cloud registration due to rapid changes and repetitive structural features, and achieves robust registration by extracting normal vectors and analyzing their distribution to adjust matching uncertainty.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that uses ground segmentation and graduated non-convexity-based registration to reject outliers, and hierarchical multi-session SLAM and instance-aware static map building to handle moving objects and dynamic environments.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper presents a novel 3D Gaussian Splatting (3DGS)-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS, improving tracking and mapping accuracy while reducing memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The paper proposes a lightweight circular convolutional Transformer network, CCTNet, to address the issues of "restricted receptive fields" and "excessive focus on local regions" in current range image-based place recognition networks, achieving superior performance with Recalls of 0.924 and 0.965 on the KITTI and Ford Campus datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot trajectory and occupancy map using 2D laser scans and odometry, representing a novel method that combines robot poses and occupancy map optimization together.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|The paper proposes a new method, IPC, for simultaneous localization and mapping (SLAM) that incrementally builds a maximally consistent set of loop closure measurements while handling large amounts of outliers, and it provides an online, consensus-based approach that outperforms several state-of-the-art methods in handling outliers while maintaining online performance.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present OverlapMamba, a novel network that represents range views as sequences and uses a stochastic reconstruction approach to build shift state space models, achieving robust place recognition and real-time efficiency.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose SceneFactory, a workflow-centric framework that supports various scene modeling applications, including depth estimation, LiDAR completion, and SLAM, with four building blocks: Mono-SLAM, depth estimation, scene reconstruction, and multi-view depth estimation.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on CPU by incorporating a mask prediction mechanism for dynamic object segmentation, enabling parallel processing with camera tracking, and demonstrating high localization accuracy in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR augmented reconstruction, monocular depth estimation, and template modeling, aiming to achieve high-fidelity, real-time, and portable facial reconstructions on a device like an iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, and introduces three advancements: a truncated depth-based ray sampling strategy, coarse-to-fine training, and a robust inter-frame point constraint for improved pose estimation and depth accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces a novel framework, MGS-SLAM, which combines sparse visual odometry with 3D Gaussian Splatting to construct a dense Gaussian map using only RGB images, improving tracking robustness and achieving state-of-the-art performance in pose estimation and novel view synthesis.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose a framework, NeuRSS, that combines neural rendering for bathymetry estimation from sidescan sonar (SSS) data and simultaneous localization and mapping (SLAM) to improve AUV positioning and bathymetric mapping, addressing the elevation degeneracy challenge in SSS SLAM.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes NGM-SLAM, a 3D Gaussian Splatting (3DGS) system that integrates neural radiance fields for progressive scene expression and loop closure detection, achieving high-quality scene reconstruction and tracking performance on multiple real-world scenes and large-scale datasets.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey and analysis of Neural Radiance Fields (NeRF) in autonomous robotics, exploring its applications in perception, localization and navigation, and decision-making, and discussing its limitations and future integration with advanced technologies for enhanced capabilities.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper aims to highlight the crucial role of place recognition (PR) in Simultaneous Localization and Mapping (SLAM) 2.0, and provide a comprehensive review of the current state-of-the-art advancements in PR, as well as its broad applications in robotics, while emphasizing the need for scalable, adaptable, and efficient solutions.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|The paper proposes a neural mapping framework that anchors lightweight neural fields to a sparse visual SLAM system's pose graph, enabling efficient incorporation of loop closure constraints and scalable mapping.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|The paper introduces a hybrid visual SLAM system that combines deep feature extraction and deep matching methods to enhance adaptability in challenging environments, such as low-light conditions and dynamic lighting, and outperforms state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors present X-SLAM, a real-time dense differentiable SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, enabling task-aware optimization and high-order differentiation for improved accuracy and efficiency in various applications.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present Panoptic-SLAM, an open-source visual SLAM system that uses panoptic segmentation to filter dynamic objects and is robust to unknown moving objects, achieving higher accuracy than several state-of-the-art systems in dynamic environments.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions from the paper's abstract and introduction are:1. **Cooperative MP-SLAM**: The paper introduces a Bayesian particle-based SPA for cooperative MP-SLAM, enabling data fusion over different observations of map features (VAs) by different MTs and cooperative MT-to-MT measurements using RF signals.2. **Modeling exchange of information**: The paper models the exchange of information between different MTs, allowing for cooperative localization and data fusion of VAs over different MTs.3. **Inertial measurement unit (IMU) integration**: The paper fully integrates an IMU as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation, allowing to cope with complex trajectories.4. **Numerical simulation**: The paper analyzes the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulation.5. **Scalability**: The paper claims that the proposed algorithm is scalable for large numbers of PVAs and measurements by using a "redundant formulation" and message passing.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions in one sentence under 50 words:The authors present RTG-SLAM, a real-time 3D reconstruction system that uses Gaussian splatting, achieving comparable quality to state-of-the-art NeRF-based SLAM methods but with around twice the speed and half the memory cost.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces the storage requirements of 3DGS by factorizing coordinates and attributes, allowing for efficient representation of dense clusters of Gaussians with significantly fewer parameters while preserving image quality.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a novel V-SLAM system that uses SIFT features and brute-force matching to overcome tracking losses in human colonoscopies, achieving real-time performance and significantly improving map merging and relocation capabilities compared to ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), which leverages a hierarchical assembly of Gaussians and NeRF initialization to render large-scale scenes with high-fidelity details and accelerated rendering performance, achieving a significant leap in performance and speed over state-of-the-art methods.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel RGB-only SLAM system that uses 3D Gaussian splatting as a map representation, dynamically adapting to keyframe pose and depth updates, and refining depth updates with a monocular depth estimator, achieving superior or on-par performance with existing RGB-only SLAM methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view 360-degree scene reconstruction, filling in missing details and cleaning novel views, and achieves better performance than existing methods on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.These contributions aim to address the limitations of traditional terrain representations, such as Digital Elevation Models (DEMs), and develop a more robust and versatile navigation solution for autonomous ground robots.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions of the paper's abstract and introduction:The authors propose NeB-SLAM, a neural block-based, scalable, and real-time RGB-D SLAM method for unknown scenes, which adopts a divide-and-conquer mapping strategy and adaptive map growth to achieve efficient scene coverage and hole-filling.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose HDR-GS, a novel framework for 3D high dynamic range imaging, which offers efficient rendering, controllable exposure time, and improved visual quality, outperforming state-of-the-art NeRF-based methods in terms of PSNR, SSIM, and LPIPS.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original GS point clouds, ensuring security, fidelity, and flexibility, with capabilities to hide multiple messages and extract them accurately.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are: a method to enhance translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM, which uses a 3-DoF Bundle Adjustment (BA) to improve translation estimate, keeps rotation estimate fixed, and updates rotation estimate by considering IMU measurements and gyroscope bias.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents an approach to improve Neural Radiance Fields (NeRFs) by introducing ray tracing, which efficiently renders consistent reflections of nearby and distant content, and renders higher-quality specular reflections without relying on large and computationally expensive neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a framework that combines visual SLAM and human mesh reconstruction to jointly reconstruct camera trajectories, human meshes, and scene point clouds in a common world frame, addressing ambiguities in depth, scale, and dynamic scenes.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of this paper are: Neural Directional Encoding (NDE), a feature-grid-like encoding for modeling high-frequency view-dependent appearance and global illumination effects in rendering specular objects, which outperforms the state of the art in view synthesis and achieves fast (real-time) inference.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper's key contributions are a two-staged pipeline for camera relocalization under varying lighting conditions, a hash-encoded NeRF for fast training and robust camera pose refinement, and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration with distinct spatial viewpoints, sensor modalities, and coverage ranges, which caters to diverse research interests and enables the study of multi-modal collaborative perception using real-world data.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:1. Investigating how to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations for efficient learning.2. Exploring the use of vision foundation models for extremely label-efficient training to achieve competitive results with fully supervised learning methods.3. Developing a novel panoptic segmentation approach that requires as few as ten annotated images and can be used as a plug-in for existing methods.4. Introducing a method for automatic target-less camera-LiDAR calibration that requires neither human initialization nor special data recording.5. Investigating the use of multi-agent collaboration for efficient robot learning.These contributions aim to address the limitations of existing methods that rely on large amounts of densely labeled training data and instead aim to achieve efficient learning with minimal human annotations.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality triangular meshes with illumination-decoupled textures from text or single images, utilizing multi-view diffusion models, transformer-based models, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which achieves superior quality and compression efficiency by employing a compact residual feature grid and a coefficient feature grid, and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that splits scenes into blocks, uses Alternating Direction Method of Multipliers (ADMM) for consistency, and achieves 6+ times faster training and state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MG-SLAM, a monocular SLAM system that combines 3D Gaussian Splatting with a language-extended loop closure module based on CLIP features to achieve drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, enabling accurate reconstructions of scenes with vastly varying appearances and achieving state-of-the-art rendering fidelity.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MOSS, a framework that addresses the challenge of reconstructing 3D clothed humans by incorporating kinematic information to guide Gaussian split and detect local deformations, resulting in state-of-the-art visual quality and real-time rendering.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, using a Neural Radiance Field (NeRF) model to generate a large training set from a sparse collection of spaceborne images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework that solves the challenges of LIO algorithms in indoor multifloor environments by utilizing normal vectors from LiDAR scans for correspondence search, mitigating degeneracy through normal vector direction distribution analysis, and implementing viewpoint-based loop closure to ensure robust registration.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The key contributions from the paper's abstract and introduction are the development of MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo to efficiently reconstruct unseen scenes, and proposes a hybrid Gaussian rendering and a consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper explores the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G wireless networks to support immersive communication applications. The authors discuss the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks, and highlight the potential of NeRF and 3D-GS to provide photorealistic rendering results for complex scenes. The paper also emphasizes the need for new distributed training and inference methods for NeRF and 3D-GS models, as well as joint computation and communication designs to minimize end-to-end latency while preserving quality of experience (QoE) requirements.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions of the paper are:* A novel multi-view photometric stereo method that leverages per-pixel intensity renderings rather than relying mainly on estimated normals.* A method that models point light attenuation and explicitly raytraces cast shadows in order to best approximate each point's incoming radiance.* A fully neural material renderer that uses minimal prior assumptions and is jointly optimized with the surface.* The ability to achieve competitive reconstruction accuracy using only 6 lights and match the SOTA performance when all lights and normal map information is also fused.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a Judge to evaluate object realism and ensure that generated objects are both adversarial and realistic.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Proposing a novel two-stage framework for simulating electromagnetic signal propagation in RIS-enabled wireless environments, which accurately characterizes signal dynamics.* Integrating NeRF-based ray tracing techniques with electromagnetic physics to model the signal field for any specified RIS placement and receiver location.* Validating the effectiveness of the proposed method through simulations and measured data, demonstrating superior prediction performance compared to NeRF2 and traditional MRI and MLP methods.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work in diverse scenarios, featuring fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to address the challenges of real-world robotic services and SLAM competitions.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that uses structured coordinates and decomposed representations of Gaussians to reduce spatial redundancy and achieve high-performance, compact storage, and fast rendering in 3D scene representation.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS), a scalable and efficient method that overcomes the challenges of rendering large-scale scenes by incorporating a hierarchical Gaussian structure, dynamic weighting, and rapid NeRF initialization, achieving a significant performance leap.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a novel method that uses pretrained 2D diffusion models for sparse-view reconstruction of 360-degree scenes, effectively filling in missing details and generating novel views through iterative updates and 2D-to-3D distillation.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here are the key contributions from the paper's abstract and introduction:* The paper introduces Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* NEMos can be generated from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.* The paper proposes a novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm is introduced that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.* The paper presents experiments on simulated and real-world terrain imagery, demonstrating NEMos' ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.These contributions aim to address the limitations of traditional terrain representations, such as digital elevation models (DEMs), by providing a more efficient and effective way to generate and utilize terrain information for autonomous ground robots.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The key contributions of the paper are the proposal of High Dynamic Range Gaussian Splatting (HDR-GS) framework for 3D HDR imaging, which can render novel HDR views and reconstruct LDR images with a user input exposure time, achieving superior performance on HDR novel view synthesis while enjoying 1000x faster inference speed and reduced training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The key contributions of the paper can be summarized as follows: the authors propose a novel steganography framework, GS-Hider, specifically designed for 3D Gaussian Splatting (3DGS) that enables the hiding of messages in 3D scenes and images while ensuring high fidelity, security, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a ray tracing-based approach that outperforms existing methods for rendering view-dependent appearance and reflections in shiny objects, using a small and inexpensive network to decode feature vectors, while reducing optimization and rendering time.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a novel view-dependent appearance encoding method for rendering specular objects, which improves modeling of high-frequency angular signals and efficiently handles interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting and shadow conditions using a hash-encoded NeRF, which achieves state-of-the-art results under varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts by leveraging a multi-view diffusion model, a transformer-based model, and a gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by employing a compact residual feature grid, coefficient feature grid, and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for Large-scale 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times, ensures training convergence, and achieves state-of-the-art rendering quality, while maintaining a single global 3DGS model during inference.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a real-time rendering method that models time-dependent Gaussian primitives and decomposes color for improved geometric consistency, achieving state-of-the-art rendering fidelity on 3 datasets and 100x faster rendering speed than NeRF-based counterparts.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework that leverages kinematic information to achieve motion-aware 3D clothed human synthesis, improving surface deformation, joint details, and clothing folds, and outperforming existing methods in visual quality and efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, enabling autonomous rendezvous and proximity operations for Active Debris Removal missions. The method leverages an in-the-wild Neural Radiance Field (NeRF) to generate a large dataset of images with diverse viewpoints and illumination conditions, which is then used to train an off-the-shelf spacecraft pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach derived from Multi-View Stereo (MVS) that efficiently reconstructs unseen scenes by encoding geometry-aware Gaussian representations, decoding them into Gaussian parameters, and proposing a hybrid Gaussian rendering and a multi-view geometric consistent aggregation strategy for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:* The paper discusses the importance of efficient representation, transmission, and reconstruction of 3D contents in 6G networks, particularly for immersive communication applications such as extended reality (XR), telepresence, and metaverse.* Neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) are introduced as promising 3D representation techniques that can provide photorealistic rendering results for complex scenes.* The paper highlights the challenges of integrating NeRF and 3D-GS in 6G networks, including the need for new distributed training and inference methods, joint computation and communication designs, and efficient transmission and storage of radiance field models.* The authors propose a comprehensive overview of the integration of NeRF and 3D-GS in 6G, including model compression, rendering acceleration, and joint computation and communication designs.* The paper emphasizes the importance of embracing radiance field rendering in 6G networks to support emerging 3D applications with enhanced quality of experience.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learned renderers.* Unlike previous methods, this approach explicitly uses per-pixel intensity renderings rather than relying mainly on estimated normals.* The method models point light attenuation and explicitly ray-traces cast shadows to best approximate each point's incoming radiance.* The estimated normal and segmentation maps can also be incorporated to maximize surface accuracy.* The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.* The approach is among the first to outperform the classical DiLiGenT-MV method, achieving an average Chamfer distance of 0.2mm for objects imaged at 1.5m distance with a 400x400 resolution.Please note that this is a single sentence summary under 50 words.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summarized response in a single sentence under 50 words:This paper proposes a gradient-based texture optimization method using an evaluative mechanism called the "Judge" to craft realistic-looking adversarial objects for autonomous driving systems, aiming to ensure adversarial objects can blend seamlessly into real-world environments without detection.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in one sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to model dynamic electromagnetic fields in RIS-enabled environments, accurately capturing complex propagation dynamics and signal field for any specified RIS placement and receiver location, enhancing RIS deployment for efficient communication.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving accurate real-time tracking, high-fidelity reconstruction, and state-of-the-art performance on indoor RGB-D datasets with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive overview of methodologies enabling Large Language Models (LLMs) to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction in AI systems, and discussing challenges and future research directions.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:1. Developing a procedure to convert between implicit representations of scenes, such as neural radiance fields (NeRFs), and explicit representations, such as Gaussian splatting (GS).2. Showcasing the benefits of this conversion, including the ability to achieve the best of both worlds: the high rendering quality of NeRFs and the fast rendering speed of GS.3. Demonstrating the efficacy of this approach on a variety of datasets, including those with sparse views, and on views recorded from an ego-centric camera along hiking trails.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an in-depth analysis of Dynamic NeRF, a novel implicit method for 3D reconstruction and representation with high resolution, highlighting its development history, key methods, and comparison of features, and discusses its potential applications and future directions.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a method that synergistically integrates a coordinate-based network and a tensorial feature network to improve the performance of Neural Radiance Fields (NeRFs) from sparse inputs.* The method captures low-frequency details using coordinate-based features and fine-grained details using multi-plane features, allowing for efficient and effective representation of radiance fields.* The authors show that the proposed method outperforms other state-of-the-art methods, including explicit representation methods, in terms of reconstruction quality and rendering speed.* The method reduces the number of parameters by avoiding the need for a spatial low-resolution grid and replacing it with coordinate-based features.Note that the abstract and introduction are concise and provide an overview of the paper's main contributions, but do not fully reveal the technical details of the proposed method.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module, enhancing NeRF-based scene editing tasks by addressing object movement variability and empty regions, achieving state-of-the-art performance in 3D object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a framework for real-time 3D facial reconstruction using LiDAR augmented augmented reality, enabling high-fidelity, interactive, and immersive holographic experiences on portable devices like the iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|This paper proposes Truncated Depth-NeRF (TD-NeRF), a method that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses using monocular depth priors, achieving superior performance and more accurate depth geometry on three datasets.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LIVE, a novel design method to create interactive LaTeX graphic items, enabling the design of more dynamic and informative figures and tables, and aims to improve the writing of traditional papers, particularly review papers, by adding interactive elements.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes SketchDream, a text-driven 3D content generation and editing method that supports NeRF generation from hand-drawn sketches and achieves free-view sketch-based local editing, addressing challenges in 2D-to-3D translation, text-based control, and local editing.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
