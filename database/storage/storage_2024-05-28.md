# arxiv-daily
 Automated deployment @ 2024-05-28 20:51:06 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while preserving image quality. The key contributions are: 1) factorized coordinates and features using classical matrix and tensor factorization techniques, and 2) a binary mask for removing unnecessary Gaussians to accelerate training and rendering speed. The method achieves a significant reduction in storage costs by downsizing 3DGS over 90%, while maintaining comparable image quality.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a real-time V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving 88% mapping coverage in the C3VD dataset and 53% in a real colonoscopy, a 70% improvement over ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Pyramidal 3D Gaussian Splatting (PyGS), which enhances 3D Gaussian Splatting to model large-scale scenes with high-fidelity results and accelerated rendering performance, addressing challenges such as heterogenous object scales and sparse point cloud generation.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a novel RGB-only SLAM system using 3D Gaussian Splatting that combines frame-to-frame tracking with global map and pose optimization, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses 2D diffusion models and a cascaded approach to fill in missing details and clean novel views in sparse-view reconstruction of 360-degree scenes.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper's abstract and introduction can be summarized as follows:* The authors introduce Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model, allowing for the representation of terrain elevation from 2D camera images.* NEMos jointly train a height field and radiance field within a NeRF framework, leveraging quantile regression to learn the height information from images alongside the NeRF density distribution.* The authors propose a novel method for path planning that leverages the continuous and differentiable nature of the height field to achieve smoother paths than those obtained via discrete planning over equivalent digital elevation models (DEMs).* The paper evaluates the quality of the NEMo training and analyzes the path planning results for the KT-22 and Red Rocks scenes, demonstrating the effectiveness of the proposed approach.Note that this summary is focused on the key contributions mentioned in the abstract and introduction, and does not include all the details provided in the paper.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which employs a divide-and-conquer mapping strategy and adaptive map growth strategy to achieve real-time, scalable, and predictive dense SLAM in unfamiliar settings.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which outperforms state-of-the-art NeRF-based methods by 1.91 dB on HDR novel view synthesis while enjoying 1000x inference speed and 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel steganography framework, dubbed GS-Hider, which enables the invisible embedding and extraction of 3D scenes and images into 3D Gaussian Splatting (3DGS) point cloud files, addressing the unique challenges of 3DGS's explicit 3D representation and real-time rendering speeds.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes a novel method, ETA, that enhances translation accuracy during the initialization stage of Stereo Visual-Inertial SLAM systems by using a 3 Degree-of-Freedom Bundle Adjustment to refine translation estimates independently of rotation, while also considering IMU measurements and gyroscope bias to improve rotation estimation.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a ray tracing approach for Neural Radiance Fields (NeRFs) that tackles the limitations of previous methods by rendering consistent reflections of nearby and distant scene content using a small MLP and ray tracing, achieving improved efficiency and photorealistic specular appearance.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper introduces SynCHMR, a pipeline that combines Human-aware Metric SLAM with Scene-aware SMPL Denoising to reconstruct metric-scale camera poses, scene point clouds, and human meshes from monocular videos, enabling consistent and synergistic recovery of camera and human movements in a common world frame.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The key contributions of the paper are the introduction of Neural Directional Encoding (NDE), a view-dependent appearance encoding of neural radiance fields (NeRF) that improves the modeling of high-frequency angular signals and specifically addresses the challenging interreflection effects in rendering specular objects. NDE uses a novel spatio-spatial parameterization by cone-tracing a spatial feature grid to encode near-field reflections and achieves both high-quality modeling of view-dependent effects and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization under varying lighting conditions, utilizing a hash-encoded neural radiance field (NeRF) and a shadow removal module, and contributes a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to improve the pose optimization process.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring raw sensor inputs, pose estimation, and optional high-level perception annotation, to facilitate research in this understudied area and unlock the potential of multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The contributions from the paper's abstract and introduction can be summarized in a single sentence under 50 words:The research focuses on developing label-efficient and continual learning approaches for robotic systems, enabling robots to adapt to new environments and tasks with minimal human supervision, utilizing concepts from vision foundation models and graph-based optimization.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel feed-forward framework called LDM that generates high-fidelity, illumination-decoupled textured meshes from a single image or text prompts, introducing a tensorial SDF representation to improve convergence speed and enhancing geometry and texture quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel approach that jointly optimizes dynamic NeRF representation and compression, achieving superior quality and compression efficiency by leveraging a compact residual feature grid and sequential feature compression, and outperforms state-of-the-art methods in rate-distortion performance.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining high-fidelity rendering quality, addressing the limitations of previous 3DGS methods on memory and training time.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's abstract and introduction in under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module that performs drift-corrected tracking, high-fidelity reconstruction, and achieves a high-level understanding of the environment without requiring depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The Gaussian Time Machine (GTM) method is proposed to reconstruct 3D scenes with discontinuous appearance variations, achieving state-of-the-art rendering fidelity and real-time rendering capabilities while disentangling appearance changes from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, an innovative framework for single-view clothed human reconstruction, which employs kinematic information to achieve motion-aware Gaussian split on the human surface, resulting in state-of-the-art visual quality and improved detail and realism.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) to generate a large dataset from a sparse set of images, demonstrating its feasibility on realistic images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework that enhances point cloud registration performance in indoor environments with multifloor structures by extracting normal vectors and analyzing their distribution to address degeneracy and uncertainty.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:MVSGaussian proposes a generalizable 3D Gaussian representation approach derived from Multi-View Stereo, incorporating efficient rendering and geometric consistent aggregation, achieving real-time rendering with better novel view synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions from the paper's abstract and introduction are:1. The authors highlight the importance of efficient representation, transmission, and reconstruction of 3D contents for immersive communication, a key challenge in 6G networks.2. They discuss the pros and cons of two promising 3D representation techniques, Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS), and their potential applications in 6G networks.3. The integration of NeRF and 3D-GS in 6G networks is envisioned to support emerging 3D applications with enhanced quality of experience, particularly in immersive communication scenarios.4. The authors propose new approaches to address the technical challenges of integrating radiance field models into 6G networks, including joint computation and communication designs, and federated learning for distributed training and inference.5. The paper highlights the need for a unified design of the sensing-communication-computation pipeline over 6G wireless networks to minimize end-to-end latency while preserving quality of experience requirements.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and raytraces cast shadows to estimate 3D shape, achieving competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a Judge mechanism that evaluates the realism of generated objects, aiming to create a balance between adversarial effectiveness and visual realism.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method for modeling dynamic electromagnetic fields in RIS-enabled environments, accurately capturing complex propagation dynamics and enabling efficient RIS deployment for improved communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work out-of-the-box by addressing issues of catastrophic failure, ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that drastically reduces storage requirements while preserving image quality by representing and approximating dense clusters of Gaussians with significantly fewer Gaussians through efficient factorization, achieving a storage reduction of over 90% and maintaining comparable image quality compared to 3DGS.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Pyramidal 3D Gaussian Splatting (PyGS), which combines hierarchical Gaussian arrangement with NeRF initialization to represent large-scale scenes with high-fidelity and accelerated rendering performance, outperforming current state-of-the-art approaches by over 400 times.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360-degree scenes, achieving multi-view consistency and coherent details with only 9 input views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions of the paper are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.The paper proposes NEMos as a novel representation for terrain mapping, which leverages the advantages of NeRFs in fast generation solely from imagery and rich visual reconstruction, while also capturing compact terrain geometry in the form of a continuous and differentiable height field. The paper introduces a new method for jointly training a height field and radiance field, which allows the NeRF to benefit from height supervision. The path planning algorithm is designed to optimize the continuous cost function, which takes into account distance, slope changes, and control effort.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel framework, High Dynamic Range Gaussian Splatting (HDR-GS), that efficiently renders novel HDR views and reconstructs LDR images with controlled exposure time, outperforming state-of-the-art NeRF-based methods in terms of quality and speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in one sentence under 50 words:The proposed GS-Hider framework is a steganography method that embeds 3D scenes and images into original 3DGS point cloud files in an invisible manner, ensuring robust security, high fidelity, large capacity, and versatility, with applications in copyright protection, encrypted communication, and 3DGS compression.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a ray tracing-based approach to improve Neural Radiance Fields (NeRFs) for rendering high-frequency view-dependent appearance of shiny objects by casting reflection rays and decoding feature vectors into color, outperforming prior methods and requiring comparable optimization time.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Neural Directional Encoding (NDE), a feature-grid-like method that efficiently models high-frequency view-dependent appearance and complex interreflection effects in NeRF, achieving state-of-the-art results in rendering specular objects and fast evaluation speeds.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting conditions, using a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality textured meshes with decoupled illumination from text or single images in seconds, utilizing a multi-view diffusion model, transformer-based SDF predictor, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end learning scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior rate-distortion performance, efficient representation, and entropy-minimization compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed method that accelerates the training of 3D Gaussian Splatting (3DGS) on large-scale scenes by 6+ times while achieving state-of-the-art rendering quality, by splitting scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives to reconstruct 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity and speed, and disentangling appearance changes from geometry.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework for single-view clothed human reconstruction, which incorporates kinematic information to achieve motion-aware Gaussian split and detects local occlusions to restore realistic joint details and fine clothing folds.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper proposes a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera using a Neural Radiance Field (NeRF). The key contributions are:* A model-agnostic method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target, without requiring the knowledge of the target's CAD model.* A NeRF model trained on a sparse collection of images depicting the target, which is then used to generate a large dataset that captures the diversity of both the pose distribution and illumination conditions encountered in orbit.* The successful validation of the proposed method on Hardware-In-the-Loop images of SPEED+, which emulates lighting conditions close to those encountered on orbit.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo, efficient hybrid Gaussian rendering, and a consistent aggregation strategy to achieve real-time rendering with better synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper focuses on the integration of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks to support immersive communication applications that require the transmission and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summarized version of the paper's abstract and introduction in a single sentence under 50 words:The authors present a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and explicitly models point light attenuation and casts shadows, achieving competitive accuracy despite relying on minimal prior assumptions and using neural shape representations.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems.* The introduction of a Judge, an evaluative mechanism, to assess the realism of generated objects.* The use of four strategies to develop a reliable Judge: leveraging cutting-edge vision-language models, fine-tuning open-sourced models, pre-training neurosymbolic systems, and utilizing traditional image processing techniques.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel Neural Radiance Field (NeRF) based ray tracing method, called R-NeRF, to accurately model and visualize electromagnetic signal propagation in Reconfigurable Intelligent Surface (RIS) enabled wireless environments.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel dense visual SLAM approach called MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian Splatting (3DGS) to achieve state-of-the-art performance in tracking, mapping, and rendering with reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper provides a comprehensive survey of methodologies enabling Large Language Models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction in embodied AI systems, and charts a course for future research in this area.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper proposes a procedure to convert between implicit representation of scenes, such as neural radiance fields (NeRFs), and explicit representation, such as Gaussian splatting (GS). The approach aims to leverage the strengths of both representations, achieving the best of both worlds: superior rendering quality on dissimilar views and real-time rendering capabilities.Key contributions:* Development of a procedure to convert between NeRFs and GS* Achieving superior rendering quality on dissimilar views with NeRFs* Real-time rendering capabilities with GS* Minor computational cost for conversions compared to training from scratch|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|This review summarizes the development and implementation principles of Dynamic NeRF, which improves upon the original NeRF method to achieve dynamic 3D reconstruction and representation with high resolution.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The multi-plane representation has limitations in capturing low-frequency details and tends to overuse parameters, leading to instability and inefficiency when training with sparse inputs.* A novel approach is proposed to integrate the multi-plane representation with a coordinate-based network to capture both low-frequency context and fine-grained details.* The proposed method achieves comparable results to explicit encoding with fewer parameters, and outperforms other methods in dynamic NeRFs from sparse inputs.* The method leverages residual connections to synergistically combine the strengths of the two networks, and progressive training is used to disentangle the features.* The approach has implications for improving NeRFs from sparse inputs, reducing the need for complex architectures and large datasets.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes PR^2T-NeRF, an editable NeRF pipeline that enables direct manipulation of 3D object pose through implicit ray transformation and features a plug-and-play inpainting module (DNR) for effective removal and inpainting of objects in 3D scenes.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three real-time 3D facial reconstruction approaches using LiDAR, TrueDepth, and monocular depth estimation, which can run on a portable device like an iPhone 14 Pro, enabling interactive and immersive holographic experiences for various applications.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, with three key advancements: improved ray sampling, coarse-to-fine training, and robust inter-frame point constraint, achieving superior performance in pose estimation and depth geometry.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|The paper proposes LIVE, a novel design method for interactive LaTex graphic items, which can be used to design arbitrary graphics and easily analyze the citation relationships among multiple papers, aiming to improve the reading experience and vitality of traditional papers, with the code available open-source on GitHub.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes SketchDream, a text-driven 3D content generation and editing method that integrates sketches and text for generating high-quality 3D objects with detailed control over geometry and appearance, and enables free-view sketch-based local editing.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a monocular V-SLAM system that processes human colonoscopies in real-time, overcoming limitations of ORB-SLAM3 by using SIFT features and brute-force matching, achieving 100% precision and 53% mapping coverage in real colonoscopy sequences.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel RGB-only SLAM system that combines frame-to-frame tracking with 3D Gaussian map representation, enabling online map deformations, proxy depth estimation, and improved accuracy and efficiency in dense SLAM tasks.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM method for handling unknown scenes, which employs a divide-and-conquer mapping strategy and an adaptive map growth strategy to achieve full coverage of the unknown environment during tracking, and demonstrates competitive performance in mapping and tracking on various datasets.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a new initialization method for stereo visual-inertial SLAM systems, aiming to enhance translation accuracy during the initialization stage.* The proposed method uses a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) to refine the translation estimate, independently of the rotation estimate.* Unlike ORB-SLAM3, which uses a 6-DoF BA, the proposed method takes into account IMU measurements and gyroscope bias to update the rotation estimate.* The paper claims that the proposed method outperforms Stereo-NEC and other state-of-the-art methods in terms of accuracy while maintaining a comparable runtime speed.* The method is evaluated on the public benchmark, the EuRoC dataset, and the results show that the proposed method excels in accuracy.* The paper aims to address the limitations of previous methods, which are vulnerable to challenges such as fast motion, poor lighting, and textureless environments.* The method has the potential to be used in real-world visual-inertial state estimation tasks.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the contributions from the paper's abstract and introduction in one sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR) that jointly reconstructs camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities by integrating human-aware metric SLAM with scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents the first comprehensive real-world multi-robot collaborative perception dataset, featuring heterogeneous robots, distinct spatial viewpoints, and various sensor modalities, to facilitate research in this area and unlock benefits such as enhanced perception, accuracy, and redundancy.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The paper aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments by leveraging continual learning and reducing human annotations.* The paper proposes a novel concept of continual SLAM that combines lifelong SLAM and domain adaptation, allowing an autonomous vehicle to adapt to new environments without losing performance in previous environments.* The paper also proposes a label-efficient learning approach for panoptic segmentation using foundation models, which requires only a few annotated images and can yield results competitive with fully supervised learning methods.* The paper discusses the importance of fusing camera and LiDAR data for accurate mapping and proposes a novel method for automatic target-less camera-LiDAR calibration.* The paper mentions the ongoing and future directions, including transferring the insights gained from vision-based label-efficient panoptic segmentation to 3D point clouds, and exploring the impact of foundation models on unsupervised domain adaptation.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors present MG-SLAM, a monocular Gaussian SLAM system with a CLIP feature-based loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM in multifloor environments, addressing challenges of point cloud registration in confined spaces with rapid changes and repetitive structural features.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes four contributions to achieve a robust long-term robotic mapping system: ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building to handle changing environments and moving objects.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity mapping and tracking with reduced memory usage and state-of-the-art performance on RGB-D datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The paper proposes a lightweight circular convolutional Transformer network, CCTNet, which addresses the issues of "restricted receptive fields" and "excessive focus on local regions" in range image-based networks by capturing structural information in point clouds and facilitating cross-dimensional interaction of spatial and channel information.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a single sentence summarizing the paper's abstract and introduction, under 50 words: The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot poses and occupancy maps using laser scans and odometry information, outperforming existing state-of-the-art methods when a relatively accurate initial guess is provided.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents IPC, a consensus-based method that incrementally approximates the maximally consistent set of loop closure measurements, and shows that it competes with or outperforms state-of-the-art methods in handling outliers while achieving online performances in SLAM problems.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes OverlapMamba, a novel network for place recognition using raw range views (RVs) as input sequences, which outperforms typical LiDAR and multi-view combination methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents SceneFactory, a workflow-centric framework for incremental scene modeling that supports a wide range of applications, including mono-SLAM, 3D reconstruction, LiDAR completion, and SLAM, and provides a modular and expandable design for ease of upgrading and modification.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NGD-SLAM, a real-time visual SLAM system for dynamic environments that operates entirely on CPU without GPU support, achieving high localization accuracy and a tracking frame rate of 56 fps.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three high-fidelity reconstruction tools for real-time holographic overlays using LiDAR augmented 3D reconstruction, aiming to enable interactive and immersive holographic experiences on portable devices like the iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses, utilizing monocular depth priors through three key advancements: depth-based ray sampling, coarse-to-fine training, and inter-frame point constraints.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a novel framework for dense Visual Simultaneous Localization and Mapping (VSLAM) using Gaussian Splatting and sparse visual odometry, which eliminates the dependency on depth maps and enhances tracking robustness, achieving state-of-the-art performance in pose estimation and novel view synthesis fidelity.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a framework, NeuRSS, for sidescan sonar (SSS) Simultaneous Localization and Mapping (SLAM) that combines neural rendering with loop closures to estimate bathymetry and improve autonomous underwater vehicle positioning and mapping.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words: The authors introduce NGM-SLAM, a 3D Gaussian Splatting SLAM system that leverages neural radiance field submaps for progressive scene representation and integrates strengths of neural fields and 3D Gaussian Splatting for accurate hole filling and high-quality scene expression.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the state-of-the-art techniques for utilizing Neural Radiance Fields (NeRF) to enhance the capabilities of autonomous robots, focusing on perception, localization, and navigation, and exploring potential future research directions.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper aims to address the challenges in place recognition (PR) for real-world robotics by highlighting its importance in Simultaneous Localization and Mapping (SLAM) 2.0 and providing a comprehensive review of current advancements and remaining challenges in PR for scalable, adaptable, and efficient robotic navigation.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel SLAM framework that combines sparse visual SLAM and neural scene representations, introducing a multi-field scene representation that allows for large-scale map deformations and efficient loop closure handling while maintaining accuracy.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors introduce a hybrid visual SLAM system that combines deep feature extraction and deep matching methods to enhance adaptability in challenging environments, outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in one sentence under 50 words:X-SLAM, a real-time differentiable SLAM system, leverages the complex-step finite difference method to calculate numerical derivatives, bypassing the need for a large-scale computational graph, and enables task-aware optimization of SLAM parameters with high-order differentiation.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|The paper presents Panoptic-SLAM, an open-source visual SLAM system that can robustly localize and map unknown dynamic environments, using panoptic segmentation to filter dynamic objects, and achieves higher accuracy compared to state-of-the-art methods.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions from the paper's abstract and introduction are:1. **Cooperative MP-SLAM**: The authors propose a Bayesian particle-based sum-product algorithm for cooperative MP-SLAM, which enables data fusion over different observations of map features (virtual anchors) by different mobile terminals (MTs).2. **Inertial Measurement Unit (IMU) integration**: The algorithm integrates additional IMU sensor data from each MT to unlock more information for orientation and state transition estimation, allowing for more robust mapping and localization in complex trajectories.3. **Numerical simulation analysis**: The authors analyze the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple-input multiple-output (MIMO) and single-input multiple-output (SIMO) systems using numerical simulations.4. **Scalability and efficiency**: The proposed algorithm is designed to be scalable for large numbers of PVAs and measurements, achieving efficient estimation of the MT and PVA states.5. **Message passing framework**: The authors use a message passing framework to model the communication between MTs and the exchange of information about VAs.These contributions aim to improve the accuracy and robustness of MP-SLAM in wireless networks by exploiting cooperative information and integrating additional sensor data.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:RTG-SLAM, a real-time 3D reconstruction system, proposes a compact Gaussian representation and efficient on-the-fly optimization scheme, achieving high-quality reconstructions in large-scale environments with comparable speed and memory efficiency to state-of-the-art NeRF-based SLAM methods.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
