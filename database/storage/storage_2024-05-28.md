# arxiv-daily
 Automated deployment @ 2024-05-28 20:36:47 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining image quality by factorizing Gaussian coordinates and attributes, enabling fast rendering speeds and compact storage.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper presents CudaSIFT-SLAM, a real-time V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling successful merging and relocation in challenging colonoscopy environments.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|The paper introduces Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that addresses the challenges of scaling 3D Gaussian Splatting to large-scale scenes, particularly in terms of handling multiple scales, viewpoints, and initialization from large datasets.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summarizing sentence under 50 words:The authors propose a novel RGB-only SLAM system that combines frame-to-frame tracking with a deformable 3D Gaussian map representation, achieving high-quality surface reconstruction, accurate tracking, and efficient renderings while leveraging monocular depth estimation to refine depth updates.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360 scenes, demonstrating improved performance and detail coherence using an iterative update strategy.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* The use of aerial imagery to generate a lightweight representation of terrain through an implicit continuous and differentiable height field.* The ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which divides the scene into sub-maps using a divide-and-conquer strategy and an adaptive map growth strategy, providing real-time, scalable, and predictive performance in mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, achieving better PSNR, SSIM, and LPIPS performance with faster inference speed and shorter training time than existing NeRF-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a 3D Gaussian Splatting steganography framework that embeds 3D scenes and images into 3D point cloud files, enabling invisible and accurate extraction, with robust security, high fidelity, large capacity, and versatility in copyright protection and encrypted communication.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* Proposing a novel initialization method for Stereo Visual-Inertial SLAM (VI-SLAM) that enhances translation accuracy, improving upon the existing methods of ORB-SLAM3 and Stereo-NEC.* Introducing a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) approach to refine the translation estimate independently, while keeping the rotation estimate fixed.* Using IMU measurements and gyroscope bias to update the rotation estimate, unlike ORB-SLAM3, which directly obtains rotation from stereo visual odometry.* Demonstrating the efficacy of the proposed method through extensive evaluations on the EuRoC dataset, outperforming existing methods in accuracy while maintaining a comparable runtime.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a ray-tracing-based approach to Neural Radiance Fields (NeRF) that improves rendering of shiny objects by synthesizing consistent reflections of nearby and distant content, outperforming prior methods while requiring comparable optimization time and being more efficient.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces SynCHMR, a synergistic approach combining SLAM and HMR to reconstruct camera trajectories, human meshes, and scene point clouds in a common world frame from monocular videos, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce Neural Directional Encoding (NDE), a view-dependent appearance encoding method for rendering specular objects, which improves the state of the art on view synthesis of shiny objects and achieves fast inference speeds without compromising quality.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a two-staged pipeline for camera relocalization, which normalizes images with varying lighting conditions using a hash-encoded NeRF and addresses the noisy image gradient problem using a re-designed filter and gradient averaging technique, achieving state-of-the-art results.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents the first real-world multi-robot collaborative perception dataset collected using ground and aerial robots, featuring diverse sensor viewpoints, robot mobilities, and sensor modalities, and provides pose estimation and high-level perception annotation for various research tasks.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The research investigates the development of human-effort minimizing robotic systems by leveraging continual learning and reducing human annotations for efficient learning, focusing on robotic vision, mapping, and segmentation tasks.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, leveraging a multi-view diffusion model, transformer-based SDF prediction, and gradient-based mesh optimization.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes JointRF, an end-to-end joint optimization scheme for dynamic Neural Radiance Fields (NeRF) representation and compression, achieving improved quality and compression efficiency for streaming dynamic and long-sequence NeRF.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The key contributions from the paper's abstract and introduction are the proposal of DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, reducing training time by 6+ times, while achieving state-of-the-art rendering quality on large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, achieving drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without requiring RGB-D inputs or pre-defined bounding boxes.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Gaussian Time Machine (GTM) method achieves state-of-the-art rendering fidelity and real-time rendering capabilities (100 times faster than NeRF-based methods) for reconstructing 3D scenes with varying appearances using discrete training images and a lightweight neural network.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper presents MOSS, a framework that extracts global motion factors to guide 3D Gaussian split on the human surface, enabling state-of-the-art 3D clothed human synthesis from monocular videos, improving upon existing methods in both visual quality and real-time rendering capabilities.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target spacecraft by leveraging a Neural Radiance Field (NeRF) model, which represents the target's appearance in varying illumination conditions, allowing for pose estimation from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework designed for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, which extracts normal vectors from LiDAR scans to enhance point cloud registration performance and addresses degeneracy and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable Gaussian Splatting method that uses Multi-View Stereo and a pixel-aligned Gaussian representation, achieving real-time rendering with better view synthesis quality and faster fine-tuning for specific scenes.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper discusses the integration of Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks to enable efficient representation, transmission, and reconstruction of 3D contents. The contributions include:* A comprehensive overview of NeRF and 3D-GS, highlighting their applications, implementation challenges, and strengths and weaknesses.* An analysis of the limitations of traditional 3D representation approaches and the advantages of NeRF and 3D-GS in providing photorealistic rendering results.* A discussion of the technical challenges involved in integrating NeRF and 3D-GS in 6G networks, including storage and transmission overhead, computational complexity, and end-to-end latency.* A proposal for federated learning design over a hierarchical device-edge-cloud architecture to train NeRF and 3D-GS models.* An introduction to joint computation and communication designs to enhance rendering efficiency and minimize end-to-end latency.* A review of semantic communication-enabled 3D content transmission designs, which exploit radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* A discussion of the applications of NeRF and 3D-GS in wireless networks, including radio mapping and radio imaging.Overall, the paper aims to provide a comprehensive understanding of the integration of NeRF and 3D-GS in 6G networks and their potential applications in immersive communication and other wireless applications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper presents a novel multi-view photometric stereo (PS) method that leverages neural shape representations and learnt renderers. The main contributions are:1. The proposed method uses per-pixel intensity renderings to estimate 3D shape from photometric stereo images, rather than relying on estimated normals. This approach is robust to poor normal estimates and outperforms previous methods.2. The method models point light attenuation and explicitly raytraces cast shadows to accurately approximate each point's incoming radiance.3. The authors use a fully neural material renderer that uses minimal prior assumptions and is jointly optimized with the surface.4. The method achieves competitive reconstruction accuracy using only 6 lights and matches the state-of-the-art performance when all lights and normal map information are fused.The paper reviews the evolution of photometric stereo methods, from single-view to multi-view approaches, and highlights the limitations of prior methods that focused on normal-based reconstruction.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems. The method integrates a Judge, an evaluative mechanism that assesses the realism of generated objects, to ensure that the adversarial objects can seamlessly blend into real-world environments without detection. The Judge assigns a probability score to the object's realism, which is then integrated into the loss function to encourage the generation of realistic and adversarial textures. The paper analyzes four strategies for developing a robust Judge and presents experimental results.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel NeRF-based ray tracing method to model electromagnetic fields in RIS-enabled environments, enabling accurate signal field prediction and RIS deployment optimization, which has been validated through simulated and measured data.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising of ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to enable robust mapping in diverse scenarios and dynamic real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining image quality by factorizing both coordinates and features of 3D Gaussians, achieving a 90% reduction in storage costs compared to the original 3DGS method.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS) that combines a hierarchical assembly of Gaussians with NeRF initialization, achieving high-fidelity visual results, accelerated rendering performance, and addressing challenges in large-scale scene representation and initialization.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve sparse-view reconstruction of 360 scenes, outputting a multi-view consistent scene representation with retained details.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce Neural Elevation Models (NEMos), a novel representation that adapts Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for efficient and accurate path planning and terrain reconstruction from aerial imagery.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The key contributions of the paper are: proposing a novel 3D Gaussian Splatting (HDR-GS) framework for 3D HDR imaging, presenting a Dual Dynamic Range Gaussian point cloud model that can render HDR images and LDR views with controllable exposure time, and establishing a data foundation by recalibrating camera parameters and computing initial points for 3DGS-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|The paper proposes a steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) to embed 3D scenes and images into original GS point clouds in an invisible manner, accurately extract the hidden messages, and ensure security, fidelity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper presents an approach that addresses the limitations of Neural Radiance Fields by incorporating ray tracing, allowing for more efficient and high-quality rendering of view-dependent appearance, particularly for shiny objects with detailed reflections and nearby scene content.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Neural Directional Encoding (NDE) approach presents a novel feature-grid-based spatial encoding for view-dependent appearance rendering, achieving high-quality modeling and fast evaluation for rendering specular objects like shiny metals or glossy paints.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in one sentence under 50 words:The paper proposes a two-staged pipeline and a hash-encoded NeRF to normalize images with varying lighting and shadow conditions for camera relocalization, improving pose optimization and achieving state-of-the-art results on several datasets.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summarized version of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework generating high-quality triangular meshes with illumination-decoupled RGB textures from text or single images in seconds, introducing tensorial representation and an adaptive conversion strategy for convergence.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes JointRF, a novel end-to-end scheme that jointly optimizes dynamic NeRF representation and compression, achieving significant quality and compression efficiency improvement through a compact residual feature grid and sequential compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed method for training 3D Gaussian Splatting (3DGS) on large-scale scenes, which reduces training time by 6+ times while ensuring high rendering quality and convergence.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a real-time rendering method that models time-dependent Gaussian primitives with a lightweight neural network, achieving state-of-the-art rendering fidelity, 100x faster rendering than NeRF-based methods, and disentangling appearance changes for smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The MOSS framework introduces an innovative approach to single-view clothed human reconstruction, employing kinematic information to achieve motion-aware Gaussian splitting and surface deformation detection, resulting in state-of-the-art visual quality and improved realism in reconstructed surfaces.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a novel method to estimate the 6D pose of an unknown target spacecraft using an "off-the-shelf" spacecraft pose estimation network, trained using images of the target acquired through a monocular camera, leveraging Neural Radiance Fields to extend the scope of existing pose estimation methods to unknown targets.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summarization of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present MVSGaussian, a generalizable Gaussian Splatting method that efficiently reconstructs unseen scenes, achieving real-time rendering with better synthesis quality and faster fine-tuning initialization through multi-view geometric consistent point cloud aggregation.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper focuses on the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G wireless networks for immersive communications, which require efficient representation, transmission, and reconstruction of 3D contents. The authors highlight the limitations of traditional 3D representation approaches and introduce NeRF and 3D-GS as promising new techniques that can provide photorealistic rendering results for complex scenes. They discuss the challenges of integrating NeRF and 3D-GS in 6G networks, including storage and transmission of large radiance field models, training and inference of neural networks, and joint computation and communication designs. The paper aims to provide a comprehensive overview of the integration of NeRF and 3D-GS in 6G wireless networks and explores new design approaches for efficient representation, transmission, and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Key contributions from the paper's abstract and introduction:* A novel multi-view photometric stereo (PS) method that leverages per-pixel intensity renderings instead of relying on estimated normals.* The method models point light attenuation and explicitly raytraces cast shadows to best approximate each point's incoming radiance.* A fully neural material renderer is used, allowing for competitive reconstruction accuracy using only 6 lights, and matching the state-of-the-art performance when all lights and normal map information are used.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to generate realistic-looking adversarial objects for autonomous driving systems, introducing a "Judge" mechanism to evaluate the realism of generated objects and optimize their texture to balance adversarial effectiveness with realism.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here are the key contributions summarized in a single sentence under 50 words:The paper proposes a novel NeRF-based ray tracing method for modeling dynamic electromagnetic fields in Reflective Intelligent Surface (RIS)-enabled environments, enabling accurate prediction of signal field at different receiver locations and efficient RIS deployment.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting to achieve high-fidelity scene representation and real-time tracking, outperforming existing methods in terms of accuracy and memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper reviews the integration of Large Language Models (LLMs) with 3D spatial data, highlighting the strengths of LLMs, such as in-context learning and world knowledge, in advancing spatial comprehension and interaction within AI systems, while exploring challenges and applications in 3D environments.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* A procedure to convert between implicit representations (NeRFs) and explicit representations (Gaussian Splatting) with minor computational cost compared to training the models from scratch.* A compact representation of the scene using NeRFs, which can be modified easily by converting it back to GS and modifying the Gaussians.* A fast rendering capability using GS, which can be used for real-time applications such as localization and planning.* A method to achieve the best of both worlds, combining the advantages of NeRFs (superior PSNR, SSIM, and LPIPS on dissimilar views) and GS (real-time rendering and ability for easily modifying the representation).|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words: The paper reviews the development and implementation principles of Dynamic Neural Radiance Fields (NeRF), a novel method for implicit 3D reconstruction, and analyzes its potential applications, main principles, and key methods, providing a comprehensive understanding of the emerging field.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The proposed method synergistically integrates coordinate-based networks and multi-plane representations to improve the performance of neural radiance fields (NeRFs) from sparse inputs, achieving comparable results to explicit encoding with fewer parameters.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|The paper proposes an implicit ray transformation strategy for NeRF-aided editing, enabling direct manipulation of 3D object poses by operating on neural points in rays, and introduces a plug-and-play inpainting module, DNR, to address empty regions created by object removal, achieving state-of-the-art performance in 3D object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes three high-fidelity reconstruction tools for real-time holographic overlays using LiDAR augmented 3D reconstruction. The main contributions are:* Developing a monocular depth estimation approach using a ViT backbone and classical image projections to transform image pixels into voxel representations.* Utilizing the LiDAR and TrueDepth sensors on the iPhone 14 Pro to generate a fused depth frame, upscaled with a SRCNN model, and projecting points into the world coordinate system using the phone's IMU sensor.* Leveraging a deep-learning approach, MICA, to render a facial reconstruction and apply texture + mesh transformations directly through an end-to-end approach, using a modified version of MICA trained on a dataset with depth dimension generated via Marigold.These contributions aim to enable interactive and immersive holographic experiences, including augmented reality, telepresence, and entertainment, on a portable device like the iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using monocular depth priors, and introduces three key advancements: truncated depth-based ray sampling, coarse-to-fine training, and robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|The paper proposes a novel design method, LIVE, to design interactive LaTeX graphic items, which can represent more information volume than static items and provide an interactive reading experience. LIVE enables the design of interactive graphic items, called Gitems, and automatically analyzes the citation relationships between papers, adding vitality and performance factors to traditional papers, especially review papers.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|The key contributions mentioned in the abstract and introduction are:* Proposed a sketch-based text-to-3D generation and editing method, SketchDream, which supports both generation and editing of photo-realistic 3D models with high-quality and detailed control.* Introduced a sketch-based multi-view image generation diffusion model that warps sketches into 3D space and generates multi-view images with 3D consistency.* Designed a 3D attention control module to ensure 3D consistency between the generated images and the original sketch.* Developed a coarse-to-fine editing framework that allows for local editing of 3D models while preserving unedited regions.* Utilized Score Distillation Sampling (SDS) to generate high-quality 3D contents and applied a 2D silhouette loss to improve sketch faithfulness.* Tested the method on diverse categories of objects, achieving high-quality results.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a real-time V-SLAM system that utilizes SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3 in human colonoscopy, achieving significantly longer sub-maps and higher mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes an RGB-only SLAM system with a novel 3D Gaussian map representation that leverages global map and pose optimization, adaptively deforms the map to keyframe pose and depth updates, and refines depth updates with a monocular depth estimator, achieving superior or on-par performance with existing RGB-only SLAM methods.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based RGB-D SLAM system for unknown scenes, which integrates a divide-and-conquer mapping strategy and an adaptive map growth strategy for efficient representation and tracking of large-scale unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The proposed method, ETA, enhances translation accuracy in stereo visual-inertial SLAM initialization by using a 3-DoF bundle adjustment independently while updating rotation estimation with IMU measurements and gyroscope bias, outperforming existing methods in accuracy and run-time speed.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces SynCHMR, a synergistic camera and human reconstruction method that jointly estimates camera poses, scene point clouds, and human meshes in a common global coordinate system, addressing ambiguities in depth, scale, and dynamic scenarios.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summarized version of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring distinct spatial viewpoints, complementary robot mobilities, and sensor modalities, to facilitate the study of multi-modal collaborative perception using real-world data.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions in the abstract and introduction:The abstract highlights the research's focus on minimizing human effort in deploying perception-based robotic systems to previously unseen environments. The research explores ways to leverage continual learning and reduce human annotations for efficient learning.The introduction emphasizes the importance of holistic scene understanding in autonomous robotics, which requires a well-defined representation of the surroundings to capture spatial structure and assigning semantic meaning to individual objects. The research aims to address this challenge by investigating how to minimize human effort in deploying perception-based robotic systems to previously unseen environments, specifically focusing on leveraging continual learning and reducing human annotations for efficient learning.Overall, the abstract and introduction highlight the research's goal of developing more efficient and adaptable robotics systems that can learn and adapt to new environments with minimal human intervention.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking and high-fidelity reconstruction without depth sensors, using 3D Gaussian representation and CLIP feature-based loop closure.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework designed for indoor SLAM in multifloor environments, which extracts normal vectors from LiDAR scans and uses them for correspondence search to enhance point cloud registration performance, addressing challenges in indoor environments such as rapid changes in scans and repetitive structural features.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that addresses catastrophic failures in deep learning-based approaches, incorporating ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to work effectively in diverse real-world scenarios.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summarized key contribution in a single sentence under 50 words:The paper proposes MotionGS, a novel dense visual SLAM method using 3D Gaussian splatting, which combines deep feature extraction, dual keyframe selection, and optimization to achieve high-fidelity tracking, mapping, and rendering with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions in the paper's abstract and introduction in a single sentence under 50 words:The authors propose a lightweight circular convolutional Transformer network (CCTNet) that captures structural information in point clouds, improves place recognition accuracy, and surpasses comparable methods in extensive experiments on various datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes a novel optimization-based SLAM approach that simultaneously estimates the robot trajectory and occupancy map using 2D laser scans and odometry information, where the robot poses and occupancy map are optimized together, unlike existing approaches.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|The paper presents IPC, a robust online method for Pose Graph Optimization (PGO) that approximates the solution to the combinatorial problem of finding the maximally consistent set of measurements in an incremental fashion, and outperforms state-of-the-art methods in handling outliers while providing online performances.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes OverlapMamba, a novel place recognition method that utilizes raw range views (RVs) as input sequences, outperforming typical LiDAR and multi-view combination methods in time complexity and speed, and achieving state-of-the-art performance on loop closure detection and place recognition tasks.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:SceneFactory, a workflow-centric framework, supports a wide range of incremental scene modeling applications with different input combinations, and contributes a robust depth estimation block, dual-purpose multi-resolution neural points representation, and high-quality scene reconstruction methods.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NGD-SLAM, a novel real-time visual SLAM system that achieves high localization accuracy in dynamic environments without GPU support, using a mask prediction mechanism and dual-stage optical flow tracking approach for efficient and robust camera tracking.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|The paper proposes three approaches to generate real-time 3D facial reconstructions: (1) monocular depth estimation, (2) LiDAR + TrueDepth, and (3) template modeling. The key contributions are:* Developing a hybrid approach that combines depth estimation, LiDAR, and TrueDepth sensors to achieve high-fidelity facial reconstructions in real-time.* Proposing a novel pipeline that utilizes Intel MiDaS, Marigold, and SRCNN models for monocular depth estimation, LiDAR depth upsampling, and TrueDepth-based facial reconstruction.* Leveraging the iPhone 14 Pro's LiDAR and TrueDepth sensors for real-time reconstruction, and using Metal shaders for rendering the reconstructed voxel map.* Adapting a template modeling approach using MICA to render a facial reconstruction and apply texture + mesh transformations directly through an end-to-end approach.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses, leveraging monocular depth priors through three key advancements: a novel depth-based ray sampling strategy, a coarse-to-fine training strategy, and a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel framework that integrates sparse visual odometry with 3D Gaussian Splatting for dense visual simultaneous localization and mapping, eliminating the need for depth maps and enhancing tracking robustness, achieving state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeuRSS, a scalable framework for simultaneous localization and mapping (SLAM) using sidescan sonar (SSS) data, addressing the challenge of rough positioning accuracy by incorporating an elevation prior from neural rendering-based bathymetry estimation.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NGM-SLAM, a progressive dense Gaussian splatting SLAM system that utilizes neural radiance field submaps for scene expression and loop closure detection, achieving high-quality scene reconstruction, accuracy, and real-time performance in large-scale scenes.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the state-of-the-art techniques for utilizing Neural Radiance Fields (NeRF) in autonomous robotics, focusing on perception, localization, and decision-making, and explores its potential integration with advanced techniques to enhance robotic capabilities and pave the way for innovative solutions.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper bridges the gap in place recognition (PR) technology for real-world robotics by highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and provides a comprehensive review of state-of-the-art advancements and challenges in PR.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:This paper proposes a neural mapping framework that anchors lightweight neural fields to a pose graph, enabling efficient integration of loop closures and scalability, outperforming existing state-of-the-art approaches.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a hybrid visual SLAM system that combines deep feature extraction and matching methods, enhancing adaptability in challenging environments, and outperforms state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present X-SLAM, a real-time and differentiable dense SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, enabling task-aware optimization and achieving better accuracy and faster convergence in camera relocalization and active robotic scanning tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper presents Panoptic-SLAM, an open-source visual SLAM system that uses panoptic segmentation to filter dynamic objects from the scene, achieving robust localization in dynamic environments with unknown and unlabeled moving objects.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:* Modeling the exchange of information between different mobile terminals (MTs), enabling cooperative localization and data fusion of virtual anchors (VAs) over different MTs.* Fully integrating an inertial measurement unit (IMU) as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation, allowing for more robust mapping and higher localization accuracy.* Analyzing the impact of VA data fusion and cooperative measurements in multipath-based simultaneous localization and mapping (MP-SLAM) for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulations.The paper presents a Bayesian particle-based sum-product algorithm (SPA) for cooperative MP-SLAM, which enables data fusion over different observations of map features (VAs) by different MTs, as well as cooperative MT-to-MT measurements using radio signals. The algorithm jointly performs probabilistic data association (PDA) and sequential estimation of the states of the MTs and potential VAs.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors present Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system using Gaussian splatting with a compact Gaussian representation and on-the-fly Gaussian optimization, achieving comparable high-quality reconstruction with faster speed and lower memory cost compared to state-of-the-art NeRF-based SLAM methods.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
