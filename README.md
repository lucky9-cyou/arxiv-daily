# arxiv-daily
 Automated deployment @ 2024-05-28 21:10:50 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed Factorized 3D Gaussian Splatting (F-3DGS) method significantly reduces storage requirements while maintaining image quality by employing structured coordinates and decomposed representations of Gaussians through factorization, particularly from canonical polyadic and vector-matrix decompositions.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a monocular V-SLAM system that overcomes the limitations of ORB-SLAM3 by using SIFT features and brute-force matching, enabling successful map merging and relocation in real-time for human colonoscopies.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Pyramidal 3D Gaussian Splatting (PyGS) presents a hierarchical assembly of Gaussians, initialized using a rapidly trained NeRF, and optimized for large-scale scenes, achieving significant performance improvements and accelerated rendering times compared to existing state-of-the-art approaches.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes a novel RGB-only SLAM system that utilizes dynamically deforming 3D Gaussian maps, refining depth updates with a monocular depth estimator, and achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that uses latent diffusion models to improve the reconstruction of 360 3D scenes from sparse views, achieving high-quality results with details coherent with the observed inputs.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for lightweight representation of terrain through an implicit continuous and differentiable height field.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression.* A path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort, enabled by the differentiability of the height field.* The ability to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods, as demonstrated through experiments on simulated and real-world terrain imagery.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes that achieves real-time, scalable, and predictive performance using a divide-and-conquer mapping strategy and adaptive map growth strategy.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which renders HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods while enjoying faster training and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The proposed GS-Hider framework enables effective and flexible steganography for 3D Gaussian Splatting, allowing for the concealment and extraction of messages in 3D scenes and images while ensuring security, robustness, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose a new method, called ETA, to enhance translation accuracy during the initialization stage of stereo Visual-Inertial SLAM (VI-SLAM) systems.* ETA improves translation estimation using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA), conducted independently, while keeping the rotation estimate fixed, unlike ORB-SLAM3's 6-DoF BA.* ETA also updates the rotation estimate by taking into account IMU measurements and gyroscope bias, unlike ORB-SLAM3's rotation, which is directly obtained from stereo visual odometry.* The authors evaluate ETA on the public benchmark, the EuRoC dataset, demonstrating that ETA excels in accuracy and performs comparable to Stereo-NEC, a more complex method, while maintaining a runtime similar to that of ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper introduces a novel approach to Neural Radiance Fields (NeRFs) that addresses the issue of reconstructing highly specular objects by leveraging ray tracing, allowing for consistent rendering of reflections and reducing the reliance on large neural networks.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and dense scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities by marrying visual SLAM and human motion reconstruction.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a feature-grid-like approach that accurately models view-dependent appearance and global illumination effects for rendering specular objects, outperforming the state-of-the-art methods while achieving fast inference speeds.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, utilizing a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique to smoothen the process, achieving state-of-the-art results in camera relocalization under varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a comprehensive real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities, filling a significant research gap in the field of multi-robot collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes novel methods for efficient robot learning, focusing on leveraging continual learning (CL) and reducing human annotations for improved performance in previously unseen environments.* The research explores the use of vision foundation models for extremely label-efficient training, allowing for panoptic segmentation with minimal annotations.* The paper also addresses the challenge of automatic calibration for camera-LiDAR systems without human supervision or special data collection.* The author plans to extend the label-efficient segmentation techniques to 3D point clouds and combine them with robot mapping for semantic representations of an environment.Note: The above summary is under 50 words and only highlights the main contributions from the abstract and introduction.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, introducing a tensorial SDF representation and adaptive conversion strategy to improve convergence speed and quality.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving improved quality and compression efficiency by employing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining high rendering quality, by decomposing scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consensus.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which uses 3D Gaussian representation to guide scene geometry estimation and a CLIP feature-based loop closure module for drift error correction, outperforming existing methods.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a lightweight neural method for real-time rendering of 3D scenes with varying appearances, achieving state-of-the-art rendering fidelity, 100 times faster than NeRF-based methods, and enabling smooth appearance interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce MOSS, a novel framework that incorporates kinematic information to achieve motion-aware Gaussian split on the human surface, addressing limitations in current methodologies by propagating global motion across the body surface and detecting local occlusions.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRFs) to generate a large dataset of images depicting the target under varying illumination conditions.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping (SLAM) in indoor environments with multifloor structures, which addresses challenges in point cloud registration due to rapid changes and repetitive structural features, and achieves robust registration through normal vector extraction and degeneracy detection.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents MVSGaussian, a generalizable Gaussian Splatting method derived from Multi-View Stereo, which leverages MVS to encode geometry-aware Gaussian representations, integrates an efficient volume rendering design for novel view synthesis, and introduces a multi-view geometric consistent aggregation strategy to support fast fine-tuning for specific scenes.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a comprehensive overview on the integration of Neural Radiance Field (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents. The main contributions are:1. A review of the basics of radiance field rendering techniques, highlighting their applications and implementation challenges over wireless networks.2. An exploration of over-the-air training of NeRF and 3D-GS models using federated learning techniques, with a focus on hierarchical device-edge-cloud architecture.3. Presentation of practical rendering architectures for NeRF and 3D-GS models at wireless network edges, including model compression approaches and joint computation and communication designs.4. Introduction of a new semantic communication-enabled 3D content transmission design, leveraging radiance field models as a semantic knowledge base for reduced communication overhead.5. Discussion of the utilization of radiance field rendering in wireless applications such as radio mapping and radio imaging.These contributions aim to address the challenges of efficient representation, transmission, and reconstruction of 3D contents in 6G wireless networks, enabling immersive communications and merging virtual and physical worlds.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, explicitly models point light attenuation and raytraces cast shadows, and optimizes a fully neural material renderer to achieve accurate 3D shape estimation.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a modified gradient-based texture optimization method to discover realistic-looking adversarial objects for autonomous driving systems, introducing a "Judge" mechanism to assess and refine the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* Developing a novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments.* Proposing a two-stage framework that accurately models signal propagation and transmission from the transmitter to the RIS and from the RIS to the receiver.* Integrating NeRF with ray tracing techniques to enable precise prediction of signal strength and direction at various receiver locations under different RIS placements.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising of ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to enable robust mapping in diverse scenarios and dynamic real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that drastically reduces storage requirements while preserving image quality by factorizing 3D Gaussians and attributes using efficient decomposition techniques.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summarized sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting, which addresses challenges of scaling 3D Gaussian Splatting to large-scale scenes by introducing pyramidal Gaussians and dynamic weighting, achieving a significant performance leap and rendering speedup over state-of-the-art NeRF-based methods.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that uses pretrained 2D diffusion models to improve sparse-view reconstruction of 360 scenes by fine-tuning and filling in missing details, achieving superior results on the Mip-NeRF360 dataset.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The introduction of Neural Elevation Models (NEMos), which combine Neural Radiance Fields (NeRFs) with a height field to create a compact and differentiable terrain representation.* The proposal of a novel method for jointly training the NeRF and height field using quantile regression, which enables the generation of high-quality reconstructions of terrain from imagery.* The development of a path planning algorithm that leverages the continuous and differentiable nature of the height field to generate smoother paths for autonomous ground robots.These contributions address the limitations of traditional terrain representation methods, such as digital elevation models (DEMs), by providing a more lightweight and flexible representation of terrain that can be generated from imagery.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which outperforms state-of-the-art NeRF-based methods in HDR novel view synthesis, achieves 1000x inference speed, and requires 6.3% training time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel steganography framework, GS-Hider, for 3D Gaussian Splatting (3DGS) that embeds and extracts 3D scenes and images in an invisible manner, ensuring security, fidelity, capacity, and flexibility, and demonstrating its effectiveness in various applications.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The authors introduce a novel approach that combines Neural Radiance Fields (NeRFs) with ray tracing to overcome limitations in rendering highly specular objects, allowing for accurate and efficient synthesis of reflective appearances in real-world scenes.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Neural Directional Encoding (NDE), a novel method that efficiently encodes high-frequency directional signals for specular objects, enabling fast and accurate novel-view synthesis.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizing a hash-encoded NeRF with a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique for robust pose optimization.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes LDM, a novel feed-forward framework that generates high-quality textured meshes with decoupled illumination from text or single images in seconds, utilizing a multi-view diffusion model, transformer-based SDF predictor, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper proposes JointRF, a novel end-to-end joint optimization scheme for dynamic Neural Radiance Field representation and compression, achieving superior quality and compression efficiency.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that accelerates training by 6+ times on large-scale scenes while maintaining high rendering quality, by decomposing scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consensus.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|The key contributions are: Gaussian Time Machine (GTM) models time-dependent attributes of Gaussian primitives with discrete time embedding vectors, enabling accurate reconstruction of scenes with vastly differing weather and lighting conditions, and achieves state-of-the-art rendering fidelity and real-time rendering capability (100 times faster than NeRF-based methods) on three datasets.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose Motion-Based 3D Clothed Humans Synthesis (MOSS), a novel framework that incorporates kinematic information to achieve motion-aware 3D reconstruction of clothed humans, addressing limitations of previous methods that overlook the influence of motion on surface deformation.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper's abstract and introduction key contributions are summarized in a single sentence under 50 words:This paper proposes a novel method that leverages Neural Radiance Fields (NeRFs) to enable off-the-shelf spacecraft pose estimation models to be applied on unknown targets, achieved by training a NeRF on a sparse set of images depicting the target spacecraft and generating a large, diverse dataset to train a pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present MVSGaussian, a novel 3D Gaussian representation approach that efficiently reconstructs unseen scenes with real-time rendering and generalizability, leveraging Multi-View Stereo, pixel-aligned Gaussian rendering, and consistent aggregation for fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper provides a comprehensive overview of integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) in 6G networks for efficient representation, transmission, and reconstruction of 3D contents, addressing challenges in distributed training, rendering, and transmission.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|The key contributions from the paper's abstract and introduction are:* A novel multi-view photometric stereo method that leverages neural shape representations and learned renderers.* The method explicitly models point light attenuation and raytraces cast shadows to best approximate each point's incoming radiance.* The method optimizes a fully neural material renderer and achieves competitive reconstruction accuracy even with only 6 lights.* The method achieves state-of-the-art performance on the DiLiGenT-MV benchmark, outperforming classical approaches and other deep learning-based methods.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The key contributions of the paper can be summarized as:The authors introduce a modified gradient-based texture optimization method to discover realistic-looking adversarial objects, which is integrated into an existing framework using a neural object renderer. They also propose four strategies for creating a reliable "Judge" to evaluate the realism of generated objects.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The key contributions of this paper are:* A novel modeling approach using Neural Radiance Fields (NeRF) to characterize the dynamics of electromagnetic fields in RIS-enabled wireless environments, enabling accurate modeling of signal propagation and RIS deployment.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3D Gaussian Splatting (3DGS)-based Simultaneous Localization and Mapping (SLAM) approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3DGS, achieving high-fidelity scene representation and real-time tracking with reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This survey provides a comprehensive overview of methodologies enabling large language models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction in embodied AI systems, while emphasizing the need for novel approaches to harness their full potential.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here is a summary of the key contributions from the abstract and introduction:**Key Contributions:**1. Developed a procedure to convert between implicit scene representations (Neural Radiance Fields, NeRFs) and explicit scene representations (Gaussian Splatting, GS).2. Achieved the best of both worlds: superior rendering quality and OS on dissimilar views, and a compact representation.3. Converted NeRFs to GS and vice versa with a minor computational cost compared to training from scratch.**Summary:** The paper introduces a method to convert between implicit scene representations (NeRFs) and explicit scene representations (GS) for 3D scene understanding in robotics. The approach allows for both accurate rendering and compact representation of the scene, with a minor computational cost.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides a comprehensive analysis of the development and implementation principles of Dynamic Neural Radiance Field (NeRF), highlighting its potential applications and techniques, with a focus on the key methods and design principles from 2021 to 2023.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a summary of the key contributions mentioned in the paper's abstract and introduction:* The proposed method synergistically integrates the multi-plane representation with a coordinate-based network to improve the performance of static and dynamic NeRFs from sparse inputs.* The coordinate-based network handles low-frequency context, while the multi-plane features capture fine-grained details, achieving three main benefits: (1) reduced sensitivity to hyperparameters, (2) stable training through gradual changes in spectral biases, and (3) efficient parameter allocation.* The proposed method is comparable to multi-plane encoding with high denoising penalties in static NeRFs and outperforms baselines in dynamic NeRFs from sparse inputs.* The reduction in the number of parameters by skipping the allocation of a spatial low-resolution grid and replacing it with coordinate-based features does not compromise performance.* The proposed method is simple yet powerful, allowing for faster convergence and better performance compared to previous approaches.|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling module to address object movement and empty regions in NeRF-aided editing tasks, achieving state-of-the-art performance in object removal and inpainting tasks.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method for generating real-time 3D facial reconstructions using LiDAR augmented 3D reconstruction. The contributions are:1. Three approaches for generating real-time 3D facial reconstructions, each using a different method for estimating depth: monocular depth estimation, LiDAR + TrueDepth fusion, and template modeling.2. A hybrid approach that combines depth estimation and LiDAR sensing to achieve high-fidelity facial reconstructions in real-time.3. A constraint-based methodology that ensures portability, instantaneous reconstruction, and high fidelity of the rendered voxel grid.Note that the introduction highlights the limitations of previous methods for real-time 3D reconstruction, such as the need for highly calibrated scenes, steep computation costs, and failure to render dynamic scenes. The proposed approach aims to overcome these limitations and achieve high-fidelity facial reconstructions in real-time.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach to jointly optimize camera poses and Neural Radiance Fields (NeRF) using monocular depth priors, which improves pose estimation accuracy and generates more accurate depth geometry, surpassing prior works.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes LIVE, a novel design method to create interactive LaTex graphic items, enabling more informative and interactive figures and tables, which can aid in writing traditional papers, especially review papers, with improved vitality and performance factors.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes SketchDream, a method for sketch-based text-to-3D generation and editing of photo-realistic contents.* The method addresses the challenge of synthesizing realistic 3D contents from sparse 2D sketches and textual inputs by completing missing appearance details and extending single-view information into the 3D space.* The key contributions of the paper are:	+ The first sketch-based text-to-3D generation and editing method that generates high-quality 3D objects under generalized categories and supports detailed editing of reconstructed or generated NeRFs.	+ A sketch-based multi-view image generation diffusion model that utilizes depth guidance to create spatial correspondence and a 3D attention control module to ensure 3D consistency.	+ A coarse-to-fine editing framework that generates high-quality editing results with a local rendering strategy.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, the first V-SLAM system able to process complete human colonoscopies in real-time, by using SIFT features and brute-force matching, achieving better mapping coverage and longer sub-maps compared to ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose the first RGB-only SLAM system with a dense 3D Gaussian map representation, leveraging global tracking and online deformations, and achieve superior tracking, mapping, and rendering accuracy with smaller map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to efficiently represent and track complex scenes.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of the paper are:* A new method for enhancing translation accuracy during the initialization stage of Visual-Inertial SLAM (VI-SLAM) systems, which is based on a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) conducted independently, while keeping the rotation estimate fixed.* A method that updates the rotation estimate by considering IMU measurements and gyroscope bias, unlike previous methods that derive the rotation directly from stereo visual odometry.* A method that achieves performance comparable to Stereo-NEC while maintaining a runtime similar to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors introduce Synergistic Camera and Human Reconstruction (SynCHMR), a method that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos in a common global coordinate system, leveraging human-aware metric SLAM and scene-aware SMPL denoising to address depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents the first real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration with heterogeneous sensor modalities, spatial viewpoints, and coverage ranges, and provides annotations for pose estimation and high-level perception tasks.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:Contributions:1. The author presents a framework for minimizing human effort in deploying robotic systems to previously unseen environments, focusing on leveraging continual learning and reducing human annotations for efficient learning.2. The research explores the use of visual foundation models for extremely label-efficient training in panoptic segmentation.3. Continual Learning for Robotics is proposed, allowing an autonomous agent to adapt to unseen domains while retaining high performance on previous domains.4. Label-Efficient Panoptic Segmentation is developed, enabling training of segmentation networks with almost zero labels.5. LiDAR-Based Mapping is introduced, fusing complementary information from cameras and LiDAR sensors and proposing automatic target-less camera-LiDAR calibration.6. Collaborative Robot Mapping is explored, enabling multi-agent collaboration for efficient robot learning.Overall, the research aims to develop more efficient and adaptable robotic systems that can learn from limited data and adapt to new environments with minimal human intervention.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MG-SLAM, a monocular Gaussian SLAM system that uses 3D Gaussian representation and a CLIP feature-based loop closure module to achieve drift-corrected tracking, high-fidelity reconstruction, and high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper's key contributions are: proposing a normal vector-based tightly-coupled LIO framework, NV-LIO, for robust SLAM in indoor environments with multiple floors, and developing novel methods for addressing degeneracy situations and preventing wrong correspondences in loop closure.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system, comprising ground segmentation, outlier-robust registration using graduated non-convexity (GNC), hierarchical multi-session SLAM, and instance-aware static map building, to address challenges in modeling, data points, and dynamic real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity mapping and tracking with reduced memory usage and state-of-the-art performance on RGB-D datasets.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a lightweight circular convolutional Transformer network, CCTNet, which enhances place recognition by capturing structural information in point clouds and facilitating cross-dimensional interaction, achieving superior performance in various datasets, including the KITTI and Ford Campus datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose a novel optimization-based SLAM approach that simultaneously optimizes the robot trajectory and occupancy map using 2D laser scans and odometry, offering improved accuracy and uncertainty estimation compared to existing methods, particularly when a relatively accurate initial guess is provided.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|The paper presents IPC (Incremental Probabilistic Consensus), a method that approximates the solution to the combinatorial problem of finding the maximally consistent set of loop closure measurements in an incremental fashion, allowing for robust handling of large numbers of outliers while providing online performance.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes OverlapMamba, a novel deep learning-based LiDAR-based place recognition method that represents input range views as sequences, employing a stochastic reconstruction approach to build shift state space models and achieve robust place recognition with real-time efficiency.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present SceneFactory, a workflow-centric framework that supports various incremental scene modeling applications, and contribute four key components: a unified depth estimation block, dual-purpose multi-resolution neural points, and improved point rasterization, which together demonstrate high flexibility and quality competitiveness with state-of-the-art approaches.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU without GPU support by incorporating a mask prediction mechanism and a dual-stage optical flow tracking approach, enhancing efficiency and robustness in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel application that creates real-time holographic overlays using LiDAR augmented 3D reconstruction, introducing three high-fidelity reconstruction tools that can run on portable devices like the iPhone 14 Pro, enabling interactive and immersive holographic experiences.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and NeRF radiance fields using depth priors, introducing three key advancements: truncated depth-based ray sampling, coarse-to-fine training, and inter-frame point constraints for enhanced pose estimation accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|The key contributions of the paper are: introducing the first SLAM system combining sparse visual odometry with 3D Gaussian Splatting, developing a pre-trained MVS depth estimation network, proposing a depth smooth loss, and introducing a Sparse-Dense Adjustment Ring (SDAR) to ensure scale consistency.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose a novel framework, NeuRSS, that combines sidescan sonar (SSS) SLAM and neural rendering to estimate bathymetry and improve autonomous underwater vehicle (AUV) positioning, addressing elevation degeneracy and providing a scalable and efficient solution for large-scale surveys.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents NGM-SLAM, a progressive dense Gaussian splatting SLAM system that utilizes neural radiance field submaps for scene expression and loop closure detection, achieving high-quality scene reconstruction, accuracy, and real-time performance in large-scale scenes.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) in autonomous robotics, exploring its applications in perception, localization, navigation, and decision-making, as well as benchmarking its performance and discussing future avenues for integration with advanced technologies.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper presents a comprehensive review of place recognition (PR) techniques, highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and provides a roadmap for future advancements while introducing an open-source PR package and benchmark for the robotics community.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a neural mapping framework that anchors lightweight neural fields to a sparse pose graph, enabling large-scale scene representation with efficient loop closure handling, scalable mapping, and outperforming state-of-the-art approaches on large scenes.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a versatile hybrid SLAM system that combines deep feature extraction and matching methods, achieving improved adaptability and performance in challenging environments and outperforming state-of-the-art SLAM algorithms in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents X-SLAM, a real-time differentiable SLAM system that leverages the complex-step finite difference method to calculate numerical derivatives, enabling end-to-end optimization and efficient calculation of higher-order derivatives for improved accuracy and convergence.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM presents a robust open-source visual SLAM system that utilizes panoptic segmentation to filter dynamic objects, achieving average accuracy four times higher than PVO and two times higher than DynaSLAM, and tested on real-world datasets and quadruped robot scenarios.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The paper proposes a Bayesian particle-based sum-product algorithm (SPA) for cooperative multipath-based simultaneous localization and mapping (MP-SLAM) in wireless networks. The key contributions are:1. Modeling the exchange of information between different mobile terminals (MTs) to enable cooperative localization and data fusion of virtual anchors (VAs) over different MTs.2. Fully integrating an inertial measurement unit (IMU) as an additional sensor for each MT to unlock additional information for orientation and state transition estimation.3. Analyzing the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulations.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|The paper presents Real-time Gaussian SLAM (RTG-SLAM), a system that achieves real-time 3D reconstruction of large-scale environments using Gaussian splatting, featuring a compact Gaussian representation and a highly efficient on-the-fly Gaussian optimization scheme, which outperforms state-of-the-art NeRF-based SLAM methods in terms of speed, memory cost, and realism of novel view synthesis.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
