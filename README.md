# arxiv-daily
 Automated deployment @ 2024-05-28 21:02:13 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by factorizing 3D Gaussians using efficient decomposition techniques, allowing for high-quality rendering at a fraction of the storage cost of traditional 3DGS methods.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|The authors present CudaSIFT-SLAM, a novel monocular V-SLAM system that successfully processes human colonoscopies in real-time, overcoming limitations of previous top-performing V-SLAM systems by using SIFT features and brute-force matching, and achieving a 70% improvement in mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Pyramidal 3D Gaussian Splatting (PyGS) with NeRF Initialization, a method that leverages hierarchical pyramidal Gaussians and dynamic weighting to efficiently model large-scale scenes, achieving rendering speeds over 400 times faster than state-of-the-art approaches.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a globally optimized RGB-only SLAM system utilizing 3D Gaussian Splatting, which combines the strengths of frame-to-frame tracking and 3D Gaussian map representations, achieving superior or on-par performance with existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that utilizes pre-trained 2D diffusion models with fine-tuning to reconstruct 360-degree scenes from sparse views, achieving multi-view consistent scene representations with coherent details and outperforming existing methods.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* The authors propose Neural Elevation Models (NEMos), which adapt Neural Radiance Fields (NeRFs) to a 2.5D continuous and differentiable terrain model, leveraging imagery as a low-cost data source.* NEMOs can be readily generated from imagery, providing a lightweight representation of terrain through an implicit continuous and differentiable height field.* The authors introduce a novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* They also propose a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.* Experimental results show that NEMOs can generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NeB-SLAM, a neural block-based scalable RGB-D SLAM approach for unknown scenes, which uses a divide-and-conquer mapping strategy and an adaptive map growth strategy to achieve efficient and real-time mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework for 3D HDR imaging, which efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods in terms of quality and speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is the summarized key contribution from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a 3D Gaussian Splatting (3DGS) steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files, ensuring security, fidelity, and capacity while hiding multiple messages, and demonstrates its effectiveness through extensive experiments.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions from the paper's abstract and introduction are:* A new initialization method for Stereo Visual-Inertial SLAM that enhances translation accuracy during the initialization stage, using a 3 Degree-of-Freedom (DoF) Bundle Adjustment (BA) while keeping the rotation estimate fixed.* This method is designed to overcome the limitations of previous methods, including ORB-SLAM3 and Stereo-NEC, by providing more accurate initialization for Stereo Visual-Inertial SLAM systems.* The method is evaluated on the public benchmark, the EuRoC dataset, and is shown to outperform previous methods in terms of accuracy.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a ray tracing-based approach to Neural Radiance Fields (NeRFs) that improves view synthesis of shiny objects by casting reflection rays and tracing them through the NeRF representation, enabling consistent reflections of nearby and distant content while reducing computational cost.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a pipeline that jointly reconstructs 3D human motion, camera trajectories, and scene point clouds from monocular videos by integrating human-aware metric SLAM and scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is the summary of the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Neural Directional Encoding (NDE), a feature-grid-like neural radiance field that models view-dependent appearance of specular objects, achieving high-quality rendering and fast evaluation, outperforming state-of-the-art methods on engaging novel-view synthesis.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summarized sentence with key contributions from the abstract and introduction, under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting and shadow conditions for camera relocalization, utilizes a hash-encoded NeRF for fast training and robust pose refinement, and introduces a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique for smoothened gradient computing.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a pioneering real-world multi-robot collaborative perception dataset featuring air-ground robot collaboration, heterogeneous sensors, and complementary mobilities, which is designed to facilitate research on multi-modal collaborative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|The paper's abstract and introduction highlight the importance of holistic scene understanding for autonomous robotic agents and the goal to develop a perception-based robotic system that can adapt to previously unseen environments with minimal human effort. The research focuses on two key contributions: 1) continual learning and 2) label-efficient learning. The paper aims to leverage these concepts to enable robots to adapt to new environments and learn from scratch with minimal human supervision.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The authors propose LDM, a novel feed-forward framework for generating high-fidelity, illumination-decoupled textured mesh from a single image or text prompts, overcoming the limitations of previous NeRF and 3D Gaussian representations.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's main contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving significantly improved quality and compression efficiency by utilizing a compact residual feature grid, sequential feature compression, and end-to-end training.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that splits scenes into blocks, uses Alternating Direction Method of Multipliers (ADMM) for consensus, and accelerates training by 6+ times while maintaining rendering quality and stability.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a CLIP feature-based loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without relying on depth information.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives and decomposes color models for improved geometric consistency, achieving state-of-the-art rendering fidelity and outperforming NeRF-based counterparts in efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:MOSS proposes a framework that uses kinematic information to achieve motion-aware Gaussian split on human surfaces, addressing limitations of current methods, and improves upon existing approaches by incorporating global motion factors, hierarchical structure constraints, and occlusion handling.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied on an unknown target by leveraging Neural Radiance Fields (NeRF) to generate a large dataset from a sparse set of images, demonstrating its feasibility on realistic images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NV-LIO, a normal vector-based LiDAR-inertial odometry framework that enhances point cloud registration performance in indoor environments with multifloor structures by extracting normal vectors and analyzing their distribution to adjust matching uncertainty.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper proposes a new generalizable 3D Gaussian representation approach, MVSGaussian, derived from Multi-View Stereo, which can efficiently reconstruct unseen scenes with real-time rendering and fast per-scene optimization, outperforming other generalizable methods and achieving comparable performance to longer optimization times.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper provides a comprehensive overview of integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) into 6G networks to support immersive communications, with a focus on efficient representation, transmission, and reconstruction of 3D contents over wireless networks.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and jointly optimizes a fully neural material renderer with a surface to achieve competitive reconstruction accuracy.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method to generate realistic-looking adversarial objects for testing autonomous driving systems, by introducing a 'Judge' mechanism that assesses the realism of generated objects and refines their texture to ensure they are both adversarial and realistic.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel two-stage framework using Neural Radiance Fields (NeRF) and ray tracing to model dynamic electromagnetic fields in Reconfigurable Intelligent Surface (RIS)-enabled wireless environments, enabling accurate prediction of signal field for any specified RIS placement and receiver location.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that rapidly segments ground points, employs outlier-robust registration and hierarchical multi-session SLAM, and builds instance-aware static maps to handle diverse and changing real-world environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that uses SIFT features and brute-force matching to overcome tracking losses in human colonoscopies, achieving real-time performance and successfully merging sub-maps, with a 70% improvement over ORB-SLAM3.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|The paper proposes an RGB-only SLAM system that combines frame-to-frame tracking and 3D Gaussian Splatting, using a dynamically deforming map representation and adaptive monocular depth estimation to achieve high-quality reconstruction and rendering while maintaining small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based RGB-D SLAM system for unknown scenarios, which divides the scene into sub-maps, adapts map growth, and demonstrates competitive performance in mapping and tracking on various datasets.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|According to the abstract and introduction, the main contributions are:* The proposed method enhances the translation accuracy during the initialization stage of Visual-Inertial SLAM (VI-SLAM) systems by using a 3-DoF Bundle Adjustment (BA) to refine the translation estimate independently from the rotation estimate.* The method updates the rotation estimate using IMU measurements and gyroscope bias, unlike other methods that directly use stereo visual odometry, which can lead to inferior results in challenging scenarios.* The paper presents a new method called ETA (Enhancing Translation Accuracy) that focuses on improving the initialization performance of VI-SLAM systems, simultaneously improving accuracy and runtime.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), which marries monocular SLAM and human mesh reconstruction to reconstruct camera trajectories, human meshes, and scene point clouds in a common world frame, addressing depth, scale, and dynamic ambiguities.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper presents a comprehensive real-world multi-robot collaborative perception dataset, the first of its kind, featuring air-ground robot collaboration, heterogeneous sensors, and diverse spatial viewpoints, which can facilitate research in multi-modal collaborative perception.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The research focuses on minimizing human effort in deploying perception-based robotic systems to new environments, leveraging continual learning and reducing human annotations for efficient learning, and exploring label-efficient panoptic segmentation and robot mapping techniques.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which enables drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without requiring RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LiDAR-inertial odometry framework for indoor SLAM in multifloor environments, which extracts normal vectors from LiDAR scans, analyzes their directions to address degeneracy, and implements a viewpoint-based loop closure module to enhance registration performance and robustness.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that can work out of the box, featuring fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to handle diverse scenarios and dynamic environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The proposed 3DGS-based SLAM approach, MotionGS, integrates deep visual features, dual keyframe selection, and 3D Gaussian Splatting to achieve high-fidelity scene representation, accurate real-time tracking, and state-of-the-art performance in tracking and mapping while reducing memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|The key contributions of the paper are the proposal of a lightweight circular convolutional Transformer network, CCTNet, which addresses issues of restricted receptive fields and excessive focus on local regions by capturing structural information in point clouds and facilitating cross-dimensional interaction.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot trajectories and occupancy maps using 2D laser scans and odometry, representing a novel and more accurate method than existing techniques that optimize poses separately from mapping.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes IPC, a consensus-based method for online pose graph optimization that incrementally builds a maximally consistent set of loop closure measurements, outperforming state-of-the-art methods in handling outliers and providing online performance, while releasing an open-source implementation.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes OverlapMamba, a novel deep learning-based place recognition method that represents input range views as sequences, utilizing a stochastic reconstruction approach to build shift state space models and outperforms typical LiDAR and multi-view combination methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose SceneFactory, a workflow-centric framework that supports various scene modeling applications, including multi-view depth estimation, LiDAR completion, and SLAM, with four building blocks that can be combined to address different input combinations.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel visual SLAM system, NGD-SLAM, that achieves real-time performance on a CPU by incorporating a mask prediction mechanism, dual-stage optical flow tracking, and hybrid feature usage, enabling accurate tracking in dynamic environments without GPU support.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes three high-fidelity reconstruction tools that can run on a portable device, such as an iPhone 14 Pro, to enable interactive and immersive holographic experiences with metric-accurate facial reconstructions, overcoming limitations of existing methods that require high-calibrated scenes or huge computational costs.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using monocular depth priors, introducing a novel depth-based ray sampling strategy, coarse-to-fine training, and robust inter-frame point constraint for improved pose estimation and depth geometry.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces a novel SLAM system that integrates sparse visual odometry with 3D Gaussian Splatting, proposing novel techniques for depth estimation, smoothness loss, and scale consistency to achieve accurate pose estimation and map reconstruction from monocular RGB images.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeuRSS, a scalable framework for SSS SLAM that leverages neural rendering for bathymetry estimation and improves positioning accuracy using loop closures, addressing the elevation degeneracy issue in SSS SLAM, and providing high-quality bathymetry estimates.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors introduce NGM-SLAM, a 3D Gaussian Splatting SLAM system that leverages neural radiance field submaps for progressive scene expression, achieving high-quality scene reconstruction, accurate hole filling, and real-time loop closure detection and correction.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a comprehensive survey and analysis of state-of-the-art techniques for utilizing Neural Radiance Fields (NeRF) to enhance the capabilities of autonomous robots, focusing on perception, localization, navigation, and decision-making, and exploring future research directions and integrating NeRF with advanced technologies.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|This paper highlights the importance of place recognition (PR) within the Simultaneous Localization and Mapping (SLAM) 2.0 framework, emphasizing the need for scalable, adaptable, and efficient PR solutions to support real-world autonomous robotics operations.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|The paper proposes a neural mapping framework that anchors lightweight neural fields to the pose graph of a sparse visual SLAM system, allowing for efficient integration of large-scale loop closures and scalable mapping by dynamically extending the scene representation.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The paper proposes a deep learning-based Visual SLAM system that combines deep feature extraction and matching methods to enhance adaptability in challenging scenarios, achieving superior performance in localization accuracy and tracking robustness compared to state-of-the-art SLAM algorithms.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:X-SLAM, a real-time and differentiable dense SLAM system, leverages the complex-step finite difference (CSFD) method to calculate numerical derivatives, enabling the real-time calculation of higher-order differentials and task-aware optimization for improved accuracy and efficiency.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|The authors presented Panoptic-SLAM, an open-source visual SLAM system robust to dynamic environments and unknown objects, which leverages panoptic segmentation to filter dynamic objects during the state estimation process, offering superior accuracy and applicability to real-world scenarios compared to existing methods.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The paper presents a Bayesian particle-based Sum-Product Algorithm (SPA) for cooperative Multipath-based Simultaneous Localization and Mapping (MP-SLAM) in wireless networks. The key contributions are:1. Modeling the exchange of information between different Mobile Terminals (MTs), allowing for cooperative localization and data fusion of Virtual Anchors (VAs) over different MTs.2. Integrating an Inertial Measurement Unit (IMU) as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation.3. Analyzing the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulations.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system that uses Gaussian splatting with a compact representation and efficient on-the-fly optimization, achieving comparable high-quality reconstruction, superior performance in novel view synthesis and camera tracking accuracy, and outperforming state-of-the-art NeRF-based methods in speed and memory.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
