# arxiv-daily
 Automated deployment @ 2024-05-28 20:23:11 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a real-time V-SLAM system that utilizes SIFT features and brute-force matching to overcome the limitations of ORB-SLAM3 in human colonoscopy, achieving significantly longer sub-maps and higher mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandström et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an RGB-only SLAM system with a dense 3D Gaussian map representation that adapts online to keyframe pose and depth updates, leveraging global map and pose optimization, monocular depth estimation, and recurrent dense optical flow for efficient and high-quality surface reconstruction.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeB-SLAM, a neural block-based scalable RGB-D SLAM method for unknown scenes, which uses a divide-and-conquer mapping strategy and adaptive map growth to efficiently represent and track large-scale unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the abstract and introduction:The paper proposes a method to enhance translation accuracy during the initialization stage in Stereo Visual-Inertial SLAM (VI-SLAM) systems. The key contributions are:* Improving translation accuracy through a 3-DOF Bundle Adjustment (BA) independent of rotation estimation.* Updating rotation estimation using IMU measurements and gyroscope bias.* Maintaining runtime speed comparable to ORB-SLAM3, while improving accuracy.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Synergistic Camera and Human Reconstruction (SynCHMR), a novel approach that jointly reconstructs camera trajectories, human meshes, and scene point clouds from monocular videos, addressing the limitations of previous methods by integrating human-aware metric SLAM and scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:This paper presents a pioneering dataset, CoPeD, for real-world multi-robot collaborative perception featuring heterogeneous robots with distinct spatial viewpoints, sensor modalities, and mobilities, providing a comprehensive platform to study high-level scene understanding through collaborative perception in multi-robot settings.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas Vödisch et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper contributes to efficient robot learning for perception and mapping by proposing continual learning approaches for SLAM and panoptic segmentation, label-efficient methods for panoptic segmentation, and a novel camera-LiDAR calibration method, leveraging foundation models and reducing human annotations.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module, which achieves drift-corrected tracking, high-fidelity reconstruction, and a high-level understanding of the environment without requiring depth sensors or RGB-D inputs.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This paper proposes NV-LIO, a normal vector-based LIO framework designed for indoor SLAM, particularly in multifloor environments, which extracts normal vectors from LiDAR scans for enhanced registration and addresses degeneracy and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|The paper proposes a robust long-term robotic mapping system that combines fast and robust ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to enable robust mapping in diverse scenarios and dynamic environments.|[2405.11176v2](http://arxiv.org/abs/2405.11176v2)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep visual features, dual keyframe selection, and 3D Gaussian splatting for high-fidelity scene representation and real-time tracking and mapping.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a lightweight circular convolutional Transformer network (CCTNet) that improves place recognition by capturing structural information in point clouds, facilitating cross-dimensional interaction, and addressing issues of restricted receptive fields and excessive focus on local regions.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes an optimization-based SLAM approach that jointly optimizes robot trajectories and occupancy maps using 2D laser scans and odometry information, demonstrating improved accuracy and uncertainty estimates compared to state-of-the-art techniques.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The paper proposes a novel online, consensus-based method called Incremental Probabilistic Consensus (IPC) that builds on the maximally consistent set of loop closure measurements to handle large numbers of outliers in SLAM, enabling online performances and showcasing a simple and easy-to-implement solution.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|The key contributions are: the development of OverlapMamba, a novel network that represents input range views as sequences, using a stochastic reconstruction approach to build shift state space models, and achieving robust and efficient place recognition through global descriptors, outperforming typical LiDAR and multi-view combination methods in time complexity and speed.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:SceneFactory is a workflow-centric framework for incremental scene modeling that supports a wide range of applications, including multi-view depth estimation, LiDAR completion, and SLAM, with contributions including a novel dual-purpose neural points representation and robust depth estimation models.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes NGD-SLAM, a real-time visual SLAM system that achieves high accuracy and efficiency on a CPU without GPU support by incorporating a mask prediction mechanism and dual-stage optical flow tracking, allowing it to operate at 56 fps in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction and methodology:The paper proposes a method for real-time holographic overlays using LiDAR augmented 3D reconstruction, allowing for high-fidelity facial reconstructions that can be used for various applications such as augmented reality, telepresence, and entertainment.The methodology involves three attempts: Monocular Depth Estimation, LiDAR + TrueDepth, and Template Modeling. Each attempt utilizes different techniques and models to estimate depth, reconstruct faces, and render holographic overlays. The paper's contributions include:1. Real-time depth estimation using Intel MiDaS and Marigold diffusion models.2. Utilizing consumer-grade LiDAR sensors and TrueDepth infrared depth sensors for facial reconstruction.3. Deployment of a custom-trained SRCNN model for upsampling LiDAR depth frames on the Apple Neural Engine.4. Leverage of the iPhone's IMU sensor for camera pose estimation and real-time rendering.5. Development of a modified MICA model for volumetric avatar rendering and real-time facial reconstruction.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that enables training Neural Radiance Fields (NeRF) from unknown camera poses by jointly optimizing learnable parameters of the radiance field and camera poses.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|The key contributions of the proposed framework, according to the abstract and introduction, are: introducing the first SLAM system combining sparse visual odometry with 3D Gaussian Splatting, developing a pre-trained MVS depth estimation network, proposing a geometric depth smooth loss, and proposing the Sparse-Dense Adjustment Ring (SDAR) strategy to ensure scale consistency.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes NeuRSS, a scalable framework for SSS SLAM that leverages neural rendering for bathymetry estimation and improves positioning accuracy using DR and loop closures, ultimately enabling high-quality bathymetric mapping.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces NGM-SLAM, a 3D Gaussian Splatting SLAM system that leverages neural radiance field submaps for progressive scene expression, loop closure detection, and high-quality scene reconstruction, achieving state-of-the-art performance in tracking and mapping.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents a comprehensive survey of Neural Radiance Fields (NeRF) in autonomous robotics, highlighting NeRF's potential for enhancing perception, localization, navigation, and decision-making capabilities, and includes benchmarking and discussion of future research directions at the intersection of NeRF and advanced technologies.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|Here is a summary of the key contributions in a single sentence under 50 words:This paper presents a comprehensive review of place recognition (PR) techniques, highlighting its crucial role in Simultaneous Localization and Mapping (SLAM) 2.0, and provides a novel open-source package aimed at advancing PR development and benchmarking for real-world robotic systems.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a neural mapping framework that anchors lightweight neural fields to a pose graph, enabling efficient incorporation of loop closure constraints and scalability in large-scale SLAM applications, outperforming existing state-of-the-art methods in terms of quality and runtime.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|Here is a single sentence summarizing the paper's abstract and introduction in under 50 words:The paper proposes a versatile deep learning-based SLAM system that combines deep feature extraction and matching methods to improve adaptability in challenging environments, outperforming traditional approaches in terms of localization accuracy and tracking robustness.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:X-SLAM is a real-time, differentiable dense SLAM system that leverages the complex-step finite difference method to efficiently calculate numerical derivatives, enabling task-aware optimization and achieving better accuracy and faster convergence in various SLAM tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Panoptic-SLAM, an open-source visual SLAM system, uses panoptic segmentation to robustly filter dynamic objects from static environments, demonstrating on average a four-time improvement in accuracy compared to state-of-the-art methods in dynamic scenarios.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions from the paper's abstract and introduction are:1. **Cooperative MP-SLAM**: The paper introduces a Bayesian particle-based SPA for cooperative MP-SLAM, enabling data fusion over different observations of map features (VAs) by different MTs and cooperative MT-to-MT measurements using RF signals.2. **Integrating IMU sensors**: The algorithm fully integrates an inertial measurement unit (IMU) as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation, allowing to cope with complex trajectories.3. **Analyzing the impact of VA data fusion and cooperative measurements**: The paper analyzes the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulation.In summary, the paper proposes a cooperative MP-SLAM algorithm that integrates IMU sensors and analyzes the impact of VA data fusion and cooperative measurements in MP-SLAM for different system configurations.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents Real-time Gaussian SLAM (RTG-SLAM), a real-time 3D reconstruction system using Gaussian splatting, which achieves comparable high-quality reconstruction to state-of-the-art NeRF-based SLAM methods but with around twice the speed and half the memory cost.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|

## Computer Science

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements by factorizing 3D Gaussians using structured coordinates and decomposed representations, enabling fast rendering speeds and compact storage while maintaining high-quality image rendering.|[2405.17083v1](http://arxiv.org/abs/2405.17083v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors introduce Pyramidal 3D Gaussian Splatting (PyGS) that achieves high-fidelity scene representations and accelerated rendering performance, overcoming challenges in large-scale scenes through a pyramidal Gaussian structure and dynamic weighting of each level's contribution.|[2405.16829v1](http://arxiv.org/abs/2405.16829v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that leverages latent diffusion models to reconstruct 360 3D scenes from sparse views, achieving multi-view consistency and coherent details by iteratively updating a 3D Gaussian representation with generated pseudo novel views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, and can be generated from imagery and provide a lightweight representation of terrain.* Proposing a novel method for jointly training a height field and radiance field within a NeRF framework, using quantile regression.* Introducing a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.Note that this summary is under 50 words.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes HDR-GS, a novel framework for 3D HDR imaging, which achieves better performance than existing NeRF-based methods on HDR novel view synthesis, while enjoying faster training and inference speeds, and controlling exposure time.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring security, fidelity, and versatility by replacing original coefficients with coupled secured features and using parallel decoders.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper proposes a ray tracing-based approach to address limitations in Neural Radiance Fields (NeRFs) for rendering high-frequency view-dependent appearance, particularly specular reflections, by casting reflection rays into the NeRF geometry rather than querying an expensive neural network for outgoing radiance.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:Neural Directional Encoding (NDE) is proposed to model high-frequency view-dependent appearances of specular objects, using a feature-grid-like encoding of directional information that captures both far-field reflections and near-field interreflections, achieving high-quality rendering and fast evaluation.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|The paper proposes a two-staged pipeline for camera relocalization that normalizes images with varying lighting and shadow conditions, using a hash-encoded NeRF and a re-devised truncated dynamic low-pass filter, and achieves state-of-the-art results on datasets with varying lighting conditions.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|The key contributions of the paper are: a novel feed-forward framework, LDM, that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts, introducing a tensorial SDF representation, and an adaptive conversion strategy to enhance convergence speed.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, which achieves improved quality and compression efficiency by utilizing a compact residual feature grid and sequential feature compression.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|The key contributions from the paper's abstract and introduction are the proposal of DoGaussian, a method that trains 3D Gaussian Splatting (3DGS) in a distributed manner, reducing training time by 6+ times while achieving state-of-the-art rendering quality, and introducing a recursive approach to split scenes into blocks with balanced sizes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Gaussian Time Machine (GTM), a real-time rendering method that models time-dependent attributes of Gaussian primitives, enabling accurate reconstructions of 3D scenes with varying appearances, 100 times faster than NeRF-based methods, and achieving state-of-the-art rendering fidelity on several datasets.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:MOSS introduces a novel framework that combines kinematic information with Gaussian split for motion-aware 3D clothed human reconstruction, improving realism and detail in large-scale motion, and achieving state-of-the-art visual quality in 3D human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The paper presents a novel method that enables an "off-the-shelf" spacecraft pose estimator to be applied to an unknown target by leveraging Neural Radiance Fields (NeRFs) to generate a large and diverse dataset of images that capture the target's appearance under varying illumination conditions, allowing for successful pose estimation from a sparse set of images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents MVSGaussian, a generalizable 3D Gaussian representation approach that achieves real-time rendering with better synthesis quality, fast fine-tuning, and improved view synthesis, leveraging Multi-View Stereo, efficient hybrid Gaussian rendering, and a consistent aggregation strategy.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper reviews and discusses the integration of Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3D-GS) in 6G networks, highlighting their applications, challenges, and potential solutions for efficient representation, transmission, and reconstruction of 3D contents.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings and a fully neural material renderer to estimate 3D shape from photometric stereo images, achieving competitive reconstruction accuracy and robustness to poor normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|The paper's abstract and introduction outline a new approach to generate realistic-looking adversarial objects for autonomous driving systems, building upon previous research on generating transferable adversarial simulation scenarios. The main contributions are:* Proposing a modified gradient-based texture optimization method to discover realistic-looking adversarial objects.* Introducing a "Judge" mechanism that evaluates the realism of adversarial objects produced by the neural object renderer.* Investigating various strategies for optimizing the evaluation process of the Judge, including leveraging cutting-edge vision-language models, fine-tuning open-sourced models, and utilizing traditional image processing techniques.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel NeRF-based ray tracing method, R-NeRF, to accurately model dynamic electromagnetic fields in RIS-enabled environments, capturing complex signal propagation dynamics and enabling efficient RIS deployment for improved communication efficiency.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving high-fidelity reconstruction, accurate real-time tracking, and reduced memory usage.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper surveys the integration of large language models with 3D spatial data, highlighting the advantages of LLMs in processing and understanding 3D data, and presenting a comprehensive overview of methodologies, applications, and challenges in this domain.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|The key contributions of the paper are:* Developing a procedure to convert between implicit representations (Neural Radiance Fields, NeRFs) and explicit representations (Gaussian Splatting, GS) with minor computational cost compared to training from scratch.* Achieving the best of both worlds by combining the advantages of NeRFs (superior PSNR, SSIM, and LPIPS on dissimilar views, and compact representation) and GS (real-time rendering and ability for easily modifying the representation).* Evaluating the quality and efficiency of the approach using existing datasets and real-world views recorded from an ego-centric camera.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|This review discusses the development and implementation principles of Dynamic Neural Radiance Fields (NeRF), a novel approach to 3D reconstruction and representation, with a focus on its potential applications and advantages over traditional static NeRF methods.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|The key contributions from the paper's abstract and introduction are:* The paper proposes a method that synergistically integrates multi-plane representation with a coordinate-based network to improve NeRFs from sparse inputs.* The method uses residual connections between the coordinate-based network and the multi-plane representation to preserve their inherent properties and achieve efficient parameter allocation.* The proposed method is shown to achieve comparable results to explicit encoding with fewer parameters, and outperforms other methods in dynamic NeRFs from sparse inputs.(Note: Please let me know if you would like me to clarify or expand on these points!)|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a plug-and-play inpainting module, dubbed DNR, to enable NeRF-based editing tasks, particularly 3D object removal and inpainting, with improved performance and mutual information.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three approaches to generate real-time 3D facial reconstructions using LiDAR and TrueDepth sensors, leveraging monocular depth estimation, LiDAR and TrueDepth fusion, and template modeling, to achieve high-fidelity facial reconstructions on a portable device like an iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach that jointly optimizes camera poses and radiance fields using depth priors, leveraging a novel depth-based ray sampling strategy, coarse-to-fine training, and robust inter-frame point constraint to improve pose estimation accuracy.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**LIVE: LaTex Interactive Visual Editing**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes LIVE, a novel design method for interactive LaTeX graphic items, enabling the creation of dynamic and informative figures and tables, which can improve the reading experience and add vitality to traditional papers, especially review papers.|[2405.06762v1](http://arxiv.org/abs/2405.06762v1)|null|
|**2024-05-10**|**SketchDream: Sketch-based Text-to-3D Generation and Editing**|Feng-Lin Liu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes SketchDream, a method for sketch-based text-to-3D generation and editing, which integrates sketch and text prompts to generate high-quality 3D objects with detailed control and editing capabilities.|[2405.06461v2](http://arxiv.org/abs/2405.06461v2)|null|
