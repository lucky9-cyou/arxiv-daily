# arxiv-daily
 Automated deployment @ 2024-05-30 08:41:30 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/weiningwei/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/weiningwei/arxiv-daily/blob/main/database/storage).

## Computer Science

### NeRF SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The authors propose a self-supervised pre-training framework for multi-modal perception, called NS-MAE, which leverages masked multi-modal reconstruction in neural radiance fields to learn transferable representations.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines the advantages of NeRF and 3D-GS, introducing a dynamic scene rendering framework based on a hybrid representation of explicit and implicit features.* The contributions include:	+ A hybrid representation that significantly reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.	+ A learnable denoising mask that effectively identifies and removes noise points from the scene, enhancing rendering quality.	+ Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|The paper proposes HFGS, a novel approach for deformable endoscopic reconstruction, addressing under-reconstruction issues from spatial and temporal frequency perspectives, and achieves superior rendering quality in extensive experiments.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose a method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, enabling large deformation, local manipulation, and soft body simulation while maintaining high-quality rendering and having a high tolerance for mesh accuracy.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that significantly reduces storage requirements while maintaining image quality by factorizing coordinates and attributes of 3D Gaussians, allowing for efficient representation of dense scenes with a relatively small number of elements.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents CudaSIFT-SLAM, a V-SLAM system that overcomes tracking losses and deformation challenges in human colonoscopies by using SIFT features instead of ORB and brute-force matching, achieving real-time performance and improved mapping coverage.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper presents Pyramidal 3D Gaussian Splatting (PyGS), a method that addresses the challenges of modeling large-scale scenes by using a hierarchical assembly of Gaussians and dynamic weighting, achieving significant performance leaps and rendering speedup compared to state-of-the-art approaches.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a RGB-only SLAM system using 3D Gaussian Splatting, which combines frame-to-frame tracking with global consistency, online map deformations, and proxy depth estimation to achieve superior or comparable performance to existing methods in tracking, mapping, and rendering accuracy.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper proposes SparseSplat360, a method that uses pre-trained 2D diffusion models to improve the reconstruction of 360 3D scenes from sparse views, achieving multi-view consistency and coherent details through an iterative update strategy and explicit scene representation.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:* Introducing Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model, allowing for simultaneous estimation of depth and color from a 2D image.* A novel method for jointly training a height field and radiance field within a NeRF framework, leveraging quantile regression to extract height information from images.* A path planning algorithm that leverages the continuous and differentiable nature of the height field to perform gradient-based optimization of a cost function for minimizing distance, slope changes, and control effort.Please note that the paper's abstract is around 150 words and the introduction is around 300 words, so there are many more details and key contributions mentioned in the rest of the paper.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The paper proposes NeB-SLAM, an end-to-end neural block-based scalable RGB-D SLAM approach for unknown scenes, which divides the scene into sub-maps (neural blocks) and adaptively grows them during camera tracking to achieve real-time and scalable mapping and tracking.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a new framework for 3D HDR imaging that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, achieving better performance with faster training and inference speeds compared to state-of-the-art NeRF-based methods.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose a steganography framework, GS-Hider, that embeds 3D scenes and images into original 3DGS point cloud files, maintaining high security, fidelity, and capacity, while enabling efficient extraction and rendering of hidden messages.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|The key contributions of this paper are:*Proposing a method to improve translation accuracy during the initial stage of Stereo Visual Inertial SLAM; the method uses a separate 3-DoF Bundle Adjustment to refine translational estimates while keeping roational estimates fixed, enabling more accurate initialization. In contrast to existing methods (ORB-SLAM2 and Stereo-NEC), this approach does so without requiring feature matching of keypoint tracking to recover gyroscope bias. An evaluation on the EuRoC dataset demonstrates the feasibility and effectiveness of this scheme.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The paper's key contributions are a new approach to Neural Radiance Fields (NeRF) that uses ray tracing to render highly specular objects by casting reflection rays from a camera ray, synthesizing consistent reflections, and encoding features into reflected color, outperforming prior methods in view synthesis of scenes with shiny objects.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), a method that combines human-aware metric SLAM and scene-aware SMPL denoising to reconstruct camera trajectories, human meshes, and dense scene point clouds in a common world frame from monocular videos.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|Here is the summary:The paper presents Neural Directional Encoding (NDE), a novel approach to view-dependent appearance encoding of neural radiance fields (NeRF) for rendering specular objects, improving the ability to model high-frequency angular signals and addressing interreflection effects.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a two-staged pipeline that normalizes images with varying lighting conditions for camera relocalization, utilizes a hash-encoded NeRF for fast training and robust pose refinement, and introduces a re-devised truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|The paper presents a pioneering real-world multi-robot collaborative perception dataset, featuring air-ground robot collaboration with distinct spatial viewpoints, complementary robot mobilities, coverage ranges, and sensor modalities.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here are the key contributions from the paper's abstract and introduction:The research aims to minimize human effort in deploying perception-based robotic systems to previously unseen environments, focusing on:* Continual Learning (CL) for unsupervised adaptation of robotic vision systems* Label-Efficient Learning, which reduces the need for human annotationsThe research explores the use of CL and label-efficient learning for tasks such as:* Simultaneous Localization and Mapping (SLAM) and panoptic segmentation* Unsupervised depth estimation and panoptic segmentation* Automatic target-less camera-LiDAR calibration* Collaborative robot mappingBy leveraging vision foundation models and transfer learning, the research aims to reduce the need for human annotations and enable label-efficient learning for robotic tasks.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose LDM, a novel feed-forward framework generating high-fidelity, illumination-decoupled textured meshes from single images or text prompts, featuring a tensorial SDF representation, adaptive Œ≤ adjusting schedule, and gradient-based mesh optimization layer.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is the summary in a single sentence under 50 words:The paper proposes JointRF, an end-to-end joint optimization scheme for dynamic NeRF representation and compression, achieving superior quality and compression efficiency by employing a compact residual feature grid and sequential feature compression subnetwork.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality, overcoming the challenges of high memory usage and long training time for large-scale scenes.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The authors propose MG-SLAM, a monocular Gaussian SLAM system with a language-extended loop closure module that uses 3D Gaussian representation to guide scene geometry estimation and achieve real-time tracking, high-fidelity reconstruction, and a high-level understanding of the environment.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:Gaussian Time Machine (GTM) proposes a real-time rendering method for reconstructing 3D scenes with vastly varying appearances, using a lightweight neural network to model time-dependent Gaussian primitives and decompose color, achieving state-of-the-art rendering quality and efficiency.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces MOSS, a novel framework that employs kinematic information to achieve motion-aware Gaussian split on the human surface, improving the realism of reconstructed surfaces and achieving state-of-the-art visual quality in 3D clothed human synthesis from monocular videos.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper presents a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, using a Neural Radiance Field (NeRF) to represent the target and generate a large training set from sparse spaceborne images.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|The paper presents NV-LIO, a normal vector-based LIO framework for indoor SLAM in multifloor environments, which extracts normal vectors from LiDAR scans to enhance point cloud registration performance and addresses degeneracy situations and loop closure issues.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MVSGaussian, a generalizable 3D Gaussian representation approach that leverages Multi-View Stereo to efficiently reconstruct unseen scenes with real-time rendering and better synthesis quality, outperforming previous generalizable NeRF-based methods.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|Key contributions from the paper's abstract and introduction are:1. The emergence of neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) as two promising 3D representation techniques for 6G networks, enabling photorealistic rendering of complex scenes.2. The importance of efficiently representing, transmitting, and reconstructing 3D contents over wireless networks for immersive communications.3. The need for new interdisciplinary design approaches to tackle the challenges of integrating NeRF and 3D-GS in 6G networks, including joint computation and communication designs, model compression, and rendering acceleration.4. The potential applications of radiance field rendering in various areas, such as wireless sensing, communication, mobile edge computation, and artificial intelligence.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|

### NeRF
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-28**|**Self-supervised Pre-training for Transferable Multi-modal Perception**|Xiaohao Xu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NS-MAE, a self-supervised pre-training paradigm for transferable multi-modal representation learning, which leverages masked multi-modal reconstruction in neural radiance fields to learn robust and generalizable representations for diverse multi-modal and single-modal perception models in autonomous driving.|[2405.17942v1](http://arxiv.org/abs/2405.17942v1)|null|
|**2024-05-28**|**A Refined 3D Gaussian Representation for High-Quality Dynamic Scene Reconstruction**|Bin Zhang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The paper proposes a refined 3D Gaussian representation for high-quality dynamic scene reconstruction.* The method combines the advantages of NeRF and 3D-GS, introducing a hybrid representation of explicit and implicit features.* The key contributions are:	+ A hybrid representation that significantly reduces memory usage while achieving efficient and realistic rendering of dynamic scenes.	+ A learnable denoising mask that effectively identifies and removes noise points, enhancing rendering quality.	+ Static constraints and motion consistency constraints that minimize noise in points during motion, ensuring accurate and efficient rendering of dynamic scenes.Note that the paper's abstract and introduction provide an overview of the problem, the related work, and the proposed solution, but do not explicitly state the key contributions. However, the key contributions can be inferred from the abstract and introduction.|[2405.17891v1](http://arxiv.org/abs/2405.17891v1)|null|
|**2024-05-28**|**HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal High-Frequency Components for Endoscopic Scene Reconstruction**|Haoyu Zhao et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose HFGS, a novel approach for deformable endoscopic reconstruction, addressing under-reconstruction by incorporating deformation fields and spatial/temporal frequency emphasis modules, achieving superior rendering quality in experiments on two widely used benchmarks.|[2405.17872v1](http://arxiv.org/abs/2405.17872v1)|null|
|**2024-05-28**|**Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh**|Xiangjun Gao et.al.|The key contributions from the paper's abstract and introduction are:* A method for manipulating 3D Gaussian Splatting (3DGS) using a triangular mesh, which enables direct transfer of mesh manipulation to 3DGS and maintains high-quality rendering.* A triangle shape-aware Gaussian binding strategy with self-adaptation, which has a high tolerance for mesh accuracy and supports various 3DGS manipulations, including large deformations, local manipulations, and soft body simulations.|[2405.17811v1](http://arxiv.org/abs/2405.17811v1)|null|
|**2024-05-27**|**F-3DGS: Factorized Coordinates and Representations for 3D Gaussian Splatting**|Xiangyu Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose Factorized 3D Gaussian Splatting (F-3DGS), a novel approach that reduces storage requirements by factorizing dense clusters of Gaussians, enabling efficient representation of detailed 3D scenes while maintaining image quality and fast rendering speeds.|[2405.17083v2](http://arxiv.org/abs/2405.17083v2)|null|
|**2024-05-27**|**PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian Splatting**|Zipeng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The authors propose Pyramidal 3D Gaussian Splatting (PyGS), a hierarchical approach that combines 3D Gaussians with NeRF initialization to better model large-scale scenes, achieving faster rendering times and improved fine details.|[2405.16829v2](http://arxiv.org/abs/2405.16829v2)|null|
|**2024-05-26**|**Sp2360: Sparse-view 360 Scene Reconstruction using Cascaded 2D Diffusion Priors**|Soumava Paul et.al.|The paper presents SparseSplat360, a method that uses a cascade of models to improve the reconstruction of a 360-degree scene from sparse views, leveraging pre-trained 2D diffusion models with fine-tuning to fill in missing details and clean novel views.|[2405.16517v1](http://arxiv.org/abs/2405.16517v1)|null|
|**2024-05-24**|**Neural Elevation Models for Terrain Mapping and Path Planning**|Adam Dai et.al.|The key contributions from the paper's abstract and introduction are:1. The introduction of Neural Elevation Models (NEMos), which adapt Neural Radiance Fields to a 2.5D continuous and differentiable terrain model.2. The ability to generate NEMos from imagery, a low-cost data source, and provide a lightweight representation of terrain through an implicit continuous and differentiable height field.3. A novel method for jointly training a height field and radiance field within a NeRF framework using quantile regression.4. The introduction of a path planning algorithm that performs gradient-based optimization of a continuous cost function for minimizing distance, slope changes, and control effort.5. Experimental results demonstrating the ability of NEMOs to generate high-quality reconstructions and produce smoother paths compared to discrete path planning methods.|[2405.15227v1](http://arxiv.org/abs/2405.15227v1)|null|
|**2024-05-24**|**HDR-GS: Efficient High Dynamic Range Novel View Synthesis at 1000x Speed via Gaussian Splatting**|Yuanhao Cai et.al.|Here is a single sentence summary of the paper's key contributions:The paper proposes High Dynamic Range Gaussian Splatting (HDR-GS), a novel framework that efficiently renders novel HDR views and reconstructs LDR images with controllable exposure time, outperforming state-of-the-art NeRF-based methods in terms of performance and inference speed.|[2405.15125v2](http://arxiv.org/abs/2405.15125v2)|[link](https://github.com/caiyuanhao1998/hdr-gs)|
|**2024-05-24**|**GS-Hider: Hiding Messages into 3D Gaussian Splatting**|Xuanyu Zhang et.al.|Here is a summary of the key contributions from the abstract and introduction in a single sentence under 50 words:The authors propose GS-Hider, a steganography framework for 3D Gaussian Splatting (3DGS) that embeds 3D scenes and images into original 3DGS point clouds, ensuring invisible and secure transmission of multimodal messages with exceptional security, robustness, capacity, and flexibility.|[2405.15118v1](http://arxiv.org/abs/2405.15118v1)|null|
|**2024-05-23**|**NeRF-Casting: Improved View-Dependent Appearance with Consistent Reflections**|Dor Verbin et.al.|The key contributions of this paper are a ray tracing-based approach to render detailed specular appearance and consistent reflections in Neural Radiance Fields (NeRFs), which Improves the efficiency of rendering view-dependent appearance and outperforms prior methods for view synthesis of scenes containing shiny objects.|[2405.14871v1](http://arxiv.org/abs/2405.14871v1)|null|
|**2024-05-23**|**Neural Directional Encoding for Efficient and Accurate View-Dependent Appearance Modeling**|Liwen Wu et.al.|The paper introduces Neural Directional Encoding (NDE) for view-dependent appearance encoding in neural radiance fields (NeRF) for rendering specular objects, which accurately models high-frequency angular signals and addresses interreflection effects through a novel spatio-spatial parameterization via cone-tracing.|[2405.14847v1](http://arxiv.org/abs/2405.14847v1)|null|
|**2024-05-23**|**Camera Relocalization in Shadow-free Neural Radiance Fields**|Shiyao Xu et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose a two-staged pipeline that normalizes images with varying lighting and shadow conditions to improve camera relocalization, combining hash-encoded neural radiance fields with a re-designed truncated dynamic low-pass filter and numerical gradient averaging technique.|[2405.14824v1](http://arxiv.org/abs/2405.14824v1)|null|
|**2024-05-23**|**LDM: Large Tensorial SDF Model for Textured Mesh Generation**|Rengan Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel feed-forward framework, called LDM, that generates high-fidelity, illumination-decoupled textured meshes from single images or text prompts within seconds, introducing a tensorial SDF representation and adaptive conversion strategy for smooth geometry and texture production.|[2405.14580v1](http://arxiv.org/abs/2405.14580v1)|null|
|**2024-05-23**|**JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field Representation and Compression**|Zihan Zheng et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The authors propose JointRF, a novel end-to-end learning scheme that jointly optimizes dynamic NeRF representation and compression, achieving superior rate-distortion performance and eliminating the need for multi-stage training.|[2405.14452v1](http://arxiv.org/abs/2405.14452v1)|null|
|**2024-05-22**|**DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction Via Gaussian Consensus**|Yu Chen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes DoGaussian, a distributed training method for 3D Gaussian Splatting (3DGS) that reduces training time by 6+ times and achieves state-of-the-art rendering quality by splitting scenes into blocks and using Alternating Direction Method of Multipliers (ADMM) for consistency.|[2405.13943v1](http://arxiv.org/abs/2405.13943v1)|null|
|**2024-05-22**|**Gaussian Time Machine: A Real-Time Rendering Methodology for Time-Variant Appearances**|Licheng Shen et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The Gaussian Time Machine (GTM) proposes a lightweight neural rendering method for real-time rendering of 3D scenes with vastly varying appearances, achieving state-of-the-art rendering fidelity, 100 times faster than NeRF-based counterparts, and disentangling appearance changes for smooth interpolation.|[2405.13694v1](http://arxiv.org/abs/2405.13694v1)|null|
|**2024-05-21**|**MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video**|Hongsheng Wang et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper introduces Motion-Based 3D Clothed Humans Synthesis (MOSS), an innovative framework that incorporates kinematic information to achieve motion-aware Gaussian splitting and address local occlusions in single-view clothed human reconstruction, resulting in state-of-the-art visual quality and improved efficiency.|[2405.12806v1](http://arxiv.org/abs/2405.12806v1)|null|
|**2024-05-21**|**Leveraging Neural Radiance Fields for Pose Estimation of an Unknown Space Object during Proximity Operations**|Antoine Legrand et.al.|The paper's abstract and introduction describe a novel method for estimating the 6D pose of an unknown target spacecraft relative to a monocular camera, which is crucial for autonomous rendezvous and proximity operations in Active Debris Removal missions. The method leverages a Neural Radiance Field (NeRF) to represent the target spacecraft's appearance and generate a large dataset of diverse images, which is then used to train an off-the-shelf pose estimation network.|[2405.12728v1](http://arxiv.org/abs/2405.12728v1)|null|
|**2024-05-20**|**Fast Generalizable Gaussian Splatting Reconstruction from Multi-View Stereo**|Tianqi Liu et.al.|The paper presents MVSGaussian, a novel generalizable 3D Gaussian representation approach that efficiently reconstructs unseen scenes by leveraging Multi-View Stereo (MVS) encoding, pixel-aligned Gaussian representations, and a hybrid Gaussian rendering approach, achieving real-time rendering with high synthesis quality and fast per-scene optimization.|[2405.12218v1](http://arxiv.org/abs/2405.12218v1)|null|
|**2024-05-20**|**Embracing Radiance Field Rendering in 6G: Over-the-Air Training and Inference with 3D Contents**|Guanlin Wu et.al.|The key contributions of the paper are:* Integrating neural radiance field (NeRF) and 3D Gaussian splatting (3D-GS) techniques with 6G wireless networks to enable efficient representation, transmission, and reconstruction of 3D contents.* Reviewing the basics of radiance field rendering techniques, including their applications and implementation challenges over wireless networks.* Proposing a new semantic communication enabled 3D content transmission design, which exploits radiance field models as semantic knowledge bases to reduce communication overhead for distributed inference.* Discussing the integration of 3D-GS and NeRF with 6G networks, including over-the-air training and rendering, model compression, and rendering acceleration techniques.* Highlighting the importance of joint computation and communication designs to minimize end-to-end latency while preserving the quality of experience (QoE) requirements for immersive communications applications.|[2405.12155v1](http://arxiv.org/abs/2405.12155v1)|null|
|**2024-05-20**|**NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo**|Fotios Logothetis et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in one sentence under 50 words:The paper presents a novel multi-view photometric stereo method that leverages per-pixel intensity renderings, models point light attenuation, and raytraces cast shadows to estimate 3D shape from photometric stereo images, achieving competitive reconstruction accuracy and robustness to poorly estimated normals.|[2405.12057v1](http://arxiv.org/abs/2405.12057v1)|null|
|**2024-05-19**|**Searching Realistic-Looking Adversarial Objects For Autonomous Driving Systems**|Shengxiang Sun et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a method to generate realistic-looking adversarial objects for autonomous driving systems by introducing a "Judge" mechanism to assess and refine the realism of generated objects, and explores various strategies to optimize the evaluation process.|[2405.11629v1](http://arxiv.org/abs/2405.11629v1)|null|
|**2024-05-19**|**R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless Environments**|Huiying Yang et.al.|The authors propose a novel approach using Neural Radiance Fields (NeRF) to model the complex dynamics of electromagnetic fields in Reconfigurable Intelligent Surfaces (RIS)-enabled environments. The method leverages ray tracing to capture the intricate interactions between spatial position and received signal, enabling accurate characterization of signal propagation. Experimental results validate the effectiveness of the approach in predicting signal strengths in different RIS placement scenarios, with a 94.13% error rate using simulation data and a 7.42 dB mean absolute error (MAE) using measured data.|[2405.11541v1](http://arxiv.org/abs/2405.11541v1)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, that integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper provides a comprehensive survey of methodologies enabling large language models to process, understand, and generate 3D data, highlighting their potential to advance spatial comprehension and interaction within embodied AI systems and underscoring the need for novel approaches to harness their full potential.|[2405.10255v1](http://arxiv.org/abs/2405.10255v1)|null|
|**2024-05-15**|**From NeRFs to Gaussian Splats, and Back**|Siming He et.al.|Here are the key contributions from the paper's abstract and introduction:* A procedure to convert between neural radiance fields (NeRFs) and 3D Gaussian splatting (GS) models, which allows for achieving the best of both representations: the superior rendering quality of NeRFs on dissimilar views and the real-time rendering and editability of GS.* The converted models can achieve better results than training each model from scratch, making it more efficient and accurate.* The approach demonstrates the effectiveness of using neural radiance fields for dense scene representations and 3D Gaussian splatting for real-time rendering.Note: The abstract provides a summary of the contributions, and the introduction further elaborates on the idea and motivation behind the procedure.|[2405.09717v1](http://arxiv.org/abs/2405.09717v1)|[link](https://github.com/grasp-lyrl/nerftogsandback)|
|**2024-05-14**|**Dynamic NeRF: A Review**|Jinwei Lin et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This review provides an comprehensive overview of Dynamic Neural Radiance Field (NeRF) developments from 2021 to 2023, describing its principles, techniques, and implementations, and analyzing the challenges and potential applications of this dynamic and editable 3D modeling technology.|[2405.08609v1](http://arxiv.org/abs/2405.08609v1)|null|
|**2024-05-13**|**Synergistic Integration of Coordinate Network and Tensorial Feature for Improving Neural Radiance Fields from Sparse Inputs**|Mingyu Kim et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:* The authors propose a method that synergistically integrates the coordinate-based network with the multi-plane representation to improve NeRFs from sparse inputs.* The multi-plane representation constructs features via projection onto learnable grids and interpolating adjacent vertices, but tends to overuse parameters for low-frequency features due to its bias toward fine details.* The proposed method uses residual connections between the coordinate-based network and the multi-plane representation to maintain their inherent properties, enabling the coordination of low-frequency context and fine-grained details.* The authors demonstrate that the proposed method achieves comparable results to explicit encoding with fewer parameters and outperforms baselines for static and dynamic NeRFs with sparse inputs.(Note: The paper's abstract and introduction are rather lengthy, so this summary focuses on the key points.)|[2405.07857v1](http://arxiv.org/abs/2405.07857v1)|[link](https://github.com/mingyukim87/synergynerf)|
|**2024-05-12**|**Point Resampling and Ray Transformation Aid to Editable NeRF Models**|Zhenyang Li et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes an implicit ray transformation strategy and a differentiable neural-point resampling module to enable editable NeRF modeling for object removal and inpainting tasks, achieving state-of-the-art performance and efficient rendering visualization without extra supervision.|[2405.07306v1](http://arxiv.org/abs/2405.07306v1)|null|

## Robotics

### SLAM
|Publish Date|Title|Authors|Contributions|PDF|Code|
| :---: | :---: | :---: | :---: | :---: | :---: |
|**2024-05-27**|**CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in real human endoscopy**|Richard Elvira et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present CudaSIFT-SLAM, a V-SLAM system that processes human colonoscopies in real-time, combining SIFT features with brute-force matching, achieving a 70% improvement in mapping coverage and successful merges, despite frequent tracking losses.|[2405.16932v1](http://arxiv.org/abs/2405.16932v1)|null|
|**2024-05-26**|**Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians**|Erik Sandstr√∂m et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a first RGB-only SLAM system with a dense 3D Gaussian map representation that globally optimizes tracking and adapts online to loop closure and pose updates, achieving superior or on-par performance with existing methods while yielding small map sizes and fast runtimes.|[2405.16544v1](http://arxiv.org/abs/2405.16544v1)|null|
|**2024-05-24**|**NeB-SLAM: Neural Blocks-based Salable RGB-D SLAM for Unknown Scenes**|Lizhi Bai et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:NeB-SLAM, a neural block-based RGB-D SLAM method, proposes a scalable and adaptive mapping strategy to reconstruct high-quality 3D scenes with efficient memory usage and reasonable hole-filling, outperforming existing approaches in unknown environments.|[2405.15151v1](http://arxiv.org/abs/2405.15151v1)|null|
|**2024-05-23**|**ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial SLAM Initialization**|Han Song et.al.|Here is a summary of the key contributions from the paper's abstract and introduction:The paper proposes a method, called ETA, to enhance translation accuracy during the initialization stage of stereo Visual-Inertial SLAM systems. The method uses a 3-DoF Bundle Adjustment to refine the translation estimate independently, while the rotation estimate is fixed. Additionally, ETA updates the rotation estimate by considering IMU measurements and gyroscope bias, which is not done in ORB-SLAM3. The proposed method aims to achieve performance comparable to Stereo-NEC while maintaining a runtime similar to ORB-SLAM3.|[2405.15082v1](http://arxiv.org/abs/2405.15082v1)|null|
|**2024-05-23**|**Synergistic Global-space Camera and Human Reconstruction from Videos**|Yizhou Zhao et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The paper introduces Synergistic Camera and Human Reconstruction (SynCHMR), which jointly reconstructs camera trajectories, human meshes, and scene point clouds in a common world frame from monocular videos, addressing depth, scale, and dynamic ambiguities by combining human-aware metric SLAM with scene-aware SMPL denoising.|[2405.14855v1](http://arxiv.org/abs/2405.14855v1)|null|
|**2024-05-23**|**CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive Dataset in Real-World Environments**|Yang Zhou et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present a comprehensive real-world multi-robot collaborative perception dataset, featuring raw sensor inputs, pose estimation, and optional high-level perception annotation, to facilitate research in multi-robot collaborative perception and unlock the potential for high-level scene understanding.|[2405.14731v1](http://arxiv.org/abs/2405.14731v1)|[link](https://github.com/arplaboratory/coped)|
|**2024-05-23**|**Efficient Robot Learning for Perception and Mapping**|Niclas V√∂disch et.al.|Here is a summary of the paper's abstract and introduction in one sentence under 50 words:The paper proposes a framework for efficient and label-efficient robot learning, using concepts like continual learning and label-efficient learning to enable robots to adapt to new environments and tasks with minimal human annotations.|[2405.14688v1](http://arxiv.org/abs/2405.14688v1)|null|
|**2024-05-22**|**Monocular Gaussian SLAM with Language Extended Loop Closure**|Tian Lan et.al.|The paper introduces MG-SLAM, a monocular Gaussian SLAM system that uses a language-extended loop closure module to perform drift-corrected tracking and high-fidelity reconstruction, achieving a high-level understanding of the environment, and surpassing some existing RGB-D methods.|[2405.13748v1](http://arxiv.org/abs/2405.13748v1)|null|
|**2024-05-21**|**NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM in Multifloor Environments**|Dongha Chung et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors present NV-LIO, a normal vector-based LiDAR-inertial odometry framework for simultaneous localization and mapping in indoor environments, which addresses challenges in confined spaces by exploiting normal vectors, detecting degeneracy, and ensuring loop closure.|[2405.12563v2](http://arxiv.org/abs/2405.12563v2)|[link](https://github.com/dhchung/nv_lio)|
|**2024-05-18**|**Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation**|Hyungtae Lim et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a robust long-term robotic mapping system, which includes ground segmentation, outlier-robust registration, hierarchical multi-session SLAM, and instance-aware static map building to enable robust mapping in diverse scenarios and changing environments.|[2405.11176v3](http://arxiv.org/abs/2405.11176v3)|null|
|**2024-05-18**|**MotionGS : Compact Gaussian Splatting SLAM by Motion Filter**|Xinli Guo et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel 3DGS-based SLAM approach, MotionGS, which integrates deep feature extraction, dual keyframe selection, and 3D Gaussian splatting, achieving accurate real-time tracking, high-fidelity reconstruction, and reduced memory consumption.|[2405.11129v1](http://arxiv.org/abs/2405.11129v1)|[link](https://github.com/antonio521/motiongs)|
|**2024-05-17**|**CCTNet: A Circular Convolutional Transformer Network for LiDAR-based Place Recognition Handling Movable Objects Occlusion**|Gang Wang et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors propose a lightweight circular convolutional Transformer network (CCTNet) to boost performance in place recognition by capturing structural information in point clouds and facilitating cross-dimensional interaction, achieving superior results on KITTI and Ford Campus datasets.|[2405.10793v2](http://arxiv.org/abs/2405.10793v2)|null|
|**2024-05-17**|**Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous Occupancy Map**|Liang Zhao et.al.|The paper proposes an optimization-based SLAM approach that simultaneously optimizes robot trajectories and occupancy maps using 2D laser scans and odometry, with a key novelty of optimizing robot poses and occupancy maps together, resulting in more accurate estimates compared to existing methods.|[2405.10743v1](http://arxiv.org/abs/2405.10743v1)|null|
|**2024-05-14**|**IPC: Incremental Probabilistic Consensus-based Consistent Set Maximization for SLAM Backends**|Emilio Olivastri et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The paper proposes IPC, a consensus-based method that incrementally builds a maximally consistent set of loop closure measurements, applicable for online performances, and provides an open-source implementation, which competes with or outperforms state-of-the-art methods in handling outliers.|[2405.08503v1](http://arxiv.org/abs/2405.08503v1)|[link](https://github.com/EmilioOlivastri/IPC)|
|**2024-05-13**|**OverlapMamba: Novel Shift State Space Model for LiDAR-based Place Recognition**|Qiuchi Xiang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes OverlapMamba, a novel place recognition method that utilizes 3D LiDAR range views (RVs) as input, employing a stochastic reconstruction approach to build shift state space models and achieving robustness in detecting loop closures and place recognition tasks.|[2405.07966v1](http://arxiv.org/abs/2405.07966v1)|[link](https://github.com/scnu-rislab/overlapmamba)|
|**2024-05-13**|**SceneFactory: A Workflow-centric and Unified Framework for Incremental Scene Modeling**|Yijun Yuan et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The authors present SceneFactory, a workflow-centric framework that supports a wide range of scene modeling applications, including multi-view depth estimation, LiDAR completion, and 3D reconstruction, by breaking down the pipeline into four building blocks.|[2405.07847v1](http://arxiv.org/abs/2405.07847v1)|null|
|**2024-05-12**|**NGD-SLAM: Towards Real-Time SLAM for Dynamic Environments without GPU**|Yuhao Zhang et.al.|Here is a summary of the key contributions in a single sentence under 50 words:The paper proposes a novel real-time visual SLAM system, NGD-SLAM, that achieves 56 fps on a single CPU without GPU support, combining a mask prediction mechanism, dual-stage optical flow tracking, and hybrid feature usage for efficient and accurate tracking in dynamic environments.|[2405.07392v1](http://arxiv.org/abs/2405.07392v1)|[link](https://github.com/yuhaozhang7/NGD-SLAM)|
|**2024-05-12**|**Hologram: Realtime Holographic Overlays via LiDAR Augmented Reconstruction**|Ekansh Agrawal et.al.|Here is a summary of the paper's abstract and introduction in a single sentence under 50 words:The paper proposes three approaches to real-time 3D facial reconstruction using LiDAR augmented reconstruction, monocular depth estimation, LiDAR + TrueDepth fusion, and template modeling, aiming to achieve high-fidelity, metric-accurate, and portable reconstructions on a single device like an iPhone 14 Pro.|[2405.07178v1](http://arxiv.org/abs/2405.07178v1)|null|
|**2024-05-11**|**TD-NeRF: Novel Truncated Depth Prior for Joint Camera Pose and Neural Radiance Field Optimization**|Zhen Tan et.al.|Here is a summary of the key contributions mentioned in the paper's abstract and introduction in a single sentence under 50 words:The paper proposes Truncated Depth NeRF (TD-NeRF), a novel approach for training Neural Radiance Fields from unknown camera poses, utilizing monocular depth priors with a novel depth-based ray sampling strategy, coarse-to-fine training, and a robust inter-frame point constraint.|[2405.07027v1](http://arxiv.org/abs/2405.07027v1)|[link](https://github.com/nubot-nudt/td-nerf)|
|**2024-05-10**|**MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization**|Pengcheng Zhu et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose MGS-SLAM, a novel monocular Gaussian Splatting-based SLAM system that integrates sparse visual odometry with Gaussian Splatting, utilizing a pre-trained MVS depth estimation network and eliminating the need for depth maps, while achieving state-of-the-art performance.|[2405.06241v1](http://arxiv.org/abs/2405.06241v1)|null|
|**2024-05-09**|**NeuRSS: Enhancing AUV Localization and Bathymetric Mapping with Neural Rendering for Sidescan SLAM**|Yiping Xie et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:The authors propose NeuRSS, a scalable framework for sidescan sonar (SSS) SLAM that addresses elevation degeneracy by incorporating bathymetry estimation using neural rendering, enabling high-quality bathymetry and improved autonomous underwater vehicle (AUV) positioning over large timescales.|[2405.05807v1](http://arxiv.org/abs/2405.05807v1)|null|
|**2024-05-09**|**NGM-SLAM: Gaussian Splatting SLAM with Radiance Field Submap**|Mingrui Li et.al.|Here is a summary of the paper's key contributions in a single sentence under 50 words:The authors propose NGM-SLAM, a novel 3DGS-based SLAM system that uses neural radiance field submaps for progressive scene expression, achieving high-quality mapping, online loop closure detection, and state-of-the-art performance in tracking and mapping.|[2405.05702v5](http://arxiv.org/abs/2405.05702v5)|null|
|**2024-05-09**|**Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview**|Yuhang Ming et.al.|Here is a summary of the key contributions from the paper's abstract and introduction in a single sentence under 50 words:This comprehensive survey analyzes the use of Neural Radiance Fields (NeRF) in enhancing the capabilities of autonomous robots, focusing on perception, localization, navigation, and decision-making modules, and explores future research directions, including integration with advanced technologies.|[2405.05526v1](http://arxiv.org/abs/2405.05526v1)|null|
|**2024-05-08**|**General Place Recognition Survey: Towards Real-World Autonomy**|Peng Yin et.al.|The paper aims to bridge the gap in place recognition (PR) methods that support real-world robotic systems, highlighting the crucial role of PR within the Simultaneous Localization and Mapping (SLAM) 2.0 framework, and providing a comprehensive review of current advancements and challenges.|[2405.04812v1](http://arxiv.org/abs/2405.04812v1)|[link](https://github.com/MetaSLAM/GPRS)|
|**2024-05-06**|**Neural Graph Mapping for Dense SLAM with Efficient Loop Closure**|Leonard Bruns et.al.|This framework proposes a neural mapping framework that anchors lightweight neural fields to a sparse visual SLAM pose graph, addressing limitations in scalability and ability to integrate large-scale loop closures.|[2405.03633v1](http://arxiv.org/abs/2405.03633v1)|null|
|**2024-05-06**|**SL-SLAM: A robust visual-inertial SLAM based deep feature extraction and matching**|Zhang Xiao et.al.|The paper's key contributions are a novel hybrid visual SLAM system that combines deep feature extraction and deep matching methods, demonstrating improved adaptability and performance in challenging environments, and providing a comprehensive review of combining visual SLAM with deep learning techniques for the benefit of the research community.|[2405.03413v2](http://arxiv.org/abs/2405.03413v2)|null|
|**2024-05-03**|**X-SLAM: Scalable Dense SLAM for Task-aware Optimization using CSFD**|Zhexi Peng et.al.|The key contributions of the paper are: introducing X-SLAM, a real-time and differentiable dense SLAM system that leverages the complex-step finite difference (CSFD) method for efficient calculation of numerical derivatives, and demonstrating its effectiveness in end-to-end optimization frameworks for camera relocalization and active robotic scanning tasks.|[2405.02187v1](http://arxiv.org/abs/2405.02187v1)|null|
|**2024-05-03**|**Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation**|Gabriel Fischer Abati et.al.|The authors presented Panoptic-SLAM, an open-source visual SLAM system robust to dynamic environments, which uses panoptic segmentation to filter dynamic objects from the scene during state estimation, outperforming state-of-the-art systems like PVO and DynaSLAM in accuracy.|[2405.02177v1](http://arxiv.org/abs/2405.02177v1)|[link](https://github.com/iit-dlslab/panoptic-slam)|
|**2024-05-03**|**Multipath-based SLAM with Cooperation and Map Fusion in MIMO Systems**|Erik Leitinger et.al.|The key contributions of the paper are:1. **Cooperative MP-SLAM**: The authors propose a Bayesian particle-based Sum-Product Algorithm (SPA) for cooperative MP-SLAM, which enables data fusion over different observations of map features (VAs) by different MTs and cooperative MT-to-MT measurements using RF signals.2. **Inertial Measurement Unit (IMU) integration**: The authors fully integrate an IMU as an additional sensor for each MT, unlocking additional information for orientation and state transition estimation, allowing to cope with complex trajectories.3. **Analysis of VA data fusion and cooperative measurements**: The authors analyze the impact of VA data fusion and cooperative measurements in MP-SLAM for multiple input multiple output (MIMO) and single input multiple output (SIMO) systems using numerical simulation.|[2405.02126v2](http://arxiv.org/abs/2405.02126v2)|null|
|**2024-04-30**|**RTG-SLAM: Real-time 3D Reconstruction at Scale using Gaussian Splatting**|Zhexi Peng et.al.|Here is a single sentence summarizing the key contributions from the paper's abstract and introduction:The Real-time Gaussian SLAM (RTG-SLAM) system achieves real-time 3D reconstruction of large-scale environments using Gaussian splatting, outperforming state-of-the-art NeRF-based SLAM methods in terms of speed, memory, realism of novel view synthesis, and camera tracking accuracy.|[2404.19706v3](http://arxiv.org/abs/2404.19706v3)|null|
